{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    " \n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    num = 0\n",
    "    for filename in filenames:\n",
    "        num += 1\n",
    "        #print(os.path.join(dirname, filename))\n",
    "    print(dirname,num)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    DataSet库说明-\n",
    "    读取文件路径-img_dir\n",
    "    读取50,000张图片\n",
    "    输出为 X, Y\n",
    "    X是（10000，4,56,56） 1000表示样本数 4表示通道数（包含四个emcal hcal trkn trkp)\n",
    "    Y是（10000,56,56）\n",
    "\"\"\"\n",
    "# 导入相关库\n",
    "import tifffile as tiff #读取tiff文件格式\n",
    "from PIL import Image #图片处理\n",
    "#与torch 相关的库\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import imageio \n",
    "\n",
    "class MaxMinNormalizeGlobalPerChannel:\n",
    "    \"\"\"\n",
    "    针对 (Batch, Channel, Width, Height) 的张量，\n",
    "    在所有 Batch 中对每个通道整体进行最大最小归一化。\n",
    "    \"\"\"\n",
    "    def __call__(self, tensor):\n",
    "        # 确保输入是 (Batch, Channel, Width, Height) 的张量\n",
    "        assert tensor.dim() == 4, \"Input tensor must have 4 dimensions: (Batch, Channel, Width, Height).\"\n",
    "        \n",
    "        # 计算每个通道在所有 Batch 上的全局最小值和最大值\n",
    "        # 结果是 (Channel, 1, 1)\n",
    "        min_vals = tensor.amin(dim=(0, 2, 3), keepdim=True)  # 在 Batch、Width、Height 维度求最小值\n",
    "        max_vals = tensor.amax(dim=(0, 2, 3), keepdim=True)  # 在 Batch、Width、Height 维度求最大值\n",
    "        \n",
    "        # 最大最小归一化公式\n",
    "        tensor = (tensor - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "\n",
    "#创建数据集\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,img_dir,group_size=10000,size_in=10000,transform=None,\n",
    "                split_shuffle = True,splition = True):\n",
    "        self.img_dir=img_dir\n",
    "        self.images=os.listdir(img_dir)\n",
    "        self.transform=transform\n",
    "        self.all_imgs=[]\n",
    "        self.emcal=[]\n",
    "        self.hcal=[]\n",
    "        self.trkn=[]\n",
    "        self.trkp=[]\n",
    "        self.truth=[]\n",
    "        self.group_size=group_size\n",
    "        self.size_in=size_in\n",
    "        self.splition=splition\n",
    "        self.split_shuffle = split_shuffle\n",
    "        self.load_images()\n",
    "        #self.normalize()\n",
    "    \n",
    "    def load_images(self):\n",
    "        all_imgs=[]\n",
    "        to_pil = transforms.ToPILImage()\n",
    "        prefixes = ['emcal', 'hcal', 'trkn', 'trkp', 'truth']\n",
    "        for prefix in prefixes:\n",
    "            for i in range(self.size_in):\n",
    "                filename = f\"{prefix}_{str(i)}.tiff\"\n",
    "                img_path = img_path=os.path.join(self.img_dir, filename)\n",
    "                #print(img_path)\n",
    "                img_array=tiff.imread(img_path)\n",
    "                img=Image.fromarray(img_array)\n",
    "                img_tensor=transform(img)\n",
    "                all_imgs.append(img_tensor)\n",
    "        self.emcal=all_imgs[:self.size_in]\n",
    "        self.hcal=all_imgs[self.group_size:self.group_size+self.size_in]\n",
    "        self.trkn=all_imgs[2*self.group_size:2*self.group_size+self.size_in]\n",
    "        self.trkp=all_imgs[3*self.group_size:3*self.group_size+self.size_in]\n",
    "        self.truth=all_imgs[4*self.group_size:4*self.group_size+self.size_in]\n",
    "        \n",
    "        self.X=[]\n",
    "        self.Y=[]\n",
    "        picture = np.ndarray([])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformation = self.transform\n",
    "            print('transformation is not None')\n",
    "        else:\n",
    "            transformation = lambda x: x\n",
    "            print('transformation is None')\n",
    "        \n",
    "        for emcal, hcal, trkn, trkp in zip(self.emcal,self.hcal,self.trkn, self.trkp):\n",
    "            combined_features=torch.stack((emcal,hcal,trkn,trkp),dim=0).reshape(-1,56,56)\n",
    "            self.X.append(combined_features)\n",
    "        \n",
    "        self.X=torch.stack(self.X).squeeze()\n",
    "        self.X=transformation(self.X)\n",
    "        self.Y=torch.stack(self.truth)\n",
    "        self.Y=transformation(self.Y)\n",
    "        \n",
    "        N = self.X.size(0)\n",
    "        train_size = int(0.8 * N)\n",
    "        val_size = int(0.1 * N)\n",
    "        if self.split_shuffle:\n",
    "            indices = torch.randperm(N)\n",
    "\n",
    "        else:\n",
    "            indices = torch.arange(N)\n",
    "            # 按照比例划分索引\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size:train_size + val_size]\n",
    "        test_indices = indices[train_size + val_size:]\n",
    "        if self.splition == True:\n",
    "            # 根据索引划分数据集\n",
    "            self.train_X = self.X[train_indices]\n",
    "            self.train_Y = self.Y[train_indices]\n",
    "            self.val_X = self.X[val_indices]\n",
    "            self.val_Y = self.Y[val_indices]\n",
    "            self.test_X = self.X[test_indices]\n",
    "            self.test_Y = self.Y[test_indices]\n",
    "            # 释放内存\n",
    "            del self.X\n",
    "            del self.Y\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # 数据预处理后期添加\n",
    "])\n",
    "\n",
    "    \n",
    "class dataset_2(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels, kernel_size=1) #H*W->H*W\n",
    "        self.key = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.size()\n",
    "        # 生成查询、键、值\n",
    "        queries = self.query(x).view(batch_size, C, -1) # (B, C, H*W)\n",
    "        keys = self.key(x).view(batch_size, C, -1) # (B, C, H*W)\n",
    "        values = self.value(x).view(batch_size, C, -1) # (B, C, H*W)\n",
    "\n",
    "        # 计算自注意力\n",
    "        attention_scores = torch.bmm(queries.permute(0, 2, 1), keys) # (B, H*W, H*W)\n",
    "        attention_scores = self.softmax(attention_scores)\n",
    "\n",
    "        out = torch.bmm(values, attention_scores.permute(0, 2, 1)) # (B, C, H*W)\n",
    "        return out.view(batch_size, C, H, W) #不改变形状\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock,self).__init__()\n",
    "        self.fc1=nn.Linear(channels,channels//reduction,bias=False)\n",
    "        self.fc2=nn.Linear(channels//reduction,channels,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        b, c,_,_=x.size()\n",
    "        y = F.adaptive_avg_pool2d(x, (1, 1)).view(b, c) # Squeeze\n",
    "        y=F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1) # Excitation - 2nd layer\n",
    "        return x * y.expand_as(x) # Scale\n",
    "\n",
    "class DownSampling(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(DownSampling, self).__init__()\n",
    "        self.Down = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=2, stride=2),  # 2x2卷积，步幅2会让特征尺寸减半\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Down(x)\n",
    "#定义上采样层\n",
    "class UpSampling(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(UpSampling, self).__init__()\n",
    "        self.Up = nn.Conv2d(C_in, C_out, kernel_size=1)  # 改变通道数的卷积\n",
    "\n",
    "    def forward(self, x, r):\n",
    "        up = F.interpolate(x, scale_factor=2, mode='nearest')  # 使用最近邻插值进行上采样\n",
    "        x = self.Up(up)  # 改变输出通道数\n",
    "        x = torch.cat([x, r], dim=1)  # 进行跳跃连接，拼接特征\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv_UNet(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(Conv_UNet, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=3, stride=1, padding=1),  # 3x3卷积，padding=1保持尺寸不变\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class DownSampling_UNet(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(DownSampling_UNet, self).__init__()\n",
    "        self.Down = nn.Sequential(\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=2, stride=2),  # 2x2卷积，步幅2会让特征尺寸减半\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Down(x)\n",
    "\n",
    "class UpSampling_UNet(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(UpSampling_UNet, self).__init__()\n",
    "        self.Up = nn.Conv2d(C_in, C_out, kernel_size=1)  # 改变通道数的卷积\n",
    "\n",
    "    def forward(self, x, r):\n",
    "        up = F.interpolate(x, scale_factor=2, mode='nearest')  # 使用最近邻插值进行上采样\n",
    "        x = self.Up(up)  # 改变输出通道数\n",
    "        x = torch.cat([x, r], dim=1)  # 进行跳跃连接，拼接特征\n",
    "        return x\n",
    "        \n",
    "\n",
    "'''''''''\n",
    "CNN_90k:\n",
    "PS D:\\LECINSUMMER\\project4> & D:/anaconda/python.exe d:/LECINSUMMER/project4/demo.py\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]           1,616\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "              ReLU-3           [-1, 16, 56, 56]               0\n",
    "            Conv2d-4           [-1, 32, 56, 56]          12,832\n",
    "       BatchNorm2d-5           [-1, 32, 56, 56]              64\n",
    "              ReLU-6           [-1, 32, 56, 56]               0\n",
    "            Conv2d-7           [-1, 64, 56, 56]          51,264\n",
    "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
    "              ReLU-9           [-1, 64, 56, 56]               0\n",
    "           Conv2d-10           [-1, 16, 56, 56]          25,616\n",
    "           Conv2d-11            [-1, 1, 56, 56]             401\n",
    "          Sigmoid-12            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 91,953\n",
    "Trainable params: 91,953\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 8.47\n",
    "Params size (MB): 0.35\n",
    "Estimated Total Size (MB): 8.87\n",
    "----------------------------------------------------------------\n",
    "None\n",
    "'''''''''\n",
    "\n",
    "class CNN_90k(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_90k,self).__init__()\n",
    "\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Conv2d(64, 16, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(16, 1, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): #x=torch.cat((emcal,hcal,trkn,trkp),dim=1) (4,56,56)\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "'''''''''''''''''''''\n",
    "CNNwithSEBlock_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]           1,616\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "              ReLU-3           [-1, 16, 56, 56]               0\n",
    "            Conv2d-4           [-1, 32, 56, 56]          12,832\n",
    "       BatchNorm2d-5           [-1, 32, 56, 56]              64\n",
    "              ReLU-6           [-1, 32, 56, 56]               0\n",
    "            Conv2d-7           [-1, 64, 56, 56]          51,264\n",
    "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
    "              ReLU-9           [-1, 64, 56, 56]               0\n",
    "           Linear-10                    [-1, 4]             256\n",
    "           Linear-11                   [-1, 64]             256\n",
    "          SEBlock-12           [-1, 64, 56, 56]               0\n",
    "           Conv2d-13           [-1, 16, 56, 56]          25,616\n",
    "           Conv2d-14            [-1, 1, 56, 56]             401\n",
    "          Sigmoid-15            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 92,465\n",
    "Trainable params: 92,465\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 10.00\n",
    "Params size (MB): 0.35\n",
    "Estimated Total Size (MB): 10.40\n",
    "----------------------------------------------------------------\n",
    "'''''''''''''''''''''''\n",
    "\n",
    "\n",
    "\n",
    "class CNNwithSEBlock_90k(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNwithSEBlock_90k,self).__init__()\n",
    "\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.se1=SEBlock(64)\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Conv2d(64, 16, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(16, 1, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): #x=torch.cat((emcal,hcal,trkn,trkp),dim=1) (4,56,56)\n",
    "        x=self.encoder(x)\n",
    "        x=self.se1(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''''''''''\n",
    "CNNwithSelfattention_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]           1,616\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "              ReLU-3           [-1, 16, 56, 56]               0\n",
    "            Conv2d-4           [-1, 32, 56, 56]          12,832\n",
    "       BatchNorm2d-5           [-1, 32, 56, 56]              64\n",
    "              ReLU-6           [-1, 32, 56, 56]               0\n",
    "            Conv2d-7           [-1, 64, 56, 56]          51,264\n",
    "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
    "              ReLU-9           [-1, 64, 56, 56]               0\n",
    "           Conv2d-10           [-1, 64, 56, 56]           4,160\n",
    "           Conv2d-11           [-1, 64, 56, 56]           4,160\n",
    "           Conv2d-12           [-1, 64, 56, 56]           4,160\n",
    "          Softmax-13           [-1, 3136, 3136]               0\n",
    "    SelfAttention-14           [-1, 64, 56, 56]               0\n",
    "           Conv2d-15           [-1, 16, 56, 56]          25,616\n",
    "           Conv2d-16            [-1, 1, 56, 56]             401\n",
    "          Sigmoid-17            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 104,433\n",
    "Trainable params: 104,433\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 89.63\n",
    "Params size (MB): 0.40\n",
    "Estimated Total Size (MB): 90.07\n",
    "----------------------------------------------------------------\n",
    "'''''''''''\n",
    "\n",
    "class CNNwithSelfattention_90k(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNwithSelfattention_90k,self).__init__()\n",
    "\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.attention = SelfAttention(64)\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Conv2d(64, 16, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(16, 1, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): #x=torch.cat((emcal,hcal,trkn,trkp),dim=1) (4,56,56)\n",
    "        x=self.encoder(x)\n",
    "        x=self.attention(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "\n",
    "''''''''''\n",
    "CNN3D_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv3d-1         [-1, 2, 1, 56, 56]              56\n",
    "            Conv3d-2         [-1, 2, 1, 56, 56]             152\n",
    "            Conv3d-3         [-1, 2, 1, 56, 56]             296\n",
    "            Conv3d-4         [-1, 2, 1, 56, 56]              56\n",
    "            Conv3d-5         [-1, 2, 1, 56, 56]             152\n",
    "            Conv3d-6         [-1, 2, 1, 56, 56]             296\n",
    "            Conv2d-7           [-1, 32, 56, 56]           9,632\n",
    "       BatchNorm2d-8           [-1, 32, 56, 56]              64\n",
    "              ReLU-9           [-1, 32, 56, 56]               0\n",
    "           Conv2d-10           [-1, 64, 56, 56]          51,264\n",
    "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
    "             ReLU-12           [-1, 64, 56, 56]               0\n",
    "           Conv2d-13           [-1, 16, 56, 56]          25,616\n",
    "           Conv2d-14            [-1, 1, 56, 56]             401\n",
    "          Sigmoid-15            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 88,113\n",
    "Trainable params: 88,113\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "class CNN3D_90k(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D_90k,self).__init__()\n",
    "        self.conv3x3x3 = nn.Conv3d(1, 2, kernel_size=3, padding=(0,1,1))\n",
    "        self.conv3x5x5 = nn.Conv3d(1, 2, kernel_size=(3,5,5), padding=(0,2,2))\n",
    "        self.conv3x7x7 = nn.Conv3d(1, 2, kernel_size=(3,7,7), padding=(0,3,3))\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(12, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Conv2d(64, 16, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(16, 1, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): #x=torch.cat((emcal,hcal,trkn,trkp),dim=1) (4,56,56)\n",
    "        x = x.unsqueeze(1)\n",
    "        x_e_h_n = x[:,:,:3,:,:]\n",
    "        x_e_h_p = x[:,:,[0,1,3],:,:]\n",
    "        x2 = self.conv3x3x3(x_e_h_n)\n",
    "        x3 = self.conv3x5x5(x_e_h_n)\n",
    "        x4 = self.conv3x7x7(x_e_h_n)\n",
    "        x5 = self.conv3x3x3(x_e_h_p)\n",
    "        x6 = self.conv3x5x5(x_e_h_p)\n",
    "        x7 = self.conv3x7x7(x_e_h_p)\n",
    "        x = torch.cat((x2,x3,x4,x5,x6,x7),dim=1).view(-1,12,56,56)\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "\n",
    "'''''''''''\n",
    "UNet_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]             592\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "           Dropout-3           [-1, 16, 56, 56]               0\n",
    "         LeakyReLU-4           [-1, 16, 56, 56]               0\n",
    "         Conv_UNet-5           [-1, 16, 56, 56]               0\n",
    "            Conv2d-6           [-1, 32, 28, 28]           2,080\n",
    "         LeakyReLU-7           [-1, 32, 28, 28]               0\n",
    " DownSampling_UNet-8           [-1, 32, 28, 28]               0\n",
    "            Conv2d-9           [-1, 32, 28, 28]           9,248\n",
    "      BatchNorm2d-10           [-1, 32, 28, 28]              64\n",
    "          Dropout-11           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-12           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-13           [-1, 32, 28, 28]               0\n",
    "           Conv2d-14           [-1, 64, 14, 14]           8,256\n",
    "        LeakyReLU-15           [-1, 64, 14, 14]               0\n",
    "DownSampling_UNet-16           [-1, 64, 14, 14]               0\n",
    "           Conv2d-17           [-1, 64, 14, 14]          36,928\n",
    "      BatchNorm2d-18           [-1, 64, 14, 14]             128\n",
    "          Dropout-19           [-1, 64, 14, 14]               0\n",
    "        LeakyReLU-20           [-1, 64, 14, 14]               0\n",
    "        Conv_UNet-21           [-1, 64, 14, 14]               0\n",
    "           Conv2d-22           [-1, 32, 28, 28]           2,080\n",
    "  UpSampling_UNet-23           [-1, 64, 28, 28]               0\n",
    "           Conv2d-24           [-1, 32, 28, 28]          18,464\n",
    "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
    "          Dropout-26           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-27           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-28           [-1, 32, 28, 28]               0\n",
    "           Conv2d-29           [-1, 16, 56, 56]             528\n",
    "  UpSampling_UNet-30           [-1, 32, 56, 56]               0\n",
    "           Conv2d-31            [-1, 8, 56, 56]           2,312\n",
    "      BatchNorm2d-32            [-1, 8, 56, 56]              16\n",
    "          Dropout-33            [-1, 8, 56, 56]               0\n",
    "        LeakyReLU-34            [-1, 8, 56, 56]               0\n",
    "        Conv_UNet-35            [-1, 8, 56, 56]               0\n",
    "           Conv2d-36            [-1, 1, 56, 56]              73\n",
    "          Sigmoid-37            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 80,865\n",
    "Trainable params: 80,865\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 7.90\n",
    "Params size (MB): 0.31\n",
    "Estimated Total Size (MB): 8.25\n",
    "----------------------------------------------------------------\n",
    "'''''''''''\n",
    "\n",
    "class UNet_90k(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(UNet_90k, self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.C1 = Conv_UNet(self.in_channels, 16)\n",
    "        self.D1 = DownSampling_UNet(16, 32)\n",
    "        self.C2 = Conv_UNet(32, 32)\n",
    "        self.D2 = DownSampling_UNet(32, 64)\n",
    "        self.C3 = Conv_UNet(64, 64)\n",
    "        self.U1 = UpSampling_UNet(64, 32)\n",
    "        self.C4 = Conv_UNet(64, 32)\n",
    "        self.U2 = UpSampling_UNet(32, 16)\n",
    "        self.C5 = Conv_UNet(32, 8)\n",
    "        self.pred = nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        R1 = self.C1(x)\n",
    "        R2 = self.C2(self.D1(R1))\n",
    "        R3 = self.C3(self.D2(R2))\n",
    "        up1 = self.C4(self.U1(R3, R2))\n",
    "        c = self.C5(self.U2(up1,R1))\n",
    "        return self.sigmoid(self.pred(c))\n",
    "\n",
    "'''''''''''\n",
    "UnetwithSEBlock_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]             592\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "           Dropout-3           [-1, 16, 56, 56]               0\n",
    "         LeakyReLU-4           [-1, 16, 56, 56]               0\n",
    "         Conv_UNet-5           [-1, 16, 56, 56]               0\n",
    "            Conv2d-6           [-1, 32, 28, 28]           2,080\n",
    "         LeakyReLU-7           [-1, 32, 28, 28]               0\n",
    " DownSampling_UNet-8           [-1, 32, 28, 28]               0\n",
    "            Conv2d-9           [-1, 32, 28, 28]           9,248\n",
    "      BatchNorm2d-10           [-1, 32, 28, 28]              64\n",
    "          Dropout-11           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-12           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-13           [-1, 32, 28, 28]               0\n",
    "           Conv2d-14           [-1, 64, 14, 14]           8,256\n",
    "        LeakyReLU-15           [-1, 64, 14, 14]               0\n",
    "DownSampling_UNet-16           [-1, 64, 14, 14]               0\n",
    "           Conv2d-17           [-1, 64, 14, 14]          36,928\n",
    "      BatchNorm2d-18           [-1, 64, 14, 14]             128\n",
    "          Dropout-19           [-1, 64, 14, 14]               0\n",
    "        LeakyReLU-20           [-1, 64, 14, 14]               0\n",
    "        Conv_UNet-21           [-1, 64, 14, 14]               0\n",
    "           Linear-22                    [-1, 4]             256\n",
    "           Linear-23                   [-1, 64]             256\n",
    "          SEBlock-24           [-1, 64, 14, 14]               0\n",
    "           Conv2d-25           [-1, 32, 28, 28]           2,080\n",
    "  UpSampling_UNet-26           [-1, 64, 28, 28]               0\n",
    "           Conv2d-27           [-1, 32, 28, 28]          18,464\n",
    "      BatchNorm2d-28           [-1, 32, 28, 28]              64\n",
    "          Dropout-29           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-30           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-31           [-1, 32, 28, 28]               0\n",
    "           Conv2d-32           [-1, 16, 56, 56]             528\n",
    "  UpSampling_UNet-33           [-1, 32, 56, 56]               0\n",
    "           Conv2d-34            [-1, 8, 56, 56]           2,312\n",
    "      BatchNorm2d-35            [-1, 8, 56, 56]              16\n",
    "          Dropout-36            [-1, 8, 56, 56]               0\n",
    "        LeakyReLU-37            [-1, 8, 56, 56]               0\n",
    "        Conv_UNet-38            [-1, 8, 56, 56]               0\n",
    "           Conv2d-39            [-1, 1, 56, 56]              73\n",
    "          Sigmoid-40            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 81,377\n",
    "Trainable params: 81,377\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 7.99\n",
    "Params size (MB): 0.31\n",
    "Estimated Total Size (MB): 8.35\n",
    "----------------------------------------------------------------\n",
    "'''''''''''\n",
    "class UnetwithSEBlock_90k(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(UnetwithSEBlock_90k, self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.C1 = Conv_UNet(self.in_channels, 16)\n",
    "        self.D1 = DownSampling_UNet(16, 32)\n",
    "        self.C2 = Conv_UNet(32, 32)\n",
    "        self.D2 = DownSampling_UNet(32, 64)\n",
    "        self.C3 = Conv_UNet(64, 64)\n",
    "        self.se1=SEBlock(64)\n",
    "        self.U1 = UpSampling_UNet(64, 32)\n",
    "        self.C4 = Conv_UNet(64, 32)\n",
    "        self.U2 = UpSampling_UNet(32, 16)\n",
    "        self.C5 = Conv_UNet(32, 8)\n",
    "        self.pred = nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        R1 = self.C1(x)\n",
    "        R2 = self.C2(self.D1(R1))\n",
    "        R3 = self.C3(self.D2(R2))\n",
    "        R3=self.se1(R3)\n",
    "        up1 = self.C4(self.U1(R3, R2))\n",
    "        c = self.C5(self.U2(up1,R1))\n",
    "        return self.sigmoid(self.pred(c))\n",
    "\n",
    "''''''''''''''''\n",
    "UnetwithSelfattention_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv2d-1           [-1, 16, 56, 56]             592\n",
    "       BatchNorm2d-2           [-1, 16, 56, 56]              32\n",
    "           Dropout-3           [-1, 16, 56, 56]               0\n",
    "         LeakyReLU-4           [-1, 16, 56, 56]               0\n",
    "         Conv_UNet-5           [-1, 16, 56, 56]               0\n",
    "            Conv2d-6           [-1, 32, 28, 28]           2,080\n",
    "         LeakyReLU-7           [-1, 32, 28, 28]               0\n",
    " DownSampling_UNet-8           [-1, 32, 28, 28]               0\n",
    "            Conv2d-9           [-1, 32, 28, 28]           9,248\n",
    "      BatchNorm2d-10           [-1, 32, 28, 28]              64\n",
    "          Dropout-11           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-12           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-13           [-1, 32, 28, 28]               0\n",
    "           Conv2d-14           [-1, 64, 14, 14]           8,256\n",
    "        LeakyReLU-15           [-1, 64, 14, 14]               0\n",
    "DownSampling_UNet-16           [-1, 64, 14, 14]               0\n",
    "           Conv2d-17           [-1, 64, 14, 14]          36,928\n",
    "      BatchNorm2d-18           [-1, 64, 14, 14]             128\n",
    "          Dropout-19           [-1, 64, 14, 14]               0\n",
    "        LeakyReLU-20           [-1, 64, 14, 14]               0\n",
    "        Conv_UNet-21           [-1, 64, 14, 14]               0\n",
    "           Conv2d-22           [-1, 64, 14, 14]           4,160\n",
    "           Conv2d-23           [-1, 64, 14, 14]           4,160\n",
    "           Conv2d-24           [-1, 64, 14, 14]           4,160\n",
    "          Softmax-25             [-1, 196, 196]               0\n",
    "    SelfAttention-26           [-1, 64, 14, 14]               0\n",
    "           Conv2d-27           [-1, 32, 28, 28]           2,080\n",
    "  UpSampling_UNet-28           [-1, 64, 28, 28]               0\n",
    "           Conv2d-29           [-1, 32, 28, 28]          18,464\n",
    "      BatchNorm2d-30           [-1, 32, 28, 28]              64\n",
    "          Dropout-31           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-32           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-33           [-1, 32, 28, 28]               0\n",
    "           Conv2d-34           [-1, 16, 56, 56]             528\n",
    "  UpSampling_UNet-35           [-1, 32, 56, 56]               0\n",
    "           Conv2d-36            [-1, 8, 56, 56]           2,312\n",
    "      BatchNorm2d-37            [-1, 8, 56, 56]              16\n",
    "          Dropout-38            [-1, 8, 56, 56]               0\n",
    "        LeakyReLU-39            [-1, 8, 56, 56]               0\n",
    "        Conv_UNet-40            [-1, 8, 56, 56]               0\n",
    "           Conv2d-41            [-1, 1, 56, 56]              73\n",
    "          Sigmoid-42            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 93,345\n",
    "Trainable params: 93,345\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 8.57\n",
    "Params size (MB): 0.36\n",
    "Estimated Total Size (MB): 8.98\n",
    "----------------------------------------------------------------\n",
    "'''''''''''''''\n",
    "class UnetwithSelfattention_90k(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(UnetwithSelfattention_90k, self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.C1 = Conv_UNet(self.in_channels, 16) \n",
    "        self.D1 = DownSampling_UNet(16, 32) \n",
    "        self.C2 = Conv_UNet(32, 32)\n",
    "        self.D2 = DownSampling_UNet(32, 64) \n",
    "        self.C3 = Conv_UNet(64, 64)\n",
    "        self.attention = SelfAttention(64)\n",
    "        self.U1 = UpSampling_UNet(64, 32) \n",
    "        self.C4 = Conv_UNet(64, 32)  \n",
    "        self.U2 = UpSampling_UNet(32, 16) \n",
    "        self.C5 = Conv_UNet(32, 8)  \n",
    "        self.pred = nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        R1 = self.C1(x) \n",
    "        R2 = self.C2(self.D1(R1)) \n",
    "        R3 = self.C3(self.D2(R2))  \n",
    "        R3=self.attention(R3)\n",
    "        up1 = self.C4(self.U1(R3, R2))  \n",
    "        c = self.C5(self.U2(up1,R1))  \n",
    "        return self.sigmoid(self.pred(c))  \n",
    "\n",
    "\n",
    "'''''''''''''''''\n",
    "Unet3D_90k:\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv3d-1         [-1, 2, 1, 56, 56]              56\n",
    "            Conv3d-2         [-1, 2, 1, 56, 56]             152\n",
    "            Conv3d-3         [-1, 2, 1, 56, 56]             296\n",
    "            Conv3d-4         [-1, 2, 1, 56, 56]              56\n",
    "            Conv3d-5         [-1, 2, 1, 56, 56]             152\n",
    "            Conv3d-6         [-1, 2, 1, 56, 56]             296\n",
    "            Conv2d-7           [-1, 16, 56, 56]           1,744\n",
    "       BatchNorm2d-8           [-1, 16, 56, 56]              32\n",
    "           Dropout-9           [-1, 16, 56, 56]               0\n",
    "        LeakyReLU-10           [-1, 16, 56, 56]               0\n",
    "        Conv_UNet-11           [-1, 16, 56, 56]               0\n",
    "           Conv2d-12           [-1, 32, 28, 28]           2,080\n",
    "        LeakyReLU-13           [-1, 32, 28, 28]               0\n",
    "DownSampling_UNet-14           [-1, 32, 28, 28]               0\n",
    "           Conv2d-15           [-1, 32, 28, 28]           9,248\n",
    "      BatchNorm2d-16           [-1, 32, 28, 28]              64\n",
    "          Dropout-17           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-18           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-19           [-1, 32, 28, 28]               0\n",
    "           Conv2d-20           [-1, 64, 14, 14]           8,256\n",
    "        LeakyReLU-21           [-1, 64, 14, 14]               0\n",
    "DownSampling_UNet-22           [-1, 64, 14, 14]               0\n",
    "           Conv2d-23           [-1, 64, 14, 14]          36,928\n",
    "      BatchNorm2d-24           [-1, 64, 14, 14]             128\n",
    "          Dropout-25           [-1, 64, 14, 14]               0\n",
    "        LeakyReLU-26           [-1, 64, 14, 14]               0\n",
    "        Conv_UNet-27           [-1, 64, 14, 14]               0\n",
    "           Conv2d-28           [-1, 32, 28, 28]           2,080\n",
    "  UpSampling_UNet-29           [-1, 64, 28, 28]               0\n",
    "           Conv2d-30           [-1, 32, 28, 28]          18,464\n",
    "      BatchNorm2d-31           [-1, 32, 28, 28]              64\n",
    "          Dropout-32           [-1, 32, 28, 28]               0\n",
    "        LeakyReLU-33           [-1, 32, 28, 28]               0\n",
    "        Conv_UNet-34           [-1, 32, 28, 28]               0\n",
    "           Conv2d-35           [-1, 16, 56, 56]             528\n",
    "  UpSampling_UNet-36           [-1, 32, 56, 56]               0\n",
    "           Conv2d-37            [-1, 8, 56, 56]           2,312\n",
    "      BatchNorm2d-38            [-1, 8, 56, 56]              16\n",
    "          Dropout-39            [-1, 8, 56, 56]               0\n",
    "        LeakyReLU-40            [-1, 8, 56, 56]               0\n",
    "        Conv_UNet-41            [-1, 8, 56, 56]               0\n",
    "           Conv2d-42            [-1, 1, 56, 56]              73\n",
    "          Sigmoid-43            [-1, 1, 56, 56]               0\n",
    "             UNet-44            [-1, 1, 56, 56]               0\n",
    "================================================================\n",
    "Total params: 83,025\n",
    "Trainable params: 83,025\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 8.21\n",
    "Params size (MB): 0.32\n",
    "Estimated Total Size (MB): 8.57\n",
    "----------------------------------------------------------------\n",
    "'''''''''''''''''\n",
    "\n",
    "class Unet3D_90k(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet3D_90k,self).__init__()\n",
    "        self.conv3x3x3 = nn.Conv3d(1, 2, kernel_size=3, padding=(0,1,1)) #(batch_size,2,1,56,56)\n",
    "        self.conv3x5x5 = nn.Conv3d(1, 2, kernel_size=(3,5,5), padding=(0,2,2)) #(batch_size,2,1,56,56)\n",
    "        self.conv3x7x7 = nn.Conv3d(1, 2, kernel_size=(3,7,7), padding=(0,3,3)) #(batch_size,2,1,56,56)\n",
    "        self.unet=Unet3D_90k(12)\n",
    "    \n",
    "    def forward(self,x): #x=torch.cat((emcal,hcal,trkn,trkp),dim=1) (4,56,56)\n",
    "        x = x.unsqueeze(1)\n",
    "        x_e_h_n = x[:,:,:3,:,:]\n",
    "        x_e_h_p = x[:,:,[0,1,3],:,:]\n",
    "        x2 = self.conv3x3x3(x_e_h_n)\n",
    "        x3 = self.conv3x5x5(x_e_h_n)\n",
    "        x4 = self.conv3x7x7(x_e_h_n)\n",
    "        x5 = self.conv3x3x3(x_e_h_p)\n",
    "        x6 = self.conv3x5x5(x_e_h_p)\n",
    "        x7 = self.conv3x7x7(x_e_h_p)\n",
    "        x = torch.cat((x2,x3,x4,x5,x6,x7),dim=1).view(-1,12,56,56) #(batch_size,12,56,56)\n",
    "        x=self.unet(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, loss_function):\n",
    "    model.train()\n",
    "    mean_loss = torch.zeros(1).to(device)\n",
    "    \n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    \n",
    "    for step, (batch_X, batch_Y) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(batch_X.to(device))\n",
    "        loss=loss_function(outputs,batch_Y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        mean_loss = (mean_loss * step + loss.detach()) / (step + 1)  # update mean losses\n",
    "        # 打印平均loss\n",
    "        data_loader.desc = \"[epoch {}] mean loss {}\".format(epoch, round(mean_loss.item(), 7))\n",
    "        \n",
    "        if not torch.isfinite(loss):\n",
    "            print('WARNING: non-finite loss, ending training ', loss)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        \n",
    "    return mean_loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device, loss_function):\n",
    "    mean_loss = torch.zeros(1).to(device)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for batch_X, batch_Y in data_loader:\n",
    "        outputs=model(batch_X.to(device))\n",
    "        mean_loss += loss_function(outputs,batch_Y.to(device)).detach()\n",
    "    mean_loss /= len(data_loader)\n",
    "    return mean_loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_image(net, data_loader, device, label):\n",
    "    batch_size = data_loader.batch_size\n",
    "    plot_num = min(batch_size, 5)\n",
    "    net.eval()\n",
    "    fig_list = []\n",
    "    for batch_X, batch_Y in data_loader:\n",
    "        outputs=net(batch_X.to(device)).detach()\n",
    "        for i in range(plot_num):\n",
    "            fig = plt.figure()\n",
    "            fig.suptitle(label, fontsize=16)\n",
    "            ax1 = fig.add_subplot(121)\n",
    "            ax2 = fig.add_subplot(122)\n",
    "            ax1.imshow(batch_Y[i].cpu().numpy().squeeze(),cmap='jet')\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('Ground Truth')\n",
    "            ax2.imshow(outputs[i].cpu().numpy().squeeze(),cmap='jet')\n",
    "            ax2.axis('off')\n",
    "            ax2.set_title(f'Prediction')\n",
    "            \n",
    "            fig_list.append(fig)\n",
    "        break\n",
    "    return fig_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import shutil\n",
    "\n",
    "#from model import CNN3D\n",
    "#from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "#from train_and_eval import train_one_epoch, evaluate,plot_image\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(26)\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def train(args):\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(args)\n",
    "    tb_writer = SummaryWriter(log_dir=\"runs/CNN_80k/Demo1\")\n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "\n",
    "    # 定义训练以及预测时的预处理方法\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform[\"without_jet\"])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    data_set_jet = MyDataSet(img_dir=args.jet_dir,\n",
    "                                    group_size=1000,\n",
    "                                    size_in = 1000,\n",
    "                                    splition= False,\n",
    "                                    split_shuffle = False,\n",
    "                                    transform=data_transform[\"jet\"])\n",
    "    jet_dataset = dataset_2(data_set_jet.X, data_set_jet.Y)\n",
    "    \n",
    "    batch_size = args.batch_size\n",
    "    # 计算使用num_workers的数量\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 0])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw)\n",
    "    \n",
    "    jet_loader = torch.utils.data.DataLoader(jet_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "    \n",
    "    # 实例化模型\n",
    "    model = CNN_90k().to(device)\n",
    "\n",
    "    # 将模型写入tensorboard\n",
    "    init_img = torch.zeros((1, 4, 56, 56), device=device)\n",
    "    tb_writer.add_graph(model, init_img)\n",
    "\n",
    "    # 如果存在预训练权重则载入\n",
    "    if args.weights is None:\n",
    "        print(\"No weights file provided. Using random defaults.\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(args.weights))\n",
    "        print(\"using pretrain-weights.\")\n",
    "\n",
    "    # 是否冻结权重\n",
    "    if args.freeze_layers:\n",
    "        print(\"freeze layers except fc layer.\")\n",
    "        for name, para in model.named_parameters():\n",
    "            # 除最后的全连接层外，其他权重全部冻结\n",
    "            if \"decoder\" not in name:\n",
    "                para.requires_grad_(False)\n",
    "        \n",
    "    warmup_epochs_1 = 40\n",
    "    warmup_epochs_2 = 80\n",
    "    warmup_epochs_3 = 83\n",
    "    learningrate = args.lr\n",
    "\n",
    "    def lf_function(epoch): \n",
    "        if epoch < warmup_epochs_1:\n",
    "            return 1\n",
    "        elif epoch < warmup_epochs_2: \n",
    "            return 0.1\n",
    "        elif epoch < warmup_epochs_3:\n",
    "            return((epoch - warmup_epochs_2) / (warmup_epochs_3 - warmup_epochs_2)) * 0.5 + 0.1\n",
    "        else:\n",
    "            return(((1 + math.cos((epoch - warmup_epochs_3) * math.pi / (args.epochs - warmup_epochs_3))) / 2) * 0.5 + 0.1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learningrate)\n",
    "    # scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf_function)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        # train\n",
    "        train_loss = train_one_epoch(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_loader=train_loader,\n",
    "                                    device=device,\n",
    "                                    epoch=epoch,\n",
    "                                    loss_function=loss_function)\n",
    "        # update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # validate\n",
    "        if args.patten == \"train\":\n",
    "            test_loss = evaluate(model=model,\n",
    "                    data_loader=val_loader,\n",
    "                    device=device,\n",
    "                    loss_function=loss_function)\n",
    "        else:\n",
    "            test_loss = evaluate(model=model,\n",
    "                    data_loader=test_loader,\n",
    "                    device=device,\n",
    "                    loss_function=loss_function)\n",
    "\n",
    "        # add loss, acc and lr into tensorboard\n",
    "        print(\"[epoch {}] loss: {}\".format(epoch, round(test_loss, 7)))\n",
    "        tags = [\"train_loss\", \"test_loss\", \"learning_rate\"]\n",
    "        tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[1], test_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[2], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "        # add figure into tensorboard\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            fig_test = plot_image(net = model, \n",
    "                                data_loader = val_loader,\n",
    "                                device = device,\n",
    "                                label = \"test\")\n",
    "            fig_jet = plot_image(net = model,\n",
    "                                data_loader = jet_loader,\n",
    "                                device = device,\n",
    "                                label = \"jet\")\n",
    "\n",
    "            if fig_test is not None:\n",
    "                tb_writer.add_figure(\"predictions without jet\",\n",
    "                                    figure=fig_test,\n",
    "                                    global_step=epoch)\n",
    "            if fig_jet is not None:\n",
    "                tb_writer.add_figure(\"predictions with jet\",\n",
    "                                    figure=fig_jet,\n",
    "                                    global_step=epoch)\n",
    "\n",
    "        if ((epoch+1) % args.saving_routine == 0) or (epoch == args.epochs-1):\n",
    "            # save weights\n",
    "            torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))\n",
    "\n",
    "    num_cases_to_plot=5\n",
    "    test_samples=list(test_loader)[:num_cases_to_plot]\n",
    "    model.eval()\n",
    "    predicted_images=[]\n",
    "    true_images=[]\n",
    "    print(len(test_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_test, Y_test in test_samples:\n",
    "            # outputs=model(X_test.to(device),edge_index.to(device))\n",
    "            outputs=model(X_test.to(device))\n",
    "            predicted_images.append(outputs.cpu().detach().numpy())\n",
    "            true_images.append(Y_test.cpu().detach().numpy())\n",
    "    predicted_images = np.concatenate(predicted_images, axis=0)\n",
    "    true_images = np.concatenate(true_images, axis=0)\n",
    "    \n",
    "    IMAGE_NAME = 'Gauss_S1.00_NL0.30_B0.50'\n",
    "    error_list = []\n",
    "    pre_list = np.empty([])\n",
    "    true_list = np.empty([])\n",
    "    # Plotting the results\n",
    "    HEIGHT = 56\n",
    "    WIDTH =56\n",
    "    fig, axes = plt.subplots(num_cases_to_plot, 2, figsize=(10, 4 * num_cases_to_plot))\n",
    "    for i in range(num_cases_to_plot):\n",
    "        # 假设只有单一通道要显示，可以通过 denormalized_predicted_images 和 denormalized_true_images 访问真实与预测结果\n",
    "        #以下记得修改\n",
    "        pred_img = predicted_images[i].reshape(HEIGHT, WIDTH) # 假设输出是单通道形式\n",
    "        true_img = true_images[i, 0].reshape(HEIGHT, WIDTH) # 假设通道在第一维度\n",
    "        # 绘制真实图像\n",
    "        axes[i, 0].imshow(true_img) # 使用灰度图显示\n",
    "        axes[i, 0].set_title(f'True Image {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "    \n",
    "        # 绘制预测图像\n",
    "        axes[i, 1].imshow(pred_img) # 使用灰度图显示\n",
    "        axes[i, 1].set_title(f'Predicted Image {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "        error_list.append(pred_img-true_img)\n",
    "        pre_list = np.append(pre_list,pred_img)\n",
    "        true_list = np.append(true_list,true_img)\n",
    "    plt.show()\n",
    "\n",
    "    ''''''''''''\n",
    "    #假设已有模型,没有加载好jet数据集\n",
    "    ''''''''''''\n",
    "    data_transform = {\n",
    "\t\t\t\t\t\t\"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "\t\t\t\t\t\t\"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    data_set_jet = MyDataSet(img_dir=args.jet_dir,\n",
    "    \t\t\t\t\t\tgroup_size=1000,\n",
    "    \t\t\t\t\t\tsize_in = 1000,\n",
    "    \t\t\t\t\t\tsplition= False,\n",
    "    \t\t\t\t\t\tsplit_shuffle = False,\n",
    "    \t\t\t\t\t\ttransform=data_transform[\"jet\"])\n",
    "    X=data_set_jet.X #(1000,4,56,56)\n",
    "    Y=data_set_jet.Y #(1000,1,56,56)\n",
    "    \n",
    "    dataset1=dataset_2(X,Y)\n",
    "    #分割数据集\n",
    "    TEST_NUM=1000\n",
    "    BATCH_SIZE=200\n",
    "    print(TEST_NUM)\n",
    "    test_loader_jet = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    save_dir = 'predicted_images_CNN3D'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"文件夹 '{save_dir}' 已创建。\")\n",
    "    else:\n",
    "        shutil.rmtree(save_dir)\n",
    "        print(f\"文件夹 '{save_dir}' 及其内容已删除。\")\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"文件夹 '{save_dir}' 已重新创建。\")\n",
    "        \n",
    "    model.eval()\n",
    "    predicted_images=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i,(X_test, Y_test) in enumerate(test_loader_jet):\n",
    "            outputs=model(X_test.to(device))\n",
    "            predicted_images.append(outputs.cpu().detach().numpy())\n",
    "    predicted_images = np.concatenate(predicted_images, axis=0)\n",
    "    #print(predicted_images.shape)\n",
    "    #print(type(predicted_images))\n",
    "    for i in range(predicted_images.shape[0]):\n",
    "        # 取出第 i 张图 (形状 [1, 56, 56])\n",
    "        image_2d = predicted_images[i, 0]  # 形状 [56, 56]\n",
    "        # 转为 NumPy 数组 (默认是 float32 或 float64，具体看你的张量类型)\n",
    "        image_np = image_2d\n",
    "        # 直接写入 TIFF，不做任何缩放，保留原始精度\n",
    "        save_path = os.path.join(save_dir, f\"predict_{i}.tiff\")\n",
    "        tifffile.imwrite(save_path, image_np)\n",
    "\n",
    "    \n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.num_classes = 5\n",
    "        self.epochs = 100\n",
    "        self.saving_routine = 20\n",
    "        self.batch_size = 400\n",
    "        self.lr = 0.001\n",
    "        self.patten = \"Parameter\"\n",
    "        self.img_dir = '/kaggle/input/gauss-s1-00-nl0-30-b0-50'  # 修改为你的图片目录\n",
    "        self.jet_dir = '/kaggle/input/gauss-s1-00-nl0-30-b0-50-jet'    # 修改为你的Jet目录\n",
    "        self.weights = None  # 如果有预训练权重，修改为权重路径\n",
    "        self.freeze_layers = False\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "opt = Args()\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件夹内1000张tiff图片转化为txt文件,此处以CNN3D为例\n",
    "import tifffile as tiff\n",
    "import sys\n",
    "import math\n",
    "directory_path = '/kaggle/working/predicted_images_CNN3D_80k'\n",
    "sys.stdout=open('/kaggle/working/output_CNN3D_80k_predict.txt','w')\n",
    "images = []\n",
    "nums = []\n",
    "for num in range(1000):\n",
    "    filename = f\"predict_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    num=0\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                num=num+1\n",
    "    nums.append(num)\n",
    "for i in range(len(nums)):\n",
    "    print(nums[i])\n",
    "for num in range(1000):\n",
    "    filename = f\"precdict_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    for i in range(image.shape[0]): \n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                pz=i+0.5-image.shape[0]/2\n",
    "                py=(56/2/math.pi)*math.cos((j+0.5)/56*2*math.pi)\n",
    "                px=(56/2/math.pi)*math.sin((j+0.5)/56*2*math.pi)\n",
    "                pr=math.sqrt(px*px+py*py+pz*pz)\n",
    "                px=px/pr\n",
    "                py=py/pr\n",
    "                pz=pz/pr\n",
    "                print(f'{px} {py} {pz} {pixel_value}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#无需运行，结果已记录\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import sys\n",
    "import math\n",
    "directory_path = '/kaggle/input/gauss-s1-00-nl0-30-b0-50-jet'\n",
    "sys.stdout=open('/kaggle/working/output_truth.txt','w')\n",
    "images = []\n",
    "nums = []\n",
    "for num in range(1000):\n",
    "    filename = f\"truth_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    num=0\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                num=num+1\n",
    "    nums.append(num)\n",
    "for i in range(len(nums)):\n",
    "    print(nums[i])\n",
    "for num in range(1000):\n",
    "    filename = f\"truth_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    for i in range(image.shape[0]): \n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                pz=i+0.5-image.shape[0]/2\n",
    "                py=(56/2/math.pi)*math.cos((j+0.5)/56*2*math.pi)\n",
    "                px=(56/2/math.pi)*math.sin((j+0.5)/56*2*math.pi)\n",
    "                pr=math.sqrt(px*px+py*py+pz*pz)\n",
    "                px=px/pr\n",
    "                py=py/pr\n",
    "                pz=pz/pr\n",
    "                print(f'{px} {py} {pz} {pixel_value}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#无需运行，结果已记录\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import sys\n",
    "import math\n",
    "directory_path = '/kaggle/input/gauss-s1-00-nl0-30-b0-50-jet'\n",
    "sys.stdout=open('/kaggle/working/output_jet.txt','w')\n",
    "images = []\n",
    "nums = []\n",
    "for num in range(1000):\n",
    "    filename = f\"jet_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    num=0\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                num=num+1\n",
    "    nums.append(num)\n",
    "for i in range(len(nums)):\n",
    "    print(nums[i])\n",
    "for num in range(1000):\n",
    "    filename = f\"jet_{str(num)}.tiff\"\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    image = tiff.imread(file_path)\n",
    "    images.append(image)\n",
    "    for i in range(image.shape[0]): \n",
    "        for j in range(image.shape[1]):\n",
    "            pixel_value = image[i, j]\n",
    "            if pixel_value>0:\n",
    "                pz=i+0.5-image.shape[0]/2\n",
    "                py=(56/2/math.pi)*math.cos((j+0.5)/56*2*math.pi)\n",
    "                px=(56/2/math.pi)*math.sin((j+0.5)/56*2*math.pi)\n",
    "                pr=math.sqrt(px*px+py*py+pz*pz)\n",
    "                px=px/pr\n",
    "                py=py/pr\n",
    "                pz=pz/pr\n",
    "                print(f'{px} {py} {pz} {pixel_value}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处以CNN3D为例\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from math import pi\n",
    "import os\n",
    "import sys\n",
    "sys.stdout=open('/kaggle/working/errors_CNN3D_80k_jet_2dis.txt','w')\n",
    "def chord_length(x1, y1, x2, y2, r):\n",
    "    L = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    d = math.sqrt(r ** 2 - (L / 2) ** 2)\n",
    "    cos_theta = (L ** 2 + r ** 2 - d ** 2) / (2 * L * r)\n",
    "    theta = math.acos(cos_theta)\n",
    "    s = theta * r\n",
    "    return s\n",
    "    \n",
    "def calculate_spatial_coordinates(rap, phi, Pt, E):\n",
    "    p_T = Pt \n",
    "    p_x = p_T * math.cos(phi)\n",
    "    p_y = p_T * math.sin(phi)\n",
    "    p_z = E * math.sinh(rap) \n",
    "    x = p_x / E \n",
    "    y = p_y / E \n",
    "    z = p_z / E \n",
    "    return x, y, z\n",
    "\n",
    "def plot_filled_circle_in_3d(px=0, py=0, area=0, height=0, color=\"black\"):\n",
    "    theta = np.linspace(0, 2 * np.pi, 100) \n",
    "    radius= math.sqrt(area/2/pi)\n",
    "    ax.set_xlim(-3, 3) \n",
    "    ax.set_ylim(-1, 7)\n",
    "    ax.set_zlim(0, 200) \n",
    "    x = radius * np.cos(theta)+px \n",
    "    y = radius * np.sin(theta)+py  \n",
    "    z = np.zeros_like(x) \n",
    "    ax.plot(x, y, z, color=color)\n",
    "    for t in theta:\n",
    "        x_fill = np.linspace(-radius, radius, 50)\n",
    "        y_fill = np.sqrt(radius ** 2 - x_fill ** 2) \n",
    "        z_fill = np.zeros_like(x_fill)\n",
    "        ax.plot_surface(np.array([x_fill+px, x_fill+px]), np.array([y_fill+py, -y_fill+py]), np.array([z_fill, z_fill]),\n",
    "                        color=color, alpha=0.5)\n",
    "    x = 0.1*np.cos(theta)+px  \n",
    "    y = 0.1*np.sin(theta)+py  \n",
    "    z = np.linspace(0, height, 100) \n",
    "    X, Z = np.meshgrid(x, z)\n",
    "    Y = np.meshgrid(y, z)[0]\n",
    "    ax.plot_surface(X, Y, Z, color=color, alpha=0.8)\n",
    "    Z_top = np.full_like(X, z[-1])\n",
    "    Z_bottom = np.full_like(X, z[0])\n",
    "    ax.plot_surface(X, Y, Z_top, color=color, alpha=0.5)\n",
    "    ax.plot_surface(X, Y, Z_bottom, color=color, alpha=0.5)\n",
    "    ax.set_xlabel('y')\n",
    "    ax.set_ylabel('φ')\n",
    "    ax.set_zlabel('Pt(GeV)')\n",
    "\n",
    "# 打开文件\n",
    "with open('kagge/input/result_truth.txt', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    content = file.read()\n",
    "    # 分割内容为行\n",
    "    lines = content.strip().split('\\n')\n",
    "    # 读取每行的数字\n",
    "    truth_numbers = []\n",
    "    for line in lines:\n",
    "        # 分割行中的数字\n",
    "        truth_numbers_in_line = line.split()\n",
    "        # 将数字转换为浮点数列表\n",
    "        truth_numbers.extend(map(float, truth_numbers_in_line))\n",
    "    # 打印所有数字\n",
    "    #for number in numbers:\n",
    "        #print(number)\n",
    "truth_numbers_size = len(truth_numbers)\n",
    "#print(truth_numbers_size)\n",
    "num=0\n",
    "truth_clusters= []\n",
    "truth_raps= []\n",
    "truth_phis= []\n",
    "truth_pts= []\n",
    "truth_E= []\n",
    "truth_areas= []\n",
    "truth_x= []\n",
    "truth_y= []\n",
    "truth_z= []\n",
    "p=0\n",
    "for i in range(truth_numbers_size):\n",
    "    if p!=0:\n",
    "        p=p-1\n",
    "        continue\n",
    "    if num==0:\n",
    "        truth_clusters.append(int(truth_numbers[i]))\n",
    "        num=int(truth_numbers[i])\n",
    "        continue\n",
    "    num=num-1;\n",
    "    truth_raps.append(truth_numbers[i])\n",
    "    truth_phis.append(truth_numbers[i+1])\n",
    "    truth_pts.append(truth_numbers[i+2])\n",
    "    truth_E.append(truth_numbers[i+3])\n",
    "    truth_areas.append(truth_numbers[i+4])\n",
    "    y, x, z = calculate_spatial_coordinates(truth_numbers[i], truth_numbers[i+1], truth_numbers[i+2],truth_numbers[i+3])\n",
    "    truth_y.append(y)\n",
    "    truth_x.append(x)\n",
    "    truth_z.append(z)\n",
    "    p=4\n",
    "truth_clusters_size = len(truth_clusters)\n",
    "#print(truth_clusters_size)\n",
    "truth_pos=0\n",
    "truth_clusters[-1]=0\n",
    "\n",
    "\n",
    "with open('kagge/input/result_jet.txt', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    content = file.read()\n",
    "    # 分割内容为行\n",
    "    lines = content.strip().split('\\n')\n",
    "    # 读取每行的数字\n",
    "    jet_numbers = []\n",
    "    for line in lines:\n",
    "        # 分割行中的数字\n",
    "        jet_numbers_in_line = line.split()\n",
    "        # 将数字转换为浮点数列表\n",
    "        jet_numbers.extend(map(float, jet_numbers_in_line))\n",
    "    # 打印所有数字\n",
    "    #for number in numbers:\n",
    "        #print(number)\n",
    "jet_numbers_size = len(jet_numbers)\n",
    "#print(jet_numbers_size)\n",
    "num=0\n",
    "jet_clusters= []\n",
    "jet_raps= []\n",
    "jet_phis= []\n",
    "jet_pts= []\n",
    "jet_E= []\n",
    "jet_areas= []\n",
    "jet_x= []\n",
    "jet_y= []\n",
    "jet_z= []\n",
    "p=0\n",
    "for i in range(jet_numbers_size):\n",
    "    if p!=0:\n",
    "        p=p-1\n",
    "        continue\n",
    "    if num==0:\n",
    "        jet_clusters.append(int(jet_numbers[i]))\n",
    "        num=int(jet_numbers[i])\n",
    "        continue\n",
    "    num=num-1;\n",
    "    jet_raps.append(jet_numbers[i])\n",
    "    jet_phis.append(jet_numbers[i+1])\n",
    "    jet_pts.append(jet_numbers[i+2])\n",
    "    jet_E.append(jet_numbers[i+3])\n",
    "    jet_areas.append(jet_numbers[i+4])\n",
    "    y, x, z = calculate_spatial_coordinates(jet_numbers[i], jet_numbers[i+1], jet_numbers[i+2],jet_numbers[i+3])\n",
    "    jet_y.append(y)\n",
    "    jet_x.append(x)\n",
    "    jet_z.append(z)\n",
    "    p=4\n",
    "jet_clusters_size = len(jet_clusters)\n",
    "#print(jet_clusters_size)\n",
    "jet_pos=0\n",
    "jet_clusters[-1]=0\n",
    "\n",
    "with open('kagge/input/result_predict.txt', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    content = file.read()\n",
    "    # 分割内容为行\n",
    "    lines = content.strip().split('\\n')\n",
    "    # 读取每行的数字\n",
    "    predict_numbers = []\n",
    "    for line in lines:\n",
    "        # 分割行中的数字\n",
    "        predict_numbers_in_line = line.split()\n",
    "\n",
    "        # 将数字转换为浮点数列表\n",
    "        predict_numbers.extend(map(float, predict_numbers_in_line))\n",
    "\n",
    "    # 打印所有数字\n",
    "    #for number in numbers:\n",
    "        #print(number)\n",
    "predict_numbers_size = len(predict_numbers)\n",
    "#print(f'predict_numbers_size:{predict_numbers_size}')\n",
    "num=0\n",
    "predict_clusters= []\n",
    "predict_raps= []\n",
    "predict_phis= []\n",
    "predict_pts= []\n",
    "predict_E= []\n",
    "predict_areas= []\n",
    "predict_x= []\n",
    "predict_y= []\n",
    "predict_z= []\n",
    "p=0\n",
    "for i in range(predict_numbers_size):\n",
    "    if p!=0:\n",
    "        p=p-1\n",
    "        continue\n",
    "    if num==0:\n",
    "        predict_clusters.append(int(predict_numbers[i]))\n",
    "        num=int(predict_numbers[i])\n",
    "        continue\n",
    "    num=num-1;\n",
    "    predict_raps.append(predict_numbers[i])\n",
    "    predict_phis.append(predict_numbers[i+1])\n",
    "    predict_pts.append(predict_numbers[i+2])\n",
    "    predict_E.append(predict_numbers[i+3])\n",
    "    predict_areas.append(predict_numbers[i+4])\n",
    "    y, x, z = calculate_spatial_coordinates(predict_numbers[i], predict_numbers[i+1], predict_numbers[i+2],predict_numbers[i+3])\n",
    "    predict_y.append(y)\n",
    "    predict_x.append(x)\n",
    "    predict_z.append(z)\n",
    "    p=4\n",
    "predict_clusters_size = len(predict_clusters)\n",
    "#print(predict_clusters_size)\n",
    "predict_pos=0\n",
    "predict_clusters[-1]=0\n",
    "\n",
    "def distance(x1, y1, x2, y2):\n",
    "    \"\"\"Calculate the Euclidean distance between two points in 2D space.\"\"\"\n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5\n",
    "def cos_between_vectors(x1,y1,x2, y2):\n",
    "    # 计算点积\n",
    "    dot_product = x1 * x2 + y1 * y2\n",
    "    # 计算两个向量的模\n",
    "    magnitude_v1 = math.sqrt(x1**2 + y1**2)\n",
    "    magnitude_v2 = math.sqrt(x2**2 + y2**2)\n",
    "    # 计算夹角的余弦值\n",
    "    cos_angle = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    return cos_angle\n",
    "\n",
    "output_folder='output_figure'\n",
    "for i in range(truth_clusters_size):\n",
    "    truth_pos=truth_pos+truth_clusters[i-1]\n",
    "    jet_pos = jet_pos + jet_clusters[i - 1]\n",
    "    predict_pos = predict_pos + predict_clusters[i - 1]\n",
    "    if jet_clusters[i]==0:\n",
    "        continue\n",
    "    truth_min_cos =-1\n",
    "    predict_min_cos = -1\n",
    "    truth_min_distance = math.sqrt(56*56+56*56)\n",
    "    predict_min_distance = math.sqrt(56 * 56 + 56 * 56)\n",
    "    truth_id=0\n",
    "    for j in range(truth_clusters[i]):\n",
    "       if truth_min_distance>distance(x1=truth_raps[j+ truth_pos],y1=truth_phis[j+ truth_pos],x2=jet_raps[jet_pos],y2=jet_phis[jet_pos]):\n",
    "           truth_id=j\n",
    "           truth_min_distance = distance(x1=truth_raps[j + truth_pos], y1=truth_phis[j + truth_pos], x2=jet_raps[jet_pos],y2=jet_phis[jet_pos])\n",
    "    for j in range(predict_clusters[i]):\n",
    "       if predict_min_distance > distance(x1=predict_raps[j + predict_pos], y1=predict_phis[j + predict_pos],x2=jet_raps[jet_pos], y2=jet_phis[jet_pos]):\n",
    "           predict_id = j\n",
    "           predict_min_distance = distance(x1=predict_raps[j + predict_pos], y1=predict_phis[j + predict_pos],x2=jet_raps[jet_pos], y2=jet_phis[jet_pos])\n",
    "    x=jet_y[jet_pos]\n",
    "    y=jet_x[jet_pos]\n",
    "    z=jet_z[jet_pos]\n",
    "    r=56/2/math.pi\n",
    "    y=-y;\n",
    "    theta=math.atan(x/math.fabs(y))\n",
    "    dis=(math.pi-theta)*r\n",
    "    x=truth_y[truth_id+truth_pos]\n",
    "    y=truth_x[truth_id+truth_pos]\n",
    "    z=truth_z[truth_id+truth_pos]\n",
    "    r = 56 / 2 / math.pi\n",
    "    y = -y;\n",
    "    theta = math.atan(x / math.fabs(y))\n",
    "    dis = (math.pi - theta) * r\n",
    "    dis1=dis\n",
    "    z1=z\n",
    "    x1=x\n",
    "    y1=y\n",
    "    x=predict_y[predict_id+predict_pos]\n",
    "    y=predict_x[predict_id+predict_pos]\n",
    "    z=predict_z[predict_id+predict_pos]\n",
    "    r = 56 / 2 / math.pi\n",
    "    y = -y;\n",
    "    theta = math.atan(x / math.fabs(y))\n",
    "    dis = (math.pi - theta) * r\n",
    "    # print(f'x:{x*r/math.sqrt(x*x+y*y)}  y:{y*r/math.sqrt(x*x+y*y)} width:{z+28}  r:{x*x+y*y}');\n",
    "    #print(f'width:{dis}  height:{28 + z}');\n",
    "    print(f'{math.sqrt((dis1-dis)*(dis1-dis)+(z1-z)*(z1-z))}')\n",
    "   # print(f'{math.sqrt((x1 - x) * (x1 -x) + (y1-y)*(y1-y)+(z1 - z) * (z1 - z))}')\n",
    "   # print(f'{(predict_E[predict_id+predict_pos]-truth_E[truth_id+truth_pos])/truth_E[truth_id+truth_pos]}')\n",
    "    #print(f'{truth_pts[truth_id+truth_pos]}   {predict_pts[predict_id+predict_pos]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
