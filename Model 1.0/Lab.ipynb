{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce52327-502f-4f14-8fb9-de8bc447851d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.020664, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.003047, Validation Loss: 0.003182\n",
      " Epoch 3: Train Loss: 0.001342, Validation Loss: 0.001283\n",
      " Epoch 4: Train Loss: 0.000975, Validation Loss: 0.000897\n",
      " Epoch 5: Train Loss: 0.000837, Validation Loss: 0.000789\n",
      " Epoch 6: Train Loss: 0.000753, Validation Loss: 0.000721\n",
      " Epoch 7: Train Loss: 0.000693, Validation Loss: 0.000671\n",
      " Epoch 8: Train Loss: 0.000649, Validation Loss: 0.000629\n",
      " Epoch 9: Train Loss: 0.000612, Validation Loss: 0.000600\n",
      " Epoch 10: Train Loss: 0.000583, Validation Loss: 0.000575\n",
      " Epoch 11: Train Loss: 0.000557, Validation Loss: 0.000554\n",
      " Epoch 12: Train Loss: 0.000537, Validation Loss: 0.000534\n",
      " Epoch 13: Train Loss: 0.000519, Validation Loss: 0.000526\n",
      " Epoch 14: Train Loss: 0.000506, Validation Loss: 0.000506\n",
      " Epoch 15: Train Loss: 0.000490, Validation Loss: 0.000493\n",
      " Epoch 16: Train Loss: 0.000477, Validation Loss: 0.000480\n",
      " Epoch 17: Train Loss: 0.000467, Validation Loss: 0.000474\n",
      " Epoch 18: Train Loss: 0.000454, Validation Loss: 0.000459\n",
      " Epoch 19: Train Loss: 0.000444, Validation Loss: 0.000448\n",
      " Epoch 20: Train Loss: 0.000433, Validation Loss: 0.000441\n",
      " Epoch 21: Train Loss: 0.000429, Validation Loss: 0.000450\n",
      " Epoch 22: Train Loss: 0.000422, Validation Loss: 0.000425\n",
      " Epoch 23: Train Loss: 0.000410, Validation Loss: 0.000427\n",
      " Epoch 24: Train Loss: 0.000405, Validation Loss: 0.000422\n",
      " Epoch 25: Train Loss: 0.000399, Validation Loss: 0.000407\n",
      " Epoch 26: Train Loss: 0.000394, Validation Loss: 0.000401\n",
      " Epoch 27: Train Loss: 0.000388, Validation Loss: 0.000403\n",
      " Epoch 28: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 29: Train Loss: 0.000378, Validation Loss: 0.000395\n",
      " Epoch 30: Train Loss: 0.000376, Validation Loss: 0.000395\n",
      " Epoch 31: Train Loss: 0.000364, Validation Loss: 0.000380\n",
      " Epoch 32: Train Loss: 0.000359, Validation Loss: 0.000376\n",
      " Epoch 33: Train Loss: 0.000358, Validation Loss: 0.000374\n",
      " Epoch 34: Train Loss: 0.000354, Validation Loss: 0.000375\n",
      " Epoch 35: Train Loss: 0.000352, Validation Loss: 0.000370\n",
      " Epoch 36: Train Loss: 0.000349, Validation Loss: 0.000369\n",
      " Epoch 37: Train Loss: 0.000349, Validation Loss: 0.000366\n",
      " Epoch 38: Train Loss: 0.000343, Validation Loss: 0.000365\n",
      " Epoch 39: Train Loss: 0.000346, Validation Loss: 0.000364\n",
      " Epoch 40: Train Loss: 0.000341, Validation Loss: 0.000368\n",
      " Epoch 41: Train Loss: 0.000340, Validation Loss: 0.000359\n",
      " Epoch 42: Train Loss: 0.000336, Validation Loss: 0.000360\n",
      " Epoch 43: Train Loss: 0.000334, Validation Loss: 0.000357\n",
      " Epoch 44: Train Loss: 0.000333, Validation Loss: 0.000354\n",
      " Epoch 45: Train Loss: 0.000330, Validation Loss: 0.000352\n",
      " Epoch 46: Train Loss: 0.000328, Validation Loss: 0.000352\n",
      " Epoch 47: Train Loss: 0.000329, Validation Loss: 0.000349\n",
      " Epoch 48: Train Loss: 0.000325, Validation Loss: 0.000350\n",
      " Epoch 49: Train Loss: 0.000322, Validation Loss: 0.000349\n",
      " Epoch 50: Train Loss: 0.000321, Validation Loss: 0.000346\n",
      " Epoch 51: Train Loss: 0.000321, Validation Loss: 0.000351\n",
      " Epoch 52: Train Loss: 0.000317, Validation Loss: 0.000346\n",
      " Epoch 53: Train Loss: 0.000316, Validation Loss: 0.000342\n",
      " Epoch 54: Train Loss: 0.000313, Validation Loss: 0.000347\n",
      " Epoch 55: Train Loss: 0.000316, Validation Loss: 0.000338\n",
      " Epoch 56: Train Loss: 0.000311, Validation Loss: 0.000337\n",
      " Epoch 57: Train Loss: 0.000312, Validation Loss: 0.000336\n",
      " Epoch 58: Train Loss: 0.000309, Validation Loss: 0.000334\n",
      " Epoch 59: Train Loss: 0.000309, Validation Loss: 0.000337\n",
      " Epoch 60: Train Loss: 0.000313, Validation Loss: 0.000333\n",
      " Epoch 61: Train Loss: 0.000300, Validation Loss: 0.000330\n",
      " Epoch 62: Train Loss: 0.000298, Validation Loss: 0.000329\n",
      " Epoch 63: Train Loss: 0.000297, Validation Loss: 0.000329\n",
      " Epoch 64: Train Loss: 0.000297, Validation Loss: 0.000328\n",
      " Epoch 65: Train Loss: 0.000296, Validation Loss: 0.000327\n",
      " Epoch 66: Train Loss: 0.000294, Validation Loss: 0.000333\n",
      " Epoch 67: Train Loss: 0.000294, Validation Loss: 0.000327\n",
      " Epoch 68: Train Loss: 0.000297, Validation Loss: 0.000331\n",
      " Epoch 69: Train Loss: 0.000294, Validation Loss: 0.000325\n",
      " Epoch 70: Train Loss: 0.000291, Validation Loss: 0.000325\n",
      " Epoch 71: Train Loss: 0.000291, Validation Loss: 0.000323\n",
      " Epoch 72: Train Loss: 0.000289, Validation Loss: 0.000324\n",
      " Epoch 73: Train Loss: 0.000288, Validation Loss: 0.000326\n",
      " Epoch 74: Train Loss: 0.000288, Validation Loss: 0.000322\n",
      " Epoch 75: Train Loss: 0.000290, Validation Loss: 0.000321\n",
      " Epoch 76: Train Loss: 0.000286, Validation Loss: 0.000321\n",
      " Epoch 77: Train Loss: 0.000286, Validation Loss: 0.000322\n",
      " Epoch 78: Train Loss: 0.000284, Validation Loss: 0.000321\n",
      " Epoch 79: Train Loss: 0.000284, Validation Loss: 0.000320\n",
      " Epoch 80: Train Loss: 0.000285, Validation Loss: 0.000320\n",
      " Epoch 81: Train Loss: 0.000283, Validation Loss: 0.000321\n",
      " Epoch 82: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 83: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 84: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 85: Train Loss: 0.000278, Validation Loss: 0.000315\n",
      " Epoch 86: Train Loss: 0.000277, Validation Loss: 0.000318\n",
      " Epoch 87: Train Loss: 0.000276, Validation Loss: 0.000315\n",
      " Epoch 88: Train Loss: 0.000277, Validation Loss: 0.000317\n",
      " Epoch 89: Train Loss: 0.000277, Validation Loss: 0.000314\n",
      " Epoch 90: Train Loss: 0.000275, Validation Loss: 0.000321\n",
      " Epoch 91: Train Loss: 0.000272, Validation Loss: 0.000315\n",
      " Epoch 92: Train Loss: 0.000271, Validation Loss: 0.000313\n",
      " Epoch 93: Train Loss: 0.000270, Validation Loss: 0.000313\n",
      " Epoch 94: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 95: Train Loss: 0.000268, Validation Loss: 0.000312\n",
      " Epoch 96: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 97: Train Loss: 0.000269, Validation Loss: 0.000311\n",
      " Epoch 98: Train Loss: 0.000267, Validation Loss: 0.000311\n",
      " Epoch 99: Train Loss: 0.000268, Validation Loss: 0.000311\n",
      " Epoch 100: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 101: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 102: Train Loss: 0.000265, Validation Loss: 0.000310\n",
      " Epoch 103: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 104: Train Loss: 0.000264, Validation Loss: 0.000310\n",
      " Epoch 105: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 106: Train Loss: 0.000263, Validation Loss: 0.000309\n",
      " Epoch 107: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 108: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 109: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 110: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 111: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 112: Train Loss: 0.000261, Validation Loss: 0.000308\n",
      " Epoch 113: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 114: Train Loss: 0.000259, Validation Loss: 0.000309\n",
      " Epoch 115: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 116: Train Loss: 0.000261, Validation Loss: 0.000311\n",
      " Epoch 117: Train Loss: 0.000258, Validation Loss: 0.000306\n",
      " Epoch 118: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 119: Train Loss: 0.000256, Validation Loss: 0.000305\n",
      " Epoch 120: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 121: Train Loss: 0.000254, Validation Loss: 0.000309\n",
      " Epoch 122: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 123: Train Loss: 0.000253, Validation Loss: 0.000305\n",
      " Epoch 124: Train Loss: 0.000252, Validation Loss: 0.000304\n",
      " Epoch 125: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 126: Train Loss: 0.000252, Validation Loss: 0.000305\n",
      " Epoch 127: Train Loss: 0.000251, Validation Loss: 0.000305\n",
      " Epoch 128: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 129: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 130: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 131: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 132: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 133: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 134: Train Loss: 0.000249, Validation Loss: 0.000303\n",
      " Epoch 135: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 136: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 137: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 138: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 139: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 140: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 141: Train Loss: 0.000246, Validation Loss: 0.000305\n",
      " Epoch 142: Train Loss: 0.000247, Validation Loss: 0.000303\n",
      " Epoch 143: Train Loss: 0.000247, Validation Loss: 0.000304\n",
      " Epoch 144: Train Loss: 0.000246, Validation Loss: 0.000302\n",
      " Epoch 145: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 146: Train Loss: 0.000245, Validation Loss: 0.000305\n",
      " Epoch 147: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 148: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 149: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 150: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 151: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 152: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 153: Train Loss: 0.000242, Validation Loss: 0.000301\n",
      " Epoch 154: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 155: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 156: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 157: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 158: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 159: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 160: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 161: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 162: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 163: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 164: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 165: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 166: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 167: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 168: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 169: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 170: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 171: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 172: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 173: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 174: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 175: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 176: Train Loss: 0.000237, Validation Loss: 0.000300\n",
      " Epoch 177: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 178: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 179: Train Loss: 0.000236, Validation Loss: 0.000300\n",
      " Epoch 180: Train Loss: 0.000236, Validation Loss: 0.000301\n",
      " Epoch 181: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 182: Train Loss: 0.000235, Validation Loss: 0.000302\n",
      " Epoch 183: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 184: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 185: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 186: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 187: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 188: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 189: Train Loss: 0.000233, Validation Loss: 0.000301\n",
      " Epoch 190: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 191: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 192: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 193: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 194: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 195: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 196: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 197: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 198: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 199: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 200: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 201: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      " Epoch 202: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 203: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 204: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      " Epoch 205: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 206: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 207: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 208: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 209: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 210: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 211: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 212: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 213: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 214: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 215: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 216: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 217: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 218: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 219: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 220: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 221: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 222: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 223: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 224: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 225: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 226: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 227: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 228: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 229: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 230: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 231: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 232: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 233: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 234: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 235: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 236: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 237: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 238: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 239: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 240: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 241: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 242: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 243: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 244: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 245: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 246: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 247: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 248: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      "Early stopping at epoch 248 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016293, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.007308, Validation Loss: 0.009537\n",
      " Epoch 3: Train Loss: 0.005686, Validation Loss: 0.005249\n",
      " Epoch 4: Train Loss: 0.002820, Validation Loss: 0.002623\n",
      " Epoch 5: Train Loss: 0.001262, Validation Loss: 0.001208\n",
      " Epoch 6: Train Loss: 0.000950, Validation Loss: 0.000869\n",
      " Epoch 7: Train Loss: 0.000800, Validation Loss: 0.000771\n",
      " Epoch 8: Train Loss: 0.000702, Validation Loss: 0.000685\n",
      " Epoch 9: Train Loss: 0.000637, Validation Loss: 0.000611\n",
      " Epoch 10: Train Loss: 0.000594, Validation Loss: 0.000581\n",
      " Epoch 11: Train Loss: 0.000568, Validation Loss: 0.000650\n",
      " Epoch 12: Train Loss: 0.000530, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000507, Validation Loss: 0.000499\n",
      " Epoch 14: Train Loss: 0.000490, Validation Loss: 0.000500\n",
      " Epoch 15: Train Loss: 0.000479, Validation Loss: 0.000505\n",
      " Epoch 16: Train Loss: 0.000465, Validation Loss: 0.000483\n",
      " Epoch 17: Train Loss: 0.000454, Validation Loss: 0.000568\n",
      " Epoch 18: Train Loss: 0.000453, Validation Loss: 0.000449\n",
      " Epoch 19: Train Loss: 0.000432, Validation Loss: 0.000431\n",
      " Epoch 20: Train Loss: 0.000422, Validation Loss: 0.000424\n",
      " Epoch 21: Train Loss: 0.000413, Validation Loss: 0.000424\n",
      " Epoch 22: Train Loss: 0.000410, Validation Loss: 0.000415\n",
      " Epoch 23: Train Loss: 0.000414, Validation Loss: 0.000457\n",
      " Epoch 24: Train Loss: 0.000397, Validation Loss: 0.000430\n",
      " Epoch 25: Train Loss: 0.000391, Validation Loss: 0.000441\n",
      " Epoch 26: Train Loss: 0.000392, Validation Loss: 0.000434\n",
      " Epoch 27: Train Loss: 0.000383, Validation Loss: 0.000398\n",
      " Epoch 28: Train Loss: 0.000380, Validation Loss: 0.000643\n",
      " Epoch 29: Train Loss: 0.001859, Validation Loss: 0.002344\n",
      " Epoch 30: Train Loss: 0.000713, Validation Loss: 0.000628\n",
      " Epoch 31: Train Loss: 0.000567, Validation Loss: 0.000556\n",
      " Epoch 32: Train Loss: 0.000526, Validation Loss: 0.000513\n",
      " Epoch 33: Train Loss: 0.000500, Validation Loss: 0.000488\n",
      " Epoch 34: Train Loss: 0.000476, Validation Loss: 0.000476\n",
      " Epoch 35: Train Loss: 0.000455, Validation Loss: 0.000449\n",
      " Epoch 36: Train Loss: 0.000441, Validation Loss: 0.000431\n",
      " Epoch 37: Train Loss: 0.000422, Validation Loss: 0.000434\n",
      " Epoch 38: Train Loss: 0.000412, Validation Loss: 0.000409\n",
      " Epoch 39: Train Loss: 0.000403, Validation Loss: 0.000404\n",
      " Epoch 40: Train Loss: 0.000397, Validation Loss: 0.000402\n",
      " Epoch 41: Train Loss: 0.000391, Validation Loss: 0.000390\n",
      " Epoch 42: Train Loss: 0.000384, Validation Loss: 0.000387\n",
      " Epoch 43: Train Loss: 0.000380, Validation Loss: 0.000384\n",
      " Epoch 44: Train Loss: 0.000379, Validation Loss: 0.000378\n",
      " Epoch 45: Train Loss: 0.000372, Validation Loss: 0.000373\n",
      " Epoch 46: Train Loss: 0.000368, Validation Loss: 0.000377\n",
      " Epoch 47: Train Loss: 0.000368, Validation Loss: 0.000374\n",
      " Epoch 48: Train Loss: 0.000364, Validation Loss: 0.000387\n",
      " Epoch 49: Train Loss: 0.000357, Validation Loss: 0.000359\n",
      " Epoch 50: Train Loss: 0.000355, Validation Loss: 0.000360\n",
      " Epoch 51: Train Loss: 0.000355, Validation Loss: 0.000355\n",
      " Epoch 52: Train Loss: 0.000345, Validation Loss: 0.000353\n",
      " Epoch 53: Train Loss: 0.000343, Validation Loss: 0.000351\n",
      " Epoch 54: Train Loss: 0.000344, Validation Loss: 0.000352\n",
      " Epoch 55: Train Loss: 0.000346, Validation Loss: 0.000345\n",
      " Epoch 56: Train Loss: 0.000337, Validation Loss: 0.000346\n",
      " Epoch 57: Train Loss: 0.000335, Validation Loss: 0.000352\n",
      " Epoch 58: Train Loss: 0.000330, Validation Loss: 0.000337\n",
      " Epoch 59: Train Loss: 0.000331, Validation Loss: 0.000343\n",
      " Epoch 60: Train Loss: 0.000330, Validation Loss: 0.000358\n",
      " Epoch 61: Train Loss: 0.000325, Validation Loss: 0.000334\n",
      " Epoch 62: Train Loss: 0.000321, Validation Loss: 0.000330\n",
      " Epoch 63: Train Loss: 0.000319, Validation Loss: 0.000331\n",
      " Epoch 64: Train Loss: 0.000318, Validation Loss: 0.000329\n",
      " Epoch 65: Train Loss: 0.000317, Validation Loss: 0.000334\n",
      " Epoch 66: Train Loss: 0.000315, Validation Loss: 0.000329\n",
      " Epoch 67: Train Loss: 0.000316, Validation Loss: 0.000329\n",
      " Epoch 68: Train Loss: 0.000315, Validation Loss: 0.000325\n",
      " Epoch 69: Train Loss: 0.000312, Validation Loss: 0.000323\n",
      " Epoch 70: Train Loss: 0.000311, Validation Loss: 0.000323\n",
      " Epoch 71: Train Loss: 0.000310, Validation Loss: 0.000325\n",
      " Epoch 72: Train Loss: 0.000309, Validation Loss: 0.000323\n",
      " Epoch 73: Train Loss: 0.000309, Validation Loss: 0.000321\n",
      " Epoch 74: Train Loss: 0.000307, Validation Loss: 0.000331\n",
      " Epoch 75: Train Loss: 0.000307, Validation Loss: 0.000320\n",
      " Epoch 76: Train Loss: 0.000304, Validation Loss: 0.000321\n",
      " Epoch 77: Train Loss: 0.000303, Validation Loss: 0.000317\n",
      " Epoch 78: Train Loss: 0.000303, Validation Loss: 0.000315\n",
      " Epoch 79: Train Loss: 0.000301, Validation Loss: 0.000315\n",
      " Epoch 80: Train Loss: 0.000300, Validation Loss: 0.000318\n",
      " Epoch 81: Train Loss: 0.000299, Validation Loss: 0.000313\n",
      " Epoch 82: Train Loss: 0.000298, Validation Loss: 0.000312\n",
      " Epoch 83: Train Loss: 0.000299, Validation Loss: 0.000312\n",
      " Epoch 84: Train Loss: 0.000296, Validation Loss: 0.000310\n",
      " Epoch 85: Train Loss: 0.000296, Validation Loss: 0.000309\n",
      " Epoch 86: Train Loss: 0.000293, Validation Loss: 0.000317\n",
      " Epoch 87: Train Loss: 0.000292, Validation Loss: 0.000311\n",
      " Epoch 88: Train Loss: 0.000291, Validation Loss: 0.000307\n",
      " Epoch 89: Train Loss: 0.000292, Validation Loss: 0.000309\n",
      " Epoch 90: Train Loss: 0.000289, Validation Loss: 0.000305\n",
      " Epoch 91: Train Loss: 0.000287, Validation Loss: 0.000305\n",
      " Epoch 92: Train Loss: 0.000286, Validation Loss: 0.000303\n",
      " Epoch 93: Train Loss: 0.000285, Validation Loss: 0.000310\n",
      " Epoch 94: Train Loss: 0.000285, Validation Loss: 0.000306\n",
      " Epoch 95: Train Loss: 0.000285, Validation Loss: 0.000303\n",
      " Epoch 96: Train Loss: 0.000284, Validation Loss: 0.000303\n",
      " Epoch 97: Train Loss: 0.000283, Validation Loss: 0.000303\n",
      " Epoch 98: Train Loss: 0.000284, Validation Loss: 0.000302\n",
      " Epoch 99: Train Loss: 0.000284, Validation Loss: 0.000302\n",
      " Epoch 100: Train Loss: 0.000281, Validation Loss: 0.000301\n",
      " Epoch 101: Train Loss: 0.000280, Validation Loss: 0.000301\n",
      " Epoch 102: Train Loss: 0.000280, Validation Loss: 0.000306\n",
      " Epoch 103: Train Loss: 0.000280, Validation Loss: 0.000301\n",
      " Epoch 104: Train Loss: 0.000279, Validation Loss: 0.000303\n",
      " Epoch 105: Train Loss: 0.000278, Validation Loss: 0.000304\n",
      " Epoch 106: Train Loss: 0.000278, Validation Loss: 0.000309\n",
      " Epoch 107: Train Loss: 0.000278, Validation Loss: 0.000298\n",
      " Epoch 108: Train Loss: 0.000277, Validation Loss: 0.000298\n",
      " Epoch 109: Train Loss: 0.000277, Validation Loss: 0.000309\n",
      " Epoch 110: Train Loss: 0.000276, Validation Loss: 0.000298\n",
      " Epoch 111: Train Loss: 0.000277, Validation Loss: 0.000298\n",
      " Epoch 112: Train Loss: 0.000275, Validation Loss: 0.000300\n",
      " Epoch 113: Train Loss: 0.000273, Validation Loss: 0.000295\n",
      " Epoch 114: Train Loss: 0.000274, Validation Loss: 0.000296\n",
      " Epoch 115: Train Loss: 0.000274, Validation Loss: 0.000295\n",
      " Epoch 116: Train Loss: 0.000272, Validation Loss: 0.000294\n",
      " Epoch 117: Train Loss: 0.000270, Validation Loss: 0.000295\n",
      " Epoch 118: Train Loss: 0.000271, Validation Loss: 0.000293\n",
      " Epoch 119: Train Loss: 0.000270, Validation Loss: 0.000302\n",
      " Epoch 120: Train Loss: 0.000269, Validation Loss: 0.000294\n",
      " Epoch 121: Train Loss: 0.000267, Validation Loss: 0.000291\n",
      " Epoch 122: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 123: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 124: Train Loss: 0.000267, Validation Loss: 0.000291\n",
      " Epoch 125: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 126: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 127: Train Loss: 0.000265, Validation Loss: 0.000292\n",
      " Epoch 128: Train Loss: 0.000264, Validation Loss: 0.000290\n",
      " Epoch 129: Train Loss: 0.000264, Validation Loss: 0.000291\n",
      " Epoch 130: Train Loss: 0.000264, Validation Loss: 0.000290\n",
      " Epoch 131: Train Loss: 0.000265, Validation Loss: 0.000290\n",
      " Epoch 132: Train Loss: 0.000263, Validation Loss: 0.000292\n",
      " Epoch 133: Train Loss: 0.000263, Validation Loss: 0.000289\n",
      " Epoch 134: Train Loss: 0.000263, Validation Loss: 0.000289\n",
      " Epoch 135: Train Loss: 0.000262, Validation Loss: 0.000290\n",
      " Epoch 136: Train Loss: 0.000262, Validation Loss: 0.000288\n",
      " Epoch 137: Train Loss: 0.000261, Validation Loss: 0.000291\n",
      " Epoch 138: Train Loss: 0.000261, Validation Loss: 0.000288\n",
      " Epoch 139: Train Loss: 0.000261, Validation Loss: 0.000291\n",
      " Epoch 140: Train Loss: 0.000261, Validation Loss: 0.000287\n",
      " Epoch 141: Train Loss: 0.000260, Validation Loss: 0.000288\n",
      " Epoch 142: Train Loss: 0.000261, Validation Loss: 0.000287\n",
      " Epoch 143: Train Loss: 0.000259, Validation Loss: 0.000289\n",
      " Epoch 144: Train Loss: 0.000259, Validation Loss: 0.000289\n",
      " Epoch 145: Train Loss: 0.000259, Validation Loss: 0.000286\n",
      " Epoch 146: Train Loss: 0.000259, Validation Loss: 0.000286\n",
      " Epoch 147: Train Loss: 0.000257, Validation Loss: 0.000287\n",
      " Epoch 148: Train Loss: 0.000257, Validation Loss: 0.000290\n",
      " Epoch 149: Train Loss: 0.000256, Validation Loss: 0.000286\n",
      " Epoch 150: Train Loss: 0.000258, Validation Loss: 0.000285\n",
      " Epoch 151: Train Loss: 0.000255, Validation Loss: 0.000285\n",
      " Epoch 152: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 153: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 154: Train Loss: 0.000254, Validation Loss: 0.000286\n",
      " Epoch 155: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 156: Train Loss: 0.000254, Validation Loss: 0.000287\n",
      " Epoch 157: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 158: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 159: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 160: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 161: Train Loss: 0.000253, Validation Loss: 0.000286\n",
      " Epoch 162: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 163: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 164: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 165: Train Loss: 0.000251, Validation Loss: 0.000284\n",
      " Epoch 166: Train Loss: 0.000251, Validation Loss: 0.000284\n",
      " Epoch 167: Train Loss: 0.000252, Validation Loss: 0.000283\n",
      " Epoch 168: Train Loss: 0.000251, Validation Loss: 0.000287\n",
      " Epoch 169: Train Loss: 0.000251, Validation Loss: 0.000283\n",
      " Epoch 170: Train Loss: 0.000251, Validation Loss: 0.000287\n",
      " Epoch 171: Train Loss: 0.000251, Validation Loss: 0.000283\n",
      " Epoch 172: Train Loss: 0.000250, Validation Loss: 0.000283\n",
      " Epoch 173: Train Loss: 0.000250, Validation Loss: 0.000283\n",
      " Epoch 174: Train Loss: 0.000250, Validation Loss: 0.000282\n",
      " Epoch 175: Train Loss: 0.000249, Validation Loss: 0.000286\n",
      " Epoch 176: Train Loss: 0.000249, Validation Loss: 0.000282\n",
      " Epoch 177: Train Loss: 0.000249, Validation Loss: 0.000283\n",
      " Epoch 178: Train Loss: 0.000249, Validation Loss: 0.000282\n",
      " Epoch 179: Train Loss: 0.000249, Validation Loss: 0.000283\n",
      " Epoch 180: Train Loss: 0.000248, Validation Loss: 0.000284\n",
      " Epoch 181: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 182: Train Loss: 0.000247, Validation Loss: 0.000283\n",
      " Epoch 183: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 184: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 185: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 186: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 187: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 188: Train Loss: 0.000246, Validation Loss: 0.000282\n",
      " Epoch 189: Train Loss: 0.000246, Validation Loss: 0.000282\n",
      " Epoch 190: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 191: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 192: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 193: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 194: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 195: Train Loss: 0.000245, Validation Loss: 0.000282\n",
      " Epoch 196: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 197: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 198: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 199: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 200: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 201: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 202: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 203: Train Loss: 0.000244, Validation Loss: 0.000280\n",
      " Epoch 204: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 205: Train Loss: 0.000243, Validation Loss: 0.000281\n",
      " Epoch 206: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 207: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 208: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 209: Train Loss: 0.000243, Validation Loss: 0.000283\n",
      " Epoch 210: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 211: Train Loss: 0.000242, Validation Loss: 0.000281\n",
      " Epoch 212: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 213: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 214: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 215: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 216: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 217: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 218: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 219: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 220: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 221: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 222: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 223: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 224: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 225: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 226: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 227: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 228: Train Loss: 0.000241, Validation Loss: 0.000282\n",
      " Epoch 229: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 230: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 231: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 232: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 233: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 234: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 235: Train Loss: 0.000240, Validation Loss: 0.000279\n",
      " Epoch 236: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 237: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 238: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 239: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 240: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 241: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 242: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 243: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 244: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 245: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 246: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 247: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 248: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 249: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 250: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 251: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 252: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 253: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 254: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 255: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 256: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 257: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 258: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 259: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 260: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 261: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 262: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 263: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 264: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 265: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 266: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 267: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 268: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 269: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 270: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 271: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 272: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 273: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 274: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 275: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 276: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 277: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 278: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 279: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 280: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 281: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 282: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 283: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 284: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 285: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 286: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 287: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 288: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 289: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 290: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 291: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 292: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 293: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 294: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 295: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 296: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 297: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 298: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 299: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 300: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 301: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 302: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 303: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 304: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 305: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 306: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 307: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 308: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 309: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 310: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 311: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 312: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 313: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 314: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 315: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 316: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 317: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 318: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 319: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 320: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 321: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 322: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 323: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 324: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 325: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 326: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 327: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 328: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 329: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 330: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 331: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 332: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 333: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 334: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 335: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 336: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 337: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 338: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 339: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 340: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 341: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 342: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 343: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 344: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 345: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 346: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 347: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 348: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 349: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 350: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 351: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 352: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 353: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 354: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 355: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 356: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 357: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 358: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 359: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 360: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 361: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 362: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 363: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 364: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 365: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 366: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 367: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 368: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 369: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 370: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 371: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 372: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 373: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 374: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 375: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 376: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 377: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 378: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 379: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 380: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 381: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 382: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 383: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 384: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 385: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 386: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 387: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 388: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 389: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 390: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 391: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 392: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 393: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 394: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 395: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 396: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 397: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 398: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 399: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 400: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 401: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 402: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 403: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 404: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 405: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 406: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 407: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 408: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 409: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 410: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 411: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 412: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 413: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 414: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 415: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 416: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 417: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 418: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 419: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 420: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 421: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 422: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 423: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 424: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 425: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 426: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 427: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 428: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 429: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 430: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 431: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 432: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 433: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 434: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 435: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 436: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 437: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 438: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 439: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 440: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 441: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 442: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 443: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 444: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 445: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 446: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      "Early stopping at epoch 446 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014178, Validation Loss: 0.018114\n",
      " Epoch 2: Train Loss: 0.002815, Validation Loss: 0.003503\n",
      " Epoch 3: Train Loss: 0.001962, Validation Loss: 0.002233\n",
      " Epoch 4: Train Loss: 0.001320, Validation Loss: 0.001201\n",
      " Epoch 5: Train Loss: 0.000923, Validation Loss: 0.000874\n",
      " Epoch 6: Train Loss: 0.000807, Validation Loss: 0.000768\n",
      " Epoch 7: Train Loss: 0.000730, Validation Loss: 0.000700\n",
      " Epoch 8: Train Loss: 0.000672, Validation Loss: 0.000648\n",
      " Epoch 9: Train Loss: 0.000624, Validation Loss: 0.000608\n",
      " Epoch 10: Train Loss: 0.000587, Validation Loss: 0.000580\n",
      " Epoch 11: Train Loss: 0.000551, Validation Loss: 0.000540\n",
      " Epoch 12: Train Loss: 0.000523, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000502, Validation Loss: 0.000501\n",
      " Epoch 14: Train Loss: 0.000483, Validation Loss: 0.000491\n",
      " Epoch 15: Train Loss: 0.000467, Validation Loss: 0.000466\n",
      " Epoch 16: Train Loss: 0.000452, Validation Loss: 0.000459\n",
      " Epoch 17: Train Loss: 0.000439, Validation Loss: 0.000444\n",
      " Epoch 18: Train Loss: 0.000429, Validation Loss: 0.000437\n",
      " Epoch 19: Train Loss: 0.000421, Validation Loss: 0.000430\n",
      " Epoch 20: Train Loss: 0.000411, Validation Loss: 0.000417\n",
      " Epoch 21: Train Loss: 0.000404, Validation Loss: 0.000411\n",
      " Epoch 22: Train Loss: 0.000400, Validation Loss: 0.000409\n",
      " Epoch 23: Train Loss: 0.000390, Validation Loss: 0.000398\n",
      " Epoch 24: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 25: Train Loss: 0.000378, Validation Loss: 0.000389\n",
      " Epoch 26: Train Loss: 0.000373, Validation Loss: 0.000382\n",
      " Epoch 27: Train Loss: 0.000367, Validation Loss: 0.000379\n",
      " Epoch 28: Train Loss: 0.000362, Validation Loss: 0.000379\n",
      " Epoch 29: Train Loss: 0.000359, Validation Loss: 0.000375\n",
      " Epoch 30: Train Loss: 0.000357, Validation Loss: 0.000367\n",
      " Epoch 31: Train Loss: 0.000345, Validation Loss: 0.000361\n",
      " Epoch 32: Train Loss: 0.000342, Validation Loss: 0.000360\n",
      " Epoch 33: Train Loss: 0.000339, Validation Loss: 0.000357\n",
      " Epoch 34: Train Loss: 0.000338, Validation Loss: 0.000356\n",
      " Epoch 35: Train Loss: 0.000336, Validation Loss: 0.000355\n",
      " Epoch 36: Train Loss: 0.000333, Validation Loss: 0.000352\n",
      " Epoch 37: Train Loss: 0.000332, Validation Loss: 0.000350\n",
      " Epoch 38: Train Loss: 0.000329, Validation Loss: 0.000349\n",
      " Epoch 39: Train Loss: 0.000327, Validation Loss: 0.000346\n",
      " Epoch 40: Train Loss: 0.000325, Validation Loss: 0.000344\n",
      " Epoch 41: Train Loss: 0.000323, Validation Loss: 0.000343\n",
      " Epoch 42: Train Loss: 0.000321, Validation Loss: 0.000340\n",
      " Epoch 43: Train Loss: 0.000319, Validation Loss: 0.000342\n",
      " Epoch 44: Train Loss: 0.000317, Validation Loss: 0.000339\n",
      " Epoch 45: Train Loss: 0.000317, Validation Loss: 0.000338\n",
      " Epoch 46: Train Loss: 0.000313, Validation Loss: 0.000335\n",
      " Epoch 47: Train Loss: 0.000313, Validation Loss: 0.000337\n",
      " Epoch 48: Train Loss: 0.000312, Validation Loss: 0.000334\n",
      " Epoch 49: Train Loss: 0.000310, Validation Loss: 0.000332\n",
      " Epoch 50: Train Loss: 0.000306, Validation Loss: 0.000331\n",
      " Epoch 51: Train Loss: 0.000306, Validation Loss: 0.000329\n",
      " Epoch 52: Train Loss: 0.000305, Validation Loss: 0.000329\n",
      " Epoch 53: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 54: Train Loss: 0.000299, Validation Loss: 0.000328\n",
      " Epoch 55: Train Loss: 0.000299, Validation Loss: 0.000321\n",
      " Epoch 56: Train Loss: 0.000300, Validation Loss: 0.000323\n",
      " Epoch 57: Train Loss: 0.000297, Validation Loss: 0.000324\n",
      " Epoch 58: Train Loss: 0.000294, Validation Loss: 0.000323\n",
      " Epoch 59: Train Loss: 0.000294, Validation Loss: 0.000316\n",
      " Epoch 60: Train Loss: 0.000290, Validation Loss: 0.000316\n",
      " Epoch 61: Train Loss: 0.000285, Validation Loss: 0.000313\n",
      " Epoch 62: Train Loss: 0.000285, Validation Loss: 0.000312\n",
      " Epoch 63: Train Loss: 0.000283, Validation Loss: 0.000312\n",
      " Epoch 64: Train Loss: 0.000282, Validation Loss: 0.000312\n",
      " Epoch 65: Train Loss: 0.000284, Validation Loss: 0.000310\n",
      " Epoch 66: Train Loss: 0.000282, Validation Loss: 0.000310\n",
      " Epoch 67: Train Loss: 0.000281, Validation Loss: 0.000310\n",
      " Epoch 68: Train Loss: 0.000280, Validation Loss: 0.000309\n",
      " Epoch 69: Train Loss: 0.000279, Validation Loss: 0.000309\n",
      " Epoch 70: Train Loss: 0.000278, Validation Loss: 0.000308\n",
      " Epoch 71: Train Loss: 0.000277, Validation Loss: 0.000307\n",
      " Epoch 72: Train Loss: 0.000276, Validation Loss: 0.000306\n",
      " Epoch 73: Train Loss: 0.000275, Validation Loss: 0.000307\n",
      " Epoch 74: Train Loss: 0.000275, Validation Loss: 0.000306\n",
      " Epoch 75: Train Loss: 0.000274, Validation Loss: 0.000304\n",
      " Epoch 76: Train Loss: 0.000273, Validation Loss: 0.000304\n",
      " Epoch 77: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 78: Train Loss: 0.000274, Validation Loss: 0.000309\n",
      " Epoch 79: Train Loss: 0.000272, Validation Loss: 0.000304\n",
      " Epoch 80: Train Loss: 0.000270, Validation Loss: 0.000302\n",
      " Epoch 81: Train Loss: 0.000269, Validation Loss: 0.000302\n",
      " Epoch 82: Train Loss: 0.000268, Validation Loss: 0.000303\n",
      " Epoch 83: Train Loss: 0.000267, Validation Loss: 0.000300\n",
      " Epoch 84: Train Loss: 0.000266, Validation Loss: 0.000300\n",
      " Epoch 85: Train Loss: 0.000265, Validation Loss: 0.000301\n",
      " Epoch 86: Train Loss: 0.000265, Validation Loss: 0.000298\n",
      " Epoch 87: Train Loss: 0.000264, Validation Loss: 0.000299\n",
      " Epoch 88: Train Loss: 0.000263, Validation Loss: 0.000299\n",
      " Epoch 89: Train Loss: 0.000263, Validation Loss: 0.000297\n",
      " Epoch 90: Train Loss: 0.000263, Validation Loss: 0.000298\n",
      " Epoch 91: Train Loss: 0.000258, Validation Loss: 0.000295\n",
      " Epoch 92: Train Loss: 0.000257, Validation Loss: 0.000295\n",
      " Epoch 93: Train Loss: 0.000257, Validation Loss: 0.000294\n",
      " Epoch 94: Train Loss: 0.000257, Validation Loss: 0.000298\n",
      " Epoch 95: Train Loss: 0.000257, Validation Loss: 0.000295\n",
      " Epoch 96: Train Loss: 0.000255, Validation Loss: 0.000294\n",
      " Epoch 97: Train Loss: 0.000255, Validation Loss: 0.000293\n",
      " Epoch 98: Train Loss: 0.000255, Validation Loss: 0.000293\n",
      " Epoch 99: Train Loss: 0.000254, Validation Loss: 0.000293\n",
      " Epoch 100: Train Loss: 0.000253, Validation Loss: 0.000293\n",
      " Epoch 101: Train Loss: 0.000253, Validation Loss: 0.000292\n",
      " Epoch 102: Train Loss: 0.000252, Validation Loss: 0.000292\n",
      " Epoch 103: Train Loss: 0.000252, Validation Loss: 0.000291\n",
      " Epoch 104: Train Loss: 0.000251, Validation Loss: 0.000291\n",
      " Epoch 105: Train Loss: 0.000251, Validation Loss: 0.000291\n",
      " Epoch 106: Train Loss: 0.000250, Validation Loss: 0.000291\n",
      " Epoch 107: Train Loss: 0.000250, Validation Loss: 0.000290\n",
      " Epoch 108: Train Loss: 0.000249, Validation Loss: 0.000290\n",
      " Epoch 109: Train Loss: 0.000249, Validation Loss: 0.000291\n",
      " Epoch 110: Train Loss: 0.000248, Validation Loss: 0.000290\n",
      " Epoch 111: Train Loss: 0.000249, Validation Loss: 0.000291\n",
      " Epoch 112: Train Loss: 0.000248, Validation Loss: 0.000290\n",
      " Epoch 113: Train Loss: 0.000247, Validation Loss: 0.000289\n",
      " Epoch 114: Train Loss: 0.000246, Validation Loss: 0.000288\n",
      " Epoch 115: Train Loss: 0.000247, Validation Loss: 0.000290\n",
      " Epoch 116: Train Loss: 0.000246, Validation Loss: 0.000288\n",
      " Epoch 117: Train Loss: 0.000245, Validation Loss: 0.000288\n",
      " Epoch 118: Train Loss: 0.000244, Validation Loss: 0.000287\n",
      " Epoch 119: Train Loss: 0.000243, Validation Loss: 0.000287\n",
      " Epoch 120: Train Loss: 0.000243, Validation Loss: 0.000287\n",
      " Epoch 121: Train Loss: 0.000241, Validation Loss: 0.000285\n",
      " Epoch 122: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 123: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 124: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 125: Train Loss: 0.000240, Validation Loss: 0.000285\n",
      " Epoch 126: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 127: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 128: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 129: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 130: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 131: Train Loss: 0.000237, Validation Loss: 0.000285\n",
      " Epoch 132: Train Loss: 0.000237, Validation Loss: 0.000284\n",
      " Epoch 133: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 134: Train Loss: 0.000237, Validation Loss: 0.000284\n",
      " Epoch 135: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 136: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 137: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 138: Train Loss: 0.000235, Validation Loss: 0.000284\n",
      " Epoch 139: Train Loss: 0.000235, Validation Loss: 0.000284\n",
      " Epoch 140: Train Loss: 0.000235, Validation Loss: 0.000283\n",
      " Epoch 141: Train Loss: 0.000234, Validation Loss: 0.000284\n",
      " Epoch 142: Train Loss: 0.000234, Validation Loss: 0.000284\n",
      " Epoch 143: Train Loss: 0.000235, Validation Loss: 0.000283\n",
      " Epoch 144: Train Loss: 0.000234, Validation Loss: 0.000283\n",
      " Epoch 145: Train Loss: 0.000233, Validation Loss: 0.000283\n",
      " Epoch 146: Train Loss: 0.000233, Validation Loss: 0.000283\n",
      " Epoch 147: Train Loss: 0.000232, Validation Loss: 0.000283\n",
      " Epoch 148: Train Loss: 0.000232, Validation Loss: 0.000282\n",
      " Epoch 149: Train Loss: 0.000231, Validation Loss: 0.000282\n",
      " Epoch 150: Train Loss: 0.000231, Validation Loss: 0.000282\n",
      " Epoch 151: Train Loss: 0.000230, Validation Loss: 0.000282\n",
      " Epoch 152: Train Loss: 0.000230, Validation Loss: 0.000281\n",
      " Epoch 153: Train Loss: 0.000230, Validation Loss: 0.000282\n",
      " Epoch 154: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 155: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 156: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 157: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 158: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 159: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 160: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 161: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 162: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 163: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 164: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 165: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 166: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 167: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 168: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 169: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 170: Train Loss: 0.000226, Validation Loss: 0.000281\n",
      " Epoch 171: Train Loss: 0.000226, Validation Loss: 0.000281\n",
      " Epoch 172: Train Loss: 0.000226, Validation Loss: 0.000280\n",
      " Epoch 173: Train Loss: 0.000225, Validation Loss: 0.000281\n",
      " Epoch 174: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 175: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 176: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 177: Train Loss: 0.000224, Validation Loss: 0.000280\n",
      " Epoch 178: Train Loss: 0.000224, Validation Loss: 0.000280\n",
      " Epoch 179: Train Loss: 0.000224, Validation Loss: 0.000281\n",
      " Epoch 180: Train Loss: 0.000224, Validation Loss: 0.000281\n",
      " Epoch 181: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 182: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 183: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 184: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 185: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 186: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 187: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 188: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 189: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 190: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 191: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 192: Train Loss: 0.000221, Validation Loss: 0.000280\n",
      " Epoch 193: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 194: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 195: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 196: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 197: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 198: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 199: Train Loss: 0.000220, Validation Loss: 0.000280\n",
      " Epoch 200: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 201: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 202: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 203: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 204: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 205: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 206: Train Loss: 0.000220, Validation Loss: 0.000280\n",
      " Epoch 207: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 208: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 209: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 210: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 211: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 212: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 213: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 214: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 215: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 216: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 217: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 218: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 219: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 220: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 221: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 222: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 223: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 224: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 225: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 226: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 227: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 228: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 229: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 230: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 231: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 232: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 233: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 234: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 235: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 236: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 237: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 238: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 239: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 240: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 241: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 242: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 243: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 244: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 245: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 246: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 247: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 248: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 249: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 250: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 251: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 252: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 253: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 254: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 255: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 256: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 257: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 258: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 259: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 260: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 261: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 262: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 263: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 264: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 265: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 266: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 267: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 268: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 269: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 270: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 271: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 272: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 273: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 274: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 275: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 276: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 277: Train Loss: 0.000214, Validation Loss: 0.000279\n",
      " Epoch 278: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 279: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 280: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 281: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 282: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 283: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 284: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 285: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 286: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 287: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 288: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 289: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 290: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 291: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 292: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 293: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 294: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 295: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 296: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 297: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 298: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 299: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 300: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 301: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 302: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 303: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 304: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 305: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 306: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 307: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 308: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 309: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 310: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 311: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 312: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 313: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 314: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 315: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 316: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 317: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 318: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 319: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 320: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 321: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 322: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 323: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 324: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 325: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 326: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 327: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 328: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 329: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 330: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 331: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 332: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 333: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 334: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 335: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 336: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 337: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 338: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 339: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 340: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 341: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 342: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 343: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 344: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 345: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 346: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 347: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 348: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 349: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 350: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 351: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 352: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 353: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 354: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 355: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 356: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 357: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 358: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 359: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 360: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 361: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 362: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 363: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 364: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 365: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 366: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 367: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 368: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 369: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 370: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 371: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 372: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 373: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 374: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 375: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 376: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 377: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 378: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 379: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 380: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 381: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 382: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 383: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 384: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 385: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 386: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 387: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 388: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 389: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 390: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      "Early stopping at epoch 390 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012375, Validation Loss: 0.029329\n",
      " Epoch 2: Train Loss: 0.002698, Validation Loss: 0.005570\n",
      " Epoch 3: Train Loss: 0.001861, Validation Loss: 0.001761\n",
      " Epoch 4: Train Loss: 0.001559, Validation Loss: 0.001402\n",
      " Epoch 5: Train Loss: 0.001243, Validation Loss: 0.001192\n",
      " Epoch 6: Train Loss: 0.000926, Validation Loss: 0.000858\n",
      " Epoch 7: Train Loss: 0.000700, Validation Loss: 0.000683\n",
      " Epoch 8: Train Loss: 0.000632, Validation Loss: 0.000611\n",
      " Epoch 9: Train Loss: 0.000583, Validation Loss: 0.000576\n",
      " Epoch 10: Train Loss: 0.000547, Validation Loss: 0.000542\n",
      " Epoch 11: Train Loss: 0.000515, Validation Loss: 0.000507\n",
      " Epoch 12: Train Loss: 0.000489, Validation Loss: 0.000505\n",
      " Epoch 13: Train Loss: 0.000468, Validation Loss: 0.000467\n",
      " Epoch 14: Train Loss: 0.000451, Validation Loss: 0.000453\n",
      " Epoch 15: Train Loss: 0.000439, Validation Loss: 0.000439\n",
      " Epoch 16: Train Loss: 0.000425, Validation Loss: 0.000429\n",
      " Epoch 17: Train Loss: 0.000414, Validation Loss: 0.000420\n",
      " Epoch 18: Train Loss: 0.000406, Validation Loss: 0.000410\n",
      " Epoch 19: Train Loss: 0.000399, Validation Loss: 0.000407\n",
      " Epoch 20: Train Loss: 0.000391, Validation Loss: 0.000406\n",
      " Epoch 21: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 22: Train Loss: 0.000377, Validation Loss: 0.000397\n",
      " Epoch 23: Train Loss: 0.000374, Validation Loss: 0.000391\n",
      " Epoch 24: Train Loss: 0.000370, Validation Loss: 0.000388\n",
      " Epoch 25: Train Loss: 0.000362, Validation Loss: 0.000374\n",
      " Epoch 26: Train Loss: 0.000354, Validation Loss: 0.000381\n",
      " Epoch 27: Train Loss: 0.000353, Validation Loss: 0.000386\n",
      " Epoch 28: Train Loss: 0.000350, Validation Loss: 0.000363\n",
      " Epoch 29: Train Loss: 0.000341, Validation Loss: 0.000360\n",
      " Epoch 30: Train Loss: 0.000342, Validation Loss: 0.000354\n",
      " Epoch 31: Train Loss: 0.000330, Validation Loss: 0.000349\n",
      " Epoch 32: Train Loss: 0.000327, Validation Loss: 0.000348\n",
      " Epoch 33: Train Loss: 0.000325, Validation Loss: 0.000346\n",
      " Epoch 34: Train Loss: 0.000324, Validation Loss: 0.000345\n",
      " Epoch 35: Train Loss: 0.000322, Validation Loss: 0.000343\n",
      " Epoch 36: Train Loss: 0.000320, Validation Loss: 0.000341\n",
      " Epoch 37: Train Loss: 0.000318, Validation Loss: 0.000340\n",
      " Epoch 38: Train Loss: 0.000316, Validation Loss: 0.000339\n",
      " Epoch 39: Train Loss: 0.000316, Validation Loss: 0.000339\n",
      " Epoch 40: Train Loss: 0.000313, Validation Loss: 0.000335\n",
      " Epoch 41: Train Loss: 0.000312, Validation Loss: 0.000337\n",
      " Epoch 42: Train Loss: 0.000309, Validation Loss: 0.000332\n",
      " Epoch 43: Train Loss: 0.000307, Validation Loss: 0.000331\n",
      " Epoch 44: Train Loss: 0.000309, Validation Loss: 0.000332\n",
      " Epoch 45: Train Loss: 0.000305, Validation Loss: 0.000328\n",
      " Epoch 46: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 47: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 48: Train Loss: 0.000299, Validation Loss: 0.000327\n",
      " Epoch 49: Train Loss: 0.000298, Validation Loss: 0.000324\n",
      " Epoch 50: Train Loss: 0.000296, Validation Loss: 0.000325\n",
      " Epoch 51: Train Loss: 0.000295, Validation Loss: 0.000323\n",
      " Epoch 52: Train Loss: 0.000294, Validation Loss: 0.000320\n",
      " Epoch 53: Train Loss: 0.000292, Validation Loss: 0.000321\n",
      " Epoch 54: Train Loss: 0.000289, Validation Loss: 0.000321\n",
      " Epoch 55: Train Loss: 0.000289, Validation Loss: 0.000316\n",
      " Epoch 56: Train Loss: 0.000288, Validation Loss: 0.000314\n",
      " Epoch 57: Train Loss: 0.000287, Validation Loss: 0.000314\n",
      " Epoch 58: Train Loss: 0.000285, Validation Loss: 0.000313\n",
      " Epoch 59: Train Loss: 0.000283, Validation Loss: 0.000314\n",
      " Epoch 60: Train Loss: 0.000279, Validation Loss: 0.000311\n",
      " Epoch 61: Train Loss: 0.000276, Validation Loss: 0.000308\n",
      " Epoch 62: Train Loss: 0.000274, Validation Loss: 0.000307\n",
      " Epoch 63: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 64: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 65: Train Loss: 0.000272, Validation Loss: 0.000306\n",
      " Epoch 66: Train Loss: 0.000271, Validation Loss: 0.000306\n",
      " Epoch 67: Train Loss: 0.000270, Validation Loss: 0.000305\n",
      " Epoch 68: Train Loss: 0.000270, Validation Loss: 0.000305\n",
      " Epoch 69: Train Loss: 0.000269, Validation Loss: 0.000304\n",
      " Epoch 70: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 71: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 72: Train Loss: 0.000266, Validation Loss: 0.000304\n",
      " Epoch 73: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 74: Train Loss: 0.000265, Validation Loss: 0.000301\n",
      " Epoch 75: Train Loss: 0.000264, Validation Loss: 0.000301\n",
      " Epoch 76: Train Loss: 0.000264, Validation Loss: 0.000300\n",
      " Epoch 77: Train Loss: 0.000262, Validation Loss: 0.000300\n",
      " Epoch 78: Train Loss: 0.000261, Validation Loss: 0.000301\n",
      " Epoch 79: Train Loss: 0.000262, Validation Loss: 0.000301\n",
      " Epoch 80: Train Loss: 0.000261, Validation Loss: 0.000300\n",
      " Epoch 81: Train Loss: 0.000262, Validation Loss: 0.000298\n",
      " Epoch 82: Train Loss: 0.000259, Validation Loss: 0.000297\n",
      " Epoch 83: Train Loss: 0.000257, Validation Loss: 0.000300\n",
      " Epoch 84: Train Loss: 0.000256, Validation Loss: 0.000297\n",
      " Epoch 85: Train Loss: 0.000257, Validation Loss: 0.000298\n",
      " Epoch 86: Train Loss: 0.000258, Validation Loss: 0.000300\n",
      " Epoch 87: Train Loss: 0.000254, Validation Loss: 0.000298\n",
      " Epoch 88: Train Loss: 0.000252, Validation Loss: 0.000296\n",
      " Epoch 89: Train Loss: 0.000253, Validation Loss: 0.000294\n",
      " Epoch 90: Train Loss: 0.000252, Validation Loss: 0.000294\n",
      " Epoch 91: Train Loss: 0.000248, Validation Loss: 0.000293\n",
      " Epoch 92: Train Loss: 0.000247, Validation Loss: 0.000293\n",
      " Epoch 93: Train Loss: 0.000246, Validation Loss: 0.000292\n",
      " Epoch 94: Train Loss: 0.000247, Validation Loss: 0.000292\n",
      " Epoch 95: Train Loss: 0.000247, Validation Loss: 0.000292\n",
      " Epoch 96: Train Loss: 0.000245, Validation Loss: 0.000292\n",
      " Epoch 97: Train Loss: 0.000244, Validation Loss: 0.000292\n",
      " Epoch 98: Train Loss: 0.000244, Validation Loss: 0.000293\n",
      " Epoch 99: Train Loss: 0.000244, Validation Loss: 0.000292\n",
      " Epoch 100: Train Loss: 0.000243, Validation Loss: 0.000291\n",
      " Epoch 101: Train Loss: 0.000244, Validation Loss: 0.000291\n",
      " Epoch 102: Train Loss: 0.000243, Validation Loss: 0.000291\n",
      " Epoch 103: Train Loss: 0.000242, Validation Loss: 0.000291\n",
      " Epoch 104: Train Loss: 0.000242, Validation Loss: 0.000290\n",
      " Epoch 105: Train Loss: 0.000241, Validation Loss: 0.000292\n",
      " Epoch 106: Train Loss: 0.000242, Validation Loss: 0.000290\n",
      " Epoch 107: Train Loss: 0.000240, Validation Loss: 0.000290\n",
      " Epoch 108: Train Loss: 0.000240, Validation Loss: 0.000291\n",
      " Epoch 109: Train Loss: 0.000239, Validation Loss: 0.000290\n",
      " Epoch 110: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 111: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 112: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 113: Train Loss: 0.000237, Validation Loss: 0.000288\n",
      " Epoch 114: Train Loss: 0.000237, Validation Loss: 0.000290\n",
      " Epoch 115: Train Loss: 0.000236, Validation Loss: 0.000289\n",
      " Epoch 116: Train Loss: 0.000235, Validation Loss: 0.000288\n",
      " Epoch 117: Train Loss: 0.000236, Validation Loss: 0.000288\n",
      " Epoch 118: Train Loss: 0.000234, Validation Loss: 0.000288\n",
      " Epoch 119: Train Loss: 0.000234, Validation Loss: 0.000288\n",
      " Epoch 120: Train Loss: 0.000233, Validation Loss: 0.000288\n",
      " Epoch 121: Train Loss: 0.000231, Validation Loss: 0.000287\n",
      " Epoch 122: Train Loss: 0.000231, Validation Loss: 0.000288\n",
      " Epoch 123: Train Loss: 0.000231, Validation Loss: 0.000287\n",
      " Epoch 124: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 125: Train Loss: 0.000230, Validation Loss: 0.000288\n",
      " Epoch 126: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 127: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 128: Train Loss: 0.000229, Validation Loss: 0.000286\n",
      " Epoch 129: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 130: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 131: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 132: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 133: Train Loss: 0.000227, Validation Loss: 0.000286\n",
      " Epoch 134: Train Loss: 0.000227, Validation Loss: 0.000286\n",
      " Epoch 135: Train Loss: 0.000226, Validation Loss: 0.000287\n",
      " Epoch 136: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 137: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 138: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 139: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 140: Train Loss: 0.000225, Validation Loss: 0.000286\n",
      " Epoch 141: Train Loss: 0.000225, Validation Loss: 0.000286\n",
      " Epoch 142: Train Loss: 0.000224, Validation Loss: 0.000286\n",
      " Epoch 143: Train Loss: 0.000224, Validation Loss: 0.000286\n",
      " Epoch 144: Train Loss: 0.000224, Validation Loss: 0.000285\n",
      " Epoch 145: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 146: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 147: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 148: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 149: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 150: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 151: Train Loss: 0.000220, Validation Loss: 0.000285\n",
      " Epoch 152: Train Loss: 0.000220, Validation Loss: 0.000284\n",
      " Epoch 153: Train Loss: 0.000220, Validation Loss: 0.000284\n",
      " Epoch 154: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 155: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 156: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 157: Train Loss: 0.000219, Validation Loss: 0.000284\n",
      " Epoch 158: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 159: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 160: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 161: Train Loss: 0.000218, Validation Loss: 0.000284\n",
      " Epoch 162: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 163: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 164: Train Loss: 0.000217, Validation Loss: 0.000284\n",
      " Epoch 165: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 166: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 167: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 168: Train Loss: 0.000216, Validation Loss: 0.000284\n",
      " Epoch 169: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 170: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 171: Train Loss: 0.000216, Validation Loss: 0.000284\n",
      " Epoch 172: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 173: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 174: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 175: Train Loss: 0.000215, Validation Loss: 0.000284\n",
      " Epoch 176: Train Loss: 0.000215, Validation Loss: 0.000284\n",
      " Epoch 177: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 178: Train Loss: 0.000214, Validation Loss: 0.000284\n",
      " Epoch 179: Train Loss: 0.000214, Validation Loss: 0.000285\n",
      " Epoch 180: Train Loss: 0.000214, Validation Loss: 0.000284\n",
      " Epoch 181: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 182: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 183: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 184: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 185: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 186: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 187: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 188: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 189: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 190: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 191: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 192: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 193: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 194: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 195: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 196: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 197: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 198: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 199: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 200: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 201: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 202: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 203: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 204: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 205: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 206: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      "Early stopping at epoch 206 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.024109, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.005868, Validation Loss: 0.017491\n",
      " Epoch 3: Train Loss: 0.003269, Validation Loss: 0.002703\n",
      " Epoch 4: Train Loss: 0.002206, Validation Loss: 0.001676\n",
      " Epoch 5: Train Loss: 0.001774, Validation Loss: 0.001300\n",
      " Epoch 6: Train Loss: 0.001534, Validation Loss: 0.001087\n",
      " Epoch 7: Train Loss: 0.001383, Validation Loss: 0.000987\n",
      " Epoch 8: Train Loss: 0.001275, Validation Loss: 0.000886\n",
      " Epoch 9: Train Loss: 0.001189, Validation Loss: 0.000812\n",
      " Epoch 10: Train Loss: 0.001120, Validation Loss: 0.000808\n",
      " Epoch 11: Train Loss: 0.001066, Validation Loss: 0.000713\n",
      " Epoch 12: Train Loss: 0.001022, Validation Loss: 0.000719\n",
      " Epoch 13: Train Loss: 0.000986, Validation Loss: 0.000646\n",
      " Epoch 14: Train Loss: 0.000955, Validation Loss: 0.000629\n",
      " Epoch 15: Train Loss: 0.000916, Validation Loss: 0.000610\n",
      " Epoch 16: Train Loss: 0.000890, Validation Loss: 0.000567\n",
      " Epoch 17: Train Loss: 0.000868, Validation Loss: 0.000607\n",
      " Epoch 18: Train Loss: 0.000845, Validation Loss: 0.000545\n",
      " Epoch 19: Train Loss: 0.000826, Validation Loss: 0.000527\n",
      " Epoch 20: Train Loss: 0.000820, Validation Loss: 0.000618\n",
      " Epoch 21: Train Loss: 0.000798, Validation Loss: 0.000523\n",
      " Epoch 22: Train Loss: 0.000774, Validation Loss: 0.000549\n",
      " Epoch 23: Train Loss: 0.000760, Validation Loss: 0.000488\n",
      " Epoch 24: Train Loss: 0.000748, Validation Loss: 0.000518\n",
      " Epoch 25: Train Loss: 0.000733, Validation Loss: 0.000499\n",
      " Epoch 26: Train Loss: 0.000723, Validation Loss: 0.000480\n",
      " Epoch 27: Train Loss: 0.000712, Validation Loss: 0.000475\n",
      " Epoch 28: Train Loss: 0.000702, Validation Loss: 0.000522\n",
      " Epoch 29: Train Loss: 0.000693, Validation Loss: 0.000462\n",
      " Epoch 30: Train Loss: 0.000682, Validation Loss: 0.000479\n",
      " Epoch 31: Train Loss: 0.000673, Validation Loss: 0.000453\n",
      " Epoch 32: Train Loss: 0.000667, Validation Loss: 0.000465\n",
      " Epoch 33: Train Loss: 0.000662, Validation Loss: 0.000478\n",
      " Epoch 34: Train Loss: 0.000661, Validation Loss: 0.000461\n",
      " Epoch 35: Train Loss: 0.000654, Validation Loss: 0.000446\n",
      " Epoch 36: Train Loss: 0.000650, Validation Loss: 0.000472\n",
      " Epoch 37: Train Loss: 0.000647, Validation Loss: 0.000452\n",
      " Epoch 38: Train Loss: 0.000640, Validation Loss: 0.000459\n",
      " Epoch 39: Train Loss: 0.000641, Validation Loss: 0.000436\n",
      " Epoch 40: Train Loss: 0.000635, Validation Loss: 0.000443\n",
      " Epoch 41: Train Loss: 0.000629, Validation Loss: 0.000433\n",
      " Epoch 42: Train Loss: 0.000626, Validation Loss: 0.000428\n",
      " Epoch 43: Train Loss: 0.000622, Validation Loss: 0.000427\n",
      " Epoch 44: Train Loss: 0.000620, Validation Loss: 0.000461\n",
      " Epoch 45: Train Loss: 0.000616, Validation Loss: 0.000443\n",
      " Epoch 46: Train Loss: 0.000612, Validation Loss: 0.000454\n",
      " Epoch 47: Train Loss: 0.000611, Validation Loss: 0.000420\n",
      " Epoch 48: Train Loss: 0.000602, Validation Loss: 0.000423\n",
      " Epoch 49: Train Loss: 0.000601, Validation Loss: 0.000432\n",
      " Epoch 50: Train Loss: 0.000600, Validation Loss: 0.000422\n",
      " Epoch 51: Train Loss: 0.000593, Validation Loss: 0.000443\n",
      " Epoch 52: Train Loss: 0.000591, Validation Loss: 0.000434\n",
      " Epoch 53: Train Loss: 0.000585, Validation Loss: 0.000428\n",
      " Epoch 54: Train Loss: 0.000583, Validation Loss: 0.000451\n",
      " Epoch 55: Train Loss: 0.000581, Validation Loss: 0.000404\n",
      " Epoch 56: Train Loss: 0.000577, Validation Loss: 0.000433\n",
      " Epoch 57: Train Loss: 0.000574, Validation Loss: 0.000399\n",
      " Epoch 58: Train Loss: 0.000571, Validation Loss: 0.000453\n",
      " Epoch 59: Train Loss: 0.000570, Validation Loss: 0.000436\n",
      " Epoch 60: Train Loss: 0.000565, Validation Loss: 0.000433\n",
      " Epoch 61: Train Loss: 0.000559, Validation Loss: 0.000438\n",
      " Epoch 62: Train Loss: 0.000558, Validation Loss: 0.000413\n",
      " Epoch 63: Train Loss: 0.000554, Validation Loss: 0.000434\n",
      " Epoch 64: Train Loss: 0.000554, Validation Loss: 0.000402\n",
      " Epoch 65: Train Loss: 0.000553, Validation Loss: 0.000457\n",
      " Epoch 66: Train Loss: 0.000552, Validation Loss: 0.000423\n",
      " Epoch 67: Train Loss: 0.000550, Validation Loss: 0.000414\n",
      " Epoch 68: Train Loss: 0.000548, Validation Loss: 0.000423\n",
      " Epoch 69: Train Loss: 0.000545, Validation Loss: 0.000440\n",
      " Epoch 70: Train Loss: 0.000546, Validation Loss: 0.000395\n",
      " Epoch 71: Train Loss: 0.000544, Validation Loss: 0.000409\n",
      " Epoch 72: Train Loss: 0.000542, Validation Loss: 0.000417\n",
      " Epoch 73: Train Loss: 0.000544, Validation Loss: 0.000428\n",
      " Epoch 74: Train Loss: 0.000539, Validation Loss: 0.000436\n",
      " Epoch 75: Train Loss: 0.000537, Validation Loss: 0.000417\n",
      " Epoch 76: Train Loss: 0.000537, Validation Loss: 0.000448\n",
      " Epoch 77: Train Loss: 0.000535, Validation Loss: 0.000415\n",
      " Epoch 78: Train Loss: 0.000533, Validation Loss: 0.000437\n",
      " Epoch 79: Train Loss: 0.000530, Validation Loss: 0.000415\n",
      " Epoch 80: Train Loss: 0.000534, Validation Loss: 0.000427\n",
      " Epoch 81: Train Loss: 0.000528, Validation Loss: 0.000429\n",
      " Epoch 82: Train Loss: 0.000526, Validation Loss: 0.000407\n",
      " Epoch 83: Train Loss: 0.000527, Validation Loss: 0.000405\n",
      " Epoch 84: Train Loss: 0.000525, Validation Loss: 0.000431\n",
      " Epoch 85: Train Loss: 0.000522, Validation Loss: 0.000419\n",
      " Epoch 86: Train Loss: 0.000520, Validation Loss: 0.000406\n",
      " Epoch 87: Train Loss: 0.000521, Validation Loss: 0.000415\n",
      " Epoch 88: Train Loss: 0.000521, Validation Loss: 0.000411\n",
      " Epoch 89: Train Loss: 0.000515, Validation Loss: 0.000430\n",
      " Epoch 90: Train Loss: 0.000515, Validation Loss: 0.000451\n",
      "Early stopping at epoch 90 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.023452, Validation Loss: 0.029496\n",
      " Epoch 2: Train Loss: 0.006325, Validation Loss: 0.017793\n",
      " Epoch 3: Train Loss: 0.003521, Validation Loss: 0.003373\n",
      " Epoch 4: Train Loss: 0.002210, Validation Loss: 0.001927\n",
      " Epoch 5: Train Loss: 0.001697, Validation Loss: 0.001200\n",
      " Epoch 6: Train Loss: 0.001458, Validation Loss: 0.001043\n",
      " Epoch 7: Train Loss: 0.001317, Validation Loss: 0.000903\n",
      " Epoch 8: Train Loss: 0.001227, Validation Loss: 0.000887\n",
      " Epoch 9: Train Loss: 0.001160, Validation Loss: 0.000831\n",
      " Epoch 10: Train Loss: 0.001086, Validation Loss: 0.000742\n",
      " Epoch 11: Train Loss: 0.001039, Validation Loss: 0.000738\n",
      " Epoch 12: Train Loss: 0.001005, Validation Loss: 0.000683\n",
      " Epoch 13: Train Loss: 0.000978, Validation Loss: 0.000690\n",
      " Epoch 14: Train Loss: 0.001272, Validation Loss: 0.001010\n",
      " Epoch 15: Train Loss: 0.001001, Validation Loss: 0.000687\n",
      " Epoch 16: Train Loss: 0.000934, Validation Loss: 0.000644\n",
      " Epoch 17: Train Loss: 0.000901, Validation Loss: 0.000601\n",
      " Epoch 18: Train Loss: 0.000879, Validation Loss: 0.000601\n",
      " Epoch 19: Train Loss: 0.000854, Validation Loss: 0.000570\n",
      " Epoch 20: Train Loss: 0.000830, Validation Loss: 0.000572\n",
      " Epoch 21: Train Loss: 0.000816, Validation Loss: 0.000551\n",
      " Epoch 22: Train Loss: 0.000801, Validation Loss: 0.000541\n",
      " Epoch 23: Train Loss: 0.000790, Validation Loss: 0.000526\n",
      " Epoch 24: Train Loss: 0.000767, Validation Loss: 0.000549\n",
      " Epoch 25: Train Loss: 0.000760, Validation Loss: 0.000517\n",
      " Epoch 26: Train Loss: 0.000744, Validation Loss: 0.000542\n",
      " Epoch 27: Train Loss: 0.000735, Validation Loss: 0.000496\n",
      " Epoch 28: Train Loss: 0.000727, Validation Loss: 0.000500\n",
      " Epoch 29: Train Loss: 0.000710, Validation Loss: 0.000521\n",
      " Epoch 30: Train Loss: 0.000702, Validation Loss: 0.000522\n",
      " Epoch 31: Train Loss: 0.000692, Validation Loss: 0.000495\n",
      " Epoch 32: Train Loss: 0.000687, Validation Loss: 0.000477\n",
      " Epoch 33: Train Loss: 0.000685, Validation Loss: 0.000523\n",
      " Epoch 34: Train Loss: 0.000681, Validation Loss: 0.000469\n",
      " Epoch 35: Train Loss: 0.000672, Validation Loss: 0.000463\n",
      " Epoch 36: Train Loss: 0.000669, Validation Loss: 0.000501\n",
      " Epoch 37: Train Loss: 0.000667, Validation Loss: 0.000519\n",
      " Epoch 38: Train Loss: 0.000660, Validation Loss: 0.000528\n",
      " Epoch 39: Train Loss: 0.000658, Validation Loss: 0.000474\n",
      " Epoch 40: Train Loss: 0.000649, Validation Loss: 0.000476\n",
      " Epoch 41: Train Loss: 0.000651, Validation Loss: 0.000435\n",
      " Epoch 42: Train Loss: 0.000653, Validation Loss: 0.000488\n",
      " Epoch 43: Train Loss: 0.000643, Validation Loss: 0.000448\n",
      " Epoch 44: Train Loss: 0.000633, Validation Loss: 0.000467\n",
      " Epoch 45: Train Loss: 0.000631, Validation Loss: 0.000467\n",
      " Epoch 46: Train Loss: 0.000630, Validation Loss: 0.000425\n",
      " Epoch 47: Train Loss: 0.000628, Validation Loss: 0.000449\n",
      " Epoch 48: Train Loss: 0.000618, Validation Loss: 0.000465\n",
      " Epoch 49: Train Loss: 0.000620, Validation Loss: 0.000531\n",
      " Epoch 50: Train Loss: 0.000613, Validation Loss: 0.000518\n",
      " Epoch 51: Train Loss: 0.000615, Validation Loss: 0.000504\n",
      " Epoch 52: Train Loss: 0.000605, Validation Loss: 0.000439\n",
      " Epoch 53: Train Loss: 0.000605, Validation Loss: 0.000423\n",
      " Epoch 54: Train Loss: 0.000597, Validation Loss: 0.000436\n",
      " Epoch 55: Train Loss: 0.000598, Validation Loss: 0.000441\n",
      " Epoch 56: Train Loss: 0.000596, Validation Loss: 0.000468\n",
      " Epoch 57: Train Loss: 0.000592, Validation Loss: 0.000542\n",
      " Epoch 58: Train Loss: 0.000587, Validation Loss: 0.000475\n",
      " Epoch 59: Train Loss: 0.000582, Validation Loss: 0.000458\n",
      " Epoch 60: Train Loss: 0.000580, Validation Loss: 0.000446\n",
      " Epoch 61: Train Loss: 0.000574, Validation Loss: 0.000476\n",
      " Epoch 62: Train Loss: 0.000572, Validation Loss: 0.000473\n",
      " Epoch 63: Train Loss: 0.000571, Validation Loss: 0.000449\n",
      " Epoch 64: Train Loss: 0.000570, Validation Loss: 0.000454\n",
      " Epoch 65: Train Loss: 0.000566, Validation Loss: 0.000460\n",
      " Epoch 66: Train Loss: 0.000566, Validation Loss: 0.000461\n",
      " Epoch 67: Train Loss: 0.000564, Validation Loss: 0.000426\n",
      " Epoch 68: Train Loss: 0.000563, Validation Loss: 0.000426\n",
      " Epoch 69: Train Loss: 0.000561, Validation Loss: 0.000433\n",
      " Epoch 70: Train Loss: 0.000560, Validation Loss: 0.000455\n",
      " Epoch 71: Train Loss: 0.000557, Validation Loss: 0.000466\n",
      " Epoch 72: Train Loss: 0.000557, Validation Loss: 0.000442\n",
      " Epoch 73: Train Loss: 0.000555, Validation Loss: 0.000548\n",
      "Early stopping at epoch 73 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.021412, Validation Loss: 0.020440\n",
      " Epoch 2: Train Loss: 0.006966, Validation Loss: 0.009168\n",
      " Epoch 3: Train Loss: 0.004020, Validation Loss: 0.003114\n",
      " Epoch 4: Train Loss: 0.002555, Validation Loss: 0.002011\n",
      " Epoch 5: Train Loss: 0.002070, Validation Loss: 0.001531\n",
      " Epoch 6: Train Loss: 0.001623, Validation Loss: 0.001050\n",
      " Epoch 7: Train Loss: 0.001294, Validation Loss: 0.000862\n",
      " Epoch 8: Train Loss: 0.001165, Validation Loss: 0.000741\n",
      " Epoch 9: Train Loss: 0.001069, Validation Loss: 0.000733\n",
      " Epoch 10: Train Loss: 0.001000, Validation Loss: 0.000687\n",
      " Epoch 11: Train Loss: 0.000952, Validation Loss: 0.000631\n",
      " Epoch 12: Train Loss: 0.000915, Validation Loss: 0.000614\n",
      " Epoch 13: Train Loss: 0.000878, Validation Loss: 0.000623\n",
      " Epoch 14: Train Loss: 0.000848, Validation Loss: 0.000571\n",
      " Epoch 15: Train Loss: 0.000822, Validation Loss: 0.000613\n",
      " Epoch 16: Train Loss: 0.000799, Validation Loss: 0.000573\n",
      " Epoch 17: Train Loss: 0.000779, Validation Loss: 0.000536\n",
      " Epoch 18: Train Loss: 0.000761, Validation Loss: 0.000539\n",
      " Epoch 19: Train Loss: 0.000745, Validation Loss: 0.000579\n",
      " Epoch 20: Train Loss: 0.000744, Validation Loss: 0.000554\n",
      " Epoch 21: Train Loss: 0.000723, Validation Loss: 0.000494\n",
      " Epoch 22: Train Loss: 0.000702, Validation Loss: 0.000537\n",
      " Epoch 23: Train Loss: 0.000690, Validation Loss: 0.000492\n",
      " Epoch 24: Train Loss: 0.000678, Validation Loss: 0.000491\n",
      " Epoch 25: Train Loss: 0.000669, Validation Loss: 0.000523\n",
      " Epoch 26: Train Loss: 0.000658, Validation Loss: 0.000502\n",
      " Epoch 27: Train Loss: 0.000651, Validation Loss: 0.000458\n",
      " Epoch 28: Train Loss: 0.000651, Validation Loss: 0.000570\n",
      " Epoch 29: Train Loss: 0.000649, Validation Loss: 0.000470\n",
      " Epoch 30: Train Loss: 0.000626, Validation Loss: 0.000521\n",
      " Epoch 31: Train Loss: 0.000617, Validation Loss: 0.000506\n",
      " Epoch 32: Train Loss: 0.000613, Validation Loss: 0.000463\n",
      " Epoch 33: Train Loss: 0.000609, Validation Loss: 0.000462\n",
      " Epoch 34: Train Loss: 0.000605, Validation Loss: 0.000467\n",
      " Epoch 35: Train Loss: 0.000602, Validation Loss: 0.000494\n",
      " Epoch 36: Train Loss: 0.000598, Validation Loss: 0.000530\n",
      " Epoch 37: Train Loss: 0.000595, Validation Loss: 0.000482\n",
      " Epoch 38: Train Loss: 0.000592, Validation Loss: 0.000510\n",
      " Epoch 39: Train Loss: 0.000588, Validation Loss: 0.000496\n",
      " Epoch 40: Train Loss: 0.000584, Validation Loss: 0.000487\n",
      " Epoch 41: Train Loss: 0.000581, Validation Loss: 0.000524\n",
      " Epoch 42: Train Loss: 0.000578, Validation Loss: 0.000511\n",
      " Epoch 43: Train Loss: 0.000575, Validation Loss: 0.000463\n",
      " Epoch 44: Train Loss: 0.000573, Validation Loss: 0.000482\n",
      " Epoch 45: Train Loss: 0.000568, Validation Loss: 0.000487\n",
      " Epoch 46: Train Loss: 0.000567, Validation Loss: 0.000482\n",
      " Epoch 47: Train Loss: 0.000563, Validation Loss: 0.000501\n",
      "Early stopping at epoch 47 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015911, Validation Loss: 0.023326\n",
      " Epoch 2: Train Loss: 0.004041, Validation Loss: 0.003119\n",
      " Epoch 3: Train Loss: 0.002641, Validation Loss: 0.001937\n",
      " Epoch 4: Train Loss: 0.001987, Validation Loss: 0.001627\n",
      " Epoch 5: Train Loss: 0.001555, Validation Loss: 0.001224\n",
      " Epoch 6: Train Loss: 0.001312, Validation Loss: 0.000970\n",
      " Epoch 7: Train Loss: 0.001187, Validation Loss: 0.000903\n",
      " Epoch 8: Train Loss: 0.001111, Validation Loss: 0.000824\n",
      " Epoch 9: Train Loss: 0.001049, Validation Loss: 0.000785\n",
      " Epoch 10: Train Loss: 0.001001, Validation Loss: 0.000731\n",
      " Epoch 11: Train Loss: 0.000953, Validation Loss: 0.000709\n",
      " Epoch 12: Train Loss: 0.000924, Validation Loss: 0.000652\n",
      " Epoch 13: Train Loss: 0.000888, Validation Loss: 0.000650\n",
      " Epoch 14: Train Loss: 0.000861, Validation Loss: 0.000615\n",
      " Epoch 15: Train Loss: 0.000832, Validation Loss: 0.000613\n",
      " Epoch 16: Train Loss: 0.000813, Validation Loss: 0.000604\n",
      " Epoch 17: Train Loss: 0.000791, Validation Loss: 0.000571\n",
      " Epoch 18: Train Loss: 0.000780, Validation Loss: 0.000585\n",
      " Epoch 19: Train Loss: 0.000756, Validation Loss: 0.000606\n",
      " Epoch 20: Train Loss: 0.000743, Validation Loss: 0.000527\n",
      " Epoch 21: Train Loss: 0.000726, Validation Loss: 0.000512\n",
      " Epoch 22: Train Loss: 0.000708, Validation Loss: 0.000524\n",
      " Epoch 23: Train Loss: 0.000698, Validation Loss: 0.000521\n",
      " Epoch 24: Train Loss: 0.000690, Validation Loss: 0.000485\n",
      " Epoch 25: Train Loss: 0.000673, Validation Loss: 0.000470\n",
      " Epoch 26: Train Loss: 0.000667, Validation Loss: 0.000476\n",
      " Epoch 27: Train Loss: 0.000656, Validation Loss: 0.000472\n",
      " Epoch 28: Train Loss: 0.000645, Validation Loss: 0.000452\n",
      " Epoch 29: Train Loss: 0.000637, Validation Loss: 0.000460\n",
      " Epoch 30: Train Loss: 0.000631, Validation Loss: 0.000448\n",
      " Epoch 31: Train Loss: 0.000619, Validation Loss: 0.000441\n",
      " Epoch 32: Train Loss: 0.000614, Validation Loss: 0.000436\n",
      " Epoch 33: Train Loss: 0.000611, Validation Loss: 0.000448\n",
      " Epoch 34: Train Loss: 0.000606, Validation Loss: 0.000437\n",
      " Epoch 35: Train Loss: 0.000603, Validation Loss: 0.000429\n",
      " Epoch 36: Train Loss: 0.000600, Validation Loss: 0.000436\n",
      " Epoch 37: Train Loss: 0.000607, Validation Loss: 0.000430\n",
      " Epoch 38: Train Loss: 0.000597, Validation Loss: 0.000424\n",
      " Epoch 39: Train Loss: 0.000593, Validation Loss: 0.000429\n",
      " Epoch 40: Train Loss: 0.000586, Validation Loss: 0.000419\n",
      " Epoch 41: Train Loss: 0.000581, Validation Loss: 0.000418\n",
      " Epoch 42: Train Loss: 0.000580, Validation Loss: 0.000415\n",
      " Epoch 43: Train Loss: 0.000575, Validation Loss: 0.000426\n",
      " Epoch 44: Train Loss: 0.000575, Validation Loss: 0.000430\n",
      " Epoch 45: Train Loss: 0.000573, Validation Loss: 0.000425\n",
      " Epoch 46: Train Loss: 0.000567, Validation Loss: 0.000428\n",
      " Epoch 47: Train Loss: 0.000564, Validation Loss: 0.000410\n",
      " Epoch 48: Train Loss: 0.000561, Validation Loss: 0.000414\n",
      " Epoch 49: Train Loss: 0.000556, Validation Loss: 0.000422\n",
      " Epoch 50: Train Loss: 0.000559, Validation Loss: 0.000406\n",
      " Epoch 51: Train Loss: 0.000552, Validation Loss: 0.000404\n",
      " Epoch 52: Train Loss: 0.000552, Validation Loss: 0.000408\n",
      " Epoch 53: Train Loss: 0.000547, Validation Loss: 0.000413\n",
      " Epoch 54: Train Loss: 0.000543, Validation Loss: 0.000428\n",
      " Epoch 55: Train Loss: 0.000541, Validation Loss: 0.000441\n",
      " Epoch 56: Train Loss: 0.000546, Validation Loss: 0.000408\n",
      " Epoch 57: Train Loss: 0.000535, Validation Loss: 0.000411\n",
      " Epoch 58: Train Loss: 0.000537, Validation Loss: 0.000438\n",
      " Epoch 59: Train Loss: 0.000527, Validation Loss: 0.000435\n",
      " Epoch 60: Train Loss: 0.000526, Validation Loss: 0.000421\n",
      " Epoch 61: Train Loss: 0.000522, Validation Loss: 0.000441\n",
      " Epoch 62: Train Loss: 0.000520, Validation Loss: 0.000417\n",
      " Epoch 63: Train Loss: 0.000518, Validation Loss: 0.000416\n",
      " Epoch 64: Train Loss: 0.000518, Validation Loss: 0.000415\n",
      " Epoch 65: Train Loss: 0.000518, Validation Loss: 0.000480\n",
      " Epoch 66: Train Loss: 0.000515, Validation Loss: 0.000432\n",
      " Epoch 67: Train Loss: 0.000515, Validation Loss: 0.000404\n",
      " Epoch 68: Train Loss: 0.000520, Validation Loss: 0.000469\n",
      " Epoch 69: Train Loss: 0.000514, Validation Loss: 0.000451\n",
      " Epoch 70: Train Loss: 0.000509, Validation Loss: 0.000430\n",
      " Epoch 71: Train Loss: 0.000507, Validation Loss: 0.000448\n",
      "Early stopping at epoch 71 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016034, Validation Loss: 0.025959\n",
      " Epoch 2: Train Loss: 0.004353, Validation Loss: 0.003479\n",
      " Epoch 3: Train Loss: 0.002566, Validation Loss: 0.002163\n",
      " Epoch 4: Train Loss: 0.001722, Validation Loss: 0.001290\n",
      " Epoch 5: Train Loss: 0.001447, Validation Loss: 0.001055\n",
      " Epoch 6: Train Loss: 0.001297, Validation Loss: 0.000904\n",
      " Epoch 7: Train Loss: 0.001191, Validation Loss: 0.000862\n",
      " Epoch 8: Train Loss: 0.001129, Validation Loss: 0.000834\n",
      " Epoch 9: Train Loss: 0.001060, Validation Loss: 0.000771\n",
      " Epoch 10: Train Loss: 0.001001, Validation Loss: 0.000723\n",
      " Epoch 11: Train Loss: 0.000960, Validation Loss: 0.000739\n",
      " Epoch 12: Train Loss: 0.000923, Validation Loss: 0.000680\n",
      " Epoch 13: Train Loss: 0.000895, Validation Loss: 0.000648\n",
      " Epoch 14: Train Loss: 0.000861, Validation Loss: 0.000715\n",
      " Epoch 15: Train Loss: 0.000835, Validation Loss: 0.000626\n",
      " Epoch 16: Train Loss: 0.000822, Validation Loss: 0.000616\n",
      " Epoch 17: Train Loss: 0.000794, Validation Loss: 0.000593\n",
      " Epoch 18: Train Loss: 0.000778, Validation Loss: 0.000590\n",
      " Epoch 19: Train Loss: 0.000763, Validation Loss: 0.000608\n",
      " Epoch 20: Train Loss: 0.000747, Validation Loss: 0.000580\n",
      " Epoch 21: Train Loss: 0.000741, Validation Loss: 0.000529\n",
      " Epoch 22: Train Loss: 0.000718, Validation Loss: 0.000545\n",
      " Epoch 23: Train Loss: 0.000712, Validation Loss: 0.000554\n",
      " Epoch 24: Train Loss: 0.000694, Validation Loss: 0.000524\n",
      " Epoch 25: Train Loss: 0.000680, Validation Loss: 0.000553\n",
      " Epoch 26: Train Loss: 0.000668, Validation Loss: 0.000489\n",
      " Epoch 27: Train Loss: 0.000658, Validation Loss: 0.000480\n",
      " Epoch 28: Train Loss: 0.000650, Validation Loss: 0.000480\n",
      " Epoch 29: Train Loss: 0.000640, Validation Loss: 0.000452\n",
      " Epoch 30: Train Loss: 0.000633, Validation Loss: 0.000478\n",
      " Epoch 31: Train Loss: 0.000621, Validation Loss: 0.000446\n",
      " Epoch 32: Train Loss: 0.000616, Validation Loss: 0.000444\n",
      " Epoch 33: Train Loss: 0.000611, Validation Loss: 0.000454\n",
      " Epoch 34: Train Loss: 0.000608, Validation Loss: 0.000432\n",
      " Epoch 35: Train Loss: 0.000603, Validation Loss: 0.000436\n",
      " Epoch 36: Train Loss: 0.000601, Validation Loss: 0.000435\n",
      " Epoch 37: Train Loss: 0.000598, Validation Loss: 0.000430\n",
      " Epoch 38: Train Loss: 0.000596, Validation Loss: 0.000434\n",
      " Epoch 39: Train Loss: 0.000588, Validation Loss: 0.000429\n",
      " Epoch 40: Train Loss: 0.000585, Validation Loss: 0.000441\n",
      " Epoch 41: Train Loss: 0.000583, Validation Loss: 0.000432\n",
      " Epoch 42: Train Loss: 0.000577, Validation Loss: 0.000422\n",
      " Epoch 43: Train Loss: 0.000578, Validation Loss: 0.000424\n",
      " Epoch 44: Train Loss: 0.000572, Validation Loss: 0.000415\n",
      " Epoch 45: Train Loss: 0.000567, Validation Loss: 0.000421\n",
      " Epoch 46: Train Loss: 0.000567, Validation Loss: 0.000415\n",
      " Epoch 47: Train Loss: 0.000561, Validation Loss: 0.000420\n",
      " Epoch 48: Train Loss: 0.000560, Validation Loss: 0.000414\n",
      " Epoch 49: Train Loss: 0.000555, Validation Loss: 0.000444\n",
      " Epoch 50: Train Loss: 0.000552, Validation Loss: 0.000407\n",
      " Epoch 51: Train Loss: 0.000550, Validation Loss: 0.000420\n",
      " Epoch 52: Train Loss: 0.000552, Validation Loss: 0.000421\n",
      " Epoch 53: Train Loss: 0.000543, Validation Loss: 0.000420\n",
      " Epoch 54: Train Loss: 0.000542, Validation Loss: 0.000426\n",
      " Epoch 55: Train Loss: 0.000539, Validation Loss: 0.000471\n",
      " Epoch 56: Train Loss: 0.000537, Validation Loss: 0.000423\n",
      " Epoch 57: Train Loss: 0.000533, Validation Loss: 0.000444\n",
      " Epoch 58: Train Loss: 0.000531, Validation Loss: 0.000436\n",
      " Epoch 59: Train Loss: 0.000527, Validation Loss: 0.000405\n",
      " Epoch 60: Train Loss: 0.000526, Validation Loss: 0.000408\n",
      " Epoch 61: Train Loss: 0.000520, Validation Loss: 0.000437\n",
      " Epoch 62: Train Loss: 0.000519, Validation Loss: 0.000437\n",
      " Epoch 63: Train Loss: 0.000517, Validation Loss: 0.000463\n",
      " Epoch 64: Train Loss: 0.000517, Validation Loss: 0.000430\n",
      " Epoch 65: Train Loss: 0.000515, Validation Loss: 0.000442\n",
      " Epoch 66: Train Loss: 0.000512, Validation Loss: 0.000439\n",
      " Epoch 67: Train Loss: 0.000512, Validation Loss: 0.000453\n",
      " Epoch 68: Train Loss: 0.000510, Validation Loss: 0.000456\n",
      " Epoch 69: Train Loss: 0.000509, Validation Loss: 0.000446\n",
      " Epoch 70: Train Loss: 0.000509, Validation Loss: 0.000468\n",
      " Epoch 71: Train Loss: 0.000506, Validation Loss: 0.000451\n",
      " Epoch 72: Train Loss: 0.000506, Validation Loss: 0.000448\n",
      " Epoch 73: Train Loss: 0.000504, Validation Loss: 0.000464\n",
      " Epoch 74: Train Loss: 0.000504, Validation Loss: 0.000485\n",
      " Epoch 75: Train Loss: 0.000504, Validation Loss: 0.000485\n",
      " Epoch 76: Train Loss: 0.000499, Validation Loss: 0.000484\n",
      " Epoch 77: Train Loss: 0.000501, Validation Loss: 0.000435\n",
      " Epoch 78: Train Loss: 0.000497, Validation Loss: 0.000473\n",
      " Epoch 79: Train Loss: 0.000494, Validation Loss: 0.000462\n",
      "Early stopping at epoch 79 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.021716, Validation Loss: 0.029578\n",
      " Epoch 2: Train Loss: 0.005863, Validation Loss: 0.005486\n",
      " Epoch 3: Train Loss: 0.003398, Validation Loss: 0.002438\n",
      " Epoch 4: Train Loss: 0.002471, Validation Loss: 0.001969\n",
      " Epoch 5: Train Loss: 0.002161, Validation Loss: 0.001811\n",
      " Epoch 6: Train Loss: 0.001743, Validation Loss: 0.001210\n",
      " Epoch 7: Train Loss: 0.001306, Validation Loss: 0.000929\n",
      " Epoch 8: Train Loss: 0.001180, Validation Loss: 0.000861\n",
      " Epoch 9: Train Loss: 0.001106, Validation Loss: 0.000815\n",
      " Epoch 10: Train Loss: 0.001053, Validation Loss: 0.000781\n",
      " Epoch 11: Train Loss: 0.001005, Validation Loss: 0.000743\n",
      " Epoch 12: Train Loss: 0.000967, Validation Loss: 0.000721\n",
      " Epoch 13: Train Loss: 0.000931, Validation Loss: 0.000686\n",
      " Epoch 14: Train Loss: 0.000904, Validation Loss: 0.000675\n",
      " Epoch 15: Train Loss: 0.000879, Validation Loss: 0.000649\n",
      " Epoch 16: Train Loss: 0.000856, Validation Loss: 0.000631\n",
      " Epoch 17: Train Loss: 0.000835, Validation Loss: 0.000651\n",
      " Epoch 18: Train Loss: 0.000822, Validation Loss: 0.000597\n",
      " Epoch 19: Train Loss: 0.000799, Validation Loss: 0.000622\n",
      " Epoch 20: Train Loss: 0.000783, Validation Loss: 0.000617\n",
      " Epoch 21: Train Loss: 0.000782, Validation Loss: 0.000596\n",
      " Epoch 22: Train Loss: 0.000759, Validation Loss: 0.000560\n",
      " Epoch 23: Train Loss: 0.000738, Validation Loss: 0.000553\n",
      " Epoch 24: Train Loss: 0.000725, Validation Loss: 0.000556\n",
      " Epoch 25: Train Loss: 0.000713, Validation Loss: 0.000528\n",
      " Epoch 26: Train Loss: 0.000704, Validation Loss: 0.000549\n",
      " Epoch 27: Train Loss: 0.000692, Validation Loss: 0.000525\n",
      " Epoch 28: Train Loss: 0.000684, Validation Loss: 0.000536\n",
      " Epoch 29: Train Loss: 0.000673, Validation Loss: 0.000512\n",
      " Epoch 30: Train Loss: 0.000666, Validation Loss: 0.000566\n",
      " Epoch 31: Train Loss: 0.000655, Validation Loss: 0.000515\n",
      " Epoch 32: Train Loss: 0.000650, Validation Loss: 0.000507\n",
      " Epoch 33: Train Loss: 0.000646, Validation Loss: 0.000531\n",
      " Epoch 34: Train Loss: 0.000641, Validation Loss: 0.000502\n",
      " Epoch 35: Train Loss: 0.000638, Validation Loss: 0.000520\n",
      " Epoch 36: Train Loss: 0.000633, Validation Loss: 0.000514\n",
      " Epoch 37: Train Loss: 0.000629, Validation Loss: 0.000507\n",
      " Epoch 38: Train Loss: 0.000625, Validation Loss: 0.000494\n",
      " Epoch 39: Train Loss: 0.000621, Validation Loss: 0.000484\n",
      " Epoch 40: Train Loss: 0.000618, Validation Loss: 0.000500\n",
      " Epoch 41: Train Loss: 0.000613, Validation Loss: 0.000468\n",
      " Epoch 42: Train Loss: 0.000610, Validation Loss: 0.000478\n",
      " Epoch 43: Train Loss: 0.000606, Validation Loss: 0.000469\n",
      " Epoch 44: Train Loss: 0.000604, Validation Loss: 0.000474\n",
      " Epoch 45: Train Loss: 0.000599, Validation Loss: 0.000474\n",
      " Epoch 46: Train Loss: 0.000595, Validation Loss: 0.000501\n",
      " Epoch 47: Train Loss: 0.000592, Validation Loss: 0.000480\n",
      " Epoch 48: Train Loss: 0.000588, Validation Loss: 0.000456\n",
      " Epoch 49: Train Loss: 0.000584, Validation Loss: 0.000471\n",
      " Epoch 50: Train Loss: 0.000584, Validation Loss: 0.000498\n",
      " Epoch 51: Train Loss: 0.000577, Validation Loss: 0.000460\n",
      " Epoch 52: Train Loss: 0.000575, Validation Loss: 0.000478\n",
      " Epoch 53: Train Loss: 0.000572, Validation Loss: 0.000449\n",
      " Epoch 54: Train Loss: 0.000568, Validation Loss: 0.000449\n",
      " Epoch 55: Train Loss: 0.000565, Validation Loss: 0.000443\n",
      " Epoch 56: Train Loss: 0.000562, Validation Loss: 0.000443\n",
      " Epoch 57: Train Loss: 0.000558, Validation Loss: 0.000435\n",
      " Epoch 58: Train Loss: 0.000556, Validation Loss: 0.000453\n",
      " Epoch 59: Train Loss: 0.000552, Validation Loss: 0.000454\n",
      " Epoch 60: Train Loss: 0.000552, Validation Loss: 0.000481\n",
      " Epoch 61: Train Loss: 0.000545, Validation Loss: 0.000461\n",
      " Epoch 62: Train Loss: 0.000543, Validation Loss: 0.000439\n",
      " Epoch 63: Train Loss: 0.000542, Validation Loss: 0.000443\n",
      " Epoch 64: Train Loss: 0.000540, Validation Loss: 0.000439\n",
      " Epoch 65: Train Loss: 0.000538, Validation Loss: 0.000439\n",
      " Epoch 66: Train Loss: 0.000537, Validation Loss: 0.000446\n",
      " Epoch 67: Train Loss: 0.000535, Validation Loss: 0.000464\n",
      " Epoch 68: Train Loss: 0.000533, Validation Loss: 0.000443\n",
      " Epoch 69: Train Loss: 0.000531, Validation Loss: 0.000449\n",
      " Epoch 70: Train Loss: 0.000530, Validation Loss: 0.000431\n",
      " Epoch 71: Train Loss: 0.000529, Validation Loss: 0.000427\n",
      " Epoch 72: Train Loss: 0.000527, Validation Loss: 0.000436\n",
      " Epoch 73: Train Loss: 0.000525, Validation Loss: 0.000436\n",
      " Epoch 74: Train Loss: 0.000524, Validation Loss: 0.000447\n",
      " Epoch 75: Train Loss: 0.000522, Validation Loss: 0.000432\n",
      " Epoch 76: Train Loss: 0.000521, Validation Loss: 0.000434\n",
      " Epoch 77: Train Loss: 0.000519, Validation Loss: 0.000437\n",
      " Epoch 78: Train Loss: 0.000516, Validation Loss: 0.000431\n",
      " Epoch 79: Train Loss: 0.000515, Validation Loss: 0.000440\n",
      " Epoch 80: Train Loss: 0.000514, Validation Loss: 0.000444\n",
      " Epoch 81: Train Loss: 0.000514, Validation Loss: 0.000438\n",
      " Epoch 82: Train Loss: 0.000511, Validation Loss: 0.000434\n",
      " Epoch 83: Train Loss: 0.000509, Validation Loss: 0.000427\n",
      " Epoch 84: Train Loss: 0.000507, Validation Loss: 0.000447\n",
      " Epoch 85: Train Loss: 0.000506, Validation Loss: 0.000448\n",
      " Epoch 86: Train Loss: 0.000504, Validation Loss: 0.000470\n",
      " Epoch 87: Train Loss: 0.000502, Validation Loss: 0.000432\n",
      " Epoch 88: Train Loss: 0.000501, Validation Loss: 0.000440\n",
      " Epoch 89: Train Loss: 0.000499, Validation Loss: 0.000435\n",
      " Epoch 90: Train Loss: 0.000498, Validation Loss: 0.000447\n",
      " Epoch 91: Train Loss: 0.000495, Validation Loss: 0.000444\n",
      " Epoch 92: Train Loss: 0.000494, Validation Loss: 0.000441\n",
      " Epoch 93: Train Loss: 0.000493, Validation Loss: 0.000440\n",
      " Epoch 94: Train Loss: 0.000493, Validation Loss: 0.000434\n",
      " Epoch 95: Train Loss: 0.000491, Validation Loss: 0.000452\n",
      " Epoch 96: Train Loss: 0.000491, Validation Loss: 0.000452\n",
      " Epoch 97: Train Loss: 0.000490, Validation Loss: 0.000448\n",
      " Epoch 98: Train Loss: 0.000489, Validation Loss: 0.000451\n",
      " Epoch 99: Train Loss: 0.000488, Validation Loss: 0.000443\n",
      " Epoch 100: Train Loss: 0.000487, Validation Loss: 0.000466\n",
      " Epoch 101: Train Loss: 0.000487, Validation Loss: 0.000440\n",
      " Epoch 102: Train Loss: 0.000486, Validation Loss: 0.000441\n",
      " Epoch 103: Train Loss: 0.000484, Validation Loss: 0.000467\n",
      "Early stopping at epoch 103 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.0002997401461470872\n",
      "Training Time: 1846.510597229004\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.000278433202765882\n",
      "Training Time: 12994.583952665329\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.00027825470897369087\n",
      "Training Time: 3074.900449037552\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0002839059161487967\n",
      "Training Time: 1708.9917833805084\n",
      "--------------------------------------------------\n",
      "Model: UNet\n",
      "Validation Loss: 0.00039462000131607056\n",
      "Training Time: 970.607438325882\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock\n",
      "Validation Loss: 0.00042265208321623504\n",
      "Training Time: 789.2120950222015\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention\n",
      "Validation Loss: 0.00045815156772732735\n",
      "Training Time: 531.1373219490051\n",
      "--------------------------------------------------\n",
      "Model: UNet3D\n",
      "Validation Loss: 0.0004035355232190341\n",
      "Training Time: 800.8017156124115\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D\n",
      "Validation Loss: 0.0004053286393173039\n",
      "Training Time: 894.2077379226685\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D\n",
      "Validation Loss: 0.0004270387871656567\n",
      "Training Time: 1215.3915836811066\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# first exp\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from model_train import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, WeightedMSELoss\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    'UNet': UNet,\n",
    "    'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    'UNet3D': UNet3D,\n",
    "    'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = WeightedMSELoss()\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/01/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform[\"without_jet\"])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = '/home/linux/3.3lab/Gauss_S1.00_NL0.30_B0.50_Jet/Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2882639b-89f8-449b-b869-c31d76f0edc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.020664, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.003047, Validation Loss: 0.003182\n",
      " Epoch 3: Train Loss: 0.001342, Validation Loss: 0.001283\n",
      " Epoch 4: Train Loss: 0.000975, Validation Loss: 0.000897\n",
      " Epoch 5: Train Loss: 0.000837, Validation Loss: 0.000789\n",
      " Epoch 6: Train Loss: 0.000753, Validation Loss: 0.000721\n",
      " Epoch 7: Train Loss: 0.000693, Validation Loss: 0.000671\n",
      " Epoch 8: Train Loss: 0.000649, Validation Loss: 0.000629\n",
      " Epoch 9: Train Loss: 0.000612, Validation Loss: 0.000600\n",
      " Epoch 10: Train Loss: 0.000583, Validation Loss: 0.000575\n",
      " Epoch 11: Train Loss: 0.000557, Validation Loss: 0.000554\n",
      " Epoch 12: Train Loss: 0.000537, Validation Loss: 0.000534\n",
      " Epoch 13: Train Loss: 0.000519, Validation Loss: 0.000526\n",
      " Epoch 14: Train Loss: 0.000506, Validation Loss: 0.000506\n",
      " Epoch 15: Train Loss: 0.000490, Validation Loss: 0.000493\n",
      " Epoch 16: Train Loss: 0.000477, Validation Loss: 0.000480\n",
      " Epoch 17: Train Loss: 0.000467, Validation Loss: 0.000474\n",
      " Epoch 18: Train Loss: 0.000454, Validation Loss: 0.000459\n",
      " Epoch 19: Train Loss: 0.000444, Validation Loss: 0.000448\n",
      " Epoch 20: Train Loss: 0.000433, Validation Loss: 0.000441\n",
      " Epoch 21: Train Loss: 0.000429, Validation Loss: 0.000450\n",
      " Epoch 22: Train Loss: 0.000422, Validation Loss: 0.000425\n",
      " Epoch 23: Train Loss: 0.000410, Validation Loss: 0.000427\n",
      " Epoch 24: Train Loss: 0.000405, Validation Loss: 0.000422\n",
      " Epoch 25: Train Loss: 0.000399, Validation Loss: 0.000407\n",
      " Epoch 26: Train Loss: 0.000394, Validation Loss: 0.000401\n",
      " Epoch 27: Train Loss: 0.000388, Validation Loss: 0.000403\n",
      " Epoch 28: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 29: Train Loss: 0.000378, Validation Loss: 0.000395\n",
      " Epoch 30: Train Loss: 0.000376, Validation Loss: 0.000395\n",
      " Epoch 31: Train Loss: 0.000364, Validation Loss: 0.000380\n",
      " Epoch 32: Train Loss: 0.000359, Validation Loss: 0.000376\n",
      " Epoch 33: Train Loss: 0.000358, Validation Loss: 0.000374\n",
      " Epoch 34: Train Loss: 0.000354, Validation Loss: 0.000375\n",
      " Epoch 35: Train Loss: 0.000352, Validation Loss: 0.000370\n",
      " Epoch 36: Train Loss: 0.000349, Validation Loss: 0.000369\n",
      " Epoch 37: Train Loss: 0.000349, Validation Loss: 0.000366\n",
      " Epoch 38: Train Loss: 0.000343, Validation Loss: 0.000365\n",
      " Epoch 39: Train Loss: 0.000346, Validation Loss: 0.000364\n",
      " Epoch 40: Train Loss: 0.000341, Validation Loss: 0.000368\n",
      " Epoch 41: Train Loss: 0.000340, Validation Loss: 0.000359\n",
      " Epoch 42: Train Loss: 0.000336, Validation Loss: 0.000360\n",
      " Epoch 43: Train Loss: 0.000334, Validation Loss: 0.000357\n",
      " Epoch 44: Train Loss: 0.000333, Validation Loss: 0.000354\n",
      " Epoch 45: Train Loss: 0.000330, Validation Loss: 0.000352\n",
      " Epoch 46: Train Loss: 0.000328, Validation Loss: 0.000352\n",
      " Epoch 47: Train Loss: 0.000329, Validation Loss: 0.000349\n",
      " Epoch 48: Train Loss: 0.000325, Validation Loss: 0.000350\n",
      " Epoch 49: Train Loss: 0.000322, Validation Loss: 0.000349\n",
      " Epoch 50: Train Loss: 0.000321, Validation Loss: 0.000346\n",
      " Epoch 51: Train Loss: 0.000321, Validation Loss: 0.000351\n",
      " Epoch 52: Train Loss: 0.000317, Validation Loss: 0.000346\n",
      " Epoch 53: Train Loss: 0.000316, Validation Loss: 0.000342\n",
      " Epoch 54: Train Loss: 0.000313, Validation Loss: 0.000347\n",
      " Epoch 55: Train Loss: 0.000316, Validation Loss: 0.000338\n",
      " Epoch 56: Train Loss: 0.000311, Validation Loss: 0.000337\n",
      " Epoch 57: Train Loss: 0.000312, Validation Loss: 0.000336\n",
      " Epoch 58: Train Loss: 0.000309, Validation Loss: 0.000334\n",
      " Epoch 59: Train Loss: 0.000309, Validation Loss: 0.000337\n",
      " Epoch 60: Train Loss: 0.000313, Validation Loss: 0.000333\n",
      " Epoch 61: Train Loss: 0.000300, Validation Loss: 0.000330\n",
      " Epoch 62: Train Loss: 0.000298, Validation Loss: 0.000329\n",
      " Epoch 63: Train Loss: 0.000297, Validation Loss: 0.000329\n",
      " Epoch 64: Train Loss: 0.000297, Validation Loss: 0.000328\n",
      " Epoch 65: Train Loss: 0.000296, Validation Loss: 0.000327\n",
      " Epoch 66: Train Loss: 0.000294, Validation Loss: 0.000333\n",
      " Epoch 67: Train Loss: 0.000294, Validation Loss: 0.000327\n",
      " Epoch 68: Train Loss: 0.000297, Validation Loss: 0.000331\n",
      " Epoch 69: Train Loss: 0.000294, Validation Loss: 0.000325\n",
      " Epoch 70: Train Loss: 0.000291, Validation Loss: 0.000325\n",
      " Epoch 71: Train Loss: 0.000291, Validation Loss: 0.000323\n",
      " Epoch 72: Train Loss: 0.000289, Validation Loss: 0.000324\n",
      " Epoch 73: Train Loss: 0.000288, Validation Loss: 0.000326\n",
      " Epoch 74: Train Loss: 0.000288, Validation Loss: 0.000322\n",
      " Epoch 75: Train Loss: 0.000290, Validation Loss: 0.000321\n",
      " Epoch 76: Train Loss: 0.000286, Validation Loss: 0.000321\n",
      " Epoch 77: Train Loss: 0.000286, Validation Loss: 0.000322\n",
      " Epoch 78: Train Loss: 0.000284, Validation Loss: 0.000321\n",
      " Epoch 79: Train Loss: 0.000284, Validation Loss: 0.000320\n",
      " Epoch 80: Train Loss: 0.000285, Validation Loss: 0.000320\n",
      " Epoch 81: Train Loss: 0.000283, Validation Loss: 0.000321\n",
      " Epoch 82: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 83: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 84: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 85: Train Loss: 0.000278, Validation Loss: 0.000315\n",
      " Epoch 86: Train Loss: 0.000277, Validation Loss: 0.000318\n",
      " Epoch 87: Train Loss: 0.000276, Validation Loss: 0.000315\n",
      " Epoch 88: Train Loss: 0.000277, Validation Loss: 0.000317\n",
      " Epoch 89: Train Loss: 0.000277, Validation Loss: 0.000314\n",
      " Epoch 90: Train Loss: 0.000275, Validation Loss: 0.000321\n",
      " Epoch 91: Train Loss: 0.000272, Validation Loss: 0.000315\n",
      " Epoch 92: Train Loss: 0.000271, Validation Loss: 0.000313\n",
      " Epoch 93: Train Loss: 0.000270, Validation Loss: 0.000313\n",
      " Epoch 94: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 95: Train Loss: 0.000268, Validation Loss: 0.000312\n",
      " Epoch 96: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 97: Train Loss: 0.000269, Validation Loss: 0.000311\n",
      " Epoch 98: Train Loss: 0.000267, Validation Loss: 0.000311\n",
      " Epoch 99: Train Loss: 0.000268, Validation Loss: 0.000311\n",
      " Epoch 100: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 101: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 102: Train Loss: 0.000265, Validation Loss: 0.000310\n",
      " Epoch 103: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 104: Train Loss: 0.000264, Validation Loss: 0.000310\n",
      " Epoch 105: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 106: Train Loss: 0.000263, Validation Loss: 0.000309\n",
      " Epoch 107: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 108: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 109: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 110: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 111: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 112: Train Loss: 0.000261, Validation Loss: 0.000308\n",
      " Epoch 113: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 114: Train Loss: 0.000259, Validation Loss: 0.000309\n",
      " Epoch 115: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 116: Train Loss: 0.000261, Validation Loss: 0.000311\n",
      " Epoch 117: Train Loss: 0.000258, Validation Loss: 0.000306\n",
      " Epoch 118: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 119: Train Loss: 0.000256, Validation Loss: 0.000305\n",
      " Epoch 120: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 121: Train Loss: 0.000254, Validation Loss: 0.000309\n",
      " Epoch 122: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 123: Train Loss: 0.000253, Validation Loss: 0.000305\n",
      " Epoch 124: Train Loss: 0.000252, Validation Loss: 0.000304\n",
      " Epoch 125: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 126: Train Loss: 0.000252, Validation Loss: 0.000305\n",
      " Epoch 127: Train Loss: 0.000251, Validation Loss: 0.000305\n",
      " Epoch 128: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 129: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 130: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 131: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 132: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 133: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 134: Train Loss: 0.000249, Validation Loss: 0.000303\n",
      " Epoch 135: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 136: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 137: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 138: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 139: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 140: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 141: Train Loss: 0.000246, Validation Loss: 0.000305\n",
      " Epoch 142: Train Loss: 0.000247, Validation Loss: 0.000303\n",
      " Epoch 143: Train Loss: 0.000247, Validation Loss: 0.000304\n",
      " Epoch 144: Train Loss: 0.000246, Validation Loss: 0.000302\n",
      " Epoch 145: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 146: Train Loss: 0.000245, Validation Loss: 0.000305\n",
      " Epoch 147: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 148: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 149: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 150: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 151: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 152: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 153: Train Loss: 0.000242, Validation Loss: 0.000301\n",
      " Epoch 154: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 155: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 156: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 157: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 158: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 159: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 160: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 161: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 162: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 163: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 164: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 165: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 166: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 167: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 168: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 169: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 170: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 171: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 172: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 173: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 174: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 175: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 176: Train Loss: 0.000237, Validation Loss: 0.000300\n",
      " Epoch 177: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 178: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 179: Train Loss: 0.000236, Validation Loss: 0.000300\n",
      " Epoch 180: Train Loss: 0.000236, Validation Loss: 0.000301\n",
      " Epoch 181: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 182: Train Loss: 0.000235, Validation Loss: 0.000302\n",
      " Epoch 183: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 184: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 185: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 186: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 187: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 188: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 189: Train Loss: 0.000233, Validation Loss: 0.000301\n",
      " Epoch 190: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 191: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 192: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 193: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 194: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 195: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 196: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 197: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 198: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 199: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 200: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 201: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      "Early stopping at epoch 201 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.015017, Validation Loss: 0.029486\n",
      " Epoch 2: Train Loss: 0.006244, Validation Loss: 0.007100\n",
      " Epoch 3: Train Loss: 0.004136, Validation Loss: 0.002965\n",
      " Epoch 4: Train Loss: 0.001620, Validation Loss: 0.001586\n",
      " Epoch 5: Train Loss: 0.001063, Validation Loss: 0.000977\n",
      " Epoch 6: Train Loss: 0.000861, Validation Loss: 0.000833\n",
      " Epoch 7: Train Loss: 0.000734, Validation Loss: 0.000704\n",
      " Epoch 8: Train Loss: 0.000669, Validation Loss: 0.000652\n",
      " Epoch 9: Train Loss: 0.000603, Validation Loss: 0.000587\n",
      " Epoch 10: Train Loss: 0.000564, Validation Loss: 0.000722\n",
      " Epoch 11: Train Loss: 0.000538, Validation Loss: 0.000538\n",
      " Epoch 12: Train Loss: 0.000507, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000493, Validation Loss: 0.000512\n",
      " Epoch 14: Train Loss: 0.000468, Validation Loss: 0.000524\n",
      " Epoch 15: Train Loss: 0.000457, Validation Loss: 0.000465\n",
      " Epoch 16: Train Loss: 0.000441, Validation Loss: 0.000458\n",
      " Epoch 17: Train Loss: 0.000432, Validation Loss: 0.000463\n",
      " Epoch 18: Train Loss: 0.001056, Validation Loss: 0.000710\n",
      " Epoch 19: Train Loss: 0.000544, Validation Loss: 0.000507\n",
      " Epoch 20: Train Loss: 0.000466, Validation Loss: 0.000474\n",
      " Epoch 21: Train Loss: 0.000441, Validation Loss: 0.000492\n",
      " Epoch 22: Train Loss: 0.000424, Validation Loss: 0.000422\n",
      " Epoch 23: Train Loss: 0.000411, Validation Loss: 0.000421\n",
      " Epoch 24: Train Loss: 0.000402, Validation Loss: 0.000410\n",
      " Epoch 25: Train Loss: 0.000392, Validation Loss: 0.000396\n",
      " Epoch 26: Train Loss: 0.000388, Validation Loss: 0.000402\n",
      " Epoch 27: Train Loss: 0.000379, Validation Loss: 0.000382\n",
      " Epoch 28: Train Loss: 0.000370, Validation Loss: 0.000377\n",
      " Epoch 29: Train Loss: 0.000367, Validation Loss: 0.000372\n",
      " Epoch 30: Train Loss: 0.000363, Validation Loss: 0.000435\n",
      " Epoch 31: Train Loss: 0.000356, Validation Loss: 0.000372\n",
      " Epoch 32: Train Loss: 0.000349, Validation Loss: 0.000360\n",
      " Epoch 33: Train Loss: 0.000347, Validation Loss: 0.000359\n",
      " Epoch 34: Train Loss: 0.000344, Validation Loss: 0.000359\n",
      " Epoch 35: Train Loss: 0.000343, Validation Loss: 0.000364\n",
      " Epoch 36: Train Loss: 0.000341, Validation Loss: 0.000353\n",
      " Epoch 37: Train Loss: 0.000338, Validation Loss: 0.000350\n",
      " Epoch 38: Train Loss: 0.000335, Validation Loss: 0.000363\n",
      " Epoch 39: Train Loss: 0.000334, Validation Loss: 0.000346\n",
      " Epoch 40: Train Loss: 0.000332, Validation Loss: 0.000345\n",
      " Epoch 41: Train Loss: 0.000329, Validation Loss: 0.000344\n",
      " Epoch 42: Train Loss: 0.000328, Validation Loss: 0.000348\n",
      " Epoch 43: Train Loss: 0.000326, Validation Loss: 0.000355\n",
      " Epoch 44: Train Loss: 0.000324, Validation Loss: 0.000338\n",
      " Epoch 45: Train Loss: 0.000322, Validation Loss: 0.000342\n",
      " Epoch 46: Train Loss: 0.000323, Validation Loss: 0.000355\n",
      " Epoch 47: Train Loss: 0.000320, Validation Loss: 0.000335\n",
      " Epoch 48: Train Loss: 0.000315, Validation Loss: 0.000335\n",
      " Epoch 49: Train Loss: 0.000314, Validation Loss: 0.000340\n",
      " Epoch 50: Train Loss: 0.000313, Validation Loss: 0.000333\n",
      " Epoch 51: Train Loss: 0.000310, Validation Loss: 0.000333\n",
      " Epoch 52: Train Loss: 0.000309, Validation Loss: 0.000360\n",
      " Epoch 53: Train Loss: 0.000308, Validation Loss: 0.000325\n",
      " Epoch 54: Train Loss: 0.000306, Validation Loss: 0.000341\n",
      " Epoch 55: Train Loss: 0.000304, Validation Loss: 0.000351\n",
      " Epoch 56: Train Loss: 0.000302, Validation Loss: 0.000331\n",
      " Epoch 57: Train Loss: 0.000300, Validation Loss: 0.000321\n",
      " Epoch 58: Train Loss: 0.000305, Validation Loss: 0.000336\n",
      " Epoch 59: Train Loss: 0.000300, Validation Loss: 0.000316\n",
      " Epoch 60: Train Loss: 0.000299, Validation Loss: 0.000348\n",
      " Epoch 61: Train Loss: 0.000299, Validation Loss: 0.000317\n",
      " Epoch 62: Train Loss: 0.000288, Validation Loss: 0.000314\n",
      " Epoch 63: Train Loss: 0.000287, Validation Loss: 0.000314\n",
      " Epoch 64: Train Loss: 0.000286, Validation Loss: 0.000311\n",
      " Epoch 65: Train Loss: 0.000286, Validation Loss: 0.000311\n",
      " Epoch 66: Train Loss: 0.000283, Validation Loss: 0.000315\n",
      " Epoch 67: Train Loss: 0.000284, Validation Loss: 0.000314\n",
      " Epoch 68: Train Loss: 0.000282, Validation Loss: 0.000312\n",
      " Epoch 69: Train Loss: 0.000282, Validation Loss: 0.000309\n",
      " Epoch 70: Train Loss: 0.000280, Validation Loss: 0.000310\n",
      " Epoch 71: Train Loss: 0.000279, Validation Loss: 0.000314\n",
      " Epoch 72: Train Loss: 0.000279, Validation Loss: 0.000307\n",
      " Epoch 73: Train Loss: 0.000278, Validation Loss: 0.000309\n",
      " Epoch 74: Train Loss: 0.000277, Validation Loss: 0.000309\n",
      " Epoch 75: Train Loss: 0.000279, Validation Loss: 0.000319\n",
      " Epoch 76: Train Loss: 0.000276, Validation Loss: 0.000309\n",
      " Epoch 77: Train Loss: 0.000276, Validation Loss: 0.000308\n",
      " Epoch 78: Train Loss: 0.000275, Validation Loss: 0.000306\n",
      " Epoch 79: Train Loss: 0.000272, Validation Loss: 0.000303\n",
      " Epoch 80: Train Loss: 0.000272, Validation Loss: 0.000311\n",
      " Epoch 81: Train Loss: 0.000273, Validation Loss: 0.000302\n",
      " Epoch 82: Train Loss: 0.000270, Validation Loss: 0.000304\n",
      " Epoch 83: Train Loss: 0.000271, Validation Loss: 0.000310\n",
      " Epoch 84: Train Loss: 0.000268, Validation Loss: 0.000300\n",
      " Epoch 85: Train Loss: 0.000268, Validation Loss: 0.000311\n",
      " Epoch 86: Train Loss: 0.000266, Validation Loss: 0.000300\n",
      " Epoch 87: Train Loss: 0.000266, Validation Loss: 0.000313\n",
      " Epoch 88: Train Loss: 0.000266, Validation Loss: 0.000304\n",
      " Epoch 89: Train Loss: 0.000264, Validation Loss: 0.000301\n",
      " Epoch 90: Train Loss: 0.000261, Validation Loss: 0.000304\n",
      " Epoch 91: Train Loss: 0.000258, Validation Loss: 0.000300\n",
      " Epoch 92: Train Loss: 0.000258, Validation Loss: 0.000295\n",
      " Epoch 93: Train Loss: 0.000257, Validation Loss: 0.000296\n",
      " Epoch 94: Train Loss: 0.000256, Validation Loss: 0.000296\n",
      " Epoch 95: Train Loss: 0.000256, Validation Loss: 0.000297\n",
      " Epoch 96: Train Loss: 0.000255, Validation Loss: 0.000295\n",
      " Epoch 97: Train Loss: 0.000255, Validation Loss: 0.000297\n",
      " Epoch 98: Train Loss: 0.000254, Validation Loss: 0.000296\n",
      " Epoch 99: Train Loss: 0.000256, Validation Loss: 0.000313\n",
      " Epoch 100: Train Loss: 0.000257, Validation Loss: 0.000297\n",
      " Epoch 101: Train Loss: 0.000252, Validation Loss: 0.000294\n",
      " Epoch 102: Train Loss: 0.000253, Validation Loss: 0.000294\n",
      " Epoch 103: Train Loss: 0.000251, Validation Loss: 0.000294\n",
      " Epoch 104: Train Loss: 0.000251, Validation Loss: 0.000294\n",
      " Epoch 105: Train Loss: 0.000251, Validation Loss: 0.000293\n",
      " Epoch 106: Train Loss: 0.000250, Validation Loss: 0.000293\n",
      " Epoch 107: Train Loss: 0.000250, Validation Loss: 0.000298\n",
      " Epoch 108: Train Loss: 0.000252, Validation Loss: 0.000293\n",
      " Epoch 109: Train Loss: 0.000249, Validation Loss: 0.000293\n",
      " Epoch 110: Train Loss: 0.000248, Validation Loss: 0.000292\n",
      " Epoch 111: Train Loss: 0.000246, Validation Loss: 0.000291\n",
      " Epoch 112: Train Loss: 0.000246, Validation Loss: 0.000296\n",
      " Epoch 113: Train Loss: 0.000245, Validation Loss: 0.000295\n",
      " Epoch 114: Train Loss: 0.000248, Validation Loss: 0.000296\n",
      " Epoch 115: Train Loss: 0.000247, Validation Loss: 0.000303\n",
      " Epoch 116: Train Loss: 0.000245, Validation Loss: 0.000293\n",
      " Epoch 117: Train Loss: 0.000243, Validation Loss: 0.000294\n",
      " Epoch 118: Train Loss: 0.000243, Validation Loss: 0.000294\n",
      " Epoch 119: Train Loss: 0.000242, Validation Loss: 0.000301\n",
      " Epoch 120: Train Loss: 0.000241, Validation Loss: 0.000293\n",
      " Epoch 121: Train Loss: 0.000239, Validation Loss: 0.000289\n",
      " Epoch 122: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 123: Train Loss: 0.000237, Validation Loss: 0.000290\n",
      " Epoch 124: Train Loss: 0.000237, Validation Loss: 0.000292\n",
      " Epoch 125: Train Loss: 0.000237, Validation Loss: 0.000290\n",
      " Epoch 126: Train Loss: 0.000237, Validation Loss: 0.000289\n",
      " Epoch 127: Train Loss: 0.000236, Validation Loss: 0.000294\n",
      " Epoch 128: Train Loss: 0.000235, Validation Loss: 0.000289\n",
      " Epoch 129: Train Loss: 0.000235, Validation Loss: 0.000289\n",
      " Epoch 130: Train Loss: 0.000235, Validation Loss: 0.000289\n",
      " Epoch 131: Train Loss: 0.000234, Validation Loss: 0.000290\n",
      " Epoch 132: Train Loss: 0.000234, Validation Loss: 0.000289\n",
      " Epoch 133: Train Loss: 0.000234, Validation Loss: 0.000289\n",
      " Epoch 134: Train Loss: 0.000234, Validation Loss: 0.000293\n",
      " Epoch 135: Train Loss: 0.000232, Validation Loss: 0.000289\n",
      " Epoch 136: Train Loss: 0.000233, Validation Loss: 0.000290\n",
      " Epoch 137: Train Loss: 0.000231, Validation Loss: 0.000288\n",
      " Epoch 138: Train Loss: 0.000231, Validation Loss: 0.000290\n",
      " Epoch 139: Train Loss: 0.000232, Validation Loss: 0.000291\n",
      " Epoch 140: Train Loss: 0.000231, Validation Loss: 0.000294\n",
      " Epoch 141: Train Loss: 0.000230, Validation Loss: 0.000288\n",
      " Epoch 142: Train Loss: 0.000230, Validation Loss: 0.000289\n",
      " Epoch 143: Train Loss: 0.000230, Validation Loss: 0.000292\n",
      " Epoch 144: Train Loss: 0.000229, Validation Loss: 0.000289\n",
      " Epoch 145: Train Loss: 0.000229, Validation Loss: 0.000288\n",
      " Epoch 146: Train Loss: 0.000230, Validation Loss: 0.000288\n",
      " Epoch 147: Train Loss: 0.000227, Validation Loss: 0.000288\n",
      " Epoch 148: Train Loss: 0.000226, Validation Loss: 0.000288\n",
      " Epoch 149: Train Loss: 0.000226, Validation Loss: 0.000288\n",
      " Epoch 150: Train Loss: 0.000227, Validation Loss: 0.000290\n",
      " Epoch 151: Train Loss: 0.000224, Validation Loss: 0.000288\n",
      " Epoch 152: Train Loss: 0.000224, Validation Loss: 0.000288\n",
      " Epoch 153: Train Loss: 0.000223, Validation Loss: 0.000288\n",
      " Epoch 154: Train Loss: 0.000223, Validation Loss: 0.000287\n",
      " Epoch 155: Train Loss: 0.000223, Validation Loss: 0.000287\n",
      " Epoch 156: Train Loss: 0.000223, Validation Loss: 0.000287\n",
      " Epoch 157: Train Loss: 0.000222, Validation Loss: 0.000287\n",
      " Epoch 158: Train Loss: 0.000222, Validation Loss: 0.000287\n",
      " Epoch 159: Train Loss: 0.000222, Validation Loss: 0.000288\n",
      " Epoch 160: Train Loss: 0.000222, Validation Loss: 0.000287\n",
      " Epoch 161: Train Loss: 0.000222, Validation Loss: 0.000291\n",
      " Epoch 162: Train Loss: 0.000221, Validation Loss: 0.000288\n",
      " Epoch 163: Train Loss: 0.000222, Validation Loss: 0.000288\n",
      " Epoch 164: Train Loss: 0.000221, Validation Loss: 0.000288\n",
      "Early stopping at epoch 164 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.015417, Validation Loss: 0.022609\n",
      " Epoch 2: Train Loss: 0.002639, Validation Loss: 0.004494\n",
      " Epoch 3: Train Loss: 0.001780, Validation Loss: 0.001732\n",
      " Epoch 4: Train Loss: 0.001103, Validation Loss: 0.000953\n",
      " Epoch 5: Train Loss: 0.000883, Validation Loss: 0.000830\n",
      " Epoch 6: Train Loss: 0.000786, Validation Loss: 0.000757\n",
      " Epoch 7: Train Loss: 0.000715, Validation Loss: 0.000692\n",
      " Epoch 8: Train Loss: 0.000658, Validation Loss: 0.000651\n",
      " Epoch 9: Train Loss: 0.000614, Validation Loss: 0.000609\n",
      " Epoch 10: Train Loss: 0.000579, Validation Loss: 0.000571\n",
      " Epoch 11: Train Loss: 0.000549, Validation Loss: 0.000552\n",
      " Epoch 12: Train Loss: 0.000527, Validation Loss: 0.000525\n",
      " Epoch 13: Train Loss: 0.000508, Validation Loss: 0.000503\n",
      " Epoch 14: Train Loss: 0.000486, Validation Loss: 0.000488\n",
      " Epoch 15: Train Loss: 0.000471, Validation Loss: 0.000479\n",
      " Epoch 16: Train Loss: 0.000460, Validation Loss: 0.000470\n",
      " Epoch 17: Train Loss: 0.000448, Validation Loss: 0.000457\n",
      " Epoch 18: Train Loss: 0.000438, Validation Loss: 0.000443\n",
      " Epoch 19: Train Loss: 0.000429, Validation Loss: 0.000437\n",
      " Epoch 20: Train Loss: 0.000422, Validation Loss: 0.000436\n",
      " Epoch 21: Train Loss: 0.000413, Validation Loss: 0.000424\n",
      " Epoch 22: Train Loss: 0.000407, Validation Loss: 0.000451\n",
      " Epoch 23: Train Loss: 0.000401, Validation Loss: 0.000412\n",
      " Epoch 24: Train Loss: 0.000394, Validation Loss: 0.000401\n",
      " Epoch 25: Train Loss: 0.000388, Validation Loss: 0.000400\n",
      " Epoch 26: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 27: Train Loss: 0.000375, Validation Loss: 0.000386\n",
      " Epoch 28: Train Loss: 0.000371, Validation Loss: 0.000387\n",
      " Epoch 29: Train Loss: 0.000367, Validation Loss: 0.000374\n",
      " Epoch 30: Train Loss: 0.000359, Validation Loss: 0.000371\n",
      " Epoch 31: Train Loss: 0.000351, Validation Loss: 0.000365\n",
      " Epoch 32: Train Loss: 0.000347, Validation Loss: 0.000363\n",
      " Epoch 33: Train Loss: 0.000345, Validation Loss: 0.000361\n",
      " Epoch 34: Train Loss: 0.000343, Validation Loss: 0.000358\n",
      " Epoch 35: Train Loss: 0.000341, Validation Loss: 0.000357\n",
      " Epoch 36: Train Loss: 0.000338, Validation Loss: 0.000354\n",
      " Epoch 37: Train Loss: 0.000336, Validation Loss: 0.000352\n",
      " Epoch 38: Train Loss: 0.000334, Validation Loss: 0.000351\n",
      " Epoch 39: Train Loss: 0.000331, Validation Loss: 0.000349\n",
      " Epoch 40: Train Loss: 0.000329, Validation Loss: 0.000346\n",
      " Epoch 41: Train Loss: 0.000326, Validation Loss: 0.000346\n",
      " Epoch 42: Train Loss: 0.000326, Validation Loss: 0.000344\n",
      " Epoch 43: Train Loss: 0.000324, Validation Loss: 0.000342\n",
      " Epoch 44: Train Loss: 0.000321, Validation Loss: 0.000340\n",
      " Epoch 45: Train Loss: 0.000321, Validation Loss: 0.000339\n",
      " Epoch 46: Train Loss: 0.000318, Validation Loss: 0.000341\n",
      " Epoch 47: Train Loss: 0.000316, Validation Loss: 0.000334\n",
      " Epoch 48: Train Loss: 0.000317, Validation Loss: 0.000334\n",
      " Epoch 49: Train Loss: 0.000314, Validation Loss: 0.000333\n",
      " Epoch 50: Train Loss: 0.000311, Validation Loss: 0.000338\n",
      " Epoch 51: Train Loss: 0.000311, Validation Loss: 0.000334\n",
      " Epoch 52: Train Loss: 0.000308, Validation Loss: 0.000328\n",
      " Epoch 53: Train Loss: 0.000305, Validation Loss: 0.000329\n",
      " Epoch 54: Train Loss: 0.000305, Validation Loss: 0.000327\n",
      " Epoch 55: Train Loss: 0.000302, Validation Loss: 0.000323\n",
      " Epoch 56: Train Loss: 0.000301, Validation Loss: 0.000322\n",
      " Epoch 57: Train Loss: 0.000304, Validation Loss: 0.000323\n",
      " Epoch 58: Train Loss: 0.000298, Validation Loss: 0.000319\n",
      " Epoch 59: Train Loss: 0.000298, Validation Loss: 0.000317\n",
      " Epoch 60: Train Loss: 0.000294, Validation Loss: 0.000320\n",
      " Epoch 61: Train Loss: 0.000290, Validation Loss: 0.000314\n",
      " Epoch 62: Train Loss: 0.000287, Validation Loss: 0.000312\n",
      " Epoch 63: Train Loss: 0.000286, Validation Loss: 0.000311\n",
      " Epoch 64: Train Loss: 0.000286, Validation Loss: 0.000311\n",
      " Epoch 65: Train Loss: 0.000286, Validation Loss: 0.000310\n",
      " Epoch 66: Train Loss: 0.000284, Validation Loss: 0.000312\n",
      " Epoch 67: Train Loss: 0.000284, Validation Loss: 0.000310\n",
      " Epoch 68: Train Loss: 0.000283, Validation Loss: 0.000310\n",
      " Epoch 69: Train Loss: 0.000282, Validation Loss: 0.000308\n",
      " Epoch 70: Train Loss: 0.000281, Validation Loss: 0.000308\n",
      " Epoch 71: Train Loss: 0.000280, Validation Loss: 0.000308\n",
      " Epoch 72: Train Loss: 0.000279, Validation Loss: 0.000306\n",
      " Epoch 73: Train Loss: 0.000279, Validation Loss: 0.000306\n",
      " Epoch 74: Train Loss: 0.000278, Validation Loss: 0.000307\n",
      " Epoch 75: Train Loss: 0.000277, Validation Loss: 0.000304\n",
      " Epoch 76: Train Loss: 0.000276, Validation Loss: 0.000306\n",
      " Epoch 77: Train Loss: 0.000275, Validation Loss: 0.000304\n",
      " Epoch 78: Train Loss: 0.000275, Validation Loss: 0.000302\n",
      " Epoch 79: Train Loss: 0.000273, Validation Loss: 0.000302\n",
      " Epoch 80: Train Loss: 0.000272, Validation Loss: 0.000302\n",
      " Epoch 81: Train Loss: 0.000273, Validation Loss: 0.000301\n",
      " Epoch 82: Train Loss: 0.000272, Validation Loss: 0.000303\n",
      " Epoch 83: Train Loss: 0.000270, Validation Loss: 0.000309\n",
      " Epoch 84: Train Loss: 0.000270, Validation Loss: 0.000299\n",
      " Epoch 85: Train Loss: 0.000269, Validation Loss: 0.000298\n",
      " Epoch 86: Train Loss: 0.000267, Validation Loss: 0.000298\n",
      " Epoch 87: Train Loss: 0.000267, Validation Loss: 0.000299\n",
      " Epoch 88: Train Loss: 0.000266, Validation Loss: 0.000299\n",
      " Epoch 89: Train Loss: 0.000266, Validation Loss: 0.000299\n",
      " Epoch 90: Train Loss: 0.000264, Validation Loss: 0.000297\n",
      " Epoch 91: Train Loss: 0.000261, Validation Loss: 0.000294\n",
      " Epoch 92: Train Loss: 0.000260, Validation Loss: 0.000294\n",
      " Epoch 93: Train Loss: 0.000260, Validation Loss: 0.000293\n",
      " Epoch 94: Train Loss: 0.000259, Validation Loss: 0.000294\n",
      " Epoch 95: Train Loss: 0.000259, Validation Loss: 0.000294\n",
      " Epoch 96: Train Loss: 0.000259, Validation Loss: 0.000293\n",
      " Epoch 97: Train Loss: 0.000258, Validation Loss: 0.000293\n",
      " Epoch 98: Train Loss: 0.000257, Validation Loss: 0.000293\n",
      " Epoch 99: Train Loss: 0.000257, Validation Loss: 0.000292\n",
      " Epoch 100: Train Loss: 0.000256, Validation Loss: 0.000292\n",
      " Epoch 101: Train Loss: 0.000256, Validation Loss: 0.000292\n",
      " Epoch 102: Train Loss: 0.000256, Validation Loss: 0.000292\n",
      " Epoch 103: Train Loss: 0.000256, Validation Loss: 0.000291\n",
      " Epoch 104: Train Loss: 0.000255, Validation Loss: 0.000291\n",
      " Epoch 105: Train Loss: 0.000254, Validation Loss: 0.000293\n",
      " Epoch 106: Train Loss: 0.000255, Validation Loss: 0.000290\n",
      " Epoch 107: Train Loss: 0.000253, Validation Loss: 0.000290\n",
      " Epoch 108: Train Loss: 0.000252, Validation Loss: 0.000290\n",
      " Epoch 109: Train Loss: 0.000252, Validation Loss: 0.000291\n",
      " Epoch 110: Train Loss: 0.000252, Validation Loss: 0.000289\n",
      " Epoch 111: Train Loss: 0.000251, Validation Loss: 0.000289\n",
      " Epoch 112: Train Loss: 0.000251, Validation Loss: 0.000289\n",
      " Epoch 113: Train Loss: 0.000251, Validation Loss: 0.000288\n",
      " Epoch 114: Train Loss: 0.000250, Validation Loss: 0.000289\n",
      " Epoch 115: Train Loss: 0.000250, Validation Loss: 0.000290\n",
      " Epoch 116: Train Loss: 0.000248, Validation Loss: 0.000288\n",
      " Epoch 117: Train Loss: 0.000249, Validation Loss: 0.000287\n",
      " Epoch 118: Train Loss: 0.000248, Validation Loss: 0.000288\n",
      " Epoch 119: Train Loss: 0.000249, Validation Loss: 0.000287\n",
      " Epoch 120: Train Loss: 0.000247, Validation Loss: 0.000288\n",
      " Epoch 121: Train Loss: 0.000245, Validation Loss: 0.000285\n",
      " Epoch 122: Train Loss: 0.000244, Validation Loss: 0.000285\n",
      " Epoch 123: Train Loss: 0.000243, Validation Loss: 0.000285\n",
      " Epoch 124: Train Loss: 0.000243, Validation Loss: 0.000285\n",
      " Epoch 125: Train Loss: 0.000243, Validation Loss: 0.000285\n",
      " Epoch 126: Train Loss: 0.000242, Validation Loss: 0.000285\n",
      " Epoch 127: Train Loss: 0.000242, Validation Loss: 0.000285\n",
      " Epoch 128: Train Loss: 0.000242, Validation Loss: 0.000285\n",
      " Epoch 129: Train Loss: 0.000242, Validation Loss: 0.000284\n",
      " Epoch 130: Train Loss: 0.000241, Validation Loss: 0.000284\n",
      " Epoch 131: Train Loss: 0.000241, Validation Loss: 0.000285\n",
      " Epoch 132: Train Loss: 0.000241, Validation Loss: 0.000284\n",
      " Epoch 133: Train Loss: 0.000240, Validation Loss: 0.000284\n",
      " Epoch 134: Train Loss: 0.000240, Validation Loss: 0.000284\n",
      " Epoch 135: Train Loss: 0.000241, Validation Loss: 0.000285\n",
      " Epoch 136: Train Loss: 0.000239, Validation Loss: 0.000283\n",
      " Epoch 137: Train Loss: 0.000239, Validation Loss: 0.000283\n",
      " Epoch 138: Train Loss: 0.000239, Validation Loss: 0.000283\n",
      " Epoch 139: Train Loss: 0.000238, Validation Loss: 0.000283\n",
      " Epoch 140: Train Loss: 0.000238, Validation Loss: 0.000283\n",
      " Epoch 141: Train Loss: 0.000238, Validation Loss: 0.000283\n",
      " Epoch 142: Train Loss: 0.000238, Validation Loss: 0.000283\n",
      " Epoch 143: Train Loss: 0.000237, Validation Loss: 0.000284\n",
      " Epoch 144: Train Loss: 0.000237, Validation Loss: 0.000283\n",
      " Epoch 145: Train Loss: 0.000237, Validation Loss: 0.000283\n",
      " Epoch 146: Train Loss: 0.000236, Validation Loss: 0.000282\n",
      " Epoch 147: Train Loss: 0.000236, Validation Loss: 0.000282\n",
      " Epoch 148: Train Loss: 0.000235, Validation Loss: 0.000282\n",
      " Epoch 149: Train Loss: 0.000235, Validation Loss: 0.000282\n",
      " Epoch 150: Train Loss: 0.000235, Validation Loss: 0.000283\n",
      " Epoch 151: Train Loss: 0.000234, Validation Loss: 0.000281\n",
      " Epoch 152: Train Loss: 0.000233, Validation Loss: 0.000281\n",
      " Epoch 153: Train Loss: 0.000233, Validation Loss: 0.000281\n",
      " Epoch 154: Train Loss: 0.000233, Validation Loss: 0.000281\n",
      " Epoch 155: Train Loss: 0.000233, Validation Loss: 0.000281\n",
      " Epoch 156: Train Loss: 0.000233, Validation Loss: 0.000281\n",
      " Epoch 157: Train Loss: 0.000232, Validation Loss: 0.000281\n",
      " Epoch 158: Train Loss: 0.000232, Validation Loss: 0.000282\n",
      " Epoch 159: Train Loss: 0.000232, Validation Loss: 0.000281\n",
      " Epoch 160: Train Loss: 0.000231, Validation Loss: 0.000281\n",
      " Epoch 161: Train Loss: 0.000231, Validation Loss: 0.000281\n",
      " Epoch 162: Train Loss: 0.000231, Validation Loss: 0.000281\n",
      " Epoch 163: Train Loss: 0.000231, Validation Loss: 0.000280\n",
      " Epoch 164: Train Loss: 0.000231, Validation Loss: 0.000280\n",
      " Epoch 165: Train Loss: 0.000231, Validation Loss: 0.000281\n",
      " Epoch 166: Train Loss: 0.000230, Validation Loss: 0.000281\n",
      " Epoch 167: Train Loss: 0.000230, Validation Loss: 0.000280\n",
      " Epoch 168: Train Loss: 0.000230, Validation Loss: 0.000280\n",
      " Epoch 169: Train Loss: 0.000230, Validation Loss: 0.000280\n",
      " Epoch 170: Train Loss: 0.000230, Validation Loss: 0.000280\n",
      " Epoch 171: Train Loss: 0.000230, Validation Loss: 0.000282\n",
      " Epoch 172: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 173: Train Loss: 0.000229, Validation Loss: 0.000280\n",
      " Epoch 174: Train Loss: 0.000229, Validation Loss: 0.000280\n",
      " Epoch 175: Train Loss: 0.000229, Validation Loss: 0.000280\n",
      " Epoch 176: Train Loss: 0.000228, Validation Loss: 0.000280\n",
      " Epoch 177: Train Loss: 0.000228, Validation Loss: 0.000280\n",
      " Epoch 178: Train Loss: 0.000228, Validation Loss: 0.000280\n",
      " Epoch 179: Train Loss: 0.000228, Validation Loss: 0.000280\n",
      " Epoch 180: Train Loss: 0.000228, Validation Loss: 0.000280\n",
      " Epoch 181: Train Loss: 0.000227, Validation Loss: 0.000280\n",
      " Epoch 182: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 183: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 184: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 185: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 186: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 187: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 188: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 189: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 190: Train Loss: 0.000226, Validation Loss: 0.000279\n",
      " Epoch 191: Train Loss: 0.000225, Validation Loss: 0.000279\n",
      " Epoch 192: Train Loss: 0.000225, Validation Loss: 0.000279\n",
      "Early stopping at epoch 192 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.014684, Validation Loss: 0.012219\n",
      " Epoch 2: Train Loss: 0.003504, Validation Loss: 0.002711\n",
      " Epoch 3: Train Loss: 0.001562, Validation Loss: 0.001303\n",
      " Epoch 4: Train Loss: 0.001100, Validation Loss: 0.001016\n",
      " Epoch 5: Train Loss: 0.000949, Validation Loss: 0.000875\n",
      " Epoch 6: Train Loss: 0.000826, Validation Loss: 0.000781\n",
      " Epoch 7: Train Loss: 0.000733, Validation Loss: 0.000693\n",
      " Epoch 8: Train Loss: 0.000660, Validation Loss: 0.000630\n",
      " Epoch 9: Train Loss: 0.000601, Validation Loss: 0.000606\n",
      " Epoch 10: Train Loss: 0.000564, Validation Loss: 0.000572\n",
      " Epoch 11: Train Loss: 0.000534, Validation Loss: 0.000530\n",
      " Epoch 12: Train Loss: 0.000514, Validation Loss: 0.000523\n",
      " Epoch 13: Train Loss: 0.000494, Validation Loss: 0.000500\n",
      " Epoch 14: Train Loss: 0.000479, Validation Loss: 0.000481\n",
      " Epoch 15: Train Loss: 0.000464, Validation Loss: 0.000468\n",
      " Epoch 16: Train Loss: 0.000469, Validation Loss: 0.000546\n",
      " Epoch 17: Train Loss: 0.000467, Validation Loss: 0.000455\n",
      " Epoch 18: Train Loss: 0.000438, Validation Loss: 0.000456\n",
      " Epoch 19: Train Loss: 0.000430, Validation Loss: 0.000431\n",
      " Epoch 20: Train Loss: 0.000418, Validation Loss: 0.000432\n",
      " Epoch 21: Train Loss: 0.000411, Validation Loss: 0.000416\n",
      " Epoch 22: Train Loss: 0.000400, Validation Loss: 0.000405\n",
      " Epoch 23: Train Loss: 0.000402, Validation Loss: 0.000419\n",
      " Epoch 24: Train Loss: 0.000392, Validation Loss: 0.000395\n",
      " Epoch 25: Train Loss: 0.000389, Validation Loss: 0.000395\n",
      " Epoch 26: Train Loss: 0.000379, Validation Loss: 0.000385\n",
      " Epoch 27: Train Loss: 0.000382, Validation Loss: 0.000406\n",
      " Epoch 28: Train Loss: 0.000382, Validation Loss: 0.000384\n",
      " Epoch 29: Train Loss: 0.000366, Validation Loss: 0.000381\n",
      " Epoch 30: Train Loss: 0.000363, Validation Loss: 0.000375\n",
      " Epoch 31: Train Loss: 0.000353, Validation Loss: 0.000364\n",
      " Epoch 32: Train Loss: 0.000350, Validation Loss: 0.000359\n",
      " Epoch 33: Train Loss: 0.000348, Validation Loss: 0.000357\n",
      " Epoch 34: Train Loss: 0.000345, Validation Loss: 0.000356\n",
      " Epoch 35: Train Loss: 0.000344, Validation Loss: 0.000354\n",
      " Epoch 36: Train Loss: 0.000341, Validation Loss: 0.000358\n",
      " Epoch 37: Train Loss: 0.000339, Validation Loss: 0.000351\n",
      " Epoch 38: Train Loss: 0.000337, Validation Loss: 0.000348\n",
      " Epoch 39: Train Loss: 0.000335, Validation Loss: 0.000350\n",
      " Epoch 40: Train Loss: 0.000334, Validation Loss: 0.000344\n",
      " Epoch 41: Train Loss: 0.000331, Validation Loss: 0.000342\n",
      " Epoch 42: Train Loss: 0.000340, Validation Loss: 0.000352\n",
      " Epoch 43: Train Loss: 0.000332, Validation Loss: 0.000341\n",
      " Epoch 44: Train Loss: 0.000327, Validation Loss: 0.000337\n",
      " Epoch 45: Train Loss: 0.000325, Validation Loss: 0.000347\n",
      " Epoch 46: Train Loss: 0.000322, Validation Loss: 0.000337\n",
      " Epoch 47: Train Loss: 0.000321, Validation Loss: 0.000330\n",
      " Epoch 48: Train Loss: 0.000318, Validation Loss: 0.000329\n",
      " Epoch 49: Train Loss: 0.000317, Validation Loss: 0.000330\n",
      " Epoch 50: Train Loss: 0.000314, Validation Loss: 0.000329\n",
      " Epoch 51: Train Loss: 0.000314, Validation Loss: 0.000332\n",
      " Epoch 52: Train Loss: 0.000322, Validation Loss: 0.000335\n",
      " Epoch 53: Train Loss: 0.000330, Validation Loss: 0.000327\n",
      " Epoch 54: Train Loss: 0.000310, Validation Loss: 0.000322\n",
      " Epoch 55: Train Loss: 0.000313, Validation Loss: 0.000323\n",
      " Epoch 56: Train Loss: 0.000305, Validation Loss: 0.000319\n",
      " Epoch 57: Train Loss: 0.000305, Validation Loss: 0.000317\n",
      " Epoch 58: Train Loss: 0.000301, Validation Loss: 0.000317\n",
      " Epoch 59: Train Loss: 0.000303, Validation Loss: 0.000317\n",
      " Epoch 60: Train Loss: 0.000301, Validation Loss: 0.000314\n",
      " Epoch 61: Train Loss: 0.000295, Validation Loss: 0.000311\n",
      " Epoch 62: Train Loss: 0.000294, Validation Loss: 0.000309\n",
      " Epoch 63: Train Loss: 0.000293, Validation Loss: 0.000310\n",
      " Epoch 64: Train Loss: 0.000292, Validation Loss: 0.000311\n",
      " Epoch 65: Train Loss: 0.000292, Validation Loss: 0.000307\n",
      " Epoch 66: Train Loss: 0.000290, Validation Loss: 0.000307\n",
      " Epoch 67: Train Loss: 0.000289, Validation Loss: 0.000307\n",
      " Epoch 68: Train Loss: 0.000288, Validation Loss: 0.000305\n",
      " Epoch 69: Train Loss: 0.000288, Validation Loss: 0.000304\n",
      " Epoch 70: Train Loss: 0.000288, Validation Loss: 0.000305\n",
      " Epoch 71: Train Loss: 0.000289, Validation Loss: 0.000306\n",
      " Epoch 72: Train Loss: 0.000286, Validation Loss: 0.000302\n",
      " Epoch 73: Train Loss: 0.000285, Validation Loss: 0.000307\n",
      " Epoch 74: Train Loss: 0.000285, Validation Loss: 0.000302\n",
      " Epoch 75: Train Loss: 0.000284, Validation Loss: 0.000303\n",
      " Epoch 76: Train Loss: 0.000282, Validation Loss: 0.000299\n",
      " Epoch 77: Train Loss: 0.000282, Validation Loss: 0.000299\n",
      " Epoch 78: Train Loss: 0.000280, Validation Loss: 0.000298\n",
      " Epoch 79: Train Loss: 0.000281, Validation Loss: 0.000299\n",
      " Epoch 80: Train Loss: 0.000279, Validation Loss: 0.000299\n",
      " Epoch 81: Train Loss: 0.000278, Validation Loss: 0.000296\n",
      " Epoch 82: Train Loss: 0.000278, Validation Loss: 0.000298\n",
      " Epoch 83: Train Loss: 0.000277, Validation Loss: 0.000298\n",
      " Epoch 84: Train Loss: 0.000278, Validation Loss: 0.000298\n",
      " Epoch 85: Train Loss: 0.000276, Validation Loss: 0.000297\n",
      " Epoch 86: Train Loss: 0.000275, Validation Loss: 0.000295\n",
      " Epoch 87: Train Loss: 0.000274, Validation Loss: 0.000294\n",
      " Epoch 88: Train Loss: 0.000275, Validation Loss: 0.000295\n",
      " Epoch 89: Train Loss: 0.000274, Validation Loss: 0.000293\n",
      " Epoch 90: Train Loss: 0.000272, Validation Loss: 0.000294\n",
      " Epoch 91: Train Loss: 0.000269, Validation Loss: 0.000290\n",
      " Epoch 92: Train Loss: 0.000268, Validation Loss: 0.000290\n",
      " Epoch 93: Train Loss: 0.000268, Validation Loss: 0.000289\n",
      " Epoch 94: Train Loss: 0.000267, Validation Loss: 0.000289\n",
      " Epoch 95: Train Loss: 0.000267, Validation Loss: 0.000288\n",
      " Epoch 96: Train Loss: 0.000267, Validation Loss: 0.000292\n",
      " Epoch 97: Train Loss: 0.000266, Validation Loss: 0.000288\n",
      " Epoch 98: Train Loss: 0.000266, Validation Loss: 0.000289\n",
      " Epoch 99: Train Loss: 0.000265, Validation Loss: 0.000287\n",
      " Epoch 100: Train Loss: 0.000265, Validation Loss: 0.000287\n",
      " Epoch 101: Train Loss: 0.000264, Validation Loss: 0.000287\n",
      " Epoch 102: Train Loss: 0.000264, Validation Loss: 0.000286\n",
      " Epoch 103: Train Loss: 0.000263, Validation Loss: 0.000286\n",
      " Epoch 104: Train Loss: 0.000263, Validation Loss: 0.000286\n",
      " Epoch 105: Train Loss: 0.000263, Validation Loss: 0.000286\n",
      " Epoch 106: Train Loss: 0.000262, Validation Loss: 0.000285\n",
      " Epoch 107: Train Loss: 0.000262, Validation Loss: 0.000285\n",
      " Epoch 108: Train Loss: 0.000261, Validation Loss: 0.000284\n",
      " Epoch 109: Train Loss: 0.000262, Validation Loss: 0.000284\n",
      " Epoch 110: Train Loss: 0.000261, Validation Loss: 0.000284\n",
      " Epoch 111: Train Loss: 0.000260, Validation Loss: 0.000284\n",
      " Epoch 112: Train Loss: 0.000260, Validation Loss: 0.000283\n",
      " Epoch 113: Train Loss: 0.000259, Validation Loss: 0.000284\n",
      " Epoch 114: Train Loss: 0.000258, Validation Loss: 0.000284\n",
      " Epoch 115: Train Loss: 0.000258, Validation Loss: 0.000283\n",
      " Epoch 116: Train Loss: 0.000258, Validation Loss: 0.000285\n",
      " Epoch 117: Train Loss: 0.000258, Validation Loss: 0.000282\n",
      " Epoch 118: Train Loss: 0.000257, Validation Loss: 0.000282\n",
      " Epoch 119: Train Loss: 0.000256, Validation Loss: 0.000282\n",
      " Epoch 120: Train Loss: 0.000256, Validation Loss: 0.000281\n",
      " Epoch 121: Train Loss: 0.000254, Validation Loss: 0.000280\n",
      " Epoch 122: Train Loss: 0.000253, Validation Loss: 0.000280\n",
      " Epoch 123: Train Loss: 0.000254, Validation Loss: 0.000280\n",
      " Epoch 124: Train Loss: 0.000253, Validation Loss: 0.000279\n",
      " Epoch 125: Train Loss: 0.000253, Validation Loss: 0.000280\n",
      " Epoch 126: Train Loss: 0.000254, Validation Loss: 0.000279\n",
      " Epoch 127: Train Loss: 0.000252, Validation Loss: 0.000280\n",
      " Epoch 128: Train Loss: 0.000252, Validation Loss: 0.000279\n",
      " Epoch 129: Train Loss: 0.000252, Validation Loss: 0.000279\n",
      " Epoch 130: Train Loss: 0.000252, Validation Loss: 0.000279\n",
      " Epoch 131: Train Loss: 0.000251, Validation Loss: 0.000278\n",
      " Epoch 132: Train Loss: 0.000251, Validation Loss: 0.000278\n",
      " Epoch 133: Train Loss: 0.000251, Validation Loss: 0.000278\n",
      " Epoch 134: Train Loss: 0.000250, Validation Loss: 0.000278\n",
      " Epoch 135: Train Loss: 0.000251, Validation Loss: 0.000278\n",
      " Epoch 136: Train Loss: 0.000250, Validation Loss: 0.000278\n",
      " Epoch 137: Train Loss: 0.000250, Validation Loss: 0.000278\n",
      " Epoch 138: Train Loss: 0.000249, Validation Loss: 0.000277\n",
      " Epoch 139: Train Loss: 0.000249, Validation Loss: 0.000277\n",
      " Epoch 140: Train Loss: 0.000249, Validation Loss: 0.000277\n",
      " Epoch 141: Train Loss: 0.000249, Validation Loss: 0.000277\n",
      " Epoch 142: Train Loss: 0.000248, Validation Loss: 0.000277\n",
      " Epoch 143: Train Loss: 0.000248, Validation Loss: 0.000278\n",
      " Epoch 144: Train Loss: 0.000248, Validation Loss: 0.000277\n",
      " Epoch 145: Train Loss: 0.000247, Validation Loss: 0.000276\n",
      " Epoch 146: Train Loss: 0.000247, Validation Loss: 0.000277\n",
      " Epoch 147: Train Loss: 0.000247, Validation Loss: 0.000277\n",
      " Epoch 148: Train Loss: 0.000247, Validation Loss: 0.000276\n",
      " Epoch 149: Train Loss: 0.000246, Validation Loss: 0.000275\n",
      " Epoch 150: Train Loss: 0.000247, Validation Loss: 0.000277\n",
      " Epoch 151: Train Loss: 0.000245, Validation Loss: 0.000275\n",
      " Epoch 152: Train Loss: 0.000244, Validation Loss: 0.000275\n",
      " Epoch 153: Train Loss: 0.000244, Validation Loss: 0.000275\n",
      " Epoch 154: Train Loss: 0.000244, Validation Loss: 0.000275\n",
      " Epoch 155: Train Loss: 0.000244, Validation Loss: 0.000274\n",
      " Epoch 156: Train Loss: 0.000244, Validation Loss: 0.000274\n",
      " Epoch 157: Train Loss: 0.000244, Validation Loss: 0.000274\n",
      " Epoch 158: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 159: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 160: Train Loss: 0.000243, Validation Loss: 0.000275\n",
      " Epoch 161: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 162: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 163: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 164: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 165: Train Loss: 0.000243, Validation Loss: 0.000274\n",
      " Epoch 166: Train Loss: 0.000242, Validation Loss: 0.000274\n",
      " Epoch 167: Train Loss: 0.000242, Validation Loss: 0.000274\n",
      " Epoch 168: Train Loss: 0.000242, Validation Loss: 0.000273\n",
      " Epoch 169: Train Loss: 0.000242, Validation Loss: 0.000273\n",
      " Epoch 170: Train Loss: 0.000241, Validation Loss: 0.000273\n",
      " Epoch 171: Train Loss: 0.000242, Validation Loss: 0.000274\n",
      " Epoch 172: Train Loss: 0.000241, Validation Loss: 0.000273\n",
      " Epoch 173: Train Loss: 0.000241, Validation Loss: 0.000273\n",
      " Epoch 174: Train Loss: 0.000241, Validation Loss: 0.000274\n",
      " Epoch 175: Train Loss: 0.000241, Validation Loss: 0.000273\n",
      " Epoch 176: Train Loss: 0.000240, Validation Loss: 0.000273\n",
      " Epoch 177: Train Loss: 0.000240, Validation Loss: 0.000273\n",
      " Epoch 178: Train Loss: 0.000240, Validation Loss: 0.000272\n",
      " Epoch 179: Train Loss: 0.000241, Validation Loss: 0.000273\n",
      " Epoch 180: Train Loss: 0.000240, Validation Loss: 0.000273\n",
      " Epoch 181: Train Loss: 0.000239, Validation Loss: 0.000272\n",
      " Epoch 182: Train Loss: 0.000239, Validation Loss: 0.000272\n",
      " Epoch 183: Train Loss: 0.000239, Validation Loss: 0.000272\n",
      " Epoch 184: Train Loss: 0.000239, Validation Loss: 0.000272\n",
      " Epoch 185: Train Loss: 0.000239, Validation Loss: 0.000272\n",
      " Epoch 186: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 187: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 188: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 189: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 190: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 191: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 192: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 193: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 194: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 195: Train Loss: 0.000237, Validation Loss: 0.000272\n",
      " Epoch 196: Train Loss: 0.000238, Validation Loss: 0.000272\n",
      " Epoch 197: Train Loss: 0.000238, Validation Loss: 0.000271\n",
      " Epoch 198: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 199: Train Loss: 0.000237, Validation Loss: 0.000272\n",
      " Epoch 200: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 201: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 202: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 203: Train Loss: 0.000237, Validation Loss: 0.000271\n",
      " Epoch 204: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 205: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 206: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 207: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 208: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 209: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 210: Train Loss: 0.000236, Validation Loss: 0.000271\n",
      " Epoch 211: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 212: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 213: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 214: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 215: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 216: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 217: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 218: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 219: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 220: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 221: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 222: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 223: Train Loss: 0.000235, Validation Loss: 0.000271\n",
      " Epoch 224: Train Loss: 0.000235, Validation Loss: 0.000270\n",
      " Epoch 225: Train Loss: 0.000235, Validation Loss: 0.000270\n",
      " Epoch 226: Train Loss: 0.000235, Validation Loss: 0.000270\n",
      " Epoch 227: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 228: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 229: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 230: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 231: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 232: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 233: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 234: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 235: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 236: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 237: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 238: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 239: Train Loss: 0.000234, Validation Loss: 0.000270\n",
      " Epoch 240: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 241: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 242: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 243: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 244: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 245: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 246: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 247: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 248: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 249: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 250: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 251: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 252: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 253: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 254: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 255: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 256: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 257: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 258: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 259: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 260: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      " Epoch 261: Train Loss: 0.000233, Validation Loss: 0.000270\n",
      "Early stopping at epoch 261 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.022751, Validation Loss: 0.028831\n",
      " Epoch 2: Train Loss: 0.007435, Validation Loss: 0.010161\n",
      " Epoch 3: Train Loss: 0.004672, Validation Loss: 0.005791\n",
      " Epoch 4: Train Loss: 0.002664, Validation Loss: 0.002094\n",
      " Epoch 5: Train Loss: 0.001839, Validation Loss: 0.001437\n",
      " Epoch 6: Train Loss: 0.001519, Validation Loss: 0.001239\n",
      " Epoch 7: Train Loss: 0.001351, Validation Loss: 0.001058\n",
      " Epoch 8: Train Loss: 0.001241, Validation Loss: 0.000873\n",
      " Epoch 9: Train Loss: 0.001164, Validation Loss: 0.000901\n",
      " Epoch 10: Train Loss: 0.001104, Validation Loss: 0.000789\n",
      " Epoch 11: Train Loss: 0.001038, Validation Loss: 0.000745\n",
      " Epoch 12: Train Loss: 0.000986, Validation Loss: 0.000658\n",
      " Epoch 13: Train Loss: 0.000958, Validation Loss: 0.000636\n",
      " Epoch 14: Train Loss: 0.000937, Validation Loss: 0.000614\n",
      " Epoch 15: Train Loss: 0.000911, Validation Loss: 0.000637\n",
      " Epoch 16: Train Loss: 0.000890, Validation Loss: 0.000601\n",
      " Epoch 17: Train Loss: 0.000844, Validation Loss: 0.000580\n",
      " Epoch 18: Train Loss: 0.000830, Validation Loss: 0.000601\n",
      " Epoch 19: Train Loss: 0.000813, Validation Loss: 0.000722\n",
      " Epoch 20: Train Loss: 0.000790, Validation Loss: 0.000532\n",
      " Epoch 21: Train Loss: 0.001124, Validation Loss: 0.003310\n",
      " Epoch 22: Train Loss: 0.001497, Validation Loss: 0.000872\n",
      " Epoch 23: Train Loss: 0.001039, Validation Loss: 0.000710\n",
      " Epoch 24: Train Loss: 0.000952, Validation Loss: 0.000668\n",
      " Epoch 25: Train Loss: 0.000923, Validation Loss: 0.000642\n",
      " Epoch 26: Train Loss: 0.000880, Validation Loss: 0.000615\n",
      " Epoch 27: Train Loss: 0.000856, Validation Loss: 0.000642\n",
      " Epoch 28: Train Loss: 0.000838, Validation Loss: 0.000581\n",
      " Epoch 29: Train Loss: 0.000811, Validation Loss: 0.000577\n",
      " Epoch 30: Train Loss: 0.000793, Validation Loss: 0.000581\n",
      "Early stopping at epoch 30 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.024050, Validation Loss: 0.029387\n",
      " Epoch 2: Train Loss: 0.006665, Validation Loss: 0.027365\n",
      " Epoch 3: Train Loss: 0.003738, Validation Loss: 0.003382\n",
      " Epoch 4: Train Loss: 0.002392, Validation Loss: 0.001826\n",
      " Epoch 5: Train Loss: 0.001840, Validation Loss: 0.001461\n",
      " Epoch 6: Train Loss: 0.001564, Validation Loss: 0.001190\n",
      " Epoch 7: Train Loss: 0.001429, Validation Loss: 0.001126\n",
      " Epoch 8: Train Loss: 0.001321, Validation Loss: 0.001173\n",
      " Epoch 9: Train Loss: 0.001209, Validation Loss: 0.000939\n",
      " Epoch 10: Train Loss: 0.001145, Validation Loss: 0.000859\n",
      " Epoch 11: Train Loss: 0.001098, Validation Loss: 0.001207\n",
      " Epoch 12: Train Loss: 0.001053, Validation Loss: 0.000853\n",
      " Epoch 13: Train Loss: 0.001005, Validation Loss: 0.000725\n",
      " Epoch 14: Train Loss: 0.000968, Validation Loss: 0.000670\n",
      " Epoch 15: Train Loss: 0.000937, Validation Loss: 0.000710\n",
      " Epoch 16: Train Loss: 0.000908, Validation Loss: 0.000785\n",
      " Epoch 17: Train Loss: 0.000880, Validation Loss: 0.000916\n",
      " Epoch 18: Train Loss: 0.000852, Validation Loss: 0.000900\n",
      " Epoch 19: Train Loss: 0.000835, Validation Loss: 0.000636\n",
      " Epoch 20: Train Loss: 0.000822, Validation Loss: 0.000692\n",
      " Epoch 21: Train Loss: 0.000799, Validation Loss: 0.000788\n",
      " Epoch 22: Train Loss: 0.000795, Validation Loss: 0.000625\n",
      " Epoch 23: Train Loss: 0.000768, Validation Loss: 0.000689\n",
      " Epoch 24: Train Loss: 0.000763, Validation Loss: 0.000583\n",
      " Epoch 25: Train Loss: 0.000742, Validation Loss: 0.000570\n",
      " Epoch 26: Train Loss: 0.000728, Validation Loss: 0.000846\n",
      " Epoch 27: Train Loss: 0.000717, Validation Loss: 0.000501\n",
      " Epoch 28: Train Loss: 0.000717, Validation Loss: 0.000534\n",
      " Epoch 29: Train Loss: 0.000701, Validation Loss: 0.000567\n",
      " Epoch 30: Train Loss: 0.000693, Validation Loss: 0.000491\n",
      " Epoch 31: Train Loss: 0.000692, Validation Loss: 0.000515\n",
      " Epoch 32: Train Loss: 0.000676, Validation Loss: 0.000460\n",
      " Epoch 33: Train Loss: 0.000666, Validation Loss: 0.000513\n",
      " Epoch 34: Train Loss: 0.000667, Validation Loss: 0.000543\n",
      " Epoch 35: Train Loss: 0.000661, Validation Loss: 0.000513\n",
      " Epoch 36: Train Loss: 0.000653, Validation Loss: 0.000510\n",
      " Epoch 37: Train Loss: 0.000651, Validation Loss: 0.000500\n",
      " Epoch 38: Train Loss: 0.000650, Validation Loss: 0.000546\n",
      " Epoch 39: Train Loss: 0.000652, Validation Loss: 0.000480\n",
      " Epoch 40: Train Loss: 0.000640, Validation Loss: 0.000455\n",
      " Epoch 41: Train Loss: 0.000635, Validation Loss: 0.000496\n",
      " Epoch 42: Train Loss: 0.000629, Validation Loss: 0.000500\n",
      " Epoch 43: Train Loss: 0.000624, Validation Loss: 0.000523\n",
      " Epoch 44: Train Loss: 0.000621, Validation Loss: 0.000506\n",
      " Epoch 45: Train Loss: 0.000621, Validation Loss: 0.001748\n",
      " Epoch 46: Train Loss: 0.000619, Validation Loss: 0.000466\n",
      " Epoch 47: Train Loss: 0.000611, Validation Loss: 0.000512\n",
      " Epoch 48: Train Loss: 0.000612, Validation Loss: 0.000649\n",
      " Epoch 49: Train Loss: 0.000612, Validation Loss: 0.000570\n",
      " Epoch 50: Train Loss: 0.000612, Validation Loss: 0.000473\n",
      "Early stopping at epoch 50 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.024341, Validation Loss: 0.028661\n",
      " Epoch 2: Train Loss: 0.006796, Validation Loss: 0.007686\n",
      " Epoch 3: Train Loss: 0.004078, Validation Loss: 0.004719\n",
      " Epoch 4: Train Loss: 0.002504, Validation Loss: 0.002085\n",
      " Epoch 5: Train Loss: 0.002049, Validation Loss: 0.001856\n",
      " Epoch 6: Train Loss: 0.001740, Validation Loss: 0.001376\n",
      " Epoch 7: Train Loss: 0.001577, Validation Loss: 0.001270\n",
      " Epoch 8: Train Loss: 0.001477, Validation Loss: 0.001143\n",
      " Epoch 9: Train Loss: 0.001401, Validation Loss: 0.001136\n",
      " Epoch 10: Train Loss: 0.001323, Validation Loss: 0.003326\n",
      " Epoch 11: Train Loss: 0.001155, Validation Loss: 0.000782\n",
      " Epoch 12: Train Loss: 0.001016, Validation Loss: 0.000718\n",
      " Epoch 13: Train Loss: 0.000970, Validation Loss: 0.000700\n",
      " Epoch 14: Train Loss: 0.000929, Validation Loss: 0.000667\n",
      " Epoch 15: Train Loss: 0.000894, Validation Loss: 0.000629\n",
      " Epoch 16: Train Loss: 0.000864, Validation Loss: 0.000603\n",
      " Epoch 17: Train Loss: 0.000840, Validation Loss: 0.000634\n",
      " Epoch 18: Train Loss: 0.000819, Validation Loss: 0.000598\n",
      " Epoch 19: Train Loss: 0.000798, Validation Loss: 0.000586\n",
      " Epoch 20: Train Loss: 0.000783, Validation Loss: 0.000573\n",
      " Epoch 21: Train Loss: 0.000767, Validation Loss: 0.000578\n",
      " Epoch 22: Train Loss: 0.000750, Validation Loss: 0.000524\n",
      " Epoch 23: Train Loss: 0.000737, Validation Loss: 0.000524\n",
      " Epoch 24: Train Loss: 0.000726, Validation Loss: 0.000532\n",
      " Epoch 25: Train Loss: 0.000712, Validation Loss: 0.000532\n",
      " Epoch 26: Train Loss: 0.000702, Validation Loss: 0.000517\n",
      " Epoch 27: Train Loss: 0.000692, Validation Loss: 0.000499\n",
      " Epoch 28: Train Loss: 0.000680, Validation Loss: 0.000496\n",
      " Epoch 29: Train Loss: 0.000672, Validation Loss: 0.000535\n",
      " Epoch 30: Train Loss: 0.000664, Validation Loss: 0.000480\n",
      " Epoch 31: Train Loss: 0.000653, Validation Loss: 0.000505\n",
      " Epoch 32: Train Loss: 0.000648, Validation Loss: 0.000472\n",
      " Epoch 33: Train Loss: 0.000645, Validation Loss: 0.000497\n",
      " Epoch 34: Train Loss: 0.000639, Validation Loss: 0.000494\n",
      " Epoch 35: Train Loss: 0.000636, Validation Loss: 0.000516\n",
      " Epoch 36: Train Loss: 0.000633, Validation Loss: 0.000505\n",
      " Epoch 37: Train Loss: 0.000628, Validation Loss: 0.000510\n",
      " Epoch 38: Train Loss: 0.000624, Validation Loss: 0.000513\n",
      " Epoch 39: Train Loss: 0.000621, Validation Loss: 0.000494\n",
      " Epoch 40: Train Loss: 0.000617, Validation Loss: 0.000484\n",
      " Epoch 41: Train Loss: 0.000613, Validation Loss: 0.000485\n",
      " Epoch 42: Train Loss: 0.000610, Validation Loss: 0.000501\n",
      "Early stopping at epoch 42 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.012161, Validation Loss: 0.011657\n",
      " Epoch 2: Train Loss: 0.002902, Validation Loss: 0.002424\n",
      " Epoch 3: Train Loss: 0.001780, Validation Loss: 0.001164\n",
      " Epoch 4: Train Loss: 0.001389, Validation Loss: 0.000965\n",
      " Epoch 5: Train Loss: 0.001212, Validation Loss: 0.000892\n",
      " Epoch 6: Train Loss: 0.001103, Validation Loss: 0.000795\n",
      " Epoch 7: Train Loss: 0.001027, Validation Loss: 0.000732\n",
      " Epoch 8: Train Loss: 0.000959, Validation Loss: 0.000675\n",
      " Epoch 9: Train Loss: 0.000912, Validation Loss: 0.000687\n",
      " Epoch 10: Train Loss: 0.000875, Validation Loss: 0.000651\n",
      " Epoch 11: Train Loss: 0.000842, Validation Loss: 0.000619\n",
      " Epoch 12: Train Loss: 0.000817, Validation Loss: 0.000605\n",
      " Epoch 13: Train Loss: 0.000798, Validation Loss: 0.000577\n",
      " Epoch 14: Train Loss: 0.000764, Validation Loss: 0.000530\n",
      " Epoch 15: Train Loss: 0.000742, Validation Loss: 0.000542\n",
      " Epoch 16: Train Loss: 0.000724, Validation Loss: 0.000510\n",
      " Epoch 17: Train Loss: 0.000707, Validation Loss: 0.000493\n",
      " Epoch 18: Train Loss: 0.000699, Validation Loss: 0.000525\n",
      " Epoch 19: Train Loss: 0.000675, Validation Loss: 0.000477\n",
      " Epoch 20: Train Loss: 0.000661, Validation Loss: 0.000478\n",
      " Epoch 21: Train Loss: 0.000649, Validation Loss: 0.000467\n",
      " Epoch 22: Train Loss: 0.000638, Validation Loss: 0.000465\n",
      " Epoch 23: Train Loss: 0.000628, Validation Loss: 0.000440\n",
      " Epoch 24: Train Loss: 0.000619, Validation Loss: 0.000446\n",
      " Epoch 25: Train Loss: 0.000611, Validation Loss: 0.000466\n",
      " Epoch 26: Train Loss: 0.000602, Validation Loss: 0.000427\n",
      " Epoch 27: Train Loss: 0.000600, Validation Loss: 0.000426\n",
      " Epoch 28: Train Loss: 0.000587, Validation Loss: 0.000429\n",
      " Epoch 29: Train Loss: 0.000590, Validation Loss: 0.000501\n",
      " Epoch 30: Train Loss: 0.000576, Validation Loss: 0.000423\n",
      " Epoch 31: Train Loss: 0.000566, Validation Loss: 0.000411\n",
      " Epoch 32: Train Loss: 0.000561, Validation Loss: 0.000404\n",
      " Epoch 33: Train Loss: 0.000557, Validation Loss: 0.000405\n",
      " Epoch 34: Train Loss: 0.000554, Validation Loss: 0.000401\n",
      " Epoch 35: Train Loss: 0.000551, Validation Loss: 0.000402\n",
      " Epoch 36: Train Loss: 0.000547, Validation Loss: 0.000397\n",
      " Epoch 37: Train Loss: 0.000545, Validation Loss: 0.000393\n",
      " Epoch 38: Train Loss: 0.000541, Validation Loss: 0.000395\n",
      " Epoch 39: Train Loss: 0.000538, Validation Loss: 0.000390\n",
      " Epoch 40: Train Loss: 0.000535, Validation Loss: 0.000398\n",
      " Epoch 41: Train Loss: 0.000533, Validation Loss: 0.000393\n",
      " Epoch 42: Train Loss: 0.000530, Validation Loss: 0.000395\n",
      " Epoch 43: Train Loss: 0.000526, Validation Loss: 0.000430\n",
      " Epoch 44: Train Loss: 0.000525, Validation Loss: 0.000404\n",
      " Epoch 45: Train Loss: 0.000520, Validation Loss: 0.000397\n",
      " Epoch 46: Train Loss: 0.000518, Validation Loss: 0.000402\n",
      " Epoch 47: Train Loss: 0.000515, Validation Loss: 0.000398\n",
      " Epoch 48: Train Loss: 0.000512, Validation Loss: 0.000412\n",
      " Epoch 49: Train Loss: 0.000509, Validation Loss: 0.000439\n",
      "Early stopping at epoch 49 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.017803, Validation Loss: 0.024776\n",
      " Epoch 2: Train Loss: 0.005425, Validation Loss: 0.003940\n",
      " Epoch 3: Train Loss: 0.003199, Validation Loss: 0.002261\n",
      " Epoch 4: Train Loss: 0.002403, Validation Loss: 0.001883\n",
      " Epoch 5: Train Loss: 0.002004, Validation Loss: 0.004987\n",
      " Epoch 6: Train Loss: 0.001549, Validation Loss: 0.001258\n",
      " Epoch 7: Train Loss: 0.001293, Validation Loss: 0.000897\n",
      " Epoch 8: Train Loss: 0.001162, Validation Loss: 0.000881\n",
      " Epoch 9: Train Loss: 0.001082, Validation Loss: 0.000760\n",
      " Epoch 10: Train Loss: 0.001012, Validation Loss: 0.000723\n",
      " Epoch 11: Train Loss: 0.000966, Validation Loss: 0.000707\n",
      " Epoch 12: Train Loss: 0.000924, Validation Loss: 0.000700\n",
      " Epoch 13: Train Loss: 0.000894, Validation Loss: 0.000656\n",
      " Epoch 14: Train Loss: 0.000864, Validation Loss: 0.000640\n",
      " Epoch 15: Train Loss: 0.000841, Validation Loss: 0.000608\n",
      " Epoch 16: Train Loss: 0.000816, Validation Loss: 0.000614\n",
      " Epoch 17: Train Loss: 0.000795, Validation Loss: 0.000581\n",
      " Epoch 18: Train Loss: 0.000779, Validation Loss: 0.000577\n",
      " Epoch 19: Train Loss: 0.000762, Validation Loss: 0.000577\n",
      " Epoch 20: Train Loss: 0.000748, Validation Loss: 0.000559\n",
      " Epoch 21: Train Loss: 0.000736, Validation Loss: 0.000546\n",
      " Epoch 22: Train Loss: 0.000737, Validation Loss: 0.000525\n",
      " Epoch 23: Train Loss: 0.000705, Validation Loss: 0.000510\n",
      " Epoch 24: Train Loss: 0.000691, Validation Loss: 0.000510\n",
      " Epoch 25: Train Loss: 0.000682, Validation Loss: 0.000506\n",
      " Epoch 26: Train Loss: 0.000670, Validation Loss: 0.000493\n",
      " Epoch 27: Train Loss: 0.000663, Validation Loss: 0.000504\n",
      " Epoch 28: Train Loss: 0.000654, Validation Loss: 0.000464\n",
      " Epoch 29: Train Loss: 0.000647, Validation Loss: 0.000463\n",
      " Epoch 30: Train Loss: 0.000646, Validation Loss: 0.000450\n",
      " Epoch 31: Train Loss: 0.000629, Validation Loss: 0.000447\n",
      " Epoch 32: Train Loss: 0.000625, Validation Loss: 0.000446\n",
      " Epoch 33: Train Loss: 0.000621, Validation Loss: 0.000446\n",
      " Epoch 34: Train Loss: 0.000617, Validation Loss: 0.000445\n",
      " Epoch 35: Train Loss: 0.000614, Validation Loss: 0.000440\n",
      " Epoch 36: Train Loss: 0.000610, Validation Loss: 0.000432\n",
      " Epoch 37: Train Loss: 0.000606, Validation Loss: 0.000431\n",
      " Epoch 38: Train Loss: 0.000604, Validation Loss: 0.000428\n",
      " Epoch 39: Train Loss: 0.000600, Validation Loss: 0.000426\n",
      " Epoch 40: Train Loss: 0.000596, Validation Loss: 0.000427\n",
      " Epoch 41: Train Loss: 0.000593, Validation Loss: 0.000422\n",
      " Epoch 42: Train Loss: 0.000590, Validation Loss: 0.000429\n",
      " Epoch 43: Train Loss: 0.000587, Validation Loss: 0.000423\n",
      " Epoch 44: Train Loss: 0.000585, Validation Loss: 0.000432\n",
      " Epoch 45: Train Loss: 0.000581, Validation Loss: 0.000415\n",
      " Epoch 46: Train Loss: 0.000578, Validation Loss: 0.000417\n",
      " Epoch 47: Train Loss: 0.000576, Validation Loss: 0.000416\n",
      " Epoch 48: Train Loss: 0.000571, Validation Loss: 0.000423\n",
      " Epoch 49: Train Loss: 0.000571, Validation Loss: 0.000417\n",
      " Epoch 50: Train Loss: 0.000566, Validation Loss: 0.000412\n",
      " Epoch 51: Train Loss: 0.000565, Validation Loss: 0.000424\n",
      " Epoch 52: Train Loss: 0.000561, Validation Loss: 0.000416\n",
      " Epoch 53: Train Loss: 0.000559, Validation Loss: 0.000446\n",
      " Epoch 54: Train Loss: 0.000556, Validation Loss: 0.000428\n",
      " Epoch 55: Train Loss: 0.000556, Validation Loss: 0.000416\n",
      " Epoch 56: Train Loss: 0.000550, Validation Loss: 0.000410\n",
      " Epoch 57: Train Loss: 0.000547, Validation Loss: 0.000423\n",
      " Epoch 58: Train Loss: 0.000546, Validation Loss: 0.000425\n",
      " Epoch 59: Train Loss: 0.000542, Validation Loss: 0.000414\n",
      " Epoch 60: Train Loss: 0.000539, Validation Loss: 0.000421\n",
      " Epoch 61: Train Loss: 0.000536, Validation Loss: 0.000434\n",
      " Epoch 62: Train Loss: 0.000533, Validation Loss: 0.000435\n",
      " Epoch 63: Train Loss: 0.000532, Validation Loss: 0.000417\n",
      " Epoch 64: Train Loss: 0.000531, Validation Loss: 0.000424\n",
      " Epoch 65: Train Loss: 0.000530, Validation Loss: 0.000415\n",
      " Epoch 66: Train Loss: 0.000528, Validation Loss: 0.000422\n",
      "Early stopping at epoch 66 (no improvement in validation loss for 10 epochs).\n",
      " Epoch 1: Train Loss: 0.018993, Validation Loss: 0.029359\n",
      " Epoch 2: Train Loss: 0.005640, Validation Loss: 0.004545\n",
      " Epoch 3: Train Loss: 0.003279, Validation Loss: 0.002817\n",
      " Epoch 4: Train Loss: 0.002344, Validation Loss: 0.002027\n",
      " Epoch 5: Train Loss: 0.001622, Validation Loss: 0.001225\n",
      " Epoch 6: Train Loss: 0.001383, Validation Loss: 0.000971\n",
      " Epoch 7: Train Loss: 0.001248, Validation Loss: 0.000916\n",
      " Epoch 8: Train Loss: 0.001145, Validation Loss: 0.000877\n",
      " Epoch 9: Train Loss: 0.001079, Validation Loss: 0.000793\n",
      " Epoch 10: Train Loss: 0.001029, Validation Loss: 0.000765\n",
      " Epoch 11: Train Loss: 0.000986, Validation Loss: 0.000739\n",
      " Epoch 12: Train Loss: 0.000953, Validation Loss: 0.000717\n",
      " Epoch 13: Train Loss: 0.000919, Validation Loss: 0.000677\n",
      " Epoch 14: Train Loss: 0.000893, Validation Loss: 0.000661\n",
      " Epoch 15: Train Loss: 0.000869, Validation Loss: 0.000632\n",
      " Epoch 16: Train Loss: 0.000848, Validation Loss: 0.000625\n",
      " Epoch 17: Train Loss: 0.000826, Validation Loss: 0.000605\n",
      " Epoch 18: Train Loss: 0.000808, Validation Loss: 0.000588\n",
      " Epoch 19: Train Loss: 0.000791, Validation Loss: 0.000582\n",
      " Epoch 20: Train Loss: 0.000774, Validation Loss: 0.000568\n",
      " Epoch 21: Train Loss: 0.000758, Validation Loss: 0.000573\n",
      " Epoch 22: Train Loss: 0.000745, Validation Loss: 0.000547\n",
      " Epoch 23: Train Loss: 0.000731, Validation Loss: 0.000533\n",
      " Epoch 24: Train Loss: 0.000716, Validation Loss: 0.000515\n",
      " Epoch 25: Train Loss: 0.000706, Validation Loss: 0.000499\n",
      " Epoch 26: Train Loss: 0.000691, Validation Loss: 0.000492\n",
      " Epoch 27: Train Loss: 0.000678, Validation Loss: 0.000484\n",
      " Epoch 28: Train Loss: 0.000670, Validation Loss: 0.000478\n",
      " Epoch 29: Train Loss: 0.000656, Validation Loss: 0.000469\n",
      " Epoch 30: Train Loss: 0.000647, Validation Loss: 0.000457\n",
      " Epoch 31: Train Loss: 0.000636, Validation Loss: 0.000460\n",
      " Epoch 32: Train Loss: 0.000630, Validation Loss: 0.000460\n",
      " Epoch 33: Train Loss: 0.000625, Validation Loss: 0.000453\n",
      " Epoch 34: Train Loss: 0.000621, Validation Loss: 0.000451\n",
      " Epoch 35: Train Loss: 0.000617, Validation Loss: 0.000441\n",
      " Epoch 36: Train Loss: 0.000613, Validation Loss: 0.000453\n",
      " Epoch 37: Train Loss: 0.000609, Validation Loss: 0.000440\n",
      " Epoch 38: Train Loss: 0.000606, Validation Loss: 0.000447\n",
      " Epoch 39: Train Loss: 0.000600, Validation Loss: 0.000436\n",
      " Epoch 40: Train Loss: 0.000597, Validation Loss: 0.000434\n",
      " Epoch 41: Train Loss: 0.000592, Validation Loss: 0.000436\n",
      " Epoch 42: Train Loss: 0.000590, Validation Loss: 0.000427\n",
      " Epoch 43: Train Loss: 0.000587, Validation Loss: 0.000432\n",
      " Epoch 44: Train Loss: 0.000582, Validation Loss: 0.000430\n",
      " Epoch 45: Train Loss: 0.000579, Validation Loss: 0.000441\n",
      " Epoch 46: Train Loss: 0.000574, Validation Loss: 0.000425\n",
      " Epoch 47: Train Loss: 0.000572, Validation Loss: 0.000414\n",
      " Epoch 48: Train Loss: 0.000569, Validation Loss: 0.000445\n",
      " Epoch 49: Train Loss: 0.000564, Validation Loss: 0.000427\n",
      " Epoch 50: Train Loss: 0.000562, Validation Loss: 0.000436\n",
      " Epoch 51: Train Loss: 0.000559, Validation Loss: 0.000426\n",
      " Epoch 52: Train Loss: 0.000562, Validation Loss: 0.000428\n",
      " Epoch 53: Train Loss: 0.000553, Validation Loss: 0.000440\n",
      " Epoch 54: Train Loss: 0.000547, Validation Loss: 0.000440\n",
      " Epoch 55: Train Loss: 0.000569, Validation Loss: 0.000414\n",
      " Epoch 56: Train Loss: 0.000563, Validation Loss: 0.000402\n",
      " Epoch 57: Train Loss: 0.000554, Validation Loss: 0.000405\n",
      " Epoch 58: Train Loss: 0.000548, Validation Loss: 0.000396\n",
      " Epoch 59: Train Loss: 0.000543, Validation Loss: 0.000412\n",
      " Epoch 60: Train Loss: 0.000540, Validation Loss: 0.000416\n",
      " Epoch 61: Train Loss: 0.000536, Validation Loss: 0.000404\n",
      " Epoch 62: Train Loss: 0.000534, Validation Loss: 0.000405\n",
      " Epoch 63: Train Loss: 0.000533, Validation Loss: 0.000414\n",
      " Epoch 64: Train Loss: 0.000530, Validation Loss: 0.000408\n",
      " Epoch 65: Train Loss: 0.000528, Validation Loss: 0.000419\n",
      " Epoch 66: Train Loss: 0.000528, Validation Loss: 0.000420\n",
      " Epoch 67: Train Loss: 0.000526, Validation Loss: 0.000413\n",
      " Epoch 68: Train Loss: 0.000524, Validation Loss: 0.000419\n",
      "Early stopping at epoch 68 (no improvement in validation loss for 10 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.0003000074648298323\n",
      "Training Time: 1489.4501163959503\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.0002872203185688704\n",
      "Training Time: 4786.064566850662\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.00027912238147109747\n",
      "Training Time: 1513.2709267139435\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0002698311291169375\n",
      "Training Time: 2164.5950310230255\n",
      "--------------------------------------------------\n",
      "Model: UNet\n",
      "Validation Loss: 0.0005318347248248756\n",
      "Training Time: 323.132696390152\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock\n",
      "Validation Loss: 0.00045545381726697087\n",
      "Training Time: 541.0267820358276\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention\n",
      "Validation Loss: 0.0004715545510407537\n",
      "Training Time: 475.4975664615631\n",
      "--------------------------------------------------\n",
      "Model: UNet3D\n",
      "Validation Loss: 0.00038984979619272053\n",
      "Training Time: 553.0310163497925\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D\n",
      "Validation Loss: 0.00040997794712893665\n",
      "Training Time: 747.0719678401947\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D\n",
      "Validation Loss: 0.0003958935849368572\n",
      "Training Time: 804.690954208374\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2ed exp\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from model_train import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, WeightedMSELoss\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    'UNet': UNet,\n",
    "    'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    'UNet3D': UNet3D,\n",
    "    'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = WeightedMSELoss()\n",
    "    early_stopping = EarlyStopping(patience=10, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 20 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/02/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform[\"without_jet\"])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = '/home/linux/3.3lab/Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 1e-7\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ced8699-e871-4bc7-be14-4d6cce086981",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 287\u001b[0m\n\u001b[1;32m    283\u001b[0m opt \u001b[38;5;241m=\u001b[39m Args()\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 259\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    257\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mearlystoplimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearlystoplimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# �� 传递 accumulation_steps\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# **打印最终结果**\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 140\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_name, testloader, valloader, epochs, device, earlystoplimit, lr, accumulation_steps)\u001b[0m\n\u001b[1;32m    137\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# **前向传播**\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets) \u001b[38;5;241m/\u001b[39m accumulation_steps  \u001b[38;5;66;03m# �� 累积梯度时，损失除以 accumulation_steps\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# **反向传播**\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.4_cuda11.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.4_cuda11.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/3.3lab/model_new.py:69\u001b[0m, in \u001b[0;36mCNN_with_Attention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# 输入 x: (B, 4, 56, 56)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 融入自注意力模块\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.4_cuda11.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.4_cuda11.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/3.3lab/model_new.py:32\u001b[0m, in \u001b[0;36mSelfAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m attn_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(x_seq, x_seq, x_seq)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 将序列恢复为特征图：(B, d_model, H, W)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m attn_feature \u001b[38;5;241m=\u001b[39m \u001b[43mattn_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 映射回原通道数：(B, C, H, W)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_up(attn_feature)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# about new attention block\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# from model_train import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "from model_new import ResNet,CNN_with_Attention\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, WeightedMSELoss\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "model_dict = {\n",
    "    # 'CNN': CNN,\n",
    "    'CNN_with_Attention': CNN_with_Attention,\n",
    "    # 'ResNet': ResNet,\n",
    "    # 'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    # 'CNN3D': CNN3D,\n",
    "    # 'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = WeightedMSELoss()\n",
    "    early_stopping = EarlyStopping(patience=10, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 20 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/04/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform[\"without_jet\"])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = '/home/linux/3.3lab/Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 1e-7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674fd7b8-225d-4484-bbed-24ed32e12c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.020119, Validation Loss: 0.023445\n",
      " Epoch 2: Train Loss: 0.002864, Validation Loss: 0.001986\n",
      " Epoch 3: Train Loss: 0.001212, Validation Loss: 0.001061\n",
      " Epoch 4: Train Loss: 0.000950, Validation Loss: 0.000896\n",
      " Epoch 5: Train Loss: 0.000830, Validation Loss: 0.000783\n",
      " Epoch 6: Train Loss: 0.000747, Validation Loss: 0.000710\n",
      " Epoch 7: Train Loss: 0.000686, Validation Loss: 0.000663\n",
      " Epoch 8: Train Loss: 0.000640, Validation Loss: 0.000622\n",
      " Epoch 9: Train Loss: 0.000603, Validation Loss: 0.000589\n",
      " Epoch 10: Train Loss: 0.000574, Validation Loss: 0.000566\n",
      " Epoch 11: Train Loss: 0.000551, Validation Loss: 0.000543\n",
      " Epoch 12: Train Loss: 0.000530, Validation Loss: 0.000531\n",
      " Epoch 13: Train Loss: 0.000514, Validation Loss: 0.000507\n",
      " Epoch 14: Train Loss: 0.000494, Validation Loss: 0.000509\n",
      " Epoch 15: Train Loss: 0.000482, Validation Loss: 0.000479\n",
      " Epoch 16: Train Loss: 0.000470, Validation Loss: 0.000468\n",
      " Epoch 17: Train Loss: 0.000451, Validation Loss: 0.000463\n",
      " Epoch 18: Train Loss: 0.000447, Validation Loss: 0.000465\n",
      " Epoch 19: Train Loss: 0.000432, Validation Loss: 0.000436\n",
      " Epoch 20: Train Loss: 0.000422, Validation Loss: 0.000435\n",
      " Epoch 21: Train Loss: 0.000414, Validation Loss: 0.000422\n",
      " Epoch 22: Train Loss: 0.000408, Validation Loss: 0.000418\n",
      " Epoch 23: Train Loss: 0.000401, Validation Loss: 0.000426\n",
      " Epoch 24: Train Loss: 0.000396, Validation Loss: 0.000401\n",
      " Epoch 25: Train Loss: 0.000391, Validation Loss: 0.000409\n",
      " Epoch 26: Train Loss: 0.000389, Validation Loss: 0.000392\n",
      " Epoch 27: Train Loss: 0.000380, Validation Loss: 0.000460\n",
      " Epoch 28: Train Loss: 0.000385, Validation Loss: 0.000387\n",
      " Epoch 29: Train Loss: 0.000367, Validation Loss: 0.000386\n",
      " Epoch 30: Train Loss: 0.000362, Validation Loss: 0.000381\n",
      " Epoch 31: Train Loss: 0.000359, Validation Loss: 0.000374\n",
      " Epoch 32: Train Loss: 0.000355, Validation Loss: 0.000374\n",
      " Epoch 33: Train Loss: 0.000351, Validation Loss: 0.000373\n",
      " Epoch 34: Train Loss: 0.000349, Validation Loss: 0.000367\n",
      " Epoch 35: Train Loss: 0.000347, Validation Loss: 0.000367\n",
      " Epoch 36: Train Loss: 0.000345, Validation Loss: 0.000364\n",
      " Epoch 37: Train Loss: 0.000344, Validation Loss: 0.000364\n",
      " Epoch 38: Train Loss: 0.000341, Validation Loss: 0.000360\n",
      " Epoch 39: Train Loss: 0.000339, Validation Loss: 0.000361\n",
      " Epoch 40: Train Loss: 0.000338, Validation Loss: 0.000357\n",
      " Epoch 41: Train Loss: 0.000334, Validation Loss: 0.000355\n",
      " Epoch 42: Train Loss: 0.000333, Validation Loss: 0.000360\n",
      " Epoch 43: Train Loss: 0.000333, Validation Loss: 0.000353\n",
      " Epoch 44: Train Loss: 0.000333, Validation Loss: 0.000351\n",
      " Epoch 45: Train Loss: 0.000330, Validation Loss: 0.000351\n",
      " Epoch 46: Train Loss: 0.000326, Validation Loss: 0.000357\n",
      " Epoch 47: Train Loss: 0.000323, Validation Loss: 0.000350\n",
      " Epoch 48: Train Loss: 0.000326, Validation Loss: 0.000349\n",
      " Epoch 49: Train Loss: 0.000325, Validation Loss: 0.000380\n",
      " Epoch 50: Train Loss: 0.000327, Validation Loss: 0.000351\n",
      " Epoch 51: Train Loss: 0.000321, Validation Loss: 0.000345\n",
      " Epoch 52: Train Loss: 0.000319, Validation Loss: 0.000342\n",
      " Epoch 53: Train Loss: 0.000315, Validation Loss: 0.000348\n",
      " Epoch 54: Train Loss: 0.000314, Validation Loss: 0.000348\n",
      " Epoch 55: Train Loss: 0.000312, Validation Loss: 0.000345\n",
      " Epoch 56: Train Loss: 0.000311, Validation Loss: 0.000337\n",
      " Epoch 57: Train Loss: 0.000312, Validation Loss: 0.000336\n",
      " Epoch 58: Train Loss: 0.000306, Validation Loss: 0.000334\n",
      " Epoch 59: Train Loss: 0.000307, Validation Loss: 0.000334\n",
      " Epoch 60: Train Loss: 0.000305, Validation Loss: 0.000336\n",
      " Epoch 61: Train Loss: 0.000300, Validation Loss: 0.000332\n",
      " Epoch 62: Train Loss: 0.000298, Validation Loss: 0.000329\n",
      " Epoch 63: Train Loss: 0.000298, Validation Loss: 0.000336\n",
      " Epoch 64: Train Loss: 0.000297, Validation Loss: 0.000327\n",
      " Epoch 65: Train Loss: 0.000296, Validation Loss: 0.000328\n",
      " Epoch 66: Train Loss: 0.000295, Validation Loss: 0.000327\n",
      " Epoch 67: Train Loss: 0.000294, Validation Loss: 0.000331\n",
      " Epoch 68: Train Loss: 0.000294, Validation Loss: 0.000328\n",
      " Epoch 69: Train Loss: 0.000292, Validation Loss: 0.000325\n",
      " Epoch 70: Train Loss: 0.000293, Validation Loss: 0.000332\n",
      " Epoch 71: Train Loss: 0.000296, Validation Loss: 0.000329\n",
      " Epoch 72: Train Loss: 0.000290, Validation Loss: 0.000323\n",
      " Epoch 73: Train Loss: 0.000289, Validation Loss: 0.000323\n",
      " Epoch 74: Train Loss: 0.000288, Validation Loss: 0.000323\n",
      " Epoch 75: Train Loss: 0.000287, Validation Loss: 0.000322\n",
      " Epoch 76: Train Loss: 0.000287, Validation Loss: 0.000322\n",
      " Epoch 77: Train Loss: 0.000287, Validation Loss: 0.000324\n",
      " Epoch 78: Train Loss: 0.000286, Validation Loss: 0.000326\n",
      " Epoch 79: Train Loss: 0.000287, Validation Loss: 0.000321\n",
      " Epoch 80: Train Loss: 0.000284, Validation Loss: 0.000322\n",
      " Epoch 81: Train Loss: 0.000282, Validation Loss: 0.000320\n",
      " Epoch 82: Train Loss: 0.000281, Validation Loss: 0.000319\n",
      " Epoch 83: Train Loss: 0.000282, Validation Loss: 0.000326\n",
      " Epoch 84: Train Loss: 0.000282, Validation Loss: 0.000324\n",
      " Epoch 85: Train Loss: 0.000281, Validation Loss: 0.000319\n",
      " Epoch 86: Train Loss: 0.000279, Validation Loss: 0.000317\n",
      " Epoch 87: Train Loss: 0.000277, Validation Loss: 0.000316\n",
      " Epoch 88: Train Loss: 0.000276, Validation Loss: 0.000316\n",
      " Epoch 89: Train Loss: 0.000282, Validation Loss: 0.000327\n",
      " Epoch 90: Train Loss: 0.000275, Validation Loss: 0.000318\n",
      " Epoch 91: Train Loss: 0.000272, Validation Loss: 0.000314\n",
      " Epoch 92: Train Loss: 0.000272, Validation Loss: 0.000314\n",
      " Epoch 93: Train Loss: 0.000271, Validation Loss: 0.000323\n",
      " Epoch 94: Train Loss: 0.000270, Validation Loss: 0.000313\n",
      " Epoch 95: Train Loss: 0.000269, Validation Loss: 0.000313\n",
      " Epoch 96: Train Loss: 0.000269, Validation Loss: 0.000313\n",
      " Epoch 97: Train Loss: 0.000268, Validation Loss: 0.000313\n",
      " Epoch 98: Train Loss: 0.000268, Validation Loss: 0.000317\n",
      " Epoch 99: Train Loss: 0.000270, Validation Loss: 0.000312\n",
      " Epoch 100: Train Loss: 0.000267, Validation Loss: 0.000314\n",
      " Epoch 101: Train Loss: 0.000266, Validation Loss: 0.000312\n",
      " Epoch 102: Train Loss: 0.000266, Validation Loss: 0.000312\n",
      " Epoch 103: Train Loss: 0.000265, Validation Loss: 0.000313\n",
      " Epoch 104: Train Loss: 0.000265, Validation Loss: 0.000311\n",
      " Epoch 105: Train Loss: 0.000265, Validation Loss: 0.000310\n",
      " Epoch 106: Train Loss: 0.000263, Validation Loss: 0.000311\n",
      " Epoch 107: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 108: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 109: Train Loss: 0.000263, Validation Loss: 0.000309\n",
      " Epoch 110: Train Loss: 0.000262, Validation Loss: 0.000312\n",
      " Epoch 111: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 112: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 113: Train Loss: 0.000261, Validation Loss: 0.000310\n",
      " Epoch 114: Train Loss: 0.000260, Validation Loss: 0.000310\n",
      " Epoch 115: Train Loss: 0.000260, Validation Loss: 0.000309\n",
      " Epoch 116: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 117: Train Loss: 0.000258, Validation Loss: 0.000309\n",
      " Epoch 118: Train Loss: 0.000257, Validation Loss: 0.000307\n",
      " Epoch 119: Train Loss: 0.000257, Validation Loss: 0.000309\n",
      " Epoch 120: Train Loss: 0.000256, Validation Loss: 0.000307\n",
      " Epoch 121: Train Loss: 0.000254, Validation Loss: 0.000307\n",
      " Epoch 122: Train Loss: 0.000254, Validation Loss: 0.000310\n",
      " Epoch 123: Train Loss: 0.000253, Validation Loss: 0.000306\n",
      " Epoch 124: Train Loss: 0.000252, Validation Loss: 0.000306\n",
      " Epoch 125: Train Loss: 0.000252, Validation Loss: 0.000307\n",
      " Epoch 126: Train Loss: 0.000253, Validation Loss: 0.000306\n",
      " Epoch 127: Train Loss: 0.000253, Validation Loss: 0.000306\n",
      " Epoch 128: Train Loss: 0.000252, Validation Loss: 0.000306\n",
      " Epoch 129: Train Loss: 0.000251, Validation Loss: 0.000305\n",
      " Epoch 130: Train Loss: 0.000252, Validation Loss: 0.000306\n",
      " Epoch 131: Train Loss: 0.000251, Validation Loss: 0.000305\n",
      " Epoch 132: Train Loss: 0.000250, Validation Loss: 0.000305\n",
      " Epoch 133: Train Loss: 0.000250, Validation Loss: 0.000305\n",
      " Epoch 134: Train Loss: 0.000249, Validation Loss: 0.000305\n",
      " Epoch 135: Train Loss: 0.000249, Validation Loss: 0.000306\n",
      " Epoch 136: Train Loss: 0.000249, Validation Loss: 0.000308\n",
      " Epoch 137: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 138: Train Loss: 0.000248, Validation Loss: 0.000304\n",
      " Epoch 139: Train Loss: 0.000248, Validation Loss: 0.000304\n",
      " Epoch 140: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 141: Train Loss: 0.000247, Validation Loss: 0.000305\n",
      " Epoch 142: Train Loss: 0.000247, Validation Loss: 0.000304\n",
      " Epoch 143: Train Loss: 0.000247, Validation Loss: 0.000304\n",
      " Epoch 144: Train Loss: 0.000246, Validation Loss: 0.000304\n",
      " Epoch 145: Train Loss: 0.000245, Validation Loss: 0.000305\n",
      " Epoch 146: Train Loss: 0.000245, Validation Loss: 0.000306\n",
      " Epoch 147: Train Loss: 0.000244, Validation Loss: 0.000307\n",
      " Epoch 148: Train Loss: 0.000244, Validation Loss: 0.000303\n",
      " Epoch 149: Train Loss: 0.000243, Validation Loss: 0.000304\n",
      " Epoch 150: Train Loss: 0.000244, Validation Loss: 0.000304\n",
      " Epoch 151: Train Loss: 0.000242, Validation Loss: 0.000303\n",
      " Epoch 152: Train Loss: 0.000242, Validation Loss: 0.000304\n",
      " Epoch 153: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 154: Train Loss: 0.000241, Validation Loss: 0.000304\n",
      " Epoch 155: Train Loss: 0.000241, Validation Loss: 0.000304\n",
      " Epoch 156: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 157: Train Loss: 0.000241, Validation Loss: 0.000307\n",
      " Epoch 158: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 159: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 160: Train Loss: 0.000240, Validation Loss: 0.000304\n",
      " Epoch 161: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 162: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 163: Train Loss: 0.000240, Validation Loss: 0.000305\n",
      " Epoch 164: Train Loss: 0.000239, Validation Loss: 0.000304\n",
      " Epoch 165: Train Loss: 0.000239, Validation Loss: 0.000302\n",
      " Epoch 166: Train Loss: 0.000239, Validation Loss: 0.000303\n",
      " Epoch 167: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 168: Train Loss: 0.000238, Validation Loss: 0.000303\n",
      " Epoch 169: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 170: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 171: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 172: Train Loss: 0.000237, Validation Loss: 0.000306\n",
      " Epoch 173: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 174: Train Loss: 0.000237, Validation Loss: 0.000304\n",
      " Epoch 175: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 176: Train Loss: 0.000237, Validation Loss: 0.000304\n",
      " Epoch 177: Train Loss: 0.000236, Validation Loss: 0.000302\n",
      " Epoch 178: Train Loss: 0.000236, Validation Loss: 0.000302\n",
      " Epoch 179: Train Loss: 0.000235, Validation Loss: 0.000303\n",
      " Epoch 180: Train Loss: 0.000235, Validation Loss: 0.000304\n",
      " Epoch 181: Train Loss: 0.000234, Validation Loss: 0.000302\n",
      " Epoch 182: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 183: Train Loss: 0.000234, Validation Loss: 0.000302\n",
      " Epoch 184: Train Loss: 0.000234, Validation Loss: 0.000302\n",
      " Epoch 185: Train Loss: 0.000234, Validation Loss: 0.000302\n",
      " Epoch 186: Train Loss: 0.000234, Validation Loss: 0.000302\n",
      " Epoch 187: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 188: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 189: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 190: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 191: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 192: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 193: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 194: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 195: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 196: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 197: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 198: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 199: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 200: Train Loss: 0.000232, Validation Loss: 0.000302\n",
      " Epoch 201: Train Loss: 0.000231, Validation Loss: 0.000302\n",
      " Epoch 202: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      " Epoch 203: Train Loss: 0.000231, Validation Loss: 0.000302\n",
      " Epoch 204: Train Loss: 0.000231, Validation Loss: 0.000303\n",
      " Epoch 205: Train Loss: 0.000231, Validation Loss: 0.000302\n",
      " Epoch 206: Train Loss: 0.000231, Validation Loss: 0.000303\n",
      " Epoch 207: Train Loss: 0.000230, Validation Loss: 0.000301\n",
      " Epoch 208: Train Loss: 0.000230, Validation Loss: 0.000303\n",
      " Epoch 209: Train Loss: 0.000230, Validation Loss: 0.000302\n",
      " Epoch 210: Train Loss: 0.000230, Validation Loss: 0.000302\n",
      " Epoch 211: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 212: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 213: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 214: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 215: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 216: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 217: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 218: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 219: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 220: Train Loss: 0.000229, Validation Loss: 0.000301\n",
      " Epoch 221: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 222: Train Loss: 0.000229, Validation Loss: 0.000302\n",
      " Epoch 223: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 224: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 225: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 226: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 227: Train Loss: 0.000228, Validation Loss: 0.000301\n",
      " Epoch 228: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 229: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 230: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 231: Train Loss: 0.000227, Validation Loss: 0.000301\n",
      " Epoch 232: Train Loss: 0.000228, Validation Loss: 0.000302\n",
      " Epoch 233: Train Loss: 0.000227, Validation Loss: 0.000301\n",
      " Epoch 234: Train Loss: 0.000227, Validation Loss: 0.000302\n",
      " Epoch 235: Train Loss: 0.000227, Validation Loss: 0.000301\n",
      " Epoch 236: Train Loss: 0.000227, Validation Loss: 0.000302\n",
      " Epoch 237: Train Loss: 0.000227, Validation Loss: 0.000302\n",
      " Epoch 238: Train Loss: 0.000227, Validation Loss: 0.000301\n",
      "Early stopping at epoch 238 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014773, Validation Loss: 0.027224\n",
      " Epoch 2: Train Loss: 0.003189, Validation Loss: 0.002578\n",
      " Epoch 3: Train Loss: 0.001863, Validation Loss: 0.001522\n",
      " Epoch 4: Train Loss: 0.001112, Validation Loss: 0.000989\n",
      " Epoch 5: Train Loss: 0.000893, Validation Loss: 0.000833\n",
      " Epoch 6: Train Loss: 0.000786, Validation Loss: 0.000754\n",
      " Epoch 7: Train Loss: 0.000705, Validation Loss: 0.000674\n",
      " Epoch 8: Train Loss: 0.000643, Validation Loss: 0.000620\n",
      " Epoch 9: Train Loss: 0.000600, Validation Loss: 0.000596\n",
      " Epoch 10: Train Loss: 0.000564, Validation Loss: 0.000554\n",
      " Epoch 11: Train Loss: 0.000536, Validation Loss: 0.000533\n",
      " Epoch 12: Train Loss: 0.000515, Validation Loss: 0.000520\n",
      " Epoch 13: Train Loss: 0.000498, Validation Loss: 0.000491\n",
      " Epoch 14: Train Loss: 0.000479, Validation Loss: 0.000481\n",
      " Epoch 15: Train Loss: 0.000465, Validation Loss: 0.000468\n",
      " Epoch 16: Train Loss: 0.000456, Validation Loss: 0.000458\n",
      " Epoch 17: Train Loss: 0.000443, Validation Loss: 0.000451\n",
      " Epoch 18: Train Loss: 0.000431, Validation Loss: 0.000443\n",
      " Epoch 19: Train Loss: 0.000422, Validation Loss: 0.000427\n",
      " Epoch 20: Train Loss: 0.000414, Validation Loss: 0.000418\n",
      " Epoch 21: Train Loss: 0.000404, Validation Loss: 0.000416\n",
      " Epoch 22: Train Loss: 0.000404, Validation Loss: 0.000410\n",
      " Epoch 23: Train Loss: 0.000397, Validation Loss: 0.000403\n",
      " Epoch 24: Train Loss: 0.000387, Validation Loss: 0.000415\n",
      " Epoch 25: Train Loss: 0.000385, Validation Loss: 0.000390\n",
      " Epoch 26: Train Loss: 0.000379, Validation Loss: 0.000392\n",
      " Epoch 27: Train Loss: 0.000371, Validation Loss: 0.000393\n",
      " Epoch 28: Train Loss: 0.000367, Validation Loss: 0.000388\n",
      " Epoch 29: Train Loss: 0.000367, Validation Loss: 0.000381\n",
      " Epoch 30: Train Loss: 0.000362, Validation Loss: 0.000375\n",
      " Epoch 31: Train Loss: 0.000349, Validation Loss: 0.000364\n",
      " Epoch 32: Train Loss: 0.000344, Validation Loss: 0.000360\n",
      " Epoch 33: Train Loss: 0.000343, Validation Loss: 0.000360\n",
      " Epoch 34: Train Loss: 0.000340, Validation Loss: 0.000356\n",
      " Epoch 35: Train Loss: 0.000337, Validation Loss: 0.000354\n",
      " Epoch 36: Train Loss: 0.000336, Validation Loss: 0.000354\n",
      " Epoch 37: Train Loss: 0.000334, Validation Loss: 0.000350\n",
      " Epoch 38: Train Loss: 0.000331, Validation Loss: 0.000349\n",
      " Epoch 39: Train Loss: 0.000330, Validation Loss: 0.000348\n",
      " Epoch 40: Train Loss: 0.000328, Validation Loss: 0.000346\n",
      " Epoch 41: Train Loss: 0.000327, Validation Loss: 0.000344\n",
      " Epoch 42: Train Loss: 0.000324, Validation Loss: 0.000342\n",
      " Epoch 43: Train Loss: 0.000322, Validation Loss: 0.000343\n",
      " Epoch 44: Train Loss: 0.000320, Validation Loss: 0.000342\n",
      " Epoch 45: Train Loss: 0.000319, Validation Loss: 0.000336\n",
      " Epoch 46: Train Loss: 0.000318, Validation Loss: 0.000335\n",
      " Epoch 47: Train Loss: 0.000315, Validation Loss: 0.000336\n",
      " Epoch 48: Train Loss: 0.000313, Validation Loss: 0.000332\n",
      " Epoch 49: Train Loss: 0.000314, Validation Loss: 0.000340\n",
      " Epoch 50: Train Loss: 0.000311, Validation Loss: 0.000334\n",
      " Epoch 51: Train Loss: 0.000310, Validation Loss: 0.000328\n",
      " Epoch 52: Train Loss: 0.000310, Validation Loss: 0.000330\n",
      " Epoch 53: Train Loss: 0.000305, Validation Loss: 0.000329\n",
      " Epoch 54: Train Loss: 0.000305, Validation Loss: 0.000326\n",
      " Epoch 55: Train Loss: 0.000302, Validation Loss: 0.000323\n",
      " Epoch 56: Train Loss: 0.000300, Validation Loss: 0.000323\n",
      " Epoch 57: Train Loss: 0.000300, Validation Loss: 0.000319\n",
      " Epoch 58: Train Loss: 0.000296, Validation Loss: 0.000318\n",
      " Epoch 59: Train Loss: 0.000297, Validation Loss: 0.000315\n",
      " Epoch 60: Train Loss: 0.000298, Validation Loss: 0.000316\n",
      " Epoch 61: Train Loss: 0.000287, Validation Loss: 0.000312\n",
      " Epoch 62: Train Loss: 0.000286, Validation Loss: 0.000312\n",
      " Epoch 63: Train Loss: 0.000285, Validation Loss: 0.000310\n",
      " Epoch 64: Train Loss: 0.000285, Validation Loss: 0.000309\n",
      " Epoch 65: Train Loss: 0.000283, Validation Loss: 0.000309\n",
      " Epoch 66: Train Loss: 0.000283, Validation Loss: 0.000308\n",
      " Epoch 67: Train Loss: 0.000282, Validation Loss: 0.000307\n",
      " Epoch 68: Train Loss: 0.000281, Validation Loss: 0.000308\n",
      " Epoch 69: Train Loss: 0.000281, Validation Loss: 0.000306\n",
      " Epoch 70: Train Loss: 0.000281, Validation Loss: 0.000305\n",
      " Epoch 71: Train Loss: 0.000278, Validation Loss: 0.000304\n",
      " Epoch 72: Train Loss: 0.000277, Validation Loss: 0.000305\n",
      " Epoch 73: Train Loss: 0.000276, Validation Loss: 0.000303\n",
      " Epoch 74: Train Loss: 0.000275, Validation Loss: 0.000303\n",
      " Epoch 75: Train Loss: 0.000275, Validation Loss: 0.000301\n",
      " Epoch 76: Train Loss: 0.000273, Validation Loss: 0.000302\n",
      " Epoch 77: Train Loss: 0.000273, Validation Loss: 0.000300\n",
      " Epoch 78: Train Loss: 0.000273, Validation Loss: 0.000302\n",
      " Epoch 79: Train Loss: 0.000271, Validation Loss: 0.000299\n",
      " Epoch 80: Train Loss: 0.000271, Validation Loss: 0.000299\n",
      " Epoch 81: Train Loss: 0.000270, Validation Loss: 0.000299\n",
      " Epoch 82: Train Loss: 0.000270, Validation Loss: 0.000301\n",
      " Epoch 83: Train Loss: 0.000271, Validation Loss: 0.000298\n",
      " Epoch 84: Train Loss: 0.000267, Validation Loss: 0.000295\n",
      " Epoch 85: Train Loss: 0.000267, Validation Loss: 0.000295\n",
      " Epoch 86: Train Loss: 0.000266, Validation Loss: 0.000298\n",
      " Epoch 87: Train Loss: 0.000265, Validation Loss: 0.000294\n",
      " Epoch 88: Train Loss: 0.000263, Validation Loss: 0.000294\n",
      " Epoch 89: Train Loss: 0.000262, Validation Loss: 0.000293\n",
      " Epoch 90: Train Loss: 0.000262, Validation Loss: 0.000293\n",
      " Epoch 91: Train Loss: 0.000259, Validation Loss: 0.000291\n",
      " Epoch 92: Train Loss: 0.000258, Validation Loss: 0.000292\n",
      " Epoch 93: Train Loss: 0.000258, Validation Loss: 0.000290\n",
      " Epoch 94: Train Loss: 0.000257, Validation Loss: 0.000290\n",
      " Epoch 95: Train Loss: 0.000257, Validation Loss: 0.000290\n",
      " Epoch 96: Train Loss: 0.000256, Validation Loss: 0.000290\n",
      " Epoch 97: Train Loss: 0.000256, Validation Loss: 0.000289\n",
      " Epoch 98: Train Loss: 0.000255, Validation Loss: 0.000289\n",
      " Epoch 99: Train Loss: 0.000255, Validation Loss: 0.000288\n",
      " Epoch 100: Train Loss: 0.000255, Validation Loss: 0.000288\n",
      " Epoch 101: Train Loss: 0.000254, Validation Loss: 0.000289\n",
      " Epoch 102: Train Loss: 0.000253, Validation Loss: 0.000288\n",
      " Epoch 103: Train Loss: 0.000253, Validation Loss: 0.000288\n",
      " Epoch 104: Train Loss: 0.000253, Validation Loss: 0.000287\n",
      " Epoch 105: Train Loss: 0.000253, Validation Loss: 0.000287\n",
      " Epoch 106: Train Loss: 0.000253, Validation Loss: 0.000287\n",
      " Epoch 107: Train Loss: 0.000252, Validation Loss: 0.000287\n",
      " Epoch 108: Train Loss: 0.000251, Validation Loss: 0.000287\n",
      " Epoch 109: Train Loss: 0.000251, Validation Loss: 0.000286\n",
      " Epoch 110: Train Loss: 0.000249, Validation Loss: 0.000286\n",
      " Epoch 111: Train Loss: 0.000249, Validation Loss: 0.000285\n",
      " Epoch 112: Train Loss: 0.000249, Validation Loss: 0.000286\n",
      " Epoch 113: Train Loss: 0.000249, Validation Loss: 0.000284\n",
      " Epoch 114: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 115: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 116: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 117: Train Loss: 0.000246, Validation Loss: 0.000284\n",
      " Epoch 118: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 119: Train Loss: 0.000246, Validation Loss: 0.000283\n",
      " Epoch 120: Train Loss: 0.000245, Validation Loss: 0.000284\n",
      " Epoch 121: Train Loss: 0.000243, Validation Loss: 0.000282\n",
      " Epoch 122: Train Loss: 0.000242, Validation Loss: 0.000282\n",
      " Epoch 123: Train Loss: 0.000242, Validation Loss: 0.000282\n",
      " Epoch 124: Train Loss: 0.000242, Validation Loss: 0.000283\n",
      " Epoch 125: Train Loss: 0.000242, Validation Loss: 0.000282\n",
      " Epoch 126: Train Loss: 0.000241, Validation Loss: 0.000281\n",
      " Epoch 127: Train Loss: 0.000241, Validation Loss: 0.000281\n",
      " Epoch 128: Train Loss: 0.000241, Validation Loss: 0.000281\n",
      " Epoch 129: Train Loss: 0.000240, Validation Loss: 0.000282\n",
      " Epoch 130: Train Loss: 0.000240, Validation Loss: 0.000282\n",
      " Epoch 131: Train Loss: 0.000240, Validation Loss: 0.000282\n",
      " Epoch 132: Train Loss: 0.000239, Validation Loss: 0.000281\n",
      " Epoch 133: Train Loss: 0.000239, Validation Loss: 0.000281\n",
      " Epoch 134: Train Loss: 0.000239, Validation Loss: 0.000281\n",
      " Epoch 135: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 136: Train Loss: 0.000238, Validation Loss: 0.000281\n",
      " Epoch 137: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 138: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 139: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 140: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 141: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 142: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 143: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 144: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 145: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 146: Train Loss: 0.000235, Validation Loss: 0.000280\n",
      " Epoch 147: Train Loss: 0.000234, Validation Loss: 0.000279\n",
      " Epoch 148: Train Loss: 0.000234, Validation Loss: 0.000279\n",
      " Epoch 149: Train Loss: 0.000234, Validation Loss: 0.000280\n",
      " Epoch 150: Train Loss: 0.000234, Validation Loss: 0.000280\n",
      " Epoch 151: Train Loss: 0.000233, Validation Loss: 0.000278\n",
      " Epoch 152: Train Loss: 0.000232, Validation Loss: 0.000278\n",
      " Epoch 153: Train Loss: 0.000232, Validation Loss: 0.000278\n",
      " Epoch 154: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 155: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 156: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 157: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 158: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 159: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 160: Train Loss: 0.000231, Validation Loss: 0.000278\n",
      " Epoch 161: Train Loss: 0.000230, Validation Loss: 0.000278\n",
      " Epoch 162: Train Loss: 0.000230, Validation Loss: 0.000278\n",
      " Epoch 163: Train Loss: 0.000230, Validation Loss: 0.000278\n",
      " Epoch 164: Train Loss: 0.000230, Validation Loss: 0.000277\n",
      " Epoch 165: Train Loss: 0.000229, Validation Loss: 0.000278\n",
      " Epoch 166: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 167: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 168: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 169: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 170: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 171: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 172: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 173: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 174: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 175: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 176: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 177: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 178: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 179: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 180: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 181: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 182: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 183: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 184: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 185: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 186: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 187: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 188: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 189: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 190: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 191: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 192: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 193: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 194: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 195: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 196: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 197: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 198: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 199: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 200: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 201: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 202: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 203: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 204: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 205: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 206: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 207: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 208: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 209: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 210: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 211: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 212: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 213: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 214: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 215: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 216: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 217: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 218: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 219: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 220: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 221: Train Loss: 0.000221, Validation Loss: 0.000275\n",
      " Epoch 222: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 223: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 224: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 225: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 226: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 227: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 228: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 229: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 230: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 231: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 232: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 233: Train Loss: 0.000220, Validation Loss: 0.000275\n",
      " Epoch 234: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 235: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 236: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 237: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 238: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 239: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 240: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 241: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 242: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 243: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 244: Train Loss: 0.000219, Validation Loss: 0.000275\n",
      " Epoch 245: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 246: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 247: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 248: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 249: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 250: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 251: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 252: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 253: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 254: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 255: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 256: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 257: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 258: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 259: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 260: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 261: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 262: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 263: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 264: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 265: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 266: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 267: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 268: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 269: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 270: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 271: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 272: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 273: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 274: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 275: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 276: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 277: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 278: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 279: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 280: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 281: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 282: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 283: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 284: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 285: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 286: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 287: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 288: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 289: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 290: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 291: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 292: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 293: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 294: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 295: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 296: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 297: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 298: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 299: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 300: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 301: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 302: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 303: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 304: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 305: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 306: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 307: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 308: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 309: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 310: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 311: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 312: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 313: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 314: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 315: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 316: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 317: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 318: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 319: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 320: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 321: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 322: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 323: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 324: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 325: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 326: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 327: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 328: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 329: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 330: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 331: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 332: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 333: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 334: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      "Early stopping at epoch 334 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012496, Validation Loss: 0.020959\n",
      " Epoch 2: Train Loss: 0.002935, Validation Loss: 0.002489\n",
      " Epoch 3: Train Loss: 0.001662, Validation Loss: 0.003305\n",
      " Epoch 4: Train Loss: 0.001038, Validation Loss: 0.001017\n",
      " Epoch 5: Train Loss: 0.000869, Validation Loss: 0.000829\n",
      " Epoch 6: Train Loss: 0.000765, Validation Loss: 0.000746\n",
      " Epoch 7: Train Loss: 0.000693, Validation Loss: 0.000679\n",
      " Epoch 8: Train Loss: 0.000642, Validation Loss: 0.000637\n",
      " Epoch 9: Train Loss: 0.000603, Validation Loss: 0.000609\n",
      " Epoch 10: Train Loss: 0.000563, Validation Loss: 0.000569\n",
      " Epoch 11: Train Loss: 0.000533, Validation Loss: 0.000544\n",
      " Epoch 12: Train Loss: 0.000503, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000483, Validation Loss: 0.000496\n",
      " Epoch 14: Train Loss: 0.000467, Validation Loss: 0.000474\n",
      " Epoch 15: Train Loss: 0.000451, Validation Loss: 0.000460\n",
      " Epoch 16: Train Loss: 0.000439, Validation Loss: 0.000454\n",
      " Epoch 17: Train Loss: 0.000425, Validation Loss: 0.000443\n",
      " Epoch 18: Train Loss: 0.000425, Validation Loss: 0.000431\n",
      " Epoch 19: Train Loss: 0.000406, Validation Loss: 0.000441\n",
      " Epoch 20: Train Loss: 0.000400, Validation Loss: 0.000416\n",
      " Epoch 21: Train Loss: 0.000397, Validation Loss: 0.000406\n",
      " Epoch 22: Train Loss: 0.000391, Validation Loss: 0.000399\n",
      " Epoch 23: Train Loss: 0.000380, Validation Loss: 0.000402\n",
      " Epoch 24: Train Loss: 0.000381, Validation Loss: 0.000384\n",
      " Epoch 25: Train Loss: 0.000370, Validation Loss: 0.000378\n",
      " Epoch 26: Train Loss: 0.000363, Validation Loss: 0.000388\n",
      " Epoch 27: Train Loss: 0.000365, Validation Loss: 0.000373\n",
      " Epoch 28: Train Loss: 0.000358, Validation Loss: 0.000371\n",
      " Epoch 29: Train Loss: 0.000350, Validation Loss: 0.000364\n",
      " Epoch 30: Train Loss: 0.000346, Validation Loss: 0.000360\n",
      " Epoch 31: Train Loss: 0.000335, Validation Loss: 0.000354\n",
      " Epoch 32: Train Loss: 0.000332, Validation Loss: 0.000349\n",
      " Epoch 33: Train Loss: 0.000330, Validation Loss: 0.000348\n",
      " Epoch 34: Train Loss: 0.000329, Validation Loss: 0.000345\n",
      " Epoch 35: Train Loss: 0.000326, Validation Loss: 0.000344\n",
      " Epoch 36: Train Loss: 0.000324, Validation Loss: 0.000341\n",
      " Epoch 37: Train Loss: 0.000323, Validation Loss: 0.000342\n",
      " Epoch 38: Train Loss: 0.000321, Validation Loss: 0.000339\n",
      " Epoch 39: Train Loss: 0.000320, Validation Loss: 0.000339\n",
      " Epoch 40: Train Loss: 0.000318, Validation Loss: 0.000336\n",
      " Epoch 41: Train Loss: 0.000315, Validation Loss: 0.000337\n",
      " Epoch 42: Train Loss: 0.000313, Validation Loss: 0.000334\n",
      " Epoch 43: Train Loss: 0.000313, Validation Loss: 0.000334\n",
      " Epoch 44: Train Loss: 0.000311, Validation Loss: 0.000333\n",
      " Epoch 45: Train Loss: 0.000309, Validation Loss: 0.000332\n",
      " Epoch 46: Train Loss: 0.000307, Validation Loss: 0.000325\n",
      " Epoch 47: Train Loss: 0.000306, Validation Loss: 0.000324\n",
      " Epoch 48: Train Loss: 0.000304, Validation Loss: 0.000324\n",
      " Epoch 49: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 50: Train Loss: 0.000300, Validation Loss: 0.000319\n",
      " Epoch 51: Train Loss: 0.000299, Validation Loss: 0.000324\n",
      " Epoch 52: Train Loss: 0.000299, Validation Loss: 0.000317\n",
      " Epoch 53: Train Loss: 0.000296, Validation Loss: 0.000322\n",
      " Epoch 54: Train Loss: 0.000294, Validation Loss: 0.000314\n",
      " Epoch 55: Train Loss: 0.000294, Validation Loss: 0.000314\n",
      " Epoch 56: Train Loss: 0.000292, Validation Loss: 0.000314\n",
      " Epoch 57: Train Loss: 0.000289, Validation Loss: 0.000314\n",
      " Epoch 58: Train Loss: 0.000290, Validation Loss: 0.000311\n",
      " Epoch 59: Train Loss: 0.000292, Validation Loss: 0.000312\n",
      " Epoch 60: Train Loss: 0.000290, Validation Loss: 0.000308\n",
      " Epoch 61: Train Loss: 0.000280, Validation Loss: 0.000306\n",
      " Epoch 62: Train Loss: 0.000278, Validation Loss: 0.000304\n",
      " Epoch 63: Train Loss: 0.000278, Validation Loss: 0.000303\n",
      " Epoch 64: Train Loss: 0.000277, Validation Loss: 0.000303\n",
      " Epoch 65: Train Loss: 0.000276, Validation Loss: 0.000303\n",
      " Epoch 66: Train Loss: 0.000276, Validation Loss: 0.000304\n",
      " Epoch 67: Train Loss: 0.000274, Validation Loss: 0.000301\n",
      " Epoch 68: Train Loss: 0.000275, Validation Loss: 0.000301\n",
      " Epoch 69: Train Loss: 0.000273, Validation Loss: 0.000301\n",
      " Epoch 70: Train Loss: 0.000273, Validation Loss: 0.000300\n",
      " Epoch 71: Train Loss: 0.000272, Validation Loss: 0.000299\n",
      " Epoch 72: Train Loss: 0.000271, Validation Loss: 0.000301\n",
      " Epoch 73: Train Loss: 0.000270, Validation Loss: 0.000299\n",
      " Epoch 74: Train Loss: 0.000269, Validation Loss: 0.000299\n",
      " Epoch 75: Train Loss: 0.000269, Validation Loss: 0.000297\n",
      " Epoch 76: Train Loss: 0.000269, Validation Loss: 0.000297\n",
      " Epoch 77: Train Loss: 0.000267, Validation Loss: 0.000297\n",
      " Epoch 78: Train Loss: 0.000268, Validation Loss: 0.000296\n",
      " Epoch 79: Train Loss: 0.000265, Validation Loss: 0.000295\n",
      " Epoch 80: Train Loss: 0.000265, Validation Loss: 0.000295\n",
      " Epoch 81: Train Loss: 0.000264, Validation Loss: 0.000293\n",
      " Epoch 82: Train Loss: 0.000265, Validation Loss: 0.000296\n",
      " Epoch 83: Train Loss: 0.000267, Validation Loss: 0.000293\n",
      " Epoch 84: Train Loss: 0.000265, Validation Loss: 0.000293\n",
      " Epoch 85: Train Loss: 0.000264, Validation Loss: 0.000293\n",
      " Epoch 86: Train Loss: 0.000261, Validation Loss: 0.000295\n",
      " Epoch 87: Train Loss: 0.000260, Validation Loss: 0.000291\n",
      " Epoch 88: Train Loss: 0.000259, Validation Loss: 0.000293\n",
      " Epoch 89: Train Loss: 0.000258, Validation Loss: 0.000292\n",
      " Epoch 90: Train Loss: 0.000258, Validation Loss: 0.000292\n",
      " Epoch 91: Train Loss: 0.000254, Validation Loss: 0.000289\n",
      " Epoch 92: Train Loss: 0.000254, Validation Loss: 0.000288\n",
      " Epoch 93: Train Loss: 0.000253, Validation Loss: 0.000288\n",
      " Epoch 94: Train Loss: 0.000254, Validation Loss: 0.000288\n",
      " Epoch 95: Train Loss: 0.000253, Validation Loss: 0.000287\n",
      " Epoch 96: Train Loss: 0.000252, Validation Loss: 0.000287\n",
      " Epoch 97: Train Loss: 0.000252, Validation Loss: 0.000287\n",
      " Epoch 98: Train Loss: 0.000252, Validation Loss: 0.000286\n",
      " Epoch 99: Train Loss: 0.000251, Validation Loss: 0.000286\n",
      " Epoch 100: Train Loss: 0.000251, Validation Loss: 0.000286\n",
      " Epoch 101: Train Loss: 0.000250, Validation Loss: 0.000286\n",
      " Epoch 102: Train Loss: 0.000250, Validation Loss: 0.000286\n",
      " Epoch 103: Train Loss: 0.000250, Validation Loss: 0.000286\n",
      " Epoch 104: Train Loss: 0.000249, Validation Loss: 0.000286\n",
      " Epoch 105: Train Loss: 0.000249, Validation Loss: 0.000285\n",
      " Epoch 106: Train Loss: 0.000248, Validation Loss: 0.000286\n",
      " Epoch 107: Train Loss: 0.000248, Validation Loss: 0.000286\n",
      " Epoch 108: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 109: Train Loss: 0.000247, Validation Loss: 0.000284\n",
      " Epoch 110: Train Loss: 0.000248, Validation Loss: 0.000285\n",
      " Epoch 111: Train Loss: 0.000248, Validation Loss: 0.000284\n",
      " Epoch 112: Train Loss: 0.000246, Validation Loss: 0.000284\n",
      " Epoch 113: Train Loss: 0.000245, Validation Loss: 0.000283\n",
      " Epoch 114: Train Loss: 0.000245, Validation Loss: 0.000283\n",
      " Epoch 115: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 116: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 117: Train Loss: 0.000244, Validation Loss: 0.000286\n",
      " Epoch 118: Train Loss: 0.000244, Validation Loss: 0.000283\n",
      " Epoch 119: Train Loss: 0.000242, Validation Loss: 0.000281\n",
      " Epoch 120: Train Loss: 0.000242, Validation Loss: 0.000283\n",
      " Epoch 121: Train Loss: 0.000240, Validation Loss: 0.000281\n",
      " Epoch 122: Train Loss: 0.000240, Validation Loss: 0.000281\n",
      " Epoch 123: Train Loss: 0.000240, Validation Loss: 0.000281\n",
      " Epoch 124: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 125: Train Loss: 0.000239, Validation Loss: 0.000281\n",
      " Epoch 126: Train Loss: 0.000239, Validation Loss: 0.000281\n",
      " Epoch 127: Train Loss: 0.000238, Validation Loss: 0.000281\n",
      " Epoch 128: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 129: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 130: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 131: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 132: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 133: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 134: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 135: Train Loss: 0.000237, Validation Loss: 0.000280\n",
      " Epoch 136: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 137: Train Loss: 0.000236, Validation Loss: 0.000280\n",
      " Epoch 138: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 139: Train Loss: 0.000236, Validation Loss: 0.000281\n",
      " Epoch 140: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 141: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 142: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 143: Train Loss: 0.000234, Validation Loss: 0.000279\n",
      " Epoch 144: Train Loss: 0.000233, Validation Loss: 0.000279\n",
      " Epoch 145: Train Loss: 0.000233, Validation Loss: 0.000279\n",
      " Epoch 146: Train Loss: 0.000233, Validation Loss: 0.000278\n",
      " Epoch 147: Train Loss: 0.000233, Validation Loss: 0.000278\n",
      " Epoch 148: Train Loss: 0.000233, Validation Loss: 0.000278\n",
      " Epoch 149: Train Loss: 0.000232, Validation Loss: 0.000278\n",
      " Epoch 150: Train Loss: 0.000232, Validation Loss: 0.000279\n",
      " Epoch 151: Train Loss: 0.000231, Validation Loss: 0.000277\n",
      " Epoch 152: Train Loss: 0.000230, Validation Loss: 0.000278\n",
      " Epoch 153: Train Loss: 0.000230, Validation Loss: 0.000278\n",
      " Epoch 154: Train Loss: 0.000230, Validation Loss: 0.000277\n",
      " Epoch 155: Train Loss: 0.000230, Validation Loss: 0.000277\n",
      " Epoch 156: Train Loss: 0.000229, Validation Loss: 0.000278\n",
      " Epoch 157: Train Loss: 0.000230, Validation Loss: 0.000277\n",
      " Epoch 158: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 159: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 160: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 161: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 162: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 163: Train Loss: 0.000229, Validation Loss: 0.000277\n",
      " Epoch 164: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 165: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 166: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 167: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 168: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 169: Train Loss: 0.000228, Validation Loss: 0.000277\n",
      " Epoch 170: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 171: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 172: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 173: Train Loss: 0.000227, Validation Loss: 0.000277\n",
      " Epoch 174: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 175: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 176: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 177: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 178: Train Loss: 0.000226, Validation Loss: 0.000277\n",
      " Epoch 179: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 180: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 181: Train Loss: 0.000225, Validation Loss: 0.000276\n",
      " Epoch 182: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 183: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 184: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 185: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 186: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 187: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 188: Train Loss: 0.000224, Validation Loss: 0.000276\n",
      " Epoch 189: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 190: Train Loss: 0.000223, Validation Loss: 0.000277\n",
      " Epoch 191: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 192: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 193: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 194: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 195: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 196: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 197: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 198: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 199: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 200: Train Loss: 0.000223, Validation Loss: 0.000276\n",
      " Epoch 201: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 202: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 203: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 204: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 205: Train Loss: 0.000222, Validation Loss: 0.000276\n",
      " Epoch 206: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 207: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 208: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 209: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 210: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 211: Train Loss: 0.000221, Validation Loss: 0.000276\n",
      " Epoch 212: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 213: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 214: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 215: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 216: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 217: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 218: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 219: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 220: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 221: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 222: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 223: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 224: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 225: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 226: Train Loss: 0.000220, Validation Loss: 0.000276\n",
      " Epoch 227: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 228: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 229: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 230: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 231: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 232: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 233: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 234: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 235: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 236: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 237: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 238: Train Loss: 0.000219, Validation Loss: 0.000276\n",
      " Epoch 239: Train Loss: 0.000218, Validation Loss: 0.000276\n",
      " Epoch 240: Train Loss: 0.000218, Validation Loss: 0.000276\n",
      " Epoch 241: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 242: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 243: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 244: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 245: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 246: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 247: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 248: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 249: Train Loss: 0.000218, Validation Loss: 0.000276\n",
      " Epoch 250: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 251: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 252: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 253: Train Loss: 0.000218, Validation Loss: 0.000276\n",
      " Epoch 254: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 255: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 256: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 257: Train Loss: 0.000217, Validation Loss: 0.000276\n",
      " Epoch 258: Train Loss: 0.000218, Validation Loss: 0.000275\n",
      " Epoch 259: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 260: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 261: Train Loss: 0.000217, Validation Loss: 0.000276\n",
      " Epoch 262: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 263: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 264: Train Loss: 0.000217, Validation Loss: 0.000276\n",
      " Epoch 265: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 266: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 267: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 268: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 269: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 270: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 271: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 272: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 273: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 274: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 275: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 276: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 277: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 278: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 279: Train Loss: 0.000217, Validation Loss: 0.000276\n",
      " Epoch 280: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 281: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 282: Train Loss: 0.000217, Validation Loss: 0.000275\n",
      " Epoch 283: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 284: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 285: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 286: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 287: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 288: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 289: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 290: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 291: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 292: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 293: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 294: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 295: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 296: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 297: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 298: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 299: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 300: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 301: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 302: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 303: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 304: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      " Epoch 305: Train Loss: 0.000216, Validation Loss: 0.000275\n",
      "Early stopping at epoch 305 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016785, Validation Loss: 0.019962\n",
      " Epoch 2: Train Loss: 0.006487, Validation Loss: 0.007530\n",
      " Epoch 3: Train Loss: 0.005206, Validation Loss: 0.004543\n",
      " Epoch 4: Train Loss: 0.002849, Validation Loss: 0.002104\n",
      " Epoch 5: Train Loss: 0.001404, Validation Loss: 0.001238\n",
      " Epoch 6: Train Loss: 0.001046, Validation Loss: 0.001013\n",
      " Epoch 7: Train Loss: 0.000878, Validation Loss: 0.000828\n",
      " Epoch 8: Train Loss: 0.000775, Validation Loss: 0.000727\n",
      " Epoch 9: Train Loss: 0.000688, Validation Loss: 0.000644\n",
      " Epoch 10: Train Loss: 0.000622, Validation Loss: 0.000674\n",
      " Epoch 11: Train Loss: 0.000584, Validation Loss: 0.000628\n",
      " Epoch 12: Train Loss: 0.000550, Validation Loss: 0.000552\n",
      " Epoch 13: Train Loss: 0.000517, Validation Loss: 0.000516\n",
      " Epoch 14: Train Loss: 0.000498, Validation Loss: 0.000529\n",
      " Epoch 15: Train Loss: 0.000474, Validation Loss: 0.000498\n",
      " Epoch 16: Train Loss: 0.000463, Validation Loss: 0.000459\n",
      " Epoch 17: Train Loss: 0.000452, Validation Loss: 0.000443\n",
      " Epoch 18: Train Loss: 0.000431, Validation Loss: 0.000439\n",
      " Epoch 19: Train Loss: 0.000425, Validation Loss: 0.000449\n",
      " Epoch 20: Train Loss: 0.000414, Validation Loss: 0.000412\n",
      " Epoch 21: Train Loss: 0.000404, Validation Loss: 0.000435\n",
      " Epoch 22: Train Loss: 0.000398, Validation Loss: 0.000429\n",
      " Epoch 23: Train Loss: 0.000397, Validation Loss: 0.000396\n",
      " Epoch 24: Train Loss: 0.000383, Validation Loss: 0.000394\n",
      " Epoch 25: Train Loss: 0.000379, Validation Loss: 0.000404\n",
      " Epoch 26: Train Loss: 0.000380, Validation Loss: 0.000387\n",
      " Epoch 27: Train Loss: 0.000371, Validation Loss: 0.000411\n",
      " Epoch 28: Train Loss: 0.000359, Validation Loss: 0.000422\n",
      " Epoch 29: Train Loss: 0.000385, Validation Loss: 0.000398\n",
      " Epoch 30: Train Loss: 0.000355, Validation Loss: 0.000363\n",
      " Epoch 31: Train Loss: 0.000344, Validation Loss: 0.000355\n",
      " Epoch 32: Train Loss: 0.000337, Validation Loss: 0.000353\n",
      " Epoch 33: Train Loss: 0.000336, Validation Loss: 0.000350\n",
      " Epoch 34: Train Loss: 0.000333, Validation Loss: 0.000362\n",
      " Epoch 35: Train Loss: 0.000332, Validation Loss: 0.000348\n",
      " Epoch 36: Train Loss: 0.000331, Validation Loss: 0.000351\n",
      " Epoch 37: Train Loss: 0.000328, Validation Loss: 0.000374\n",
      " Epoch 38: Train Loss: 0.000327, Validation Loss: 0.000356\n",
      " Epoch 39: Train Loss: 0.000325, Validation Loss: 0.000355\n",
      " Epoch 40: Train Loss: 0.000325, Validation Loss: 0.000379\n",
      " Epoch 41: Train Loss: 0.000326, Validation Loss: 0.000341\n",
      " Epoch 42: Train Loss: 0.000321, Validation Loss: 0.000335\n",
      " Epoch 43: Train Loss: 0.000316, Validation Loss: 0.000351\n",
      " Epoch 44: Train Loss: 0.000314, Validation Loss: 0.000345\n",
      " Epoch 45: Train Loss: 0.000313, Validation Loss: 0.000358\n",
      " Epoch 46: Train Loss: 0.000313, Validation Loss: 0.000331\n",
      " Epoch 47: Train Loss: 0.000309, Validation Loss: 0.000342\n",
      " Epoch 48: Train Loss: 0.000308, Validation Loss: 0.000348\n",
      " Epoch 49: Train Loss: 0.000312, Validation Loss: 0.000330\n",
      " Epoch 50: Train Loss: 0.000303, Validation Loss: 0.000329\n",
      " Epoch 51: Train Loss: 0.000301, Validation Loss: 0.000337\n",
      " Epoch 52: Train Loss: 0.000299, Validation Loss: 0.000333\n",
      " Epoch 53: Train Loss: 0.000304, Validation Loss: 0.000340\n",
      " Epoch 54: Train Loss: 0.000303, Validation Loss: 0.000328\n",
      " Epoch 55: Train Loss: 0.000298, Validation Loss: 0.000327\n",
      " Epoch 56: Train Loss: 0.000304, Validation Loss: 0.000335\n",
      " Epoch 57: Train Loss: 0.000290, Validation Loss: 0.000323\n",
      " Epoch 58: Train Loss: 0.000287, Validation Loss: 0.000317\n",
      " Epoch 59: Train Loss: 0.000288, Validation Loss: 0.000345\n",
      " Epoch 60: Train Loss: 0.000289, Validation Loss: 0.000338\n",
      " Epoch 61: Train Loss: 0.000280, Validation Loss: 0.000314\n",
      " Epoch 62: Train Loss: 0.000277, Validation Loss: 0.000312\n",
      " Epoch 63: Train Loss: 0.000278, Validation Loss: 0.000311\n",
      " Epoch 64: Train Loss: 0.000276, Validation Loss: 0.000308\n",
      " Epoch 65: Train Loss: 0.000274, Validation Loss: 0.000309\n",
      " Epoch 66: Train Loss: 0.000274, Validation Loss: 0.000307\n",
      " Epoch 67: Train Loss: 0.000277, Validation Loss: 0.000312\n",
      " Epoch 68: Train Loss: 0.000275, Validation Loss: 0.000316\n",
      " Epoch 69: Train Loss: 0.000272, Validation Loss: 0.000306\n",
      " Epoch 70: Train Loss: 0.000271, Validation Loss: 0.000307\n",
      " Epoch 71: Train Loss: 0.000270, Validation Loss: 0.000312\n",
      " Epoch 72: Train Loss: 0.000274, Validation Loss: 0.000321\n",
      " Epoch 73: Train Loss: 0.000272, Validation Loss: 0.000304\n",
      " Epoch 74: Train Loss: 0.000268, Validation Loss: 0.000334\n",
      " Epoch 75: Train Loss: 0.000270, Validation Loss: 0.000307\n",
      " Epoch 76: Train Loss: 0.000266, Validation Loss: 0.000307\n",
      " Epoch 77: Train Loss: 0.000268, Validation Loss: 0.000304\n",
      " Epoch 78: Train Loss: 0.000263, Validation Loss: 0.000303\n",
      " Epoch 79: Train Loss: 0.000263, Validation Loss: 0.000301\n",
      " Epoch 80: Train Loss: 0.000262, Validation Loss: 0.000307\n",
      " Epoch 81: Train Loss: 0.000265, Validation Loss: 0.000303\n",
      " Epoch 82: Train Loss: 0.000263, Validation Loss: 0.000299\n",
      " Epoch 83: Train Loss: 0.000260, Validation Loss: 0.000299\n",
      " Epoch 84: Train Loss: 0.000262, Validation Loss: 0.000304\n",
      " Epoch 85: Train Loss: 0.000260, Validation Loss: 0.000302\n",
      " Epoch 86: Train Loss: 0.000259, Validation Loss: 0.000304\n",
      " Epoch 87: Train Loss: 0.000257, Validation Loss: 0.000305\n",
      " Epoch 88: Train Loss: 0.000256, Validation Loss: 0.000303\n",
      " Epoch 89: Train Loss: 0.000255, Validation Loss: 0.000298\n",
      " Epoch 90: Train Loss: 0.000253, Validation Loss: 0.000301\n",
      " Epoch 91: Train Loss: 0.000249, Validation Loss: 0.000294\n",
      " Epoch 92: Train Loss: 0.000246, Validation Loss: 0.000294\n",
      " Epoch 93: Train Loss: 0.000247, Validation Loss: 0.000296\n",
      " Epoch 94: Train Loss: 0.000245, Validation Loss: 0.000295\n",
      " Epoch 95: Train Loss: 0.000245, Validation Loss: 0.000297\n",
      " Epoch 96: Train Loss: 0.000246, Validation Loss: 0.000294\n",
      " Epoch 97: Train Loss: 0.000243, Validation Loss: 0.000296\n",
      " Epoch 98: Train Loss: 0.000245, Validation Loss: 0.000299\n",
      " Epoch 99: Train Loss: 0.000244, Validation Loss: 0.000295\n",
      " Epoch 100: Train Loss: 0.000243, Validation Loss: 0.000296\n",
      " Epoch 101: Train Loss: 0.000243, Validation Loss: 0.000296\n",
      " Epoch 102: Train Loss: 0.000241, Validation Loss: 0.000294\n",
      " Epoch 103: Train Loss: 0.000244, Validation Loss: 0.000295\n",
      " Epoch 104: Train Loss: 0.000241, Validation Loss: 0.000292\n",
      " Epoch 105: Train Loss: 0.000240, Validation Loss: 0.000296\n",
      " Epoch 106: Train Loss: 0.000239, Validation Loss: 0.000296\n",
      " Epoch 107: Train Loss: 0.000239, Validation Loss: 0.000302\n",
      " Epoch 108: Train Loss: 0.000240, Validation Loss: 0.000296\n",
      " Epoch 109: Train Loss: 0.000240, Validation Loss: 0.000297\n",
      " Epoch 110: Train Loss: 0.000237, Validation Loss: 0.000293\n",
      " Epoch 111: Train Loss: 0.000235, Validation Loss: 0.000294\n",
      " Epoch 112: Train Loss: 0.000237, Validation Loss: 0.000299\n",
      " Epoch 113: Train Loss: 0.000235, Validation Loss: 0.000292\n",
      " Epoch 114: Train Loss: 0.000235, Validation Loss: 0.000292\n",
      " Epoch 115: Train Loss: 0.000234, Validation Loss: 0.000293\n",
      " Epoch 116: Train Loss: 0.000233, Validation Loss: 0.000302\n",
      " Epoch 117: Train Loss: 0.000231, Validation Loss: 0.000295\n",
      " Epoch 118: Train Loss: 0.000231, Validation Loss: 0.000292\n",
      " Epoch 119: Train Loss: 0.000230, Validation Loss: 0.000294\n",
      " Epoch 120: Train Loss: 0.000230, Validation Loss: 0.000296\n",
      " Epoch 121: Train Loss: 0.000227, Validation Loss: 0.000291\n",
      " Epoch 122: Train Loss: 0.000225, Validation Loss: 0.000291\n",
      " Epoch 123: Train Loss: 0.000224, Validation Loss: 0.000292\n",
      " Epoch 124: Train Loss: 0.000224, Validation Loss: 0.000292\n",
      " Epoch 125: Train Loss: 0.000223, Validation Loss: 0.000291\n",
      " Epoch 126: Train Loss: 0.000223, Validation Loss: 0.000294\n",
      " Epoch 127: Train Loss: 0.000222, Validation Loss: 0.000291\n",
      " Epoch 128: Train Loss: 0.000222, Validation Loss: 0.000292\n",
      " Epoch 129: Train Loss: 0.000222, Validation Loss: 0.000292\n",
      " Epoch 130: Train Loss: 0.000222, Validation Loss: 0.000294\n",
      " Epoch 131: Train Loss: 0.000221, Validation Loss: 0.000290\n",
      " Epoch 132: Train Loss: 0.000221, Validation Loss: 0.000294\n",
      " Epoch 133: Train Loss: 0.000220, Validation Loss: 0.000294\n",
      " Epoch 134: Train Loss: 0.000220, Validation Loss: 0.000295\n",
      " Epoch 135: Train Loss: 0.000219, Validation Loss: 0.000292\n",
      " Epoch 136: Train Loss: 0.000220, Validation Loss: 0.000292\n",
      " Epoch 137: Train Loss: 0.000218, Validation Loss: 0.000290\n",
      " Epoch 138: Train Loss: 0.000218, Validation Loss: 0.000291\n",
      " Epoch 139: Train Loss: 0.000218, Validation Loss: 0.000292\n",
      " Epoch 140: Train Loss: 0.000217, Validation Loss: 0.000291\n",
      " Epoch 141: Train Loss: 0.000217, Validation Loss: 0.000291\n",
      " Epoch 142: Train Loss: 0.000217, Validation Loss: 0.000293\n",
      " Epoch 143: Train Loss: 0.000216, Validation Loss: 0.000291\n",
      " Epoch 144: Train Loss: 0.000215, Validation Loss: 0.000292\n",
      " Epoch 145: Train Loss: 0.000215, Validation Loss: 0.000293\n",
      " Epoch 146: Train Loss: 0.000214, Validation Loss: 0.000291\n",
      " Epoch 147: Train Loss: 0.000213, Validation Loss: 0.000294\n",
      " Epoch 148: Train Loss: 0.000213, Validation Loss: 0.000297\n",
      " Epoch 149: Train Loss: 0.000212, Validation Loss: 0.000291\n",
      " Epoch 150: Train Loss: 0.000211, Validation Loss: 0.000291\n",
      " Epoch 151: Train Loss: 0.000210, Validation Loss: 0.000293\n",
      " Epoch 152: Train Loss: 0.000209, Validation Loss: 0.000292\n",
      " Epoch 153: Train Loss: 0.000208, Validation Loss: 0.000292\n",
      " Epoch 154: Train Loss: 0.000209, Validation Loss: 0.000291\n",
      " Epoch 155: Train Loss: 0.000208, Validation Loss: 0.000290\n",
      " Epoch 156: Train Loss: 0.000207, Validation Loss: 0.000291\n",
      " Epoch 157: Train Loss: 0.000208, Validation Loss: 0.000291\n",
      "Early stopping at epoch 157 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016782, Validation Loss: 0.029567\n",
      " Epoch 2: Train Loss: 0.005003, Validation Loss: 0.005644\n",
      " Epoch 3: Train Loss: 0.001711, Validation Loss: 0.001520\n",
      " Epoch 4: Train Loss: 0.001100, Validation Loss: 0.001070\n",
      " Epoch 5: Train Loss: 0.000901, Validation Loss: 0.000837\n",
      " Epoch 6: Train Loss: 0.000793, Validation Loss: 0.000748\n",
      " Epoch 7: Train Loss: 0.000709, Validation Loss: 0.000672\n",
      " Epoch 8: Train Loss: 0.000648, Validation Loss: 0.000619\n",
      " Epoch 9: Train Loss: 0.000604, Validation Loss: 0.000584\n",
      " Epoch 10: Train Loss: 0.000568, Validation Loss: 0.000586\n",
      " Epoch 11: Train Loss: 0.000550, Validation Loss: 0.000526\n",
      " Epoch 12: Train Loss: 0.000513, Validation Loss: 0.000519\n",
      " Epoch 13: Train Loss: 0.000510, Validation Loss: 0.000501\n",
      " Epoch 14: Train Loss: 0.000471, Validation Loss: 0.000505\n",
      " Epoch 15: Train Loss: 0.000460, Validation Loss: 0.000492\n",
      " Epoch 16: Train Loss: 0.000452, Validation Loss: 0.000479\n",
      " Epoch 17: Train Loss: 0.000440, Validation Loss: 0.000459\n",
      " Epoch 18: Train Loss: 0.000423, Validation Loss: 0.000446\n",
      " Epoch 19: Train Loss: 0.000411, Validation Loss: 0.000417\n",
      " Epoch 20: Train Loss: 0.000405, Validation Loss: 0.000442\n",
      " Epoch 21: Train Loss: 0.000408, Validation Loss: 0.000421\n",
      " Epoch 22: Train Loss: 0.000387, Validation Loss: 0.000422\n",
      " Epoch 23: Train Loss: 0.000704, Validation Loss: 0.011699\n",
      " Epoch 24: Train Loss: 0.000589, Validation Loss: 0.000486\n",
      " Epoch 25: Train Loss: 0.000439, Validation Loss: 0.000471\n",
      " Epoch 26: Train Loss: 0.000414, Validation Loss: 0.000403\n",
      " Epoch 27: Train Loss: 0.000396, Validation Loss: 0.000447\n",
      " Epoch 28: Train Loss: 0.000378, Validation Loss: 0.000384\n",
      " Epoch 29: Train Loss: 0.000370, Validation Loss: 0.000375\n",
      " Epoch 30: Train Loss: 0.000370, Validation Loss: 0.000374\n",
      " Epoch 31: Train Loss: 0.000354, Validation Loss: 0.000367\n",
      " Epoch 32: Train Loss: 0.000352, Validation Loss: 0.000367\n",
      " Epoch 33: Train Loss: 0.000346, Validation Loss: 0.000360\n",
      " Epoch 34: Train Loss: 0.000344, Validation Loss: 0.000357\n",
      " Epoch 35: Train Loss: 0.000340, Validation Loss: 0.000354\n",
      " Epoch 36: Train Loss: 0.000338, Validation Loss: 0.000353\n",
      " Epoch 37: Train Loss: 0.000335, Validation Loss: 0.000350\n",
      " Epoch 38: Train Loss: 0.000332, Validation Loss: 0.000348\n",
      " Epoch 39: Train Loss: 0.000330, Validation Loss: 0.000346\n",
      " Epoch 40: Train Loss: 0.000329, Validation Loss: 0.000345\n",
      " Epoch 41: Train Loss: 0.000324, Validation Loss: 0.000346\n",
      " Epoch 42: Train Loss: 0.000322, Validation Loss: 0.000348\n",
      " Epoch 43: Train Loss: 0.000319, Validation Loss: 0.000341\n",
      " Epoch 44: Train Loss: 0.000323, Validation Loss: 0.000345\n",
      " Epoch 45: Train Loss: 0.000323, Validation Loss: 0.000338\n",
      " Epoch 46: Train Loss: 0.000319, Validation Loss: 0.000337\n",
      " Epoch 47: Train Loss: 0.000314, Validation Loss: 0.000432\n",
      " Epoch 48: Train Loss: 0.000314, Validation Loss: 0.000340\n",
      " Epoch 49: Train Loss: 0.000305, Validation Loss: 0.000331\n",
      " Epoch 50: Train Loss: 0.000311, Validation Loss: 0.000340\n",
      " Epoch 51: Train Loss: 0.000303, Validation Loss: 0.000326\n",
      " Epoch 52: Train Loss: 0.000303, Validation Loss: 0.000332\n",
      " Epoch 53: Train Loss: 0.000299, Validation Loss: 0.000326\n",
      " Epoch 54: Train Loss: 0.000298, Validation Loss: 0.000328\n",
      " Epoch 55: Train Loss: 0.000300, Validation Loss: 0.000379\n",
      " Epoch 56: Train Loss: 0.000293, Validation Loss: 0.000320\n",
      " Epoch 57: Train Loss: 0.000297, Validation Loss: 0.000321\n",
      " Epoch 58: Train Loss: 0.000290, Validation Loss: 0.000321\n",
      " Epoch 59: Train Loss: 0.000289, Validation Loss: 0.000323\n",
      " Epoch 60: Train Loss: 0.000285, Validation Loss: 0.000340\n",
      " Epoch 61: Train Loss: 0.000280, Validation Loss: 0.000315\n",
      " Epoch 62: Train Loss: 0.000278, Validation Loss: 0.000317\n",
      " Epoch 63: Train Loss: 0.000277, Validation Loss: 0.000317\n",
      " Epoch 64: Train Loss: 0.000275, Validation Loss: 0.000321\n",
      " Epoch 65: Train Loss: 0.000279, Validation Loss: 0.000315\n",
      " Epoch 66: Train Loss: 0.000275, Validation Loss: 0.000314\n",
      " Epoch 67: Train Loss: 0.000273, Validation Loss: 0.000313\n",
      " Epoch 68: Train Loss: 0.000272, Validation Loss: 0.000328\n",
      " Epoch 69: Train Loss: 0.000272, Validation Loss: 0.000315\n",
      " Epoch 70: Train Loss: 0.000271, Validation Loss: 0.000313\n",
      " Epoch 71: Train Loss: 0.000270, Validation Loss: 0.000315\n",
      " Epoch 72: Train Loss: 0.000269, Validation Loss: 0.000334\n",
      " Epoch 73: Train Loss: 0.000268, Validation Loss: 0.000319\n",
      " Epoch 74: Train Loss: 0.000268, Validation Loss: 0.000314\n",
      " Epoch 75: Train Loss: 0.000265, Validation Loss: 0.000313\n",
      " Epoch 76: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 77: Train Loss: 0.000263, Validation Loss: 0.000317\n",
      " Epoch 78: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 79: Train Loss: 0.000260, Validation Loss: 0.000321\n",
      " Epoch 80: Train Loss: 0.000260, Validation Loss: 0.000310\n",
      " Epoch 81: Train Loss: 0.000257, Validation Loss: 0.000311\n",
      " Epoch 82: Train Loss: 0.000258, Validation Loss: 0.000310\n",
      " Epoch 83: Train Loss: 0.000256, Validation Loss: 0.000322\n",
      " Epoch 84: Train Loss: 0.000258, Validation Loss: 0.000312\n",
      " Epoch 85: Train Loss: 0.000254, Validation Loss: 0.000312\n",
      " Epoch 86: Train Loss: 0.000257, Validation Loss: 0.000311\n",
      " Epoch 87: Train Loss: 0.000253, Validation Loss: 0.000314\n",
      " Epoch 88: Train Loss: 0.000253, Validation Loss: 0.000309\n",
      " Epoch 89: Train Loss: 0.000251, Validation Loss: 0.000311\n",
      " Epoch 90: Train Loss: 0.000250, Validation Loss: 0.000315\n",
      " Epoch 91: Train Loss: 0.000245, Validation Loss: 0.000305\n",
      " Epoch 92: Train Loss: 0.000243, Validation Loss: 0.000305\n",
      " Epoch 93: Train Loss: 0.000242, Validation Loss: 0.000306\n",
      " Epoch 94: Train Loss: 0.000242, Validation Loss: 0.000305\n",
      " Epoch 95: Train Loss: 0.000241, Validation Loss: 0.000306\n",
      " Epoch 96: Train Loss: 0.000242, Validation Loss: 0.000305\n",
      " Epoch 97: Train Loss: 0.000241, Validation Loss: 0.000305\n",
      " Epoch 98: Train Loss: 0.000239, Validation Loss: 0.000308\n",
      " Epoch 99: Train Loss: 0.000239, Validation Loss: 0.000309\n",
      " Epoch 100: Train Loss: 0.000238, Validation Loss: 0.000307\n",
      " Epoch 101: Train Loss: 0.000238, Validation Loss: 0.000305\n",
      " Epoch 102: Train Loss: 0.000240, Validation Loss: 0.000308\n",
      " Epoch 103: Train Loss: 0.000237, Validation Loss: 0.000304\n",
      " Epoch 104: Train Loss: 0.000236, Validation Loss: 0.000308\n",
      " Epoch 105: Train Loss: 0.000235, Validation Loss: 0.000309\n",
      " Epoch 106: Train Loss: 0.000234, Validation Loss: 0.000306\n",
      " Epoch 107: Train Loss: 0.000233, Validation Loss: 0.000304\n",
      " Epoch 108: Train Loss: 0.000232, Validation Loss: 0.000312\n",
      " Epoch 109: Train Loss: 0.000235, Validation Loss: 0.000308\n",
      " Epoch 110: Train Loss: 0.000231, Validation Loss: 0.000306\n",
      " Epoch 111: Train Loss: 0.000231, Validation Loss: 0.000305\n",
      " Epoch 112: Train Loss: 0.000230, Validation Loss: 0.000315\n",
      " Epoch 113: Train Loss: 0.000229, Validation Loss: 0.000312\n",
      " Epoch 114: Train Loss: 0.000229, Validation Loss: 0.000305\n",
      " Epoch 115: Train Loss: 0.000228, Validation Loss: 0.000306\n",
      " Epoch 116: Train Loss: 0.000229, Validation Loss: 0.000304\n",
      " Epoch 117: Train Loss: 0.000226, Validation Loss: 0.000305\n",
      " Epoch 118: Train Loss: 0.000224, Validation Loss: 0.000306\n",
      " Epoch 119: Train Loss: 0.000225, Validation Loss: 0.000307\n",
      " Epoch 120: Train Loss: 0.000224, Validation Loss: 0.000311\n",
      " Epoch 121: Train Loss: 0.000220, Validation Loss: 0.000305\n",
      " Epoch 122: Train Loss: 0.000220, Validation Loss: 0.000308\n",
      " Epoch 123: Train Loss: 0.000222, Validation Loss: 0.000305\n",
      " Epoch 124: Train Loss: 0.000219, Validation Loss: 0.000306\n",
      " Epoch 125: Train Loss: 0.000219, Validation Loss: 0.000310\n",
      " Epoch 126: Train Loss: 0.000219, Validation Loss: 0.000306\n",
      " Epoch 127: Train Loss: 0.000217, Validation Loss: 0.000306\n",
      "Early stopping at epoch 127 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012432, Validation Loss: 0.014196\n",
      " Epoch 2: Train Loss: 0.004190, Validation Loss: 0.007213\n",
      " Epoch 3: Train Loss: 0.002106, Validation Loss: 0.001933\n",
      " Epoch 4: Train Loss: 0.001303, Validation Loss: 0.001342\n",
      " Epoch 5: Train Loss: 0.001000, Validation Loss: 0.000949\n",
      " Epoch 6: Train Loss: 0.000840, Validation Loss: 0.000820\n",
      " Epoch 7: Train Loss: 0.000737, Validation Loss: 0.000708\n",
      " Epoch 8: Train Loss: 0.000671, Validation Loss: 0.000681\n",
      " Epoch 9: Train Loss: 0.000622, Validation Loss: 0.000611\n",
      " Epoch 10: Train Loss: 0.000579, Validation Loss: 0.000564\n",
      " Epoch 11: Train Loss: 0.000552, Validation Loss: 0.000583\n",
      " Epoch 12: Train Loss: 0.000525, Validation Loss: 0.000528\n",
      " Epoch 13: Train Loss: 0.000493, Validation Loss: 0.000498\n",
      " Epoch 14: Train Loss: 0.000475, Validation Loss: 0.000471\n",
      " Epoch 15: Train Loss: 0.000457, Validation Loss: 0.000509\n",
      " Epoch 16: Train Loss: 0.000437, Validation Loss: 0.000446\n",
      " Epoch 17: Train Loss: 0.000429, Validation Loss: 0.000430\n",
      " Epoch 18: Train Loss: 0.000411, Validation Loss: 0.000418\n",
      " Epoch 19: Train Loss: 0.000402, Validation Loss: 0.000428\n",
      " Epoch 20: Train Loss: 0.000401, Validation Loss: 0.000494\n",
      " Epoch 21: Train Loss: 0.000386, Validation Loss: 0.000407\n",
      " Epoch 22: Train Loss: 0.000369, Validation Loss: 0.000393\n",
      " Epoch 23: Train Loss: 0.000371, Validation Loss: 0.000417\n",
      " Epoch 24: Train Loss: 0.000369, Validation Loss: 0.000409\n",
      " Epoch 25: Train Loss: 0.000367, Validation Loss: 0.000373\n",
      " Epoch 26: Train Loss: 0.000345, Validation Loss: 0.000359\n",
      " Epoch 27: Train Loss: 0.000349, Validation Loss: 0.000402\n",
      " Epoch 28: Train Loss: 0.000336, Validation Loss: 0.000365\n",
      " Epoch 29: Train Loss: 0.000340, Validation Loss: 0.000394\n",
      " Epoch 30: Train Loss: 0.000335, Validation Loss: 0.000387\n",
      " Epoch 31: Train Loss: 0.000312, Validation Loss: 0.000339\n",
      " Epoch 32: Train Loss: 0.000307, Validation Loss: 0.000349\n",
      " Epoch 33: Train Loss: 0.000307, Validation Loss: 0.000355\n",
      " Epoch 34: Train Loss: 0.000304, Validation Loss: 0.000337\n",
      " Epoch 35: Train Loss: 0.000299, Validation Loss: 0.000335\n",
      " Epoch 36: Train Loss: 0.000299, Validation Loss: 0.000334\n",
      " Epoch 37: Train Loss: 0.000295, Validation Loss: 0.000334\n",
      " Epoch 38: Train Loss: 0.000292, Validation Loss: 0.000337\n",
      " Epoch 39: Train Loss: 0.000293, Validation Loss: 0.000371\n",
      " Epoch 40: Train Loss: 0.000286, Validation Loss: 0.000327\n",
      " Epoch 41: Train Loss: 0.000284, Validation Loss: 0.000326\n",
      " Epoch 42: Train Loss: 0.000283, Validation Loss: 0.000323\n",
      " Epoch 43: Train Loss: 0.000283, Validation Loss: 0.000324\n",
      " Epoch 44: Train Loss: 0.000277, Validation Loss: 0.000324\n",
      " Epoch 45: Train Loss: 0.000282, Validation Loss: 0.000325\n",
      " Epoch 46: Train Loss: 0.000278, Validation Loss: 0.000378\n",
      " Epoch 47: Train Loss: 0.000271, Validation Loss: 0.000321\n",
      " Epoch 48: Train Loss: 0.000270, Validation Loss: 0.000330\n",
      " Epoch 49: Train Loss: 0.000266, Validation Loss: 0.000338\n",
      " Epoch 50: Train Loss: 0.000269, Validation Loss: 0.000354\n",
      " Epoch 51: Train Loss: 0.000269, Validation Loss: 0.000346\n",
      " Epoch 52: Train Loss: 0.000260, Validation Loss: 0.000342\n",
      " Epoch 53: Train Loss: 0.000261, Validation Loss: 0.000317\n",
      " Epoch 54: Train Loss: 0.000258, Validation Loss: 0.000330\n",
      " Epoch 55: Train Loss: 0.000254, Validation Loss: 0.000347\n",
      " Epoch 56: Train Loss: 0.000254, Validation Loss: 0.000317\n",
      " Epoch 57: Train Loss: 0.000250, Validation Loss: 0.000324\n",
      " Epoch 58: Train Loss: 0.000251, Validation Loss: 0.000347\n",
      " Epoch 59: Train Loss: 0.000252, Validation Loss: 0.000336\n",
      " Epoch 60: Train Loss: 0.000248, Validation Loss: 0.000323\n",
      " Epoch 61: Train Loss: 0.000236, Validation Loss: 0.000310\n",
      " Epoch 62: Train Loss: 0.000228, Validation Loss: 0.000313\n",
      " Epoch 63: Train Loss: 0.000227, Validation Loss: 0.000314\n",
      " Epoch 64: Train Loss: 0.000228, Validation Loss: 0.000313\n",
      " Epoch 65: Train Loss: 0.000226, Validation Loss: 0.000320\n",
      " Epoch 66: Train Loss: 0.000227, Validation Loss: 0.000313\n",
      " Epoch 67: Train Loss: 0.000221, Validation Loss: 0.000316\n",
      " Epoch 68: Train Loss: 0.000222, Validation Loss: 0.000313\n",
      " Epoch 69: Train Loss: 0.000221, Validation Loss: 0.000312\n",
      " Epoch 70: Train Loss: 0.000217, Validation Loss: 0.000314\n",
      " Epoch 71: Train Loss: 0.000221, Validation Loss: 0.000317\n",
      " Epoch 72: Train Loss: 0.000217, Validation Loss: 0.000319\n",
      " Epoch 73: Train Loss: 0.000215, Validation Loss: 0.000319\n",
      " Epoch 74: Train Loss: 0.000214, Validation Loss: 0.000315\n",
      " Epoch 75: Train Loss: 0.000211, Validation Loss: 0.000314\n",
      " Epoch 76: Train Loss: 0.000210, Validation Loss: 0.000315\n",
      " Epoch 77: Train Loss: 0.000207, Validation Loss: 0.000315\n",
      " Epoch 78: Train Loss: 0.000207, Validation Loss: 0.000332\n",
      " Epoch 79: Train Loss: 0.000206, Validation Loss: 0.000330\n",
      " Epoch 80: Train Loss: 0.000208, Validation Loss: 0.000333\n",
      " Epoch 81: Train Loss: 0.000203, Validation Loss: 0.000312\n",
      "Early stopping at epoch 81 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.013428, Validation Loss: 0.028782\n",
      " Epoch 2: Train Loss: 0.003745, Validation Loss: 0.003712\n",
      " Epoch 3: Train Loss: 0.001843, Validation Loss: 0.001581\n",
      " Epoch 4: Train Loss: 0.001187, Validation Loss: 0.001110\n",
      " Epoch 5: Train Loss: 0.000950, Validation Loss: 0.000930\n",
      " Epoch 6: Train Loss: 0.000813, Validation Loss: 0.000789\n",
      " Epoch 7: Train Loss: 0.000726, Validation Loss: 0.000685\n",
      " Epoch 8: Train Loss: 0.000665, Validation Loss: 0.000637\n",
      " Epoch 9: Train Loss: 0.000613, Validation Loss: 0.000593\n",
      " Epoch 10: Train Loss: 0.000575, Validation Loss: 0.000561\n",
      " Epoch 11: Train Loss: 0.000535, Validation Loss: 0.000540\n",
      " Epoch 12: Train Loss: 0.000503, Validation Loss: 0.000499\n",
      " Epoch 13: Train Loss: 0.000483, Validation Loss: 0.000507\n",
      " Epoch 14: Train Loss: 0.000468, Validation Loss: 0.000579\n",
      " Epoch 15: Train Loss: 0.000450, Validation Loss: 0.000459\n",
      " Epoch 16: Train Loss: 0.000429, Validation Loss: 0.000493\n",
      " Epoch 17: Train Loss: 0.000418, Validation Loss: 0.000434\n",
      " Epoch 18: Train Loss: 0.000411, Validation Loss: 0.000414\n",
      " Epoch 19: Train Loss: 0.000407, Validation Loss: 0.000416\n",
      " Epoch 20: Train Loss: 0.000387, Validation Loss: 0.000407\n",
      " Epoch 21: Train Loss: 0.000393, Validation Loss: 0.000425\n",
      " Epoch 22: Train Loss: 0.000372, Validation Loss: 0.000387\n",
      " Epoch 23: Train Loss: 0.000372, Validation Loss: 0.000386\n",
      " Epoch 24: Train Loss: 0.000359, Validation Loss: 0.000400\n",
      " Epoch 25: Train Loss: 0.000376, Validation Loss: 0.000525\n",
      " Epoch 26: Train Loss: 0.000360, Validation Loss: 0.000401\n",
      " Epoch 27: Train Loss: 0.000343, Validation Loss: 0.000365\n",
      " Epoch 28: Train Loss: 0.000335, Validation Loss: 0.000540\n",
      " Epoch 29: Train Loss: 0.000351, Validation Loss: 0.000364\n",
      " Epoch 30: Train Loss: 0.000322, Validation Loss: 0.000381\n",
      " Epoch 31: Train Loss: 0.000313, Validation Loss: 0.000346\n",
      " Epoch 32: Train Loss: 0.000310, Validation Loss: 0.000349\n",
      " Epoch 33: Train Loss: 0.000307, Validation Loss: 0.000345\n",
      " Epoch 34: Train Loss: 0.000307, Validation Loss: 0.000350\n",
      " Epoch 35: Train Loss: 0.000304, Validation Loss: 0.000342\n",
      " Epoch 36: Train Loss: 0.000301, Validation Loss: 0.000343\n",
      " Epoch 37: Train Loss: 0.000298, Validation Loss: 0.000346\n",
      " Epoch 38: Train Loss: 0.000299, Validation Loss: 0.000352\n",
      " Epoch 39: Train Loss: 0.000294, Validation Loss: 0.000343\n",
      " Epoch 40: Train Loss: 0.000291, Validation Loss: 0.000332\n",
      " Epoch 41: Train Loss: 0.000287, Validation Loss: 0.000346\n",
      " Epoch 42: Train Loss: 0.000288, Validation Loss: 0.000364\n",
      " Epoch 43: Train Loss: 0.000283, Validation Loss: 0.000333\n",
      " Epoch 44: Train Loss: 0.000283, Validation Loss: 0.000330\n",
      " Epoch 45: Train Loss: 0.000281, Validation Loss: 0.000332\n",
      " Epoch 46: Train Loss: 0.000278, Validation Loss: 0.000329\n",
      " Epoch 47: Train Loss: 0.000278, Validation Loss: 0.000326\n",
      " Epoch 48: Train Loss: 0.000284, Validation Loss: 0.000335\n",
      " Epoch 49: Train Loss: 0.000276, Validation Loss: 0.000331\n",
      " Epoch 50: Train Loss: 0.000270, Validation Loss: 0.000325\n",
      " Epoch 51: Train Loss: 0.000268, Validation Loss: 0.000327\n",
      " Epoch 52: Train Loss: 0.000266, Validation Loss: 0.000331\n",
      " Epoch 53: Train Loss: 0.000263, Validation Loss: 0.000322\n",
      " Epoch 54: Train Loss: 0.000263, Validation Loss: 0.000358\n",
      " Epoch 55: Train Loss: 0.000273, Validation Loss: 0.000336\n",
      " Epoch 56: Train Loss: 0.000257, Validation Loss: 0.000345\n",
      " Epoch 57: Train Loss: 0.000259, Validation Loss: 0.000335\n",
      " Epoch 58: Train Loss: 0.000258, Validation Loss: 0.000324\n",
      " Epoch 59: Train Loss: 0.000252, Validation Loss: 0.000330\n",
      " Epoch 60: Train Loss: 0.000248, Validation Loss: 0.000318\n",
      " Epoch 61: Train Loss: 0.000240, Validation Loss: 0.000315\n",
      " Epoch 62: Train Loss: 0.000237, Validation Loss: 0.000323\n",
      " Epoch 63: Train Loss: 0.000239, Validation Loss: 0.000327\n",
      " Epoch 64: Train Loss: 0.000236, Validation Loss: 0.000316\n",
      " Epoch 65: Train Loss: 0.000234, Validation Loss: 0.000316\n",
      " Epoch 66: Train Loss: 0.000232, Validation Loss: 0.000316\n",
      " Epoch 67: Train Loss: 0.000232, Validation Loss: 0.000321\n",
      " Epoch 68: Train Loss: 0.000231, Validation Loss: 0.000318\n",
      " Epoch 69: Train Loss: 0.000231, Validation Loss: 0.000316\n",
      " Epoch 70: Train Loss: 0.000228, Validation Loss: 0.000324\n",
      " Epoch 71: Train Loss: 0.000228, Validation Loss: 0.000319\n",
      " Epoch 72: Train Loss: 0.000234, Validation Loss: 0.000327\n",
      " Epoch 73: Train Loss: 0.000228, Validation Loss: 0.000318\n",
      " Epoch 74: Train Loss: 0.000227, Validation Loss: 0.000320\n",
      " Epoch 75: Train Loss: 0.000227, Validation Loss: 0.000317\n",
      " Epoch 76: Train Loss: 0.000223, Validation Loss: 0.000322\n",
      " Epoch 77: Train Loss: 0.000225, Validation Loss: 0.000322\n",
      " Epoch 78: Train Loss: 0.000219, Validation Loss: 0.000319\n",
      " Epoch 79: Train Loss: 0.000219, Validation Loss: 0.000322\n",
      " Epoch 80: Train Loss: 0.000218, Validation Loss: 0.000343\n",
      " Epoch 81: Train Loss: 0.000217, Validation Loss: 0.000323\n",
      "Early stopping at epoch 81 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNNwithSEBlock_3\n",
      "Validation Loss: 0.00030119685106910765\n",
      "Training Time: 1837.1401019096375\n",
      "--------------------------------------------------\n",
      "Model: CNN3D_3\n",
      "Validation Loss: 0.00027484423480927944\n",
      "Training Time: 2601.5242557525635\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D_3\n",
      "Validation Loss: 0.00027532302192412317\n",
      "Training Time: 2502.7131967544556\n",
      "--------------------------------------------------\n",
      "Model: CNN_4\n",
      "Validation Loss: 0.00028987787663936615\n",
      "Training Time: 4397.101560115814\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock_4\n",
      "Validation Loss: 0.0003040801384486258\n",
      "Training Time: 3659.6132822036743\n",
      "--------------------------------------------------\n",
      "Model: CNN3D_4\n",
      "Validation Loss: 0.0003099725872743875\n",
      "Training Time: 2307.829960346222\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D_4\n",
      "Validation Loss: 0.00031491005211137235\n",
      "Training Time: 2373.522910118103\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from model_CNN import CNN_1, CNNwithSEBlock_1, CNN3D_1, CNNwithSEBlock3D_1,CNN_2, CNNwithSEBlock_2, CNN3D_2, CNNwithSEBlock3D_2,CNN_3, CNNwithSEBlock_3, CNN3D_3, CNNwithSEBlock3D_3,CNN_4, CNNwithSEBlock_4, CNN3D_4, CNNwithSEBlock3D_4\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, WeightedMSELoss\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "model_dict = {\n",
    "    # 'CNN_1': CNN_1,\n",
    "    # 'CNNwithSEBlock_1': CNNwithSEBlock_1,\n",
    "    # 'CNN3D_1': CNN3D_1,\n",
    "    # 'CNNwithSEBlock3D_1': CNNwithSEBlock3D_1,\n",
    "    # 'CNN_2': CNN_2,\n",
    "    # 'CNNwithSEBlock_2': CNNwithSEBlock_2,\n",
    "    # 'CNN3D_2': CNN3D_2,\n",
    "    # 'CNNwithSEBlock3D_2': CNNwithSEBlock3D_2,\n",
    "    # 'CNN_3': CNN_3,\n",
    "    'CNNwithSEBlock_3': CNNwithSEBlock_3,\n",
    "    'CNN3D_3': CNN3D_3,\n",
    "    'CNNwithSEBlock3D_3': CNNwithSEBlock3D_3,\n",
    "    'CNN_4': CNN_4,\n",
    "    'CNNwithSEBlock_4': CNNwithSEBlock_4,\n",
    "    'CNN3D_4': CNN3D_4,\n",
    "    'CNNwithSEBlock3D_4': CNNwithSEBlock3D_4,\n",
    "}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = WeightedMSELoss()\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/CNN/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95739da1-c2de-49cd-9d79-c44655f479b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.048260, Validation Loss: 0.009730\n",
      " Epoch 2: Train Loss: 0.013208, Validation Loss: 0.007903\n",
      " Epoch 3: Train Loss: 0.008348, Validation Loss: 0.005607\n",
      " Epoch 4: Train Loss: 0.006828, Validation Loss: 0.004442\n",
      " Epoch 5: Train Loss: 0.005813, Validation Loss: 0.003504\n",
      " Epoch 6: Train Loss: 0.005070, Validation Loss: 0.002872\n",
      " Epoch 7: Train Loss: 0.004547, Validation Loss: 0.002397\n",
      " Epoch 8: Train Loss: 0.004172, Validation Loss: 0.002126\n",
      " Epoch 9: Train Loss: 0.003901, Validation Loss: 0.001946\n",
      " Epoch 10: Train Loss: 0.003689, Validation Loss: 0.001810\n",
      " Epoch 11: Train Loss: 0.003524, Validation Loss: 0.001701\n",
      " Epoch 12: Train Loss: 0.003386, Validation Loss: 0.001618\n",
      " Epoch 13: Train Loss: 0.003269, Validation Loss: 0.001557\n",
      " Epoch 14: Train Loss: 0.003170, Validation Loss: 0.001515\n",
      " Epoch 15: Train Loss: 0.003077, Validation Loss: 0.001492\n",
      " Epoch 16: Train Loss: 0.002993, Validation Loss: 0.001458\n",
      " Epoch 17: Train Loss: 0.002912, Validation Loss: 0.001440\n",
      " Epoch 18: Train Loss: 0.002828, Validation Loss: 0.001436\n",
      " Epoch 19: Train Loss: 0.002748, Validation Loss: 0.001474\n",
      " Epoch 20: Train Loss: 0.002669, Validation Loss: 0.001507\n",
      " Epoch 21: Train Loss: 0.002600, Validation Loss: 0.001512\n",
      " Epoch 22: Train Loss: 0.002540, Validation Loss: 0.001526\n",
      " Epoch 23: Train Loss: 0.002482, Validation Loss: 0.001493\n",
      " Epoch 24: Train Loss: 0.002430, Validation Loss: 0.001459\n",
      " Epoch 25: Train Loss: 0.002380, Validation Loss: 0.001466\n",
      " Epoch 26: Train Loss: 0.002324, Validation Loss: 0.001427\n",
      " Epoch 27: Train Loss: 0.002281, Validation Loss: 0.001433\n",
      " Epoch 28: Train Loss: 0.002250, Validation Loss: 0.001431\n",
      " Epoch 29: Train Loss: 0.002222, Validation Loss: 0.001411\n",
      " Epoch 30: Train Loss: 0.002196, Validation Loss: 0.001419\n",
      " Epoch 31: Train Loss: 0.002180, Validation Loss: 0.001415\n",
      " Epoch 32: Train Loss: 0.002170, Validation Loss: 0.001429\n",
      " Epoch 33: Train Loss: 0.002160, Validation Loss: 0.001429\n",
      " Epoch 34: Train Loss: 0.002149, Validation Loss: 0.001418\n",
      " Epoch 35: Train Loss: 0.002141, Validation Loss: 0.001404\n",
      " Epoch 36: Train Loss: 0.002135, Validation Loss: 0.001431\n",
      " Epoch 37: Train Loss: 0.002124, Validation Loss: 0.001413\n",
      " Epoch 38: Train Loss: 0.002114, Validation Loss: 0.001412\n",
      " Epoch 39: Train Loss: 0.002108, Validation Loss: 0.001419\n",
      " Epoch 40: Train Loss: 0.002099, Validation Loss: 0.001414\n",
      " Epoch 41: Train Loss: 0.002089, Validation Loss: 0.001418\n",
      " Epoch 42: Train Loss: 0.002081, Validation Loss: 0.001440\n",
      " Epoch 43: Train Loss: 0.002072, Validation Loss: 0.001422\n",
      " Epoch 44: Train Loss: 0.002065, Validation Loss: 0.001423\n",
      " Epoch 45: Train Loss: 0.002055, Validation Loss: 0.001423\n",
      " Epoch 46: Train Loss: 0.002046, Validation Loss: 0.001430\n",
      " Epoch 47: Train Loss: 0.002039, Validation Loss: 0.001421\n",
      " Epoch 48: Train Loss: 0.002030, Validation Loss: 0.001418\n",
      " Epoch 49: Train Loss: 0.002017, Validation Loss: 0.001385\n",
      " Epoch 50: Train Loss: 0.002010, Validation Loss: 0.001444\n",
      " Epoch 51: Train Loss: 0.002002, Validation Loss: 0.001410\n",
      " Epoch 52: Train Loss: 0.001996, Validation Loss: 0.001412\n",
      " Epoch 53: Train Loss: 0.001989, Validation Loss: 0.001413\n",
      " Epoch 54: Train Loss: 0.001982, Validation Loss: 0.001429\n",
      " Epoch 55: Train Loss: 0.001975, Validation Loss: 0.001441\n",
      " Epoch 56: Train Loss: 0.001968, Validation Loss: 0.001421\n",
      " Epoch 57: Train Loss: 0.001962, Validation Loss: 0.001427\n",
      " Epoch 58: Train Loss: 0.001955, Validation Loss: 0.001417\n",
      " Epoch 59: Train Loss: 0.001951, Validation Loss: 0.001435\n",
      " Epoch 60: Train Loss: 0.001946, Validation Loss: 0.001432\n",
      " Epoch 61: Train Loss: 0.001939, Validation Loss: 0.001439\n",
      " Epoch 62: Train Loss: 0.001940, Validation Loss: 0.001435\n",
      " Epoch 63: Train Loss: 0.001934, Validation Loss: 0.001427\n",
      " Epoch 64: Train Loss: 0.001933, Validation Loss: 0.001436\n",
      " Epoch 65: Train Loss: 0.001928, Validation Loss: 0.001431\n",
      " Epoch 66: Train Loss: 0.001928, Validation Loss: 0.001434\n",
      " Epoch 67: Train Loss: 0.001925, Validation Loss: 0.001445\n",
      " Epoch 68: Train Loss: 0.001922, Validation Loss: 0.001445\n",
      " Epoch 69: Train Loss: 0.001918, Validation Loss: 0.001452\n",
      "Early stopping at epoch 69 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.045641, Validation Loss: 0.009330\n",
      " Epoch 2: Train Loss: 0.013198, Validation Loss: 0.007268\n",
      " Epoch 3: Train Loss: 0.008226, Validation Loss: 0.005282\n",
      " Epoch 4: Train Loss: 0.006443, Validation Loss: 0.003848\n",
      " Epoch 5: Train Loss: 0.005414, Validation Loss: 0.003021\n",
      " Epoch 6: Train Loss: 0.004696, Validation Loss: 0.002470\n",
      " Epoch 7: Train Loss: 0.004218, Validation Loss: 0.002166\n",
      " Epoch 8: Train Loss: 0.003889, Validation Loss: 0.001983\n",
      " Epoch 9: Train Loss: 0.003635, Validation Loss: 0.001892\n",
      " Epoch 10: Train Loss: 0.003434, Validation Loss: 0.001873\n",
      " Epoch 11: Train Loss: 0.003266, Validation Loss: 0.001885\n",
      " Epoch 12: Train Loss: 0.003123, Validation Loss: 0.001858\n",
      " Epoch 13: Train Loss: 0.002993, Validation Loss: 0.001860\n",
      " Epoch 14: Train Loss: 0.002888, Validation Loss: 0.001777\n",
      " Epoch 15: Train Loss: 0.002794, Validation Loss: 0.001749\n",
      " Epoch 16: Train Loss: 0.002708, Validation Loss: 0.001733\n",
      " Epoch 17: Train Loss: 0.002633, Validation Loss: 0.001733\n",
      " Epoch 18: Train Loss: 0.002562, Validation Loss: 0.001694\n",
      " Epoch 19: Train Loss: 0.002508, Validation Loss: 0.001666\n",
      " Epoch 20: Train Loss: 0.002455, Validation Loss: 0.001600\n",
      " Epoch 21: Train Loss: 0.002406, Validation Loss: 0.001518\n",
      " Epoch 22: Train Loss: 0.002360, Validation Loss: 0.001512\n",
      " Epoch 23: Train Loss: 0.002319, Validation Loss: 0.001514\n",
      " Epoch 24: Train Loss: 0.002285, Validation Loss: 0.001526\n",
      " Epoch 25: Train Loss: 0.002254, Validation Loss: 0.001570\n",
      " Epoch 26: Train Loss: 0.002227, Validation Loss: 0.001589\n",
      " Epoch 27: Train Loss: 0.002198, Validation Loss: 0.001590\n",
      " Epoch 28: Train Loss: 0.002170, Validation Loss: 0.001595\n",
      " Epoch 29: Train Loss: 0.002149, Validation Loss: 0.001608\n",
      " Epoch 30: Train Loss: 0.002120, Validation Loss: 0.001653\n",
      " Epoch 31: Train Loss: 0.002101, Validation Loss: 0.001615\n",
      " Epoch 32: Train Loss: 0.002090, Validation Loss: 0.001607\n",
      " Epoch 33: Train Loss: 0.002078, Validation Loss: 0.001593\n",
      " Epoch 34: Train Loss: 0.002068, Validation Loss: 0.001561\n",
      " Epoch 35: Train Loss: 0.002059, Validation Loss: 0.001566\n",
      " Epoch 36: Train Loss: 0.002049, Validation Loss: 0.001578\n",
      " Epoch 37: Train Loss: 0.002042, Validation Loss: 0.001579\n",
      " Epoch 38: Train Loss: 0.002032, Validation Loss: 0.001580\n",
      " Epoch 39: Train Loss: 0.002023, Validation Loss: 0.001600\n",
      " Epoch 40: Train Loss: 0.002016, Validation Loss: 0.001570\n",
      " Epoch 41: Train Loss: 0.002008, Validation Loss: 0.001565\n",
      " Epoch 42: Train Loss: 0.002003, Validation Loss: 0.001588\n",
      "Early stopping at epoch 42 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.087132, Validation Loss: 0.039526\n",
      " Epoch 2: Train Loss: 0.022189, Validation Loss: 0.012307\n",
      " Epoch 3: Train Loss: 0.011832, Validation Loss: 0.008336\n",
      " Epoch 4: Train Loss: 0.008656, Validation Loss: 0.005918\n",
      " Epoch 5: Train Loss: 0.007117, Validation Loss: 0.004601\n",
      " Epoch 6: Train Loss: 0.006159, Validation Loss: 0.003734\n",
      " Epoch 7: Train Loss: 0.005477, Validation Loss: 0.003139\n",
      " Epoch 8: Train Loss: 0.004975, Validation Loss: 0.002745\n",
      " Epoch 9: Train Loss: 0.004593, Validation Loss: 0.002423\n",
      " Epoch 10: Train Loss: 0.004288, Validation Loss: 0.002219\n",
      " Epoch 11: Train Loss: 0.004038, Validation Loss: 0.002026\n",
      " Epoch 12: Train Loss: 0.003832, Validation Loss: 0.001895\n",
      " Epoch 13: Train Loss: 0.003661, Validation Loss: 0.001831\n",
      " Epoch 14: Train Loss: 0.003519, Validation Loss: 0.001761\n",
      " Epoch 15: Train Loss: 0.003397, Validation Loss: 0.001686\n",
      " Epoch 16: Train Loss: 0.003290, Validation Loss: 0.001638\n",
      " Epoch 17: Train Loss: 0.003198, Validation Loss: 0.001649\n",
      " Epoch 18: Train Loss: 0.003109, Validation Loss: 0.001565\n",
      " Epoch 19: Train Loss: 0.003029, Validation Loss: 0.001538\n",
      " Epoch 20: Train Loss: 0.002960, Validation Loss: 0.001616\n",
      " Epoch 21: Train Loss: 0.002892, Validation Loss: 0.001493\n",
      " Epoch 22: Train Loss: 0.002828, Validation Loss: 0.001436\n",
      " Epoch 23: Train Loss: 0.002772, Validation Loss: 0.001390\n",
      " Epoch 24: Train Loss: 0.002712, Validation Loss: 0.001352\n",
      " Epoch 25: Train Loss: 0.002656, Validation Loss: 0.001362\n",
      " Epoch 26: Train Loss: 0.002609, Validation Loss: 0.001337\n",
      " Epoch 27: Train Loss: 0.002566, Validation Loss: 0.001333\n",
      " Epoch 28: Train Loss: 0.002530, Validation Loss: 0.001324\n",
      " Epoch 29: Train Loss: 0.002494, Validation Loss: 0.001308\n",
      " Epoch 30: Train Loss: 0.002465, Validation Loss: 0.001298\n",
      " Epoch 31: Train Loss: 0.002445, Validation Loss: 0.001299\n",
      " Epoch 32: Train Loss: 0.002429, Validation Loss: 0.001294\n",
      " Epoch 33: Train Loss: 0.002416, Validation Loss: 0.001288\n",
      " Epoch 34: Train Loss: 0.002400, Validation Loss: 0.001287\n",
      " Epoch 35: Train Loss: 0.002390, Validation Loss: 0.001284\n",
      " Epoch 36: Train Loss: 0.002380, Validation Loss: 0.001278\n",
      " Epoch 37: Train Loss: 0.002364, Validation Loss: 0.001271\n",
      " Epoch 38: Train Loss: 0.002356, Validation Loss: 0.001268\n",
      " Epoch 39: Train Loss: 0.002344, Validation Loss: 0.001275\n",
      " Epoch 40: Train Loss: 0.002333, Validation Loss: 0.001270\n",
      " Epoch 41: Train Loss: 0.002325, Validation Loss: 0.001260\n",
      " Epoch 42: Train Loss: 0.002311, Validation Loss: 0.001264\n",
      " Epoch 43: Train Loss: 0.002301, Validation Loss: 0.001267\n",
      " Epoch 44: Train Loss: 0.002292, Validation Loss: 0.001257\n",
      " Epoch 45: Train Loss: 0.002283, Validation Loss: 0.001258\n",
      " Epoch 46: Train Loss: 0.002273, Validation Loss: 0.001260\n",
      " Epoch 47: Train Loss: 0.002260, Validation Loss: 0.001247\n",
      " Epoch 48: Train Loss: 0.002254, Validation Loss: 0.001256\n",
      " Epoch 49: Train Loss: 0.002242, Validation Loss: 0.001254\n",
      " Epoch 50: Train Loss: 0.002235, Validation Loss: 0.001247\n",
      " Epoch 51: Train Loss: 0.002226, Validation Loss: 0.001247\n",
      " Epoch 52: Train Loss: 0.002211, Validation Loss: 0.001235\n",
      " Epoch 53: Train Loss: 0.002203, Validation Loss: 0.001245\n",
      " Epoch 54: Train Loss: 0.002192, Validation Loss: 0.001240\n",
      " Epoch 55: Train Loss: 0.002185, Validation Loss: 0.001227\n",
      " Epoch 56: Train Loss: 0.002177, Validation Loss: 0.001248\n",
      " Epoch 57: Train Loss: 0.002167, Validation Loss: 0.001247\n",
      " Epoch 58: Train Loss: 0.002158, Validation Loss: 0.001224\n",
      " Epoch 59: Train Loss: 0.002146, Validation Loss: 0.001239\n",
      " Epoch 60: Train Loss: 0.002144, Validation Loss: 0.001253\n",
      " Epoch 61: Train Loss: 0.002137, Validation Loss: 0.001249\n",
      " Epoch 62: Train Loss: 0.002132, Validation Loss: 0.001264\n",
      " Epoch 63: Train Loss: 0.002131, Validation Loss: 0.001243\n",
      " Epoch 64: Train Loss: 0.002128, Validation Loss: 0.001260\n",
      " Epoch 65: Train Loss: 0.002122, Validation Loss: 0.001259\n",
      " Epoch 66: Train Loss: 0.002116, Validation Loss: 0.001252\n",
      " Epoch 67: Train Loss: 0.002116, Validation Loss: 0.001257\n",
      " Epoch 68: Train Loss: 0.002109, Validation Loss: 0.001279\n",
      " Epoch 69: Train Loss: 0.002104, Validation Loss: 0.001277\n",
      " Epoch 70: Train Loss: 0.002100, Validation Loss: 0.001272\n",
      " Epoch 71: Train Loss: 0.002096, Validation Loss: 0.001290\n",
      " Epoch 72: Train Loss: 0.002094, Validation Loss: 0.001312\n",
      " Epoch 73: Train Loss: 0.002091, Validation Loss: 0.001273\n",
      " Epoch 74: Train Loss: 0.002084, Validation Loss: 0.001302\n",
      " Epoch 75: Train Loss: 0.002079, Validation Loss: 0.001303\n",
      " Epoch 76: Train Loss: 0.002077, Validation Loss: 0.001341\n",
      " Epoch 77: Train Loss: 0.002070, Validation Loss: 0.001338\n",
      " Epoch 78: Train Loss: 0.002070, Validation Loss: 0.001288\n",
      "Early stopping at epoch 78 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.056517, Validation Loss: 0.011323\n",
      " Epoch 2: Train Loss: 0.014412, Validation Loss: 0.007609\n",
      " Epoch 3: Train Loss: 0.008414, Validation Loss: 0.004835\n",
      " Epoch 4: Train Loss: 0.006273, Validation Loss: 0.003368\n",
      " Epoch 5: Train Loss: 0.005067, Validation Loss: 0.002740\n",
      " Epoch 6: Train Loss: 0.004388, Validation Loss: 0.002280\n",
      " Epoch 7: Train Loss: 0.003948, Validation Loss: 0.001985\n",
      " Epoch 8: Train Loss: 0.003661, Validation Loss: 0.001786\n",
      " Epoch 9: Train Loss: 0.003443, Validation Loss: 0.001644\n",
      " Epoch 10: Train Loss: 0.003280, Validation Loss: 0.001572\n",
      " Epoch 11: Train Loss: 0.003148, Validation Loss: 0.001519\n",
      " Epoch 12: Train Loss: 0.003042, Validation Loss: 0.001453\n",
      " Epoch 13: Train Loss: 0.002943, Validation Loss: 0.001439\n",
      " Epoch 14: Train Loss: 0.002853, Validation Loss: 0.001421\n",
      " Epoch 15: Train Loss: 0.002771, Validation Loss: 0.001406\n",
      " Epoch 16: Train Loss: 0.002690, Validation Loss: 0.001399\n",
      " Epoch 17: Train Loss: 0.002602, Validation Loss: 0.001385\n",
      " Epoch 18: Train Loss: 0.002522, Validation Loss: 0.001420\n",
      " Epoch 19: Train Loss: 0.002451, Validation Loss: 0.001403\n",
      " Epoch 20: Train Loss: 0.002394, Validation Loss: 0.001394\n",
      " Epoch 21: Train Loss: 0.002343, Validation Loss: 0.001373\n",
      " Epoch 22: Train Loss: 0.002293, Validation Loss: 0.001427\n",
      " Epoch 23: Train Loss: 0.002247, Validation Loss: 0.001363\n",
      " Epoch 24: Train Loss: 0.002203, Validation Loss: 0.001313\n",
      " Epoch 25: Train Loss: 0.002165, Validation Loss: 0.001299\n",
      " Epoch 26: Train Loss: 0.002125, Validation Loss: 0.001291\n",
      " Epoch 27: Train Loss: 0.002093, Validation Loss: 0.001271\n",
      " Epoch 28: Train Loss: 0.002064, Validation Loss: 0.001251\n",
      " Epoch 29: Train Loss: 0.002042, Validation Loss: 0.001294\n",
      " Epoch 30: Train Loss: 0.002016, Validation Loss: 0.001290\n",
      " Epoch 31: Train Loss: 0.001999, Validation Loss: 0.001288\n",
      " Epoch 32: Train Loss: 0.001984, Validation Loss: 0.001316\n",
      " Epoch 33: Train Loss: 0.001976, Validation Loss: 0.001292\n",
      " Epoch 34: Train Loss: 0.001967, Validation Loss: 0.001315\n",
      " Epoch 35: Train Loss: 0.001955, Validation Loss: 0.001313\n",
      " Epoch 36: Train Loss: 0.001946, Validation Loss: 0.001295\n",
      " Epoch 37: Train Loss: 0.001938, Validation Loss: 0.001271\n",
      " Epoch 38: Train Loss: 0.001927, Validation Loss: 0.001303\n",
      " Epoch 39: Train Loss: 0.001918, Validation Loss: 0.001316\n",
      " Epoch 40: Train Loss: 0.001910, Validation Loss: 0.001301\n",
      " Epoch 41: Train Loss: 0.001902, Validation Loss: 0.001298\n",
      " Epoch 42: Train Loss: 0.001892, Validation Loss: 0.001305\n",
      " Epoch 43: Train Loss: 0.001886, Validation Loss: 0.001283\n",
      " Epoch 44: Train Loss: 0.001878, Validation Loss: 0.001312\n",
      " Epoch 45: Train Loss: 0.001870, Validation Loss: 0.001310\n",
      " Epoch 46: Train Loss: 0.001864, Validation Loss: 0.001328\n",
      " Epoch 47: Train Loss: 0.001857, Validation Loss: 0.001287\n",
      " Epoch 48: Train Loss: 0.001851, Validation Loss: 0.001363\n",
      "Early stopping at epoch 48 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.046205, Validation Loss: 0.009845\n",
      " Epoch 2: Train Loss: 0.013440, Validation Loss: 0.008937\n",
      " Epoch 3: Train Loss: 0.007867, Validation Loss: 0.004273\n",
      " Epoch 4: Train Loss: 0.005685, Validation Loss: 0.003050\n",
      " Epoch 5: Train Loss: 0.004606, Validation Loss: 0.002425\n",
      " Epoch 6: Train Loss: 0.004004, Validation Loss: 0.001938\n",
      " Epoch 7: Train Loss: 0.003639, Validation Loss: 0.001727\n",
      " Epoch 8: Train Loss: 0.003385, Validation Loss: 0.001576\n",
      " Epoch 9: Train Loss: 0.003205, Validation Loss: 0.001498\n",
      " Epoch 10: Train Loss: 0.003072, Validation Loss: 0.001440\n",
      " Epoch 11: Train Loss: 0.002963, Validation Loss: 0.001406\n",
      " Epoch 12: Train Loss: 0.002870, Validation Loss: 0.001381\n",
      " Epoch 13: Train Loss: 0.002788, Validation Loss: 0.001366\n",
      " Epoch 14: Train Loss: 0.002715, Validation Loss: 0.001342\n",
      " Epoch 15: Train Loss: 0.002647, Validation Loss: 0.001330\n",
      " Epoch 16: Train Loss: 0.002583, Validation Loss: 0.001333\n",
      " Epoch 17: Train Loss: 0.002521, Validation Loss: 0.001324\n",
      " Epoch 18: Train Loss: 0.002466, Validation Loss: 0.001325\n",
      " Epoch 19: Train Loss: 0.002414, Validation Loss: 0.001341\n",
      " Epoch 20: Train Loss: 0.002361, Validation Loss: 0.001320\n",
      " Epoch 21: Train Loss: 0.002302, Validation Loss: 0.001449\n",
      " Epoch 22: Train Loss: 0.002247, Validation Loss: 0.001356\n",
      " Epoch 23: Train Loss: 0.002189, Validation Loss: 0.001408\n",
      " Epoch 24: Train Loss: 0.002144, Validation Loss: 0.001465\n",
      " Epoch 25: Train Loss: 0.002101, Validation Loss: 0.001477\n",
      " Epoch 26: Train Loss: 0.002075, Validation Loss: 0.001474\n",
      " Epoch 27: Train Loss: 0.002048, Validation Loss: 0.001504\n",
      " Epoch 28: Train Loss: 0.002026, Validation Loss: 0.001568\n",
      " Epoch 29: Train Loss: 0.002004, Validation Loss: 0.001442\n",
      " Epoch 30: Train Loss: 0.001985, Validation Loss: 0.001544\n",
      " Epoch 31: Train Loss: 0.001969, Validation Loss: 0.001501\n",
      " Epoch 32: Train Loss: 0.001958, Validation Loss: 0.001526\n",
      " Epoch 33: Train Loss: 0.001950, Validation Loss: 0.001529\n",
      " Epoch 34: Train Loss: 0.001940, Validation Loss: 0.001513\n",
      " Epoch 35: Train Loss: 0.001931, Validation Loss: 0.001507\n",
      " Epoch 36: Train Loss: 0.001923, Validation Loss: 0.001532\n",
      " Epoch 37: Train Loss: 0.001915, Validation Loss: 0.001517\n",
      " Epoch 38: Train Loss: 0.001902, Validation Loss: 0.001495\n",
      " Epoch 39: Train Loss: 0.001887, Validation Loss: 0.001522\n",
      " Epoch 40: Train Loss: 0.001875, Validation Loss: 0.001505\n",
      "Early stopping at epoch 40 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.068296, Validation Loss: 0.012033\n",
      " Epoch 2: Train Loss: 0.017824, Validation Loss: 0.011290\n",
      " Epoch 3: Train Loss: 0.009923, Validation Loss: 0.006182\n",
      " Epoch 4: Train Loss: 0.007159, Validation Loss: 0.003816\n",
      " Epoch 5: Train Loss: 0.005719, Validation Loss: 0.002885\n",
      " Epoch 6: Train Loss: 0.004859, Validation Loss: 0.002386\n",
      " Epoch 7: Train Loss: 0.004321, Validation Loss: 0.002108\n",
      " Epoch 8: Train Loss: 0.003951, Validation Loss: 0.001915\n",
      " Epoch 9: Train Loss: 0.003687, Validation Loss: 0.001790\n",
      " Epoch 10: Train Loss: 0.003471, Validation Loss: 0.001694\n",
      " Epoch 11: Train Loss: 0.003293, Validation Loss: 0.001624\n",
      " Epoch 12: Train Loss: 0.003141, Validation Loss: 0.001591\n",
      " Epoch 13: Train Loss: 0.003014, Validation Loss: 0.001528\n",
      " Epoch 14: Train Loss: 0.002909, Validation Loss: 0.001491\n",
      " Epoch 15: Train Loss: 0.002822, Validation Loss: 0.001459\n",
      " Epoch 16: Train Loss: 0.002746, Validation Loss: 0.001436\n",
      " Epoch 17: Train Loss: 0.002687, Validation Loss: 0.001427\n",
      " Epoch 18: Train Loss: 0.002629, Validation Loss: 0.001404\n",
      " Epoch 19: Train Loss: 0.002581, Validation Loss: 0.001385\n",
      " Epoch 20: Train Loss: 0.002540, Validation Loss: 0.001364\n",
      " Epoch 21: Train Loss: 0.002506, Validation Loss: 0.001379\n",
      " Epoch 22: Train Loss: 0.002469, Validation Loss: 0.001373\n",
      " Epoch 23: Train Loss: 0.002438, Validation Loss: 0.001357\n",
      " Epoch 24: Train Loss: 0.002405, Validation Loss: 0.001344\n",
      " Epoch 25: Train Loss: 0.002375, Validation Loss: 0.001348\n",
      " Epoch 26: Train Loss: 0.002346, Validation Loss: 0.001379\n",
      " Epoch 27: Train Loss: 0.002320, Validation Loss: 0.001359\n",
      " Epoch 28: Train Loss: 0.002292, Validation Loss: 0.001402\n",
      " Epoch 29: Train Loss: 0.002267, Validation Loss: 0.001463\n",
      " Epoch 30: Train Loss: 0.002242, Validation Loss: 0.001426\n",
      " Epoch 31: Train Loss: 0.002224, Validation Loss: 0.001384\n",
      " Epoch 32: Train Loss: 0.002212, Validation Loss: 0.001389\n",
      " Epoch 33: Train Loss: 0.002199, Validation Loss: 0.001464\n",
      " Epoch 34: Train Loss: 0.002185, Validation Loss: 0.001494\n",
      " Epoch 35: Train Loss: 0.002173, Validation Loss: 0.001310\n",
      " Epoch 36: Train Loss: 0.002159, Validation Loss: 0.001439\n",
      " Epoch 37: Train Loss: 0.002145, Validation Loss: 0.001363\n",
      " Epoch 38: Train Loss: 0.002131, Validation Loss: 0.001400\n",
      " Epoch 39: Train Loss: 0.002120, Validation Loss: 0.001367\n",
      " Epoch 40: Train Loss: 0.002108, Validation Loss: 0.001362\n",
      " Epoch 41: Train Loss: 0.002094, Validation Loss: 0.001402\n",
      " Epoch 42: Train Loss: 0.002079, Validation Loss: 0.001307\n",
      " Epoch 43: Train Loss: 0.002065, Validation Loss: 0.001365\n",
      " Epoch 44: Train Loss: 0.002052, Validation Loss: 0.001253\n",
      " Epoch 45: Train Loss: 0.002036, Validation Loss: 0.001368\n",
      " Epoch 46: Train Loss: 0.002026, Validation Loss: 0.001218\n",
      " Epoch 47: Train Loss: 0.002013, Validation Loss: 0.001367\n",
      " Epoch 48: Train Loss: 0.002002, Validation Loss: 0.001299\n",
      " Epoch 49: Train Loss: 0.001993, Validation Loss: 0.001224\n",
      " Epoch 50: Train Loss: 0.001981, Validation Loss: 0.001209\n",
      " Epoch 51: Train Loss: 0.001970, Validation Loss: 0.001201\n",
      " Epoch 52: Train Loss: 0.001958, Validation Loss: 0.001229\n",
      " Epoch 53: Train Loss: 0.001950, Validation Loss: 0.001310\n",
      " Epoch 54: Train Loss: 0.001939, Validation Loss: 0.001278\n",
      " Epoch 55: Train Loss: 0.001927, Validation Loss: 0.001163\n",
      " Epoch 56: Train Loss: 0.001917, Validation Loss: 0.001215\n",
      " Epoch 57: Train Loss: 0.001909, Validation Loss: 0.001155\n",
      " Epoch 58: Train Loss: 0.001896, Validation Loss: 0.001313\n",
      " Epoch 59: Train Loss: 0.001886, Validation Loss: 0.001215\n",
      " Epoch 60: Train Loss: 0.001875, Validation Loss: 0.001214\n",
      " Epoch 61: Train Loss: 0.001864, Validation Loss: 0.001155\n",
      " Epoch 62: Train Loss: 0.001856, Validation Loss: 0.001179\n",
      " Epoch 63: Train Loss: 0.001851, Validation Loss: 0.001173\n",
      " Epoch 64: Train Loss: 0.001847, Validation Loss: 0.001156\n",
      " Epoch 65: Train Loss: 0.001842, Validation Loss: 0.001154\n",
      " Epoch 66: Train Loss: 0.001838, Validation Loss: 0.001145\n",
      " Epoch 67: Train Loss: 0.001832, Validation Loss: 0.001167\n",
      " Epoch 68: Train Loss: 0.001826, Validation Loss: 0.001249\n",
      " Epoch 69: Train Loss: 0.001824, Validation Loss: 0.001154\n",
      " Epoch 70: Train Loss: 0.001818, Validation Loss: 0.001190\n",
      " Epoch 71: Train Loss: 0.001812, Validation Loss: 0.001189\n",
      " Epoch 72: Train Loss: 0.001808, Validation Loss: 0.001218\n",
      " Epoch 73: Train Loss: 0.001803, Validation Loss: 0.001161\n",
      " Epoch 74: Train Loss: 0.001796, Validation Loss: 0.001196\n",
      " Epoch 75: Train Loss: 0.001792, Validation Loss: 0.001277\n",
      " Epoch 76: Train Loss: 0.001788, Validation Loss: 0.001277\n",
      " Epoch 77: Train Loss: 0.001784, Validation Loss: 0.001286\n",
      " Epoch 78: Train Loss: 0.001779, Validation Loss: 0.001308\n",
      " Epoch 79: Train Loss: 0.001777, Validation Loss: 0.001194\n",
      " Epoch 80: Train Loss: 0.001773, Validation Loss: 0.001231\n",
      " Epoch 81: Train Loss: 0.001770, Validation Loss: 0.001272\n",
      " Epoch 82: Train Loss: 0.001765, Validation Loss: 0.001283\n",
      " Epoch 83: Train Loss: 0.001760, Validation Loss: 0.001284\n",
      " Epoch 84: Train Loss: 0.001755, Validation Loss: 0.001327\n",
      " Epoch 85: Train Loss: 0.001753, Validation Loss: 0.001294\n",
      " Epoch 86: Train Loss: 0.001747, Validation Loss: 0.001229\n",
      "Early stopping at epoch 86 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.055148, Validation Loss: 0.016547\n",
      " Epoch 2: Train Loss: 0.013775, Validation Loss: 0.008046\n",
      " Epoch 3: Train Loss: 0.008126, Validation Loss: 0.005050\n",
      " Epoch 4: Train Loss: 0.006233, Validation Loss: 0.003598\n",
      " Epoch 5: Train Loss: 0.005160, Validation Loss: 0.002816\n",
      " Epoch 6: Train Loss: 0.004456, Validation Loss: 0.002319\n",
      " Epoch 7: Train Loss: 0.003967, Validation Loss: 0.001991\n",
      " Epoch 8: Train Loss: 0.003626, Validation Loss: 0.001787\n",
      " Epoch 9: Train Loss: 0.003364, Validation Loss: 0.001650\n",
      " Epoch 10: Train Loss: 0.003156, Validation Loss: 0.001540\n",
      " Epoch 11: Train Loss: 0.002998, Validation Loss: 0.001457\n",
      " Epoch 12: Train Loss: 0.002861, Validation Loss: 0.001394\n",
      " Epoch 13: Train Loss: 0.002754, Validation Loss: 0.001371\n",
      " Epoch 14: Train Loss: 0.002663, Validation Loss: 0.001345\n",
      " Epoch 15: Train Loss: 0.002582, Validation Loss: 0.001336\n",
      " Epoch 16: Train Loss: 0.002507, Validation Loss: 0.001321\n",
      " Epoch 17: Train Loss: 0.002440, Validation Loss: 0.001314\n",
      " Epoch 18: Train Loss: 0.002382, Validation Loss: 0.001308\n",
      " Epoch 19: Train Loss: 0.002332, Validation Loss: 0.001311\n",
      " Epoch 20: Train Loss: 0.002280, Validation Loss: 0.001292\n",
      " Epoch 21: Train Loss: 0.002240, Validation Loss: 0.001273\n",
      " Epoch 22: Train Loss: 0.002199, Validation Loss: 0.001284\n",
      " Epoch 23: Train Loss: 0.002162, Validation Loss: 0.001277\n",
      " Epoch 24: Train Loss: 0.002133, Validation Loss: 0.001250\n",
      " Epoch 25: Train Loss: 0.002099, Validation Loss: 0.001250\n",
      " Epoch 26: Train Loss: 0.002069, Validation Loss: 0.001242\n",
      " Epoch 27: Train Loss: 0.002046, Validation Loss: 0.001262\n",
      " Epoch 28: Train Loss: 0.002017, Validation Loss: 0.001242\n",
      " Epoch 29: Train Loss: 0.001993, Validation Loss: 0.001238\n",
      " Epoch 30: Train Loss: 0.001971, Validation Loss: 0.001222\n",
      " Epoch 31: Train Loss: 0.001956, Validation Loss: 0.001243\n",
      " Epoch 32: Train Loss: 0.001946, Validation Loss: 0.001235\n",
      " Epoch 33: Train Loss: 0.001933, Validation Loss: 0.001246\n",
      " Epoch 34: Train Loss: 0.001924, Validation Loss: 0.001249\n",
      " Epoch 35: Train Loss: 0.001915, Validation Loss: 0.001248\n",
      " Epoch 36: Train Loss: 0.001907, Validation Loss: 0.001267\n",
      " Epoch 37: Train Loss: 0.001895, Validation Loss: 0.001249\n",
      " Epoch 38: Train Loss: 0.001889, Validation Loss: 0.001261\n",
      " Epoch 39: Train Loss: 0.001879, Validation Loss: 0.001295\n",
      " Epoch 40: Train Loss: 0.001868, Validation Loss: 0.001287\n",
      " Epoch 41: Train Loss: 0.001863, Validation Loss: 0.001296\n",
      " Epoch 42: Train Loss: 0.001856, Validation Loss: 0.001300\n",
      " Epoch 43: Train Loss: 0.001846, Validation Loss: 0.001316\n",
      " Epoch 44: Train Loss: 0.001838, Validation Loss: 0.001284\n",
      " Epoch 45: Train Loss: 0.001829, Validation Loss: 0.001302\n",
      " Epoch 46: Train Loss: 0.001822, Validation Loss: 0.001311\n",
      " Epoch 47: Train Loss: 0.001817, Validation Loss: 0.001291\n",
      " Epoch 48: Train Loss: 0.001809, Validation Loss: 0.001297\n",
      " Epoch 49: Train Loss: 0.001803, Validation Loss: 0.001302\n",
      " Epoch 50: Train Loss: 0.001794, Validation Loss: 0.001347\n",
      "Early stopping at epoch 50 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.044270, Validation Loss: 0.013111\n",
      " Epoch 2: Train Loss: 0.011687, Validation Loss: 0.006765\n",
      " Epoch 3: Train Loss: 0.007685, Validation Loss: 0.004788\n",
      " Epoch 4: Train Loss: 0.006215, Validation Loss: 0.003628\n",
      " Epoch 5: Train Loss: 0.005226, Validation Loss: 0.002860\n",
      " Epoch 6: Train Loss: 0.004528, Validation Loss: 0.002365\n",
      " Epoch 7: Train Loss: 0.004046, Validation Loss: 0.002024\n",
      " Epoch 8: Train Loss: 0.003692, Validation Loss: 0.001814\n",
      " Epoch 9: Train Loss: 0.003432, Validation Loss: 0.001666\n",
      " Epoch 10: Train Loss: 0.003213, Validation Loss: 0.001587\n",
      " Epoch 11: Train Loss: 0.002988, Validation Loss: 0.001493\n",
      " Epoch 12: Train Loss: 0.002805, Validation Loss: 0.001413\n",
      " Epoch 13: Train Loss: 0.002662, Validation Loss: 0.001354\n",
      " Epoch 14: Train Loss: 0.002552, Validation Loss: 0.001318\n",
      " Epoch 15: Train Loss: 0.002467, Validation Loss: 0.001281\n",
      " Epoch 16: Train Loss: 0.002397, Validation Loss: 0.001264\n",
      " Epoch 17: Train Loss: 0.002340, Validation Loss: 0.001257\n",
      " Epoch 18: Train Loss: 0.002283, Validation Loss: 0.001256\n",
      " Epoch 19: Train Loss: 0.002230, Validation Loss: 0.001263\n",
      " Epoch 20: Train Loss: 0.002185, Validation Loss: 0.001275\n",
      " Epoch 21: Train Loss: 0.002145, Validation Loss: 0.001294\n",
      " Epoch 22: Train Loss: 0.002109, Validation Loss: 0.001315\n",
      " Epoch 23: Train Loss: 0.002078, Validation Loss: 0.001352\n",
      " Epoch 24: Train Loss: 0.002046, Validation Loss: 0.001352\n",
      " Epoch 25: Train Loss: 0.002017, Validation Loss: 0.001374\n",
      " Epoch 26: Train Loss: 0.001989, Validation Loss: 0.001403\n",
      " Epoch 27: Train Loss: 0.001964, Validation Loss: 0.001433\n",
      " Epoch 28: Train Loss: 0.001940, Validation Loss: 0.001455\n",
      " Epoch 29: Train Loss: 0.001911, Validation Loss: 0.001476\n",
      " Epoch 30: Train Loss: 0.001888, Validation Loss: 0.001473\n",
      " Epoch 31: Train Loss: 0.001870, Validation Loss: 0.001496\n",
      " Epoch 32: Train Loss: 0.001857, Validation Loss: 0.001477\n",
      " Epoch 33: Train Loss: 0.001848, Validation Loss: 0.001512\n",
      " Epoch 34: Train Loss: 0.001839, Validation Loss: 0.001543\n",
      " Epoch 35: Train Loss: 0.001825, Validation Loss: 0.001521\n",
      " Epoch 36: Train Loss: 0.001816, Validation Loss: 0.001559\n",
      " Epoch 37: Train Loss: 0.001805, Validation Loss: 0.001562\n",
      " Epoch 38: Train Loss: 0.001788, Validation Loss: 0.001550\n",
      "Early stopping at epoch 38 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.030622, Validation Loss: 0.008554\n",
      " Epoch 2: Train Loss: 0.008664, Validation Loss: 0.006438\n",
      " Epoch 3: Train Loss: 0.006233, Validation Loss: 0.003924\n",
      " Epoch 4: Train Loss: 0.005060, Validation Loss: 0.003045\n",
      " Epoch 5: Train Loss: 0.004313, Validation Loss: 0.002398\n",
      " Epoch 6: Train Loss: 0.003832, Validation Loss: 0.002037\n",
      " Epoch 7: Train Loss: 0.003524, Validation Loss: 0.001795\n",
      " Epoch 8: Train Loss: 0.003296, Validation Loss: 0.001642\n",
      " Epoch 9: Train Loss: 0.003123, Validation Loss: 0.001538\n",
      " Epoch 10: Train Loss: 0.002960, Validation Loss: 0.001471\n",
      " Epoch 11: Train Loss: 0.002827, Validation Loss: 0.001432\n",
      " Epoch 12: Train Loss: 0.002702, Validation Loss: 0.001399\n",
      " Epoch 13: Train Loss: 0.002596, Validation Loss: 0.001358\n",
      " Epoch 14: Train Loss: 0.002495, Validation Loss: 0.001361\n",
      " Epoch 15: Train Loss: 0.002404, Validation Loss: 0.001337\n",
      " Epoch 16: Train Loss: 0.002326, Validation Loss: 0.001303\n",
      " Epoch 17: Train Loss: 0.002259, Validation Loss: 0.001275\n",
      " Epoch 18: Train Loss: 0.002200, Validation Loss: 0.001271\n",
      " Epoch 19: Train Loss: 0.002149, Validation Loss: 0.001212\n",
      " Epoch 20: Train Loss: 0.002104, Validation Loss: 0.001208\n",
      " Epoch 21: Train Loss: 0.002063, Validation Loss: 0.001200\n",
      " Epoch 22: Train Loss: 0.002023, Validation Loss: 0.001197\n",
      " Epoch 23: Train Loss: 0.001986, Validation Loss: 0.001197\n",
      " Epoch 24: Train Loss: 0.001950, Validation Loss: 0.001162\n",
      " Epoch 25: Train Loss: 0.001920, Validation Loss: 0.001188\n",
      " Epoch 26: Train Loss: 0.001891, Validation Loss: 0.001141\n",
      " Epoch 27: Train Loss: 0.001863, Validation Loss: 0.001163\n",
      " Epoch 28: Train Loss: 0.001839, Validation Loss: 0.001171\n",
      " Epoch 29: Train Loss: 0.001818, Validation Loss: 0.001169\n",
      " Epoch 30: Train Loss: 0.001799, Validation Loss: 0.001202\n",
      " Epoch 31: Train Loss: 0.001779, Validation Loss: 0.001177\n",
      " Epoch 32: Train Loss: 0.001769, Validation Loss: 0.001194\n",
      " Epoch 33: Train Loss: 0.001758, Validation Loss: 0.001221\n",
      " Epoch 34: Train Loss: 0.001752, Validation Loss: 0.001204\n",
      " Epoch 35: Train Loss: 0.001740, Validation Loss: 0.001244\n",
      " Epoch 36: Train Loss: 0.001729, Validation Loss: 0.001181\n",
      " Epoch 37: Train Loss: 0.001725, Validation Loss: 0.001196\n",
      " Epoch 38: Train Loss: 0.001716, Validation Loss: 0.001196\n",
      " Epoch 39: Train Loss: 0.001708, Validation Loss: 0.001227\n",
      " Epoch 40: Train Loss: 0.001698, Validation Loss: 0.001198\n",
      " Epoch 41: Train Loss: 0.001693, Validation Loss: 0.001204\n",
      " Epoch 42: Train Loss: 0.001685, Validation Loss: 0.001207\n",
      " Epoch 43: Train Loss: 0.001675, Validation Loss: 0.001246\n",
      " Epoch 44: Train Loss: 0.001670, Validation Loss: 0.001295\n",
      " Epoch 45: Train Loss: 0.001661, Validation Loss: 0.001241\n",
      " Epoch 46: Train Loss: 0.001655, Validation Loss: 0.001215\n",
      "Early stopping at epoch 46 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.052628, Validation Loss: 0.011667\n",
      " Epoch 2: Train Loss: 0.013742, Validation Loss: 0.007300\n",
      " Epoch 3: Train Loss: 0.007647, Validation Loss: 0.004280\n",
      " Epoch 4: Train Loss: 0.005603, Validation Loss: 0.002934\n",
      " Epoch 5: Train Loss: 0.004520, Validation Loss: 0.002289\n",
      " Epoch 6: Train Loss: 0.003888, Validation Loss: 0.001888\n",
      " Epoch 7: Train Loss: 0.003507, Validation Loss: 0.001659\n",
      " Epoch 8: Train Loss: 0.003256, Validation Loss: 0.001524\n",
      " Epoch 9: Train Loss: 0.003069, Validation Loss: 0.001443\n",
      " Epoch 10: Train Loss: 0.002910, Validation Loss: 0.001402\n",
      " Epoch 11: Train Loss: 0.002759, Validation Loss: 0.001367\n",
      " Epoch 12: Train Loss: 0.002634, Validation Loss: 0.001364\n",
      " Epoch 13: Train Loss: 0.002530, Validation Loss: 0.001270\n",
      " Epoch 14: Train Loss: 0.002439, Validation Loss: 0.001248\n",
      " Epoch 15: Train Loss: 0.002362, Validation Loss: 0.001245\n",
      " Epoch 16: Train Loss: 0.002297, Validation Loss: 0.001240\n",
      " Epoch 17: Train Loss: 0.002242, Validation Loss: 0.001232\n",
      " Epoch 18: Train Loss: 0.002198, Validation Loss: 0.001259\n",
      " Epoch 19: Train Loss: 0.002151, Validation Loss: 0.001292\n",
      " Epoch 20: Train Loss: 0.002111, Validation Loss: 0.001339\n",
      " Epoch 21: Train Loss: 0.002072, Validation Loss: 0.001348\n",
      " Epoch 22: Train Loss: 0.002037, Validation Loss: 0.001455\n",
      " Epoch 23: Train Loss: 0.002005, Validation Loss: 0.001492\n",
      " Epoch 24: Train Loss: 0.001976, Validation Loss: 0.001534\n",
      " Epoch 25: Train Loss: 0.001947, Validation Loss: 0.001457\n",
      " Epoch 26: Train Loss: 0.001919, Validation Loss: 0.001524\n",
      " Epoch 27: Train Loss: 0.001892, Validation Loss: 0.001548\n",
      " Epoch 28: Train Loss: 0.001867, Validation Loss: 0.001585\n",
      " Epoch 29: Train Loss: 0.001844, Validation Loss: 0.001595\n",
      " Epoch 30: Train Loss: 0.001819, Validation Loss: 0.001708\n",
      " Epoch 31: Train Loss: 0.001800, Validation Loss: 0.001577\n",
      " Epoch 32: Train Loss: 0.001786, Validation Loss: 0.001627\n",
      " Epoch 33: Train Loss: 0.001775, Validation Loss: 0.001665\n",
      " Epoch 34: Train Loss: 0.001765, Validation Loss: 0.001637\n",
      " Epoch 35: Train Loss: 0.001754, Validation Loss: 0.001612\n",
      " Epoch 36: Train Loss: 0.001742, Validation Loss: 0.001664\n",
      " Epoch 37: Train Loss: 0.001731, Validation Loss: 0.001576\n",
      "Early stopping at epoch 37 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.041071, Validation Loss: 0.013878\n",
      " Epoch 2: Train Loss: 0.011322, Validation Loss: 0.005852\n",
      " Epoch 3: Train Loss: 0.006654, Validation Loss: 0.003401\n",
      " Epoch 4: Train Loss: 0.004913, Validation Loss: 0.002665\n",
      " Epoch 5: Train Loss: 0.004039, Validation Loss: 0.002050\n",
      " Epoch 6: Train Loss: 0.003539, Validation Loss: 0.001739\n",
      " Epoch 7: Train Loss: 0.003217, Validation Loss: 0.001575\n",
      " Epoch 8: Train Loss: 0.002990, Validation Loss: 0.001451\n",
      " Epoch 9: Train Loss: 0.002825, Validation Loss: 0.001389\n",
      " Epoch 10: Train Loss: 0.002694, Validation Loss: 0.001326\n",
      " Epoch 11: Train Loss: 0.002585, Validation Loss: 0.001288\n",
      " Epoch 12: Train Loss: 0.002487, Validation Loss: 0.001273\n",
      " Epoch 13: Train Loss: 0.002400, Validation Loss: 0.001222\n",
      " Epoch 14: Train Loss: 0.002324, Validation Loss: 0.001212\n",
      " Epoch 15: Train Loss: 0.002252, Validation Loss: 0.001186\n",
      " Epoch 16: Train Loss: 0.002193, Validation Loss: 0.001176\n",
      " Epoch 17: Train Loss: 0.002141, Validation Loss: 0.001171\n",
      " Epoch 18: Train Loss: 0.002090, Validation Loss: 0.001151\n",
      " Epoch 19: Train Loss: 0.002047, Validation Loss: 0.001161\n",
      " Epoch 20: Train Loss: 0.002010, Validation Loss: 0.001166\n",
      " Epoch 21: Train Loss: 0.001978, Validation Loss: 0.001179\n",
      " Epoch 22: Train Loss: 0.001942, Validation Loss: 0.001162\n",
      " Epoch 23: Train Loss: 0.001913, Validation Loss: 0.001186\n",
      " Epoch 24: Train Loss: 0.001882, Validation Loss: 0.001154\n",
      " Epoch 25: Train Loss: 0.001852, Validation Loss: 0.001149\n",
      " Epoch 26: Train Loss: 0.001829, Validation Loss: 0.001217\n",
      " Epoch 27: Train Loss: 0.001802, Validation Loss: 0.001219\n",
      " Epoch 28: Train Loss: 0.001777, Validation Loss: 0.001207\n",
      " Epoch 29: Train Loss: 0.001750, Validation Loss: 0.001241\n",
      " Epoch 30: Train Loss: 0.001722, Validation Loss: 0.001239\n",
      " Epoch 31: Train Loss: 0.001703, Validation Loss: 0.001266\n",
      " Epoch 32: Train Loss: 0.001692, Validation Loss: 0.001218\n",
      " Epoch 33: Train Loss: 0.001682, Validation Loss: 0.001262\n",
      " Epoch 34: Train Loss: 0.001672, Validation Loss: 0.001240\n",
      " Epoch 35: Train Loss: 0.001664, Validation Loss: 0.001261\n",
      " Epoch 36: Train Loss: 0.001655, Validation Loss: 0.001295\n",
      " Epoch 37: Train Loss: 0.001646, Validation Loss: 0.001282\n",
      " Epoch 38: Train Loss: 0.001639, Validation Loss: 0.001250\n",
      " Epoch 39: Train Loss: 0.001630, Validation Loss: 0.001321\n",
      " Epoch 40: Train Loss: 0.001623, Validation Loss: 0.001274\n",
      " Epoch 41: Train Loss: 0.001617, Validation Loss: 0.001265\n",
      " Epoch 42: Train Loss: 0.001606, Validation Loss: 0.001268\n",
      " Epoch 43: Train Loss: 0.001599, Validation Loss: 0.001259\n",
      " Epoch 44: Train Loss: 0.001592, Validation Loss: 0.001229\n",
      " Epoch 45: Train Loss: 0.001584, Validation Loss: 0.001337\n",
      "Early stopping at epoch 45 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.044582, Validation Loss: 0.008828\n",
      " Epoch 2: Train Loss: 0.011917, Validation Loss: 0.006344\n",
      " Epoch 3: Train Loss: 0.007334, Validation Loss: 0.004404\n",
      " Epoch 4: Train Loss: 0.005629, Validation Loss: 0.003162\n",
      " Epoch 5: Train Loss: 0.004586, Validation Loss: 0.002352\n",
      " Epoch 6: Train Loss: 0.003947, Validation Loss: 0.001878\n",
      " Epoch 7: Train Loss: 0.003528, Validation Loss: 0.001643\n",
      " Epoch 8: Train Loss: 0.003223, Validation Loss: 0.001555\n",
      " Epoch 9: Train Loss: 0.002956, Validation Loss: 0.001539\n",
      " Epoch 10: Train Loss: 0.002726, Validation Loss: 0.001415\n",
      " Epoch 11: Train Loss: 0.002551, Validation Loss: 0.001310\n",
      " Epoch 12: Train Loss: 0.002432, Validation Loss: 0.001285\n",
      " Epoch 13: Train Loss: 0.002341, Validation Loss: 0.001210\n",
      " Epoch 14: Train Loss: 0.002270, Validation Loss: 0.001188\n",
      " Epoch 15: Train Loss: 0.002212, Validation Loss: 0.001172\n",
      " Epoch 16: Train Loss: 0.002163, Validation Loss: 0.001133\n",
      " Epoch 17: Train Loss: 0.002116, Validation Loss: 0.001132\n",
      " Epoch 18: Train Loss: 0.002075, Validation Loss: 0.001136\n",
      " Epoch 19: Train Loss: 0.002042, Validation Loss: 0.001107\n",
      " Epoch 20: Train Loss: 0.002010, Validation Loss: 0.001078\n",
      " Epoch 21: Train Loss: 0.001977, Validation Loss: 0.001075\n",
      " Epoch 22: Train Loss: 0.001945, Validation Loss: 0.001080\n",
      " Epoch 23: Train Loss: 0.001917, Validation Loss: 0.001087\n",
      " Epoch 24: Train Loss: 0.001889, Validation Loss: 0.001067\n",
      " Epoch 25: Train Loss: 0.001862, Validation Loss: 0.001055\n",
      " Epoch 26: Train Loss: 0.001838, Validation Loss: 0.001063\n",
      " Epoch 27: Train Loss: 0.001821, Validation Loss: 0.001035\n",
      " Epoch 28: Train Loss: 0.001795, Validation Loss: 0.001048\n",
      " Epoch 29: Train Loss: 0.001773, Validation Loss: 0.001041\n",
      " Epoch 30: Train Loss: 0.001753, Validation Loss: 0.001037\n",
      " Epoch 31: Train Loss: 0.001737, Validation Loss: 0.001021\n",
      " Epoch 32: Train Loss: 0.001727, Validation Loss: 0.001024\n",
      " Epoch 33: Train Loss: 0.001716, Validation Loss: 0.001035\n",
      " Epoch 34: Train Loss: 0.001707, Validation Loss: 0.001035\n",
      " Epoch 35: Train Loss: 0.001697, Validation Loss: 0.001033\n",
      " Epoch 36: Train Loss: 0.001689, Validation Loss: 0.001028\n",
      " Epoch 37: Train Loss: 0.001679, Validation Loss: 0.001014\n",
      " Epoch 38: Train Loss: 0.001669, Validation Loss: 0.001021\n",
      " Epoch 39: Train Loss: 0.001660, Validation Loss: 0.001045\n",
      " Epoch 40: Train Loss: 0.001649, Validation Loss: 0.001028\n",
      " Epoch 41: Train Loss: 0.001644, Validation Loss: 0.001023\n",
      " Epoch 42: Train Loss: 0.001634, Validation Loss: 0.001066\n",
      " Epoch 43: Train Loss: 0.001626, Validation Loss: 0.001076\n",
      " Epoch 44: Train Loss: 0.001617, Validation Loss: 0.001051\n",
      " Epoch 45: Train Loss: 0.001606, Validation Loss: 0.001101\n",
      " Epoch 46: Train Loss: 0.001597, Validation Loss: 0.001065\n",
      " Epoch 47: Train Loss: 0.001586, Validation Loss: 0.001090\n",
      " Epoch 48: Train Loss: 0.001580, Validation Loss: 0.001109\n",
      " Epoch 49: Train Loss: 0.001572, Validation Loss: 0.001125\n",
      " Epoch 50: Train Loss: 0.001563, Validation Loss: 0.001130\n",
      " Epoch 51: Train Loss: 0.001553, Validation Loss: 0.001150\n",
      " Epoch 52: Train Loss: 0.001545, Validation Loss: 0.001163\n",
      " Epoch 53: Train Loss: 0.001538, Validation Loss: 0.001090\n",
      " Epoch 54: Train Loss: 0.001529, Validation Loss: 0.001195\n",
      " Epoch 55: Train Loss: 0.001517, Validation Loss: 0.001108\n",
      " Epoch 56: Train Loss: 0.001509, Validation Loss: 0.001174\n",
      " Epoch 57: Train Loss: 0.001504, Validation Loss: 0.001189\n",
      "Early stopping at epoch 57 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.017050, Validation Loss: 0.029350\n",
      " Epoch 2: Train Loss: 0.003502, Validation Loss: 0.002223\n",
      " Epoch 3: Train Loss: 0.002411, Validation Loss: 0.001416\n",
      " Epoch 4: Train Loss: 0.002027, Validation Loss: 0.001181\n",
      " Epoch 5: Train Loss: 0.001812, Validation Loss: 0.001072\n",
      " Epoch 6: Train Loss: 0.001665, Validation Loss: 0.000984\n",
      " Epoch 7: Train Loss: 0.001554, Validation Loss: 0.000927\n",
      " Epoch 8: Train Loss: 0.001469, Validation Loss: 0.000893\n",
      " Epoch 9: Train Loss: 0.001398, Validation Loss: 0.000847\n",
      " Epoch 10: Train Loss: 0.001337, Validation Loss: 0.000818\n",
      " Epoch 11: Train Loss: 0.001287, Validation Loss: 0.000791\n",
      " Epoch 12: Train Loss: 0.001240, Validation Loss: 0.000767\n",
      " Epoch 13: Train Loss: 0.001201, Validation Loss: 0.000750\n",
      " Epoch 14: Train Loss: 0.001163, Validation Loss: 0.000749\n",
      " Epoch 15: Train Loss: 0.001133, Validation Loss: 0.000728\n",
      " Epoch 16: Train Loss: 0.001106, Validation Loss: 0.000714\n",
      " Epoch 17: Train Loss: 0.001074, Validation Loss: 0.000701\n",
      " Epoch 18: Train Loss: 0.001051, Validation Loss: 0.000681\n",
      " Epoch 19: Train Loss: 0.001025, Validation Loss: 0.000688\n",
      " Epoch 20: Train Loss: 0.001005, Validation Loss: 0.000694\n",
      " Epoch 21: Train Loss: 0.000987, Validation Loss: 0.000647\n",
      " Epoch 22: Train Loss: 0.000961, Validation Loss: 0.000670\n",
      " Epoch 23: Train Loss: 0.000945, Validation Loss: 0.000648\n",
      " Epoch 24: Train Loss: 0.000929, Validation Loss: 0.000646\n",
      " Epoch 25: Train Loss: 0.000911, Validation Loss: 0.000644\n",
      " Epoch 26: Train Loss: 0.000896, Validation Loss: 0.000644\n",
      " Epoch 27: Train Loss: 0.000879, Validation Loss: 0.000658\n",
      " Epoch 28: Train Loss: 0.000867, Validation Loss: 0.000663\n",
      " Epoch 29: Train Loss: 0.000857, Validation Loss: 0.000619\n",
      " Epoch 30: Train Loss: 0.000842, Validation Loss: 0.000657\n",
      " Epoch 31: Train Loss: 0.000830, Validation Loss: 0.000644\n",
      " Epoch 32: Train Loss: 0.000824, Validation Loss: 0.000679\n",
      " Epoch 33: Train Loss: 0.000819, Validation Loss: 0.000666\n",
      " Epoch 34: Train Loss: 0.000811, Validation Loss: 0.000651\n",
      " Epoch 35: Train Loss: 0.000805, Validation Loss: 0.000688\n",
      " Epoch 36: Train Loss: 0.000801, Validation Loss: 0.000648\n",
      " Epoch 37: Train Loss: 0.000795, Validation Loss: 0.000675\n",
      " Epoch 38: Train Loss: 0.000791, Validation Loss: 0.000697\n",
      " Epoch 39: Train Loss: 0.000784, Validation Loss: 0.000681\n",
      " Epoch 40: Train Loss: 0.000780, Validation Loss: 0.000693\n",
      " Epoch 41: Train Loss: 0.000775, Validation Loss: 0.000705\n",
      " Epoch 42: Train Loss: 0.000771, Validation Loss: 0.000686\n",
      " Epoch 43: Train Loss: 0.000765, Validation Loss: 0.000709\n",
      " Epoch 44: Train Loss: 0.000760, Validation Loss: 0.000746\n",
      " Epoch 45: Train Loss: 0.000756, Validation Loss: 0.000681\n",
      " Epoch 46: Train Loss: 0.000752, Validation Loss: 0.000703\n",
      " Epoch 47: Train Loss: 0.000748, Validation Loss: 0.000673\n",
      " Epoch 48: Train Loss: 0.000743, Validation Loss: 0.000719\n",
      " Epoch 49: Train Loss: 0.000737, Validation Loss: 0.000712\n",
      "Early stopping at epoch 49 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.013457, Validation Loss: 0.019080\n",
      " Epoch 2: Train Loss: 0.002962, Validation Loss: 0.001884\n",
      " Epoch 3: Train Loss: 0.002182, Validation Loss: 0.001278\n",
      " Epoch 4: Train Loss: 0.001871, Validation Loss: 0.001094\n",
      " Epoch 5: Train Loss: 0.001686, Validation Loss: 0.000983\n",
      " Epoch 6: Train Loss: 0.001560, Validation Loss: 0.000917\n",
      " Epoch 7: Train Loss: 0.001460, Validation Loss: 0.000874\n",
      " Epoch 8: Train Loss: 0.001378, Validation Loss: 0.000826\n",
      " Epoch 9: Train Loss: 0.001314, Validation Loss: 0.000802\n",
      " Epoch 10: Train Loss: 0.001260, Validation Loss: 0.000779\n",
      " Epoch 11: Train Loss: 0.001210, Validation Loss: 0.000751\n",
      " Epoch 12: Train Loss: 0.001169, Validation Loss: 0.000748\n",
      " Epoch 13: Train Loss: 0.001131, Validation Loss: 0.000719\n",
      " Epoch 14: Train Loss: 0.001096, Validation Loss: 0.000702\n",
      " Epoch 15: Train Loss: 0.001070, Validation Loss: 0.000724\n",
      " Epoch 16: Train Loss: 0.001040, Validation Loss: 0.000682\n",
      " Epoch 17: Train Loss: 0.001014, Validation Loss: 0.000678\n",
      " Epoch 18: Train Loss: 0.000991, Validation Loss: 0.000658\n",
      " Epoch 19: Train Loss: 0.000969, Validation Loss: 0.000654\n",
      " Epoch 20: Train Loss: 0.000951, Validation Loss: 0.000660\n",
      " Epoch 21: Train Loss: 0.000931, Validation Loss: 0.000643\n",
      " Epoch 22: Train Loss: 0.000912, Validation Loss: 0.000667\n",
      " Epoch 23: Train Loss: 0.000896, Validation Loss: 0.000649\n",
      " Epoch 24: Train Loss: 0.000881, Validation Loss: 0.000696\n",
      " Epoch 25: Train Loss: 0.000866, Validation Loss: 0.000749\n",
      " Epoch 26: Train Loss: 0.000854, Validation Loss: 0.000659\n",
      " Epoch 27: Train Loss: 0.000842, Validation Loss: 0.000668\n",
      " Epoch 28: Train Loss: 0.000829, Validation Loss: 0.000647\n",
      " Epoch 29: Train Loss: 0.000819, Validation Loss: 0.000668\n",
      " Epoch 30: Train Loss: 0.000807, Validation Loss: 0.000663\n",
      " Epoch 31: Train Loss: 0.000798, Validation Loss: 0.000701\n",
      " Epoch 32: Train Loss: 0.000791, Validation Loss: 0.000666\n",
      " Epoch 33: Train Loss: 0.000786, Validation Loss: 0.000682\n",
      " Epoch 34: Train Loss: 0.000780, Validation Loss: 0.000660\n",
      " Epoch 35: Train Loss: 0.000776, Validation Loss: 0.000689\n",
      " Epoch 36: Train Loss: 0.000772, Validation Loss: 0.000634\n",
      " Epoch 37: Train Loss: 0.000766, Validation Loss: 0.000660\n",
      " Epoch 38: Train Loss: 0.000761, Validation Loss: 0.000679\n",
      " Epoch 39: Train Loss: 0.000758, Validation Loss: 0.000724\n",
      " Epoch 40: Train Loss: 0.000754, Validation Loss: 0.000757\n",
      " Epoch 41: Train Loss: 0.000749, Validation Loss: 0.000714\n",
      " Epoch 42: Train Loss: 0.000743, Validation Loss: 0.000698\n",
      " Epoch 43: Train Loss: 0.000739, Validation Loss: 0.000710\n",
      " Epoch 44: Train Loss: 0.000735, Validation Loss: 0.000701\n",
      " Epoch 45: Train Loss: 0.000731, Validation Loss: 0.000710\n",
      " Epoch 46: Train Loss: 0.000727, Validation Loss: 0.000689\n",
      " Epoch 47: Train Loss: 0.000723, Validation Loss: 0.000696\n",
      " Epoch 48: Train Loss: 0.000719, Validation Loss: 0.000661\n",
      " Epoch 49: Train Loss: 0.000715, Validation Loss: 0.000716\n",
      " Epoch 50: Train Loss: 0.000710, Validation Loss: 0.000740\n",
      " Epoch 51: Train Loss: 0.000706, Validation Loss: 0.000740\n",
      " Epoch 52: Train Loss: 0.000702, Validation Loss: 0.000688\n",
      " Epoch 53: Train Loss: 0.000699, Validation Loss: 0.000738\n",
      " Epoch 54: Train Loss: 0.000695, Validation Loss: 0.000716\n",
      " Epoch 55: Train Loss: 0.000692, Validation Loss: 0.000707\n",
      " Epoch 56: Train Loss: 0.000688, Validation Loss: 0.000771\n",
      "Early stopping at epoch 56 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015369, Validation Loss: 0.029407\n",
      " Epoch 2: Train Loss: 0.003190, Validation Loss: 0.002708\n",
      " Epoch 3: Train Loss: 0.002226, Validation Loss: 0.001417\n",
      " Epoch 4: Train Loss: 0.001891, Validation Loss: 0.001248\n",
      " Epoch 5: Train Loss: 0.001699, Validation Loss: 0.001044\n",
      " Epoch 6: Train Loss: 0.001565, Validation Loss: 0.000969\n",
      " Epoch 7: Train Loss: 0.001468, Validation Loss: 0.000930\n",
      " Epoch 8: Train Loss: 0.001387, Validation Loss: 0.000889\n",
      " Epoch 9: Train Loss: 0.001325, Validation Loss: 0.000847\n",
      " Epoch 10: Train Loss: 0.001270, Validation Loss: 0.000811\n",
      " Epoch 11: Train Loss: 0.001228, Validation Loss: 0.000789\n",
      " Epoch 12: Train Loss: 0.001186, Validation Loss: 0.000745\n",
      " Epoch 13: Train Loss: 0.001154, Validation Loss: 0.000734\n",
      " Epoch 14: Train Loss: 0.001124, Validation Loss: 0.000729\n",
      " Epoch 15: Train Loss: 0.001096, Validation Loss: 0.000685\n",
      " Epoch 16: Train Loss: 0.001072, Validation Loss: 0.000683\n",
      " Epoch 17: Train Loss: 0.001046, Validation Loss: 0.000688\n",
      " Epoch 18: Train Loss: 0.001037, Validation Loss: 0.000831\n",
      " Epoch 19: Train Loss: 0.001017, Validation Loss: 0.000657\n",
      " Epoch 20: Train Loss: 0.000991, Validation Loss: 0.000670\n",
      " Epoch 21: Train Loss: 0.000977, Validation Loss: 0.000613\n",
      " Epoch 22: Train Loss: 0.000966, Validation Loss: 0.000638\n",
      " Epoch 23: Train Loss: 0.000965, Validation Loss: 0.000670\n",
      " Epoch 24: Train Loss: 0.001024, Validation Loss: 0.000634\n",
      " Epoch 25: Train Loss: 0.000943, Validation Loss: 0.000599\n",
      " Epoch 26: Train Loss: 0.000926, Validation Loss: 0.000583\n",
      " Epoch 27: Train Loss: 0.000933, Validation Loss: 0.000592\n",
      " Epoch 28: Train Loss: 0.000907, Validation Loss: 0.000569\n",
      " Epoch 29: Train Loss: 0.000890, Validation Loss: 0.000583\n",
      " Epoch 30: Train Loss: 0.000879, Validation Loss: 0.000546\n",
      " Epoch 31: Train Loss: 0.000863, Validation Loss: 0.000551\n",
      " Epoch 32: Train Loss: 0.000858, Validation Loss: 0.000543\n",
      " Epoch 33: Train Loss: 0.000854, Validation Loss: 0.000559\n",
      " Epoch 34: Train Loss: 0.000849, Validation Loss: 0.000548\n",
      " Epoch 35: Train Loss: 0.000844, Validation Loss: 0.000549\n",
      " Epoch 36: Train Loss: 0.000847, Validation Loss: 0.000552\n",
      " Epoch 37: Train Loss: 0.000843, Validation Loss: 0.000535\n",
      " Epoch 38: Train Loss: 0.000832, Validation Loss: 0.000528\n",
      " Epoch 39: Train Loss: 0.000833, Validation Loss: 0.000547\n",
      " Epoch 40: Train Loss: 0.000833, Validation Loss: 0.000521\n",
      " Epoch 41: Train Loss: 0.000825, Validation Loss: 0.000539\n",
      " Epoch 42: Train Loss: 0.000816, Validation Loss: 0.000526\n",
      " Epoch 43: Train Loss: 0.000814, Validation Loss: 0.000529\n",
      " Epoch 44: Train Loss: 0.000806, Validation Loss: 0.000526\n",
      " Epoch 45: Train Loss: 0.000805, Validation Loss: 0.000546\n",
      " Epoch 46: Train Loss: 0.000803, Validation Loss: 0.000515\n",
      " Epoch 47: Train Loss: 0.000801, Validation Loss: 0.000539\n",
      " Epoch 48: Train Loss: 0.000798, Validation Loss: 0.000558\n",
      " Epoch 49: Train Loss: 0.000793, Validation Loss: 0.000603\n",
      " Epoch 50: Train Loss: 0.000790, Validation Loss: 0.000511\n",
      " Epoch 51: Train Loss: 0.000782, Validation Loss: 0.000531\n",
      " Epoch 52: Train Loss: 0.000781, Validation Loss: 0.000512\n",
      " Epoch 53: Train Loss: 0.000779, Validation Loss: 0.000523\n",
      " Epoch 54: Train Loss: 0.000774, Validation Loss: 0.000526\n",
      " Epoch 55: Train Loss: 0.000767, Validation Loss: 0.000509\n",
      " Epoch 56: Train Loss: 0.000761, Validation Loss: 0.000510\n",
      " Epoch 57: Train Loss: 0.000761, Validation Loss: 0.000504\n",
      " Epoch 58: Train Loss: 0.000767, Validation Loss: 0.000515\n",
      " Epoch 59: Train Loss: 0.000763, Validation Loss: 0.000503\n",
      " Epoch 60: Train Loss: 0.000764, Validation Loss: 0.000559\n",
      " Epoch 61: Train Loss: 0.000753, Validation Loss: 0.000497\n",
      " Epoch 62: Train Loss: 0.000746, Validation Loss: 0.000500\n",
      " Epoch 63: Train Loss: 0.000749, Validation Loss: 0.000503\n",
      " Epoch 64: Train Loss: 0.000746, Validation Loss: 0.000510\n",
      " Epoch 65: Train Loss: 0.000742, Validation Loss: 0.000494\n",
      " Epoch 66: Train Loss: 0.000741, Validation Loss: 0.000505\n",
      " Epoch 67: Train Loss: 0.000740, Validation Loss: 0.000502\n",
      " Epoch 68: Train Loss: 0.000739, Validation Loss: 0.000498\n",
      " Epoch 69: Train Loss: 0.000736, Validation Loss: 0.000494\n",
      " Epoch 70: Train Loss: 0.000737, Validation Loss: 0.000500\n",
      " Epoch 71: Train Loss: 0.000733, Validation Loss: 0.000497\n",
      " Epoch 72: Train Loss: 0.000730, Validation Loss: 0.000488\n",
      " Epoch 73: Train Loss: 0.000730, Validation Loss: 0.000485\n",
      " Epoch 74: Train Loss: 0.000730, Validation Loss: 0.000521\n",
      " Epoch 75: Train Loss: 0.000730, Validation Loss: 0.000489\n",
      " Epoch 76: Train Loss: 0.000725, Validation Loss: 0.000494\n",
      " Epoch 77: Train Loss: 0.000727, Validation Loss: 0.000515\n",
      " Epoch 78: Train Loss: 0.000723, Validation Loss: 0.000494\n",
      " Epoch 79: Train Loss: 0.000722, Validation Loss: 0.000475\n",
      " Epoch 80: Train Loss: 0.000722, Validation Loss: 0.000477\n",
      " Epoch 81: Train Loss: 0.000720, Validation Loss: 0.000483\n",
      " Epoch 82: Train Loss: 0.000719, Validation Loss: 0.000475\n",
      " Epoch 83: Train Loss: 0.000716, Validation Loss: 0.000470\n",
      " Epoch 84: Train Loss: 0.000715, Validation Loss: 0.000473\n",
      " Epoch 85: Train Loss: 0.000718, Validation Loss: 0.000476\n",
      " Epoch 86: Train Loss: 0.000720, Validation Loss: 0.000475\n",
      " Epoch 87: Train Loss: 0.000718, Validation Loss: 0.000473\n",
      " Epoch 88: Train Loss: 0.000713, Validation Loss: 0.000480\n",
      " Epoch 89: Train Loss: 0.000709, Validation Loss: 0.000473\n",
      " Epoch 90: Train Loss: 0.000707, Validation Loss: 0.000472\n",
      " Epoch 91: Train Loss: 0.000705, Validation Loss: 0.000472\n",
      " Epoch 92: Train Loss: 0.000704, Validation Loss: 0.000479\n",
      " Epoch 93: Train Loss: 0.000704, Validation Loss: 0.000478\n",
      " Epoch 94: Train Loss: 0.000703, Validation Loss: 0.000479\n",
      " Epoch 95: Train Loss: 0.000701, Validation Loss: 0.000474\n",
      " Epoch 96: Train Loss: 0.000699, Validation Loss: 0.000478\n",
      " Epoch 97: Train Loss: 0.000698, Validation Loss: 0.000481\n",
      " Epoch 98: Train Loss: 0.000698, Validation Loss: 0.000477\n",
      " Epoch 99: Train Loss: 0.000697, Validation Loss: 0.000492\n",
      " Epoch 100: Train Loss: 0.000696, Validation Loss: 0.000469\n",
      " Epoch 101: Train Loss: 0.000695, Validation Loss: 0.000492\n",
      " Epoch 102: Train Loss: 0.000694, Validation Loss: 0.000483\n",
      " Epoch 103: Train Loss: 0.000693, Validation Loss: 0.000513\n",
      " Epoch 104: Train Loss: 0.000692, Validation Loss: 0.000475\n",
      " Epoch 105: Train Loss: 0.000693, Validation Loss: 0.000474\n",
      " Epoch 106: Train Loss: 0.000691, Validation Loss: 0.000471\n",
      " Epoch 107: Train Loss: 0.000690, Validation Loss: 0.000477\n",
      " Epoch 108: Train Loss: 0.000689, Validation Loss: 0.000473\n",
      " Epoch 109: Train Loss: 0.000688, Validation Loss: 0.000467\n",
      " Epoch 110: Train Loss: 0.000687, Validation Loss: 0.000478\n",
      " Epoch 111: Train Loss: 0.000686, Validation Loss: 0.000479\n",
      " Epoch 112: Train Loss: 0.000686, Validation Loss: 0.000482\n",
      " Epoch 113: Train Loss: 0.000685, Validation Loss: 0.000488\n",
      " Epoch 114: Train Loss: 0.000685, Validation Loss: 0.000466\n",
      " Epoch 115: Train Loss: 0.000683, Validation Loss: 0.000493\n",
      " Epoch 116: Train Loss: 0.000683, Validation Loss: 0.000468\n",
      " Epoch 117: Train Loss: 0.000682, Validation Loss: 0.000473\n",
      " Epoch 118: Train Loss: 0.000681, Validation Loss: 0.000474\n",
      " Epoch 119: Train Loss: 0.000680, Validation Loss: 0.000487\n",
      " Epoch 120: Train Loss: 0.000679, Validation Loss: 0.000475\n",
      " Epoch 121: Train Loss: 0.000679, Validation Loss: 0.000475\n",
      " Epoch 122: Train Loss: 0.000677, Validation Loss: 0.000465\n",
      " Epoch 123: Train Loss: 0.000676, Validation Loss: 0.000477\n",
      " Epoch 124: Train Loss: 0.000676, Validation Loss: 0.000481\n",
      " Epoch 125: Train Loss: 0.000676, Validation Loss: 0.000472\n",
      " Epoch 126: Train Loss: 0.000676, Validation Loss: 0.000462\n",
      " Epoch 127: Train Loss: 0.000675, Validation Loss: 0.000472\n",
      " Epoch 128: Train Loss: 0.000675, Validation Loss: 0.000489\n",
      " Epoch 129: Train Loss: 0.000675, Validation Loss: 0.000475\n",
      " Epoch 130: Train Loss: 0.000673, Validation Loss: 0.000470\n",
      " Epoch 131: Train Loss: 0.000674, Validation Loss: 0.000486\n",
      " Epoch 132: Train Loss: 0.000672, Validation Loss: 0.000471\n",
      " Epoch 133: Train Loss: 0.000673, Validation Loss: 0.000488\n",
      " Epoch 134: Train Loss: 0.000672, Validation Loss: 0.000479\n",
      " Epoch 135: Train Loss: 0.000672, Validation Loss: 0.000480\n",
      " Epoch 136: Train Loss: 0.000671, Validation Loss: 0.000472\n",
      " Epoch 137: Train Loss: 0.000671, Validation Loss: 0.000463\n",
      " Epoch 138: Train Loss: 0.000670, Validation Loss: 0.000472\n",
      " Epoch 139: Train Loss: 0.000669, Validation Loss: 0.000463\n",
      " Epoch 140: Train Loss: 0.000670, Validation Loss: 0.000460\n",
      " Epoch 141: Train Loss: 0.000669, Validation Loss: 0.000482\n",
      " Epoch 142: Train Loss: 0.000668, Validation Loss: 0.000469\n",
      " Epoch 143: Train Loss: 0.000667, Validation Loss: 0.000475\n",
      " Epoch 144: Train Loss: 0.000667, Validation Loss: 0.000466\n",
      " Epoch 145: Train Loss: 0.000667, Validation Loss: 0.000478\n",
      " Epoch 146: Train Loss: 0.000666, Validation Loss: 0.000474\n",
      " Epoch 147: Train Loss: 0.000665, Validation Loss: 0.000470\n",
      " Epoch 148: Train Loss: 0.000664, Validation Loss: 0.000466\n",
      " Epoch 149: Train Loss: 0.000665, Validation Loss: 0.000470\n",
      " Epoch 150: Train Loss: 0.000665, Validation Loss: 0.000466\n",
      " Epoch 151: Train Loss: 0.000664, Validation Loss: 0.000471\n",
      " Epoch 152: Train Loss: 0.000663, Validation Loss: 0.000473\n",
      " Epoch 153: Train Loss: 0.000664, Validation Loss: 0.000466\n",
      " Epoch 154: Train Loss: 0.000662, Validation Loss: 0.000464\n",
      " Epoch 155: Train Loss: 0.000663, Validation Loss: 0.000461\n",
      " Epoch 156: Train Loss: 0.000663, Validation Loss: 0.000468\n",
      " Epoch 157: Train Loss: 0.000662, Validation Loss: 0.000477\n",
      " Epoch 158: Train Loss: 0.000662, Validation Loss: 0.000471\n",
      " Epoch 159: Train Loss: 0.000662, Validation Loss: 0.000463\n",
      " Epoch 160: Train Loss: 0.000661, Validation Loss: 0.000476\n",
      "Early stopping at epoch 160 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.019922, Validation Loss: 0.016314\n",
      " Epoch 2: Train Loss: 0.004426, Validation Loss: 0.003221\n",
      " Epoch 3: Train Loss: 0.002768, Validation Loss: 0.001777\n",
      " Epoch 4: Train Loss: 0.002117, Validation Loss: 0.001331\n",
      " Epoch 5: Train Loss: 0.001795, Validation Loss: 0.001140\n",
      " Epoch 6: Train Loss: 0.001603, Validation Loss: 0.001013\n",
      " Epoch 7: Train Loss: 0.001471, Validation Loss: 0.000941\n",
      " Epoch 8: Train Loss: 0.001383, Validation Loss: 0.000892\n",
      " Epoch 9: Train Loss: 0.001309, Validation Loss: 0.000853\n",
      " Epoch 10: Train Loss: 0.001248, Validation Loss: 0.000797\n",
      " Epoch 11: Train Loss: 0.001198, Validation Loss: 0.000777\n",
      " Epoch 12: Train Loss: 0.001157, Validation Loss: 0.000747\n",
      " Epoch 13: Train Loss: 0.001123, Validation Loss: 0.000714\n",
      " Epoch 14: Train Loss: 0.001087, Validation Loss: 0.000699\n",
      " Epoch 15: Train Loss: 0.001060, Validation Loss: 0.000679\n",
      " Epoch 16: Train Loss: 0.001033, Validation Loss: 0.000667\n",
      " Epoch 17: Train Loss: 0.001006, Validation Loss: 0.000654\n",
      " Epoch 18: Train Loss: 0.000985, Validation Loss: 0.000644\n",
      " Epoch 19: Train Loss: 0.000964, Validation Loss: 0.000624\n",
      " Epoch 20: Train Loss: 0.000941, Validation Loss: 0.000615\n",
      " Epoch 21: Train Loss: 0.000923, Validation Loss: 0.000603\n",
      " Epoch 22: Train Loss: 0.000907, Validation Loss: 0.000587\n",
      " Epoch 23: Train Loss: 0.000889, Validation Loss: 0.000582\n",
      " Epoch 24: Train Loss: 0.000871, Validation Loss: 0.000566\n",
      " Epoch 25: Train Loss: 0.000857, Validation Loss: 0.000571\n",
      " Epoch 26: Train Loss: 0.000845, Validation Loss: 0.000589\n",
      " Epoch 27: Train Loss: 0.000834, Validation Loss: 0.000570\n",
      " Epoch 28: Train Loss: 0.000815, Validation Loss: 0.000564\n",
      " Epoch 29: Train Loss: 0.000801, Validation Loss: 0.000571\n",
      " Epoch 30: Train Loss: 0.000790, Validation Loss: 0.000587\n",
      " Epoch 31: Train Loss: 0.000780, Validation Loss: 0.000575\n",
      " Epoch 32: Train Loss: 0.000773, Validation Loss: 0.000568\n",
      " Epoch 33: Train Loss: 0.000767, Validation Loss: 0.000579\n",
      " Epoch 34: Train Loss: 0.000762, Validation Loss: 0.000569\n",
      " Epoch 35: Train Loss: 0.000756, Validation Loss: 0.000579\n",
      " Epoch 36: Train Loss: 0.000751, Validation Loss: 0.000572\n",
      " Epoch 37: Train Loss: 0.000746, Validation Loss: 0.000588\n",
      " Epoch 38: Train Loss: 0.000741, Validation Loss: 0.000610\n",
      " Epoch 39: Train Loss: 0.000735, Validation Loss: 0.000614\n",
      " Epoch 40: Train Loss: 0.000731, Validation Loss: 0.000615\n",
      " Epoch 41: Train Loss: 0.000727, Validation Loss: 0.000625\n",
      " Epoch 42: Train Loss: 0.000722, Validation Loss: 0.000616\n",
      " Epoch 43: Train Loss: 0.000717, Validation Loss: 0.000585\n",
      " Epoch 44: Train Loss: 0.000714, Validation Loss: 0.000585\n",
      " Epoch 45: Train Loss: 0.000708, Validation Loss: 0.000647\n",
      " Epoch 46: Train Loss: 0.000705, Validation Loss: 0.000705\n",
      " Epoch 47: Train Loss: 0.000700, Validation Loss: 0.000644\n",
      " Epoch 48: Train Loss: 0.000696, Validation Loss: 0.000650\n",
      "Early stopping at epoch 48 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.018306, Validation Loss: 0.009572\n",
      " Epoch 2: Train Loss: 0.003560, Validation Loss: 0.002539\n",
      " Epoch 3: Train Loss: 0.002426, Validation Loss: 0.001547\n",
      " Epoch 4: Train Loss: 0.001967, Validation Loss: 0.001270\n",
      " Epoch 5: Train Loss: 0.001720, Validation Loss: 0.001128\n",
      " Epoch 6: Train Loss: 0.001566, Validation Loss: 0.000999\n",
      " Epoch 7: Train Loss: 0.001456, Validation Loss: 0.000952\n",
      " Epoch 8: Train Loss: 0.001369, Validation Loss: 0.000892\n",
      " Epoch 9: Train Loss: 0.001303, Validation Loss: 0.000866\n",
      " Epoch 10: Train Loss: 0.001249, Validation Loss: 0.000814\n",
      " Epoch 11: Train Loss: 0.001194, Validation Loss: 0.000768\n",
      " Epoch 12: Train Loss: 0.001152, Validation Loss: 0.000766\n",
      " Epoch 13: Train Loss: 0.001116, Validation Loss: 0.000735\n",
      " Epoch 14: Train Loss: 0.001076, Validation Loss: 0.000693\n",
      " Epoch 15: Train Loss: 0.001046, Validation Loss: 0.000672\n",
      " Epoch 16: Train Loss: 0.001022, Validation Loss: 0.000654\n",
      " Epoch 17: Train Loss: 0.000992, Validation Loss: 0.000638\n",
      " Epoch 18: Train Loss: 0.000969, Validation Loss: 0.000626\n",
      " Epoch 19: Train Loss: 0.000947, Validation Loss: 0.000604\n",
      " Epoch 20: Train Loss: 0.000928, Validation Loss: 0.000591\n",
      " Epoch 21: Train Loss: 0.000907, Validation Loss: 0.000576\n",
      " Epoch 22: Train Loss: 0.000895, Validation Loss: 0.000573\n",
      " Epoch 23: Train Loss: 0.000878, Validation Loss: 0.000565\n",
      " Epoch 24: Train Loss: 0.000865, Validation Loss: 0.000555\n",
      " Epoch 25: Train Loss: 0.000851, Validation Loss: 0.000542\n",
      " Epoch 26: Train Loss: 0.000838, Validation Loss: 0.000552\n",
      " Epoch 27: Train Loss: 0.000826, Validation Loss: 0.000542\n",
      " Epoch 28: Train Loss: 0.000816, Validation Loss: 0.000541\n",
      " Epoch 29: Train Loss: 0.000807, Validation Loss: 0.000561\n",
      " Epoch 30: Train Loss: 0.000794, Validation Loss: 0.000563\n",
      " Epoch 31: Train Loss: 0.000785, Validation Loss: 0.000554\n",
      " Epoch 32: Train Loss: 0.000780, Validation Loss: 0.000539\n",
      " Epoch 33: Train Loss: 0.000775, Validation Loss: 0.000552\n",
      " Epoch 34: Train Loss: 0.000770, Validation Loss: 0.000557\n",
      " Epoch 35: Train Loss: 0.000765, Validation Loss: 0.000533\n",
      " Epoch 36: Train Loss: 0.000761, Validation Loss: 0.000554\n",
      " Epoch 37: Train Loss: 0.000755, Validation Loss: 0.000558\n",
      " Epoch 38: Train Loss: 0.000752, Validation Loss: 0.000542\n",
      " Epoch 39: Train Loss: 0.000747, Validation Loss: 0.000551\n",
      " Epoch 40: Train Loss: 0.000742, Validation Loss: 0.000560\n",
      " Epoch 41: Train Loss: 0.000738, Validation Loss: 0.000552\n",
      " Epoch 42: Train Loss: 0.000734, Validation Loss: 0.000550\n",
      " Epoch 43: Train Loss: 0.000730, Validation Loss: 0.000543\n",
      " Epoch 44: Train Loss: 0.000725, Validation Loss: 0.000539\n",
      " Epoch 45: Train Loss: 0.000721, Validation Loss: 0.000556\n",
      " Epoch 46: Train Loss: 0.000718, Validation Loss: 0.000565\n",
      " Epoch 47: Train Loss: 0.000713, Validation Loss: 0.000586\n",
      " Epoch 48: Train Loss: 0.000709, Validation Loss: 0.000575\n",
      " Epoch 49: Train Loss: 0.000706, Validation Loss: 0.000549\n",
      " Epoch 50: Train Loss: 0.000701, Validation Loss: 0.000573\n",
      " Epoch 51: Train Loss: 0.000699, Validation Loss: 0.000555\n",
      " Epoch 52: Train Loss: 0.000696, Validation Loss: 0.000586\n",
      " Epoch 53: Train Loss: 0.000690, Validation Loss: 0.000636\n",
      " Epoch 54: Train Loss: 0.000687, Validation Loss: 0.000545\n",
      " Epoch 55: Train Loss: 0.000684, Validation Loss: 0.000601\n",
      "Early stopping at epoch 55 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012278, Validation Loss: 0.013371\n",
      " Epoch 2: Train Loss: 0.002782, Validation Loss: 0.001802\n",
      " Epoch 3: Train Loss: 0.002017, Validation Loss: 0.001356\n",
      " Epoch 4: Train Loss: 0.001696, Validation Loss: 0.001185\n",
      " Epoch 5: Train Loss: 0.001521, Validation Loss: 0.001080\n",
      " Epoch 6: Train Loss: 0.001396, Validation Loss: 0.000935\n",
      " Epoch 7: Train Loss: 0.001310, Validation Loss: 0.000904\n",
      " Epoch 8: Train Loss: 0.001238, Validation Loss: 0.000843\n",
      " Epoch 9: Train Loss: 0.001183, Validation Loss: 0.000836\n",
      " Epoch 10: Train Loss: 0.001133, Validation Loss: 0.000766\n",
      " Epoch 11: Train Loss: 0.001093, Validation Loss: 0.000813\n",
      " Epoch 12: Train Loss: 0.001055, Validation Loss: 0.000717\n",
      " Epoch 13: Train Loss: 0.001021, Validation Loss: 0.000731\n",
      " Epoch 14: Train Loss: 0.000991, Validation Loss: 0.000681\n",
      " Epoch 15: Train Loss: 0.000966, Validation Loss: 0.000635\n",
      " Epoch 16: Train Loss: 0.000940, Validation Loss: 0.000668\n",
      " Epoch 17: Train Loss: 0.000919, Validation Loss: 0.000640\n",
      " Epoch 18: Train Loss: 0.000899, Validation Loss: 0.000594\n",
      " Epoch 19: Train Loss: 0.000882, Validation Loss: 0.000593\n",
      " Epoch 20: Train Loss: 0.000868, Validation Loss: 0.000602\n",
      " Epoch 21: Train Loss: 0.000859, Validation Loss: 0.000574\n",
      " Epoch 22: Train Loss: 0.000833, Validation Loss: 0.000556\n",
      " Epoch 23: Train Loss: 0.000821, Validation Loss: 0.000548\n",
      " Epoch 24: Train Loss: 0.000810, Validation Loss: 0.000562\n",
      " Epoch 25: Train Loss: 0.000795, Validation Loss: 0.000529\n",
      " Epoch 26: Train Loss: 0.000784, Validation Loss: 0.000519\n",
      " Epoch 27: Train Loss: 0.000773, Validation Loss: 0.000519\n",
      " Epoch 28: Train Loss: 0.000761, Validation Loss: 0.000537\n",
      " Epoch 29: Train Loss: 0.000750, Validation Loss: 0.000534\n",
      " Epoch 30: Train Loss: 0.000740, Validation Loss: 0.000562\n",
      " Epoch 31: Train Loss: 0.000730, Validation Loss: 0.000528\n",
      " Epoch 32: Train Loss: 0.000725, Validation Loss: 0.000530\n",
      " Epoch 33: Train Loss: 0.000720, Validation Loss: 0.000538\n",
      " Epoch 34: Train Loss: 0.000716, Validation Loss: 0.000528\n",
      " Epoch 35: Train Loss: 0.000710, Validation Loss: 0.000525\n",
      " Epoch 36: Train Loss: 0.000706, Validation Loss: 0.000537\n",
      " Epoch 37: Train Loss: 0.000702, Validation Loss: 0.000556\n",
      " Epoch 38: Train Loss: 0.000698, Validation Loss: 0.000577\n",
      " Epoch 39: Train Loss: 0.000692, Validation Loss: 0.000534\n",
      " Epoch 40: Train Loss: 0.000688, Validation Loss: 0.000581\n",
      " Epoch 41: Train Loss: 0.000685, Validation Loss: 0.000553\n",
      " Epoch 42: Train Loss: 0.000681, Validation Loss: 0.000576\n",
      " Epoch 43: Train Loss: 0.000676, Validation Loss: 0.000589\n",
      " Epoch 44: Train Loss: 0.000672, Validation Loss: 0.000585\n",
      " Epoch 45: Train Loss: 0.000668, Validation Loss: 0.000583\n",
      " Epoch 46: Train Loss: 0.000664, Validation Loss: 0.000616\n",
      "Early stopping at epoch 46 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016297, Validation Loss: 0.029240\n",
      " Epoch 2: Train Loss: 0.003355, Validation Loss: 0.002116\n",
      " Epoch 3: Train Loss: 0.002315, Validation Loss: 0.001417\n",
      " Epoch 4: Train Loss: 0.001957, Validation Loss: 0.001183\n",
      " Epoch 5: Train Loss: 0.001764, Validation Loss: 0.001061\n",
      " Epoch 6: Train Loss: 0.001635, Validation Loss: 0.000978\n",
      " Epoch 7: Train Loss: 0.001534, Validation Loss: 0.000915\n",
      " Epoch 8: Train Loss: 0.001458, Validation Loss: 0.000874\n",
      " Epoch 9: Train Loss: 0.001393, Validation Loss: 0.000835\n",
      " Epoch 10: Train Loss: 0.001339, Validation Loss: 0.000814\n",
      " Epoch 11: Train Loss: 0.001291, Validation Loss: 0.000796\n",
      " Epoch 12: Train Loss: 0.001248, Validation Loss: 0.000787\n",
      " Epoch 13: Train Loss: 0.001211, Validation Loss: 0.000748\n",
      " Epoch 14: Train Loss: 0.001176, Validation Loss: 0.000748\n",
      " Epoch 15: Train Loss: 0.001144, Validation Loss: 0.000747\n",
      " Epoch 16: Train Loss: 0.001118, Validation Loss: 0.000706\n",
      " Epoch 17: Train Loss: 0.001091, Validation Loss: 0.000723\n",
      " Epoch 18: Train Loss: 0.001065, Validation Loss: 0.000708\n",
      " Epoch 19: Train Loss: 0.001042, Validation Loss: 0.000707\n",
      " Epoch 20: Train Loss: 0.001023, Validation Loss: 0.000719\n",
      " Epoch 21: Train Loss: 0.001002, Validation Loss: 0.000693\n",
      " Epoch 22: Train Loss: 0.000983, Validation Loss: 0.000701\n",
      " Epoch 23: Train Loss: 0.000963, Validation Loss: 0.000695\n",
      " Epoch 24: Train Loss: 0.000947, Validation Loss: 0.000676\n",
      " Epoch 25: Train Loss: 0.000932, Validation Loss: 0.000692\n",
      " Epoch 26: Train Loss: 0.000920, Validation Loss: 0.000700\n",
      " Epoch 27: Train Loss: 0.000913, Validation Loss: 0.000694\n",
      " Epoch 28: Train Loss: 0.000889, Validation Loss: 0.000689\n",
      " Epoch 29: Train Loss: 0.000875, Validation Loss: 0.000705\n",
      " Epoch 30: Train Loss: 0.000864, Validation Loss: 0.000661\n",
      " Epoch 31: Train Loss: 0.000852, Validation Loss: 0.000687\n",
      " Epoch 32: Train Loss: 0.000847, Validation Loss: 0.000691\n",
      " Epoch 33: Train Loss: 0.000840, Validation Loss: 0.000664\n",
      " Epoch 34: Train Loss: 0.000835, Validation Loss: 0.000714\n",
      " Epoch 35: Train Loss: 0.000828, Validation Loss: 0.000675\n",
      " Epoch 36: Train Loss: 0.000822, Validation Loss: 0.000705\n",
      " Epoch 37: Train Loss: 0.000818, Validation Loss: 0.000674\n",
      " Epoch 38: Train Loss: 0.000811, Validation Loss: 0.000677\n",
      " Epoch 39: Train Loss: 0.000806, Validation Loss: 0.000686\n",
      " Epoch 40: Train Loss: 0.000802, Validation Loss: 0.000687\n",
      " Epoch 41: Train Loss: 0.000797, Validation Loss: 0.000674\n",
      " Epoch 42: Train Loss: 0.000791, Validation Loss: 0.000669\n",
      " Epoch 43: Train Loss: 0.000786, Validation Loss: 0.000704\n",
      " Epoch 44: Train Loss: 0.000781, Validation Loss: 0.000690\n",
      " Epoch 45: Train Loss: 0.000776, Validation Loss: 0.000658\n",
      " Epoch 46: Train Loss: 0.000771, Validation Loss: 0.000692\n",
      " Epoch 47: Train Loss: 0.000766, Validation Loss: 0.000708\n",
      " Epoch 48: Train Loss: 0.000761, Validation Loss: 0.000701\n",
      " Epoch 49: Train Loss: 0.000756, Validation Loss: 0.000655\n",
      " Epoch 50: Train Loss: 0.000753, Validation Loss: 0.000698\n",
      " Epoch 51: Train Loss: 0.000748, Validation Loss: 0.000701\n",
      " Epoch 52: Train Loss: 0.000743, Validation Loss: 0.000690\n",
      " Epoch 53: Train Loss: 0.000739, Validation Loss: 0.000698\n",
      " Epoch 54: Train Loss: 0.000736, Validation Loss: 0.000701\n",
      " Epoch 55: Train Loss: 0.000730, Validation Loss: 0.000728\n",
      " Epoch 56: Train Loss: 0.000727, Validation Loss: 0.000718\n",
      " Epoch 57: Train Loss: 0.000722, Validation Loss: 0.000739\n",
      " Epoch 58: Train Loss: 0.000718, Validation Loss: 0.000769\n",
      " Epoch 59: Train Loss: 0.000715, Validation Loss: 0.000754\n",
      " Epoch 60: Train Loss: 0.000710, Validation Loss: 0.000722\n",
      " Epoch 61: Train Loss: 0.000706, Validation Loss: 0.000743\n",
      " Epoch 62: Train Loss: 0.000705, Validation Loss: 0.000751\n",
      " Epoch 63: Train Loss: 0.000701, Validation Loss: 0.000768\n",
      " Epoch 64: Train Loss: 0.000700, Validation Loss: 0.000762\n",
      " Epoch 65: Train Loss: 0.000699, Validation Loss: 0.000770\n",
      " Epoch 66: Train Loss: 0.000697, Validation Loss: 0.000747\n",
      " Epoch 67: Train Loss: 0.000695, Validation Loss: 0.000785\n",
      " Epoch 68: Train Loss: 0.000693, Validation Loss: 0.000793\n",
      " Epoch 69: Train Loss: 0.000690, Validation Loss: 0.000780\n",
      "Early stopping at epoch 69 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.013698, Validation Loss: 0.028807\n",
      " Epoch 2: Train Loss: 0.002873, Validation Loss: 0.001775\n",
      " Epoch 3: Train Loss: 0.002096, Validation Loss: 0.001297\n",
      " Epoch 4: Train Loss: 0.001815, Validation Loss: 0.001104\n",
      " Epoch 5: Train Loss: 0.001642, Validation Loss: 0.000972\n",
      " Epoch 6: Train Loss: 0.001519, Validation Loss: 0.000906\n",
      " Epoch 7: Train Loss: 0.001423, Validation Loss: 0.000865\n",
      " Epoch 8: Train Loss: 0.001350, Validation Loss: 0.000820\n",
      " Epoch 9: Train Loss: 0.001286, Validation Loss: 0.000787\n",
      " Epoch 10: Train Loss: 0.001228, Validation Loss: 0.000765\n",
      " Epoch 11: Train Loss: 0.001182, Validation Loss: 0.000750\n",
      " Epoch 12: Train Loss: 0.001143, Validation Loss: 0.000740\n",
      " Epoch 13: Train Loss: 0.001103, Validation Loss: 0.000728\n",
      " Epoch 14: Train Loss: 0.001073, Validation Loss: 0.000700\n",
      " Epoch 15: Train Loss: 0.001041, Validation Loss: 0.000661\n",
      " Epoch 16: Train Loss: 0.001015, Validation Loss: 0.000667\n",
      " Epoch 17: Train Loss: 0.000991, Validation Loss: 0.000701\n",
      " Epoch 18: Train Loss: 0.000967, Validation Loss: 0.000697\n",
      " Epoch 19: Train Loss: 0.000945, Validation Loss: 0.000675\n",
      " Epoch 20: Train Loss: 0.000925, Validation Loss: 0.000701\n",
      " Epoch 21: Train Loss: 0.000909, Validation Loss: 0.000668\n",
      " Epoch 22: Train Loss: 0.000891, Validation Loss: 0.000669\n",
      " Epoch 23: Train Loss: 0.000875, Validation Loss: 0.000687\n",
      " Epoch 24: Train Loss: 0.000862, Validation Loss: 0.000653\n",
      " Epoch 25: Train Loss: 0.000855, Validation Loss: 0.000701\n",
      " Epoch 26: Train Loss: 0.000834, Validation Loss: 0.000691\n",
      " Epoch 27: Train Loss: 0.000820, Validation Loss: 0.000737\n",
      " Epoch 28: Train Loss: 0.000809, Validation Loss: 0.000749\n",
      " Epoch 29: Train Loss: 0.000799, Validation Loss: 0.000711\n",
      " Epoch 30: Train Loss: 0.000791, Validation Loss: 0.000822\n",
      " Epoch 31: Train Loss: 0.000777, Validation Loss: 0.000724\n",
      " Epoch 32: Train Loss: 0.000772, Validation Loss: 0.000744\n",
      " Epoch 33: Train Loss: 0.000767, Validation Loss: 0.000729\n",
      " Epoch 34: Train Loss: 0.000762, Validation Loss: 0.000774\n",
      " Epoch 35: Train Loss: 0.000757, Validation Loss: 0.000784\n",
      " Epoch 36: Train Loss: 0.000752, Validation Loss: 0.000764\n",
      " Epoch 37: Train Loss: 0.000749, Validation Loss: 0.000785\n",
      " Epoch 38: Train Loss: 0.000743, Validation Loss: 0.000764\n",
      " Epoch 39: Train Loss: 0.000738, Validation Loss: 0.000775\n",
      " Epoch 40: Train Loss: 0.000735, Validation Loss: 0.000803\n",
      " Epoch 41: Train Loss: 0.000730, Validation Loss: 0.000808\n",
      " Epoch 42: Train Loss: 0.000724, Validation Loss: 0.000805\n",
      " Epoch 43: Train Loss: 0.000722, Validation Loss: 0.000763\n",
      " Epoch 44: Train Loss: 0.000716, Validation Loss: 0.000817\n",
      "Early stopping at epoch 44 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.018333, Validation Loss: 0.026046\n",
      " Epoch 2: Train Loss: 0.004187, Validation Loss: 0.003348\n",
      " Epoch 3: Train Loss: 0.002687, Validation Loss: 0.001676\n",
      " Epoch 4: Train Loss: 0.002081, Validation Loss: 0.001250\n",
      " Epoch 5: Train Loss: 0.001804, Validation Loss: 0.001096\n",
      " Epoch 6: Train Loss: 0.001637, Validation Loss: 0.001009\n",
      " Epoch 7: Train Loss: 0.001519, Validation Loss: 0.000942\n",
      " Epoch 8: Train Loss: 0.001432, Validation Loss: 0.000894\n",
      " Epoch 9: Train Loss: 0.001358, Validation Loss: 0.000861\n",
      " Epoch 10: Train Loss: 0.001304, Validation Loss: 0.000834\n",
      " Epoch 11: Train Loss: 0.001256, Validation Loss: 0.000817\n",
      " Epoch 12: Train Loss: 0.001210, Validation Loss: 0.000774\n",
      " Epoch 13: Train Loss: 0.001173, Validation Loss: 0.000782\n",
      " Epoch 14: Train Loss: 0.001141, Validation Loss: 0.000753\n",
      " Epoch 15: Train Loss: 0.001109, Validation Loss: 0.000737\n",
      " Epoch 16: Train Loss: 0.001081, Validation Loss: 0.000720\n",
      " Epoch 17: Train Loss: 0.001053, Validation Loss: 0.000709\n",
      " Epoch 18: Train Loss: 0.001032, Validation Loss: 0.000683\n",
      " Epoch 19: Train Loss: 0.001011, Validation Loss: 0.000641\n",
      " Epoch 20: Train Loss: 0.000989, Validation Loss: 0.000661\n",
      " Epoch 21: Train Loss: 0.000969, Validation Loss: 0.000649\n",
      " Epoch 22: Train Loss: 0.000952, Validation Loss: 0.000639\n",
      " Epoch 23: Train Loss: 0.000933, Validation Loss: 0.000650\n",
      " Epoch 24: Train Loss: 0.000917, Validation Loss: 0.000651\n",
      " Epoch 25: Train Loss: 0.000903, Validation Loss: 0.000653\n",
      " Epoch 26: Train Loss: 0.000888, Validation Loss: 0.000641\n",
      " Epoch 27: Train Loss: 0.000875, Validation Loss: 0.000598\n",
      " Epoch 28: Train Loss: 0.000862, Validation Loss: 0.000584\n",
      " Epoch 29: Train Loss: 0.000851, Validation Loss: 0.000628\n",
      " Epoch 30: Train Loss: 0.000838, Validation Loss: 0.000603\n",
      " Epoch 31: Train Loss: 0.000827, Validation Loss: 0.000594\n",
      " Epoch 32: Train Loss: 0.000821, Validation Loss: 0.000612\n",
      " Epoch 33: Train Loss: 0.000815, Validation Loss: 0.000579\n",
      " Epoch 34: Train Loss: 0.000810, Validation Loss: 0.000605\n",
      " Epoch 35: Train Loss: 0.000804, Validation Loss: 0.000598\n",
      " Epoch 36: Train Loss: 0.000799, Validation Loss: 0.000604\n",
      " Epoch 37: Train Loss: 0.000794, Validation Loss: 0.000608\n",
      " Epoch 38: Train Loss: 0.000789, Validation Loss: 0.000591\n",
      " Epoch 39: Train Loss: 0.000784, Validation Loss: 0.000608\n",
      " Epoch 40: Train Loss: 0.000780, Validation Loss: 0.000596\n",
      " Epoch 41: Train Loss: 0.000774, Validation Loss: 0.000599\n",
      " Epoch 42: Train Loss: 0.000769, Validation Loss: 0.000586\n",
      " Epoch 43: Train Loss: 0.000765, Validation Loss: 0.000589\n",
      " Epoch 44: Train Loss: 0.000760, Validation Loss: 0.000600\n",
      " Epoch 45: Train Loss: 0.000755, Validation Loss: 0.000614\n",
      " Epoch 46: Train Loss: 0.000752, Validation Loss: 0.000564\n",
      " Epoch 47: Train Loss: 0.000747, Validation Loss: 0.000603\n",
      " Epoch 48: Train Loss: 0.000744, Validation Loss: 0.000604\n",
      " Epoch 49: Train Loss: 0.000739, Validation Loss: 0.000629\n",
      " Epoch 50: Train Loss: 0.000735, Validation Loss: 0.000604\n",
      " Epoch 51: Train Loss: 0.000731, Validation Loss: 0.000580\n",
      " Epoch 52: Train Loss: 0.000726, Validation Loss: 0.000581\n",
      " Epoch 53: Train Loss: 0.000723, Validation Loss: 0.000586\n",
      " Epoch 54: Train Loss: 0.000720, Validation Loss: 0.000579\n",
      " Epoch 55: Train Loss: 0.000716, Validation Loss: 0.000630\n",
      " Epoch 56: Train Loss: 0.000712, Validation Loss: 0.000607\n",
      " Epoch 57: Train Loss: 0.000709, Validation Loss: 0.000618\n",
      " Epoch 58: Train Loss: 0.000706, Validation Loss: 0.000553\n",
      " Epoch 59: Train Loss: 0.000701, Validation Loss: 0.000620\n",
      " Epoch 60: Train Loss: 0.000698, Validation Loss: 0.000627\n",
      " Epoch 61: Train Loss: 0.000693, Validation Loss: 0.000658\n",
      " Epoch 62: Train Loss: 0.000692, Validation Loss: 0.000632\n",
      " Epoch 63: Train Loss: 0.000690, Validation Loss: 0.000621\n",
      " Epoch 64: Train Loss: 0.000688, Validation Loss: 0.000618\n",
      " Epoch 65: Train Loss: 0.000686, Validation Loss: 0.000645\n",
      " Epoch 66: Train Loss: 0.000684, Validation Loss: 0.000629\n",
      " Epoch 67: Train Loss: 0.000684, Validation Loss: 0.000684\n",
      " Epoch 68: Train Loss: 0.000680, Validation Loss: 0.000625\n",
      " Epoch 69: Train Loss: 0.000678, Validation Loss: 0.000628\n",
      " Epoch 70: Train Loss: 0.000677, Validation Loss: 0.000652\n",
      " Epoch 71: Train Loss: 0.000675, Validation Loss: 0.000639\n",
      " Epoch 72: Train Loss: 0.000673, Validation Loss: 0.000628\n",
      " Epoch 73: Train Loss: 0.000672, Validation Loss: 0.000646\n",
      " Epoch 74: Train Loss: 0.000670, Validation Loss: 0.000635\n",
      " Epoch 75: Train Loss: 0.000667, Validation Loss: 0.000643\n",
      " Epoch 76: Train Loss: 0.000666, Validation Loss: 0.000615\n",
      " Epoch 77: Train Loss: 0.000663, Validation Loss: 0.000647\n",
      " Epoch 78: Train Loss: 0.000662, Validation Loss: 0.000633\n",
      "Early stopping at epoch 78 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015104, Validation Loss: 0.023546\n",
      " Epoch 2: Train Loss: 0.003195, Validation Loss: 0.002372\n",
      " Epoch 3: Train Loss: 0.002209, Validation Loss: 0.001390\n",
      " Epoch 4: Train Loss: 0.001821, Validation Loss: 0.001276\n",
      " Epoch 5: Train Loss: 0.001611, Validation Loss: 0.001116\n",
      " Epoch 6: Train Loss: 0.001476, Validation Loss: 0.001032\n",
      " Epoch 7: Train Loss: 0.001381, Validation Loss: 0.000954\n",
      " Epoch 8: Train Loss: 0.001312, Validation Loss: 0.000905\n",
      " Epoch 9: Train Loss: 0.001256, Validation Loss: 0.000853\n",
      " Epoch 10: Train Loss: 0.001206, Validation Loss: 0.000862\n",
      " Epoch 11: Train Loss: 0.001160, Validation Loss: 0.000806\n",
      " Epoch 12: Train Loss: 0.001122, Validation Loss: 0.000772\n",
      " Epoch 13: Train Loss: 0.001082, Validation Loss: 0.000750\n",
      " Epoch 14: Train Loss: 0.001046, Validation Loss: 0.000729\n",
      " Epoch 15: Train Loss: 0.001016, Validation Loss: 0.000703\n",
      " Epoch 16: Train Loss: 0.000986, Validation Loss: 0.000670\n",
      " Epoch 17: Train Loss: 0.000960, Validation Loss: 0.000630\n",
      " Epoch 18: Train Loss: 0.000934, Validation Loss: 0.000630\n",
      " Epoch 19: Train Loss: 0.000916, Validation Loss: 0.000597\n",
      " Epoch 20: Train Loss: 0.000894, Validation Loss: 0.000597\n",
      " Epoch 21: Train Loss: 0.000876, Validation Loss: 0.000628\n",
      " Epoch 22: Train Loss: 0.000863, Validation Loss: 0.000565\n",
      " Epoch 23: Train Loss: 0.000844, Validation Loss: 0.000548\n",
      " Epoch 24: Train Loss: 0.000829, Validation Loss: 0.000538\n",
      " Epoch 25: Train Loss: 0.000818, Validation Loss: 0.000543\n",
      " Epoch 26: Train Loss: 0.000803, Validation Loss: 0.000526\n",
      " Epoch 27: Train Loss: 0.000791, Validation Loss: 0.000520\n",
      " Epoch 28: Train Loss: 0.000779, Validation Loss: 0.000520\n",
      " Epoch 29: Train Loss: 0.000768, Validation Loss: 0.000510\n",
      " Epoch 30: Train Loss: 0.000759, Validation Loss: 0.000515\n",
      " Epoch 31: Train Loss: 0.000748, Validation Loss: 0.000540\n",
      " Epoch 32: Train Loss: 0.000743, Validation Loss: 0.000526\n",
      " Epoch 33: Train Loss: 0.000738, Validation Loss: 0.000538\n",
      " Epoch 34: Train Loss: 0.000734, Validation Loss: 0.000579\n",
      " Epoch 35: Train Loss: 0.000729, Validation Loss: 0.000568\n",
      " Epoch 36: Train Loss: 0.000723, Validation Loss: 0.000586\n",
      " Epoch 37: Train Loss: 0.000721, Validation Loss: 0.000543\n",
      " Epoch 38: Train Loss: 0.000715, Validation Loss: 0.000568\n",
      " Epoch 39: Train Loss: 0.000711, Validation Loss: 0.000592\n",
      " Epoch 40: Train Loss: 0.000708, Validation Loss: 0.000601\n",
      " Epoch 41: Train Loss: 0.000704, Validation Loss: 0.000615\n",
      " Epoch 42: Train Loss: 0.000699, Validation Loss: 0.000598\n",
      " Epoch 43: Train Loss: 0.000695, Validation Loss: 0.000614\n",
      " Epoch 44: Train Loss: 0.000691, Validation Loss: 0.000640\n",
      " Epoch 45: Train Loss: 0.000687, Validation Loss: 0.000606\n",
      " Epoch 46: Train Loss: 0.000684, Validation Loss: 0.000617\n",
      " Epoch 47: Train Loss: 0.000679, Validation Loss: 0.000668\n",
      " Epoch 48: Train Loss: 0.000676, Validation Loss: 0.000667\n",
      " Epoch 49: Train Loss: 0.000672, Validation Loss: 0.000646\n",
      "Early stopping at epoch 49 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015799, Validation Loss: 0.021319\n",
      " Epoch 2: Train Loss: 0.003393, Validation Loss: 0.002561\n",
      " Epoch 3: Train Loss: 0.002285, Validation Loss: 0.001559\n",
      " Epoch 4: Train Loss: 0.001878, Validation Loss: 0.001221\n",
      " Epoch 5: Train Loss: 0.001647, Validation Loss: 0.001065\n",
      " Epoch 6: Train Loss: 0.001501, Validation Loss: 0.001024\n",
      " Epoch 7: Train Loss: 0.001397, Validation Loss: 0.000918\n",
      " Epoch 8: Train Loss: 0.001317, Validation Loss: 0.000867\n",
      " Epoch 9: Train Loss: 0.001254, Validation Loss: 0.000837\n",
      " Epoch 10: Train Loss: 0.001200, Validation Loss: 0.000803\n",
      " Epoch 11: Train Loss: 0.001176, Validation Loss: 0.000818\n",
      " Epoch 12: Train Loss: 0.001121, Validation Loss: 0.000752\n",
      " Epoch 13: Train Loss: 0.001083, Validation Loss: 0.000725\n",
      " Epoch 14: Train Loss: 0.001049, Validation Loss: 0.000729\n",
      " Epoch 15: Train Loss: 0.001018, Validation Loss: 0.000682\n",
      " Epoch 16: Train Loss: 0.000994, Validation Loss: 0.000674\n",
      " Epoch 17: Train Loss: 0.000970, Validation Loss: 0.000647\n",
      " Epoch 18: Train Loss: 0.000947, Validation Loss: 0.000621\n",
      " Epoch 19: Train Loss: 0.000930, Validation Loss: 0.000619\n",
      " Epoch 20: Train Loss: 0.000906, Validation Loss: 0.000595\n",
      " Epoch 21: Train Loss: 0.000890, Validation Loss: 0.000601\n",
      " Epoch 22: Train Loss: 0.000874, Validation Loss: 0.000570\n",
      " Epoch 23: Train Loss: 0.000856, Validation Loss: 0.000559\n",
      " Epoch 24: Train Loss: 0.000842, Validation Loss: 0.000566\n",
      " Epoch 25: Train Loss: 0.000831, Validation Loss: 0.000551\n",
      " Epoch 26: Train Loss: 0.000815, Validation Loss: 0.000529\n",
      " Epoch 27: Train Loss: 0.000803, Validation Loss: 0.000526\n",
      " Epoch 28: Train Loss: 0.000790, Validation Loss: 0.000529\n",
      " Epoch 29: Train Loss: 0.000779, Validation Loss: 0.000519\n",
      " Epoch 30: Train Loss: 0.000768, Validation Loss: 0.000537\n",
      " Epoch 31: Train Loss: 0.000758, Validation Loss: 0.000526\n",
      " Epoch 32: Train Loss: 0.000752, Validation Loss: 0.000529\n",
      " Epoch 33: Train Loss: 0.000747, Validation Loss: 0.000540\n",
      " Epoch 34: Train Loss: 0.000744, Validation Loss: 0.000547\n",
      " Epoch 35: Train Loss: 0.000739, Validation Loss: 0.000543\n",
      " Epoch 36: Train Loss: 0.000734, Validation Loss: 0.000539\n",
      " Epoch 37: Train Loss: 0.000729, Validation Loss: 0.000525\n",
      " Epoch 38: Train Loss: 0.000724, Validation Loss: 0.000573\n",
      " Epoch 39: Train Loss: 0.000721, Validation Loss: 0.000533\n",
      " Epoch 40: Train Loss: 0.000716, Validation Loss: 0.000574\n",
      " Epoch 41: Train Loss: 0.000712, Validation Loss: 0.000564\n",
      " Epoch 42: Train Loss: 0.000707, Validation Loss: 0.000593\n",
      " Epoch 43: Train Loss: 0.000703, Validation Loss: 0.000555\n",
      " Epoch 44: Train Loss: 0.000699, Validation Loss: 0.000567\n",
      " Epoch 45: Train Loss: 0.000695, Validation Loss: 0.000558\n",
      " Epoch 46: Train Loss: 0.000691, Validation Loss: 0.000565\n",
      " Epoch 47: Train Loss: 0.000687, Validation Loss: 0.000589\n",
      " Epoch 48: Train Loss: 0.000683, Validation Loss: 0.000567\n",
      " Epoch 49: Train Loss: 0.000679, Validation Loss: 0.000590\n",
      "Early stopping at epoch 49 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.021496, Validation Loss: 0.017923\n",
      " Epoch 2: Train Loss: 0.004638, Validation Loss: 0.003417\n",
      " Epoch 3: Train Loss: 0.003075, Validation Loss: 0.002050\n",
      " Epoch 4: Train Loss: 0.002225, Validation Loss: 0.001411\n",
      " Epoch 5: Train Loss: 0.001858, Validation Loss: 0.001199\n",
      " Epoch 6: Train Loss: 0.001665, Validation Loss: 0.001073\n",
      " Epoch 7: Train Loss: 0.001543, Validation Loss: 0.001001\n",
      " Epoch 8: Train Loss: 0.001452, Validation Loss: 0.000961\n",
      " Epoch 9: Train Loss: 0.001382, Validation Loss: 0.000919\n",
      " Epoch 10: Train Loss: 0.001328, Validation Loss: 0.000892\n",
      " Epoch 11: Train Loss: 0.001283, Validation Loss: 0.000961\n",
      " Epoch 12: Train Loss: 0.001259, Validation Loss: 0.000817\n",
      " Epoch 13: Train Loss: 0.001200, Validation Loss: 0.000796\n",
      " Epoch 14: Train Loss: 0.001164, Validation Loss: 0.000773\n",
      " Epoch 15: Train Loss: 0.001131, Validation Loss: 0.000770\n",
      " Epoch 16: Train Loss: 0.001102, Validation Loss: 0.000734\n",
      " Epoch 17: Train Loss: 0.001073, Validation Loss: 0.000705\n",
      " Epoch 18: Train Loss: 0.001046, Validation Loss: 0.000686\n",
      " Epoch 19: Train Loss: 0.001023, Validation Loss: 0.000679\n",
      " Epoch 20: Train Loss: 0.001007, Validation Loss: 0.000711\n",
      " Epoch 21: Train Loss: 0.000979, Validation Loss: 0.000639\n",
      " Epoch 22: Train Loss: 0.000954, Validation Loss: 0.000628\n",
      " Epoch 23: Train Loss: 0.000947, Validation Loss: 0.000623\n",
      " Epoch 24: Train Loss: 0.000918, Validation Loss: 0.000605\n",
      " Epoch 25: Train Loss: 0.000897, Validation Loss: 0.000604\n",
      " Epoch 26: Train Loss: 0.000879, Validation Loss: 0.000620\n",
      " Epoch 27: Train Loss: 0.000865, Validation Loss: 0.000610\n",
      " Epoch 28: Train Loss: 0.000851, Validation Loss: 0.000597\n",
      " Epoch 29: Train Loss: 0.000840, Validation Loss: 0.000593\n",
      " Epoch 30: Train Loss: 0.000822, Validation Loss: 0.000565\n",
      " Epoch 31: Train Loss: 0.000814, Validation Loss: 0.000567\n",
      " Epoch 32: Train Loss: 0.000804, Validation Loss: 0.000581\n",
      " Epoch 33: Train Loss: 0.000799, Validation Loss: 0.000578\n",
      " Epoch 34: Train Loss: 0.000792, Validation Loss: 0.000562\n",
      " Epoch 35: Train Loss: 0.000785, Validation Loss: 0.000588\n",
      " Epoch 36: Train Loss: 0.000779, Validation Loss: 0.000614\n",
      " Epoch 37: Train Loss: 0.000774, Validation Loss: 0.000605\n",
      " Epoch 38: Train Loss: 0.000766, Validation Loss: 0.000609\n",
      " Epoch 39: Train Loss: 0.000760, Validation Loss: 0.000618\n",
      " Epoch 40: Train Loss: 0.000755, Validation Loss: 0.000604\n",
      " Epoch 41: Train Loss: 0.000749, Validation Loss: 0.000606\n",
      " Epoch 42: Train Loss: 0.000743, Validation Loss: 0.000616\n",
      " Epoch 43: Train Loss: 0.000737, Validation Loss: 0.000633\n",
      " Epoch 44: Train Loss: 0.000731, Validation Loss: 0.000642\n",
      " Epoch 45: Train Loss: 0.000726, Validation Loss: 0.000674\n",
      " Epoch 46: Train Loss: 0.000720, Validation Loss: 0.000633\n",
      " Epoch 47: Train Loss: 0.000715, Validation Loss: 0.000626\n",
      " Epoch 48: Train Loss: 0.000710, Validation Loss: 0.000655\n",
      " Epoch 49: Train Loss: 0.000706, Validation Loss: 0.000681\n",
      " Epoch 50: Train Loss: 0.000701, Validation Loss: 0.000680\n",
      " Epoch 51: Train Loss: 0.000695, Validation Loss: 0.000684\n",
      " Epoch 52: Train Loss: 0.000693, Validation Loss: 0.000728\n",
      " Epoch 53: Train Loss: 0.000688, Validation Loss: 0.000682\n",
      " Epoch 54: Train Loss: 0.000683, Validation Loss: 0.000717\n",
      "Early stopping at epoch 54 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.017851, Validation Loss: 0.029400\n",
      " Epoch 2: Train Loss: 0.004262, Validation Loss: 0.015063\n",
      " Epoch 3: Train Loss: 0.002205, Validation Loss: 0.001466\n",
      " Epoch 4: Train Loss: 0.001597, Validation Loss: 0.001083\n",
      " Epoch 5: Train Loss: 0.001394, Validation Loss: 0.001023\n",
      " Epoch 6: Train Loss: 0.001243, Validation Loss: 0.000858\n",
      " Epoch 7: Train Loss: 0.001145, Validation Loss: 0.000765\n",
      " Epoch 8: Train Loss: 0.001075, Validation Loss: 0.000731\n",
      " Epoch 9: Train Loss: 0.001027, Validation Loss: 0.000701\n",
      " Epoch 10: Train Loss: 0.000978, Validation Loss: 0.000685\n",
      " Epoch 11: Train Loss: 0.000932, Validation Loss: 0.000668\n",
      " Epoch 12: Train Loss: 0.000913, Validation Loss: 0.000666\n",
      " Epoch 13: Train Loss: 0.000876, Validation Loss: 0.000602\n",
      " Epoch 14: Train Loss: 0.000847, Validation Loss: 0.000556\n",
      " Epoch 15: Train Loss: 0.000814, Validation Loss: 0.000566\n",
      " Epoch 16: Train Loss: 0.000799, Validation Loss: 0.000585\n",
      " Epoch 17: Train Loss: 0.000791, Validation Loss: 0.000588\n",
      " Epoch 18: Train Loss: 0.000766, Validation Loss: 0.000513\n",
      " Epoch 19: Train Loss: 0.000744, Validation Loss: 0.000533\n",
      " Epoch 20: Train Loss: 0.000739, Validation Loss: 0.000536\n",
      " Epoch 21: Train Loss: 0.000725, Validation Loss: 0.000493\n",
      " Epoch 22: Train Loss: 0.000709, Validation Loss: 0.000517\n",
      " Epoch 23: Train Loss: 0.000690, Validation Loss: 0.000497\n",
      " Epoch 24: Train Loss: 0.000699, Validation Loss: 0.000478\n",
      " Epoch 25: Train Loss: 0.000676, Validation Loss: 0.000478\n",
      " Epoch 26: Train Loss: 0.000660, Validation Loss: 0.000460\n",
      " Epoch 27: Train Loss: 0.000645, Validation Loss: 0.000453\n",
      " Epoch 28: Train Loss: 0.000648, Validation Loss: 0.000465\n",
      " Epoch 29: Train Loss: 0.000638, Validation Loss: 0.000462\n",
      " Epoch 30: Train Loss: 0.000630, Validation Loss: 0.000437\n",
      " Epoch 31: Train Loss: 0.000614, Validation Loss: 0.000459\n",
      " Epoch 32: Train Loss: 0.000611, Validation Loss: 0.000479\n",
      " Epoch 33: Train Loss: 0.000612, Validation Loss: 0.000434\n",
      " Epoch 34: Train Loss: 0.000609, Validation Loss: 0.000498\n",
      " Epoch 35: Train Loss: 0.000607, Validation Loss: 0.000437\n",
      " Epoch 36: Train Loss: 0.000594, Validation Loss: 0.000469\n",
      " Epoch 37: Train Loss: 0.000590, Validation Loss: 0.000466\n",
      " Epoch 38: Train Loss: 0.000586, Validation Loss: 0.000472\n",
      " Epoch 39: Train Loss: 0.000584, Validation Loss: 0.000459\n",
      " Epoch 40: Train Loss: 0.000585, Validation Loss: 0.000435\n",
      " Epoch 41: Train Loss: 0.000576, Validation Loss: 0.000438\n",
      " Epoch 42: Train Loss: 0.000574, Validation Loss: 0.000487\n",
      " Epoch 43: Train Loss: 0.000568, Validation Loss: 0.000441\n",
      " Epoch 44: Train Loss: 0.000568, Validation Loss: 0.000431\n",
      " Epoch 45: Train Loss: 0.000563, Validation Loss: 0.000492\n",
      " Epoch 46: Train Loss: 0.000563, Validation Loss: 0.000410\n",
      " Epoch 47: Train Loss: 0.000556, Validation Loss: 0.000458\n",
      " Epoch 48: Train Loss: 0.000556, Validation Loss: 0.000435\n",
      " Epoch 49: Train Loss: 0.000550, Validation Loss: 0.000488\n",
      " Epoch 50: Train Loss: 0.000548, Validation Loss: 0.000436\n",
      " Epoch 51: Train Loss: 0.000543, Validation Loss: 0.000447\n",
      " Epoch 52: Train Loss: 0.000546, Validation Loss: 0.000481\n",
      " Epoch 53: Train Loss: 0.000536, Validation Loss: 0.000442\n",
      " Epoch 54: Train Loss: 0.000537, Validation Loss: 0.000481\n",
      " Epoch 55: Train Loss: 0.000534, Validation Loss: 0.000482\n",
      " Epoch 56: Train Loss: 0.000532, Validation Loss: 0.000501\n",
      " Epoch 57: Train Loss: 0.000528, Validation Loss: 0.000433\n",
      " Epoch 58: Train Loss: 0.000530, Validation Loss: 0.000399\n",
      " Epoch 59: Train Loss: 0.000521, Validation Loss: 0.000410\n",
      " Epoch 60: Train Loss: 0.000525, Validation Loss: 0.000416\n",
      " Epoch 61: Train Loss: 0.000516, Validation Loss: 0.000452\n",
      " Epoch 62: Train Loss: 0.000513, Validation Loss: 0.000460\n",
      " Epoch 63: Train Loss: 0.000511, Validation Loss: 0.000442\n",
      " Epoch 64: Train Loss: 0.000509, Validation Loss: 0.000463\n",
      " Epoch 65: Train Loss: 0.000512, Validation Loss: 0.000514\n",
      " Epoch 66: Train Loss: 0.000512, Validation Loss: 0.000451\n",
      " Epoch 67: Train Loss: 0.000505, Validation Loss: 0.000444\n",
      " Epoch 68: Train Loss: 0.000505, Validation Loss: 0.000484\n",
      " Epoch 69: Train Loss: 0.000508, Validation Loss: 0.000443\n",
      " Epoch 70: Train Loss: 0.000504, Validation Loss: 0.000496\n",
      " Epoch 71: Train Loss: 0.000505, Validation Loss: 0.000473\n",
      " Epoch 72: Train Loss: 0.000502, Validation Loss: 0.000443\n",
      " Epoch 73: Train Loss: 0.000499, Validation Loss: 0.000441\n",
      " Epoch 74: Train Loss: 0.000497, Validation Loss: 0.000418\n",
      " Epoch 75: Train Loss: 0.000497, Validation Loss: 0.000505\n",
      " Epoch 76: Train Loss: 0.000495, Validation Loss: 0.000466\n",
      " Epoch 77: Train Loss: 0.000493, Validation Loss: 0.000505\n",
      " Epoch 78: Train Loss: 0.000494, Validation Loss: 0.000477\n",
      "Early stopping at epoch 78 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.022347, Validation Loss: 0.029257\n",
      " Epoch 2: Train Loss: 0.006347, Validation Loss: 0.020883\n",
      " Epoch 3: Train Loss: 0.003423, Validation Loss: 0.003295\n",
      " Epoch 4: Train Loss: 0.002169, Validation Loss: 0.001544\n",
      " Epoch 5: Train Loss: 0.001726, Validation Loss: 0.001282\n",
      " Epoch 6: Train Loss: 0.001473, Validation Loss: 0.001056\n",
      " Epoch 7: Train Loss: 0.001322, Validation Loss: 0.001012\n",
      " Epoch 8: Train Loss: 0.001229, Validation Loss: 0.000888\n",
      " Epoch 9: Train Loss: 0.001196, Validation Loss: 0.000807\n",
      " Epoch 10: Train Loss: 0.001104, Validation Loss: 0.000775\n",
      " Epoch 11: Train Loss: 0.001043, Validation Loss: 0.000709\n",
      " Epoch 12: Train Loss: 0.000991, Validation Loss: 0.000694\n",
      " Epoch 13: Train Loss: 0.000981, Validation Loss: 0.000719\n",
      " Epoch 14: Train Loss: 0.000942, Validation Loss: 0.000664\n",
      " Epoch 15: Train Loss: 0.000909, Validation Loss: 0.000681\n",
      " Epoch 16: Train Loss: 0.000880, Validation Loss: 0.000658\n",
      " Epoch 17: Train Loss: 0.000852, Validation Loss: 0.000600\n",
      " Epoch 18: Train Loss: 0.000846, Validation Loss: 0.001194\n",
      " Epoch 19: Train Loss: 0.000824, Validation Loss: 0.000620\n",
      " Epoch 20: Train Loss: 0.000798, Validation Loss: 0.000555\n",
      " Epoch 21: Train Loss: 0.000781, Validation Loss: 0.000549\n",
      " Epoch 22: Train Loss: 0.000769, Validation Loss: 0.000534\n",
      " Epoch 23: Train Loss: 0.000759, Validation Loss: 0.000549\n",
      " Epoch 24: Train Loss: 0.000738, Validation Loss: 0.000542\n",
      " Epoch 25: Train Loss: 0.000732, Validation Loss: 0.000505\n",
      " Epoch 26: Train Loss: 0.000745, Validation Loss: 0.000508\n",
      " Epoch 27: Train Loss: 0.000711, Validation Loss: 0.000544\n",
      " Epoch 28: Train Loss: 0.000700, Validation Loss: 0.000490\n",
      " Epoch 29: Train Loss: 0.000702, Validation Loss: 0.000492\n",
      " Epoch 30: Train Loss: 0.000682, Validation Loss: 0.000481\n",
      " Epoch 31: Train Loss: 0.000670, Validation Loss: 0.000470\n",
      " Epoch 32: Train Loss: 0.000663, Validation Loss: 0.000472\n",
      " Epoch 33: Train Loss: 0.000655, Validation Loss: 0.000507\n",
      " Epoch 34: Train Loss: 0.000653, Validation Loss: 0.000479\n",
      " Epoch 35: Train Loss: 0.000646, Validation Loss: 0.000487\n",
      " Epoch 36: Train Loss: 0.000650, Validation Loss: 0.000498\n",
      " Epoch 37: Train Loss: 0.000641, Validation Loss: 0.000467\n",
      " Epoch 38: Train Loss: 0.000636, Validation Loss: 0.000523\n",
      " Epoch 39: Train Loss: 0.000637, Validation Loss: 0.000448\n",
      " Epoch 40: Train Loss: 0.000629, Validation Loss: 0.000474\n",
      " Epoch 41: Train Loss: 0.000623, Validation Loss: 0.000439\n",
      " Epoch 42: Train Loss: 0.000621, Validation Loss: 0.000458\n",
      " Epoch 43: Train Loss: 0.000624, Validation Loss: 0.000443\n",
      " Epoch 44: Train Loss: 0.000618, Validation Loss: 0.000474\n",
      " Epoch 45: Train Loss: 0.000608, Validation Loss: 0.000493\n",
      " Epoch 46: Train Loss: 0.000613, Validation Loss: 0.000447\n",
      " Epoch 47: Train Loss: 0.000613, Validation Loss: 0.000574\n",
      " Epoch 48: Train Loss: 0.000611, Validation Loss: 0.000506\n",
      " Epoch 49: Train Loss: 0.000604, Validation Loss: 0.000438\n",
      " Epoch 50: Train Loss: 0.000604, Validation Loss: 0.000455\n",
      " Epoch 51: Train Loss: 0.000595, Validation Loss: 0.000503\n",
      " Epoch 52: Train Loss: 0.000599, Validation Loss: 0.000437\n",
      " Epoch 53: Train Loss: 0.000587, Validation Loss: 0.000448\n",
      " Epoch 54: Train Loss: 0.000584, Validation Loss: 0.000491\n",
      " Epoch 55: Train Loss: 0.000585, Validation Loss: 0.000516\n",
      " Epoch 56: Train Loss: 0.000624, Validation Loss: 0.000528\n",
      " Epoch 57: Train Loss: 0.000609, Validation Loss: 0.000463\n",
      " Epoch 58: Train Loss: 0.000590, Validation Loss: 0.000483\n",
      " Epoch 59: Train Loss: 0.000581, Validation Loss: 0.000425\n",
      " Epoch 60: Train Loss: 0.000575, Validation Loss: 0.000469\n",
      " Epoch 61: Train Loss: 0.000564, Validation Loss: 0.000439\n",
      " Epoch 62: Train Loss: 0.000567, Validation Loss: 0.000432\n",
      " Epoch 63: Train Loss: 0.000563, Validation Loss: 0.000431\n",
      " Epoch 64: Train Loss: 0.000560, Validation Loss: 0.000436\n",
      " Epoch 65: Train Loss: 0.000560, Validation Loss: 0.000413\n",
      " Epoch 66: Train Loss: 0.000561, Validation Loss: 0.000467\n",
      " Epoch 67: Train Loss: 0.000555, Validation Loss: 0.000430\n",
      " Epoch 68: Train Loss: 0.000557, Validation Loss: 0.000460\n",
      " Epoch 69: Train Loss: 0.000559, Validation Loss: 0.000470\n",
      " Epoch 70: Train Loss: 0.000551, Validation Loss: 0.000519\n",
      " Epoch 71: Train Loss: 0.000550, Validation Loss: 0.000445\n",
      " Epoch 72: Train Loss: 0.000549, Validation Loss: 0.000410\n",
      " Epoch 73: Train Loss: 0.000547, Validation Loss: 0.000462\n",
      " Epoch 74: Train Loss: 0.000546, Validation Loss: 0.000423\n",
      " Epoch 75: Train Loss: 0.000554, Validation Loss: 0.000423\n",
      " Epoch 76: Train Loss: 0.000544, Validation Loss: 0.000428\n",
      " Epoch 77: Train Loss: 0.000541, Validation Loss: 0.000437\n",
      " Epoch 78: Train Loss: 0.000541, Validation Loss: 0.000431\n",
      " Epoch 79: Train Loss: 0.000539, Validation Loss: 0.000474\n",
      " Epoch 80: Train Loss: 0.000537, Validation Loss: 0.000411\n",
      " Epoch 81: Train Loss: 0.000534, Validation Loss: 0.000451\n",
      " Epoch 82: Train Loss: 0.000534, Validation Loss: 0.000417\n",
      " Epoch 83: Train Loss: 0.000535, Validation Loss: 0.000434\n",
      " Epoch 84: Train Loss: 0.000541, Validation Loss: 0.000421\n",
      " Epoch 85: Train Loss: 0.000534, Validation Loss: 0.000452\n",
      " Epoch 86: Train Loss: 0.000529, Validation Loss: 0.000427\n",
      " Epoch 87: Train Loss: 0.000527, Validation Loss: 0.000443\n",
      " Epoch 88: Train Loss: 0.000525, Validation Loss: 0.000487\n",
      " Epoch 89: Train Loss: 0.000527, Validation Loss: 0.000478\n",
      " Epoch 90: Train Loss: 0.000524, Validation Loss: 0.000471\n",
      " Epoch 91: Train Loss: 0.000521, Validation Loss: 0.000453\n",
      " Epoch 92: Train Loss: 0.000517, Validation Loss: 0.000440\n",
      "Early stopping at epoch 92 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016616, Validation Loss: 0.026037\n",
      " Epoch 2: Train Loss: 0.004983, Validation Loss: 0.005715\n",
      " Epoch 3: Train Loss: 0.002893, Validation Loss: 0.006036\n",
      " Epoch 4: Train Loss: 0.001799, Validation Loss: 0.001330\n",
      " Epoch 5: Train Loss: 0.001438, Validation Loss: 0.000978\n",
      " Epoch 6: Train Loss: 0.001267, Validation Loss: 0.000838\n",
      " Epoch 7: Train Loss: 0.001160, Validation Loss: 0.000745\n",
      " Epoch 8: Train Loss: 0.001083, Validation Loss: 0.000707\n",
      " Epoch 9: Train Loss: 0.001016, Validation Loss: 0.000647\n",
      " Epoch 10: Train Loss: 0.001004, Validation Loss: 0.000660\n",
      " Epoch 11: Train Loss: 0.000921, Validation Loss: 0.000607\n",
      " Epoch 12: Train Loss: 0.000880, Validation Loss: 0.000582\n",
      " Epoch 13: Train Loss: 0.000850, Validation Loss: 0.000582\n",
      " Epoch 14: Train Loss: 0.000835, Validation Loss: 0.000579\n",
      " Epoch 15: Train Loss: 0.000794, Validation Loss: 0.000515\n",
      " Epoch 16: Train Loss: 0.000781, Validation Loss: 0.000506\n",
      " Epoch 17: Train Loss: 0.000755, Validation Loss: 0.000497\n",
      " Epoch 18: Train Loss: 0.000736, Validation Loss: 0.000507\n",
      " Epoch 19: Train Loss: 0.000721, Validation Loss: 0.000496\n",
      " Epoch 20: Train Loss: 0.000709, Validation Loss: 0.000492\n",
      " Epoch 21: Train Loss: 0.000692, Validation Loss: 0.000516\n",
      " Epoch 22: Train Loss: 0.000679, Validation Loss: 0.000502\n",
      " Epoch 23: Train Loss: 0.000668, Validation Loss: 0.000493\n",
      " Epoch 24: Train Loss: 0.000660, Validation Loss: 0.000522\n",
      " Epoch 25: Train Loss: 0.000647, Validation Loss: 0.000466\n",
      " Epoch 26: Train Loss: 0.000637, Validation Loss: 0.000444\n",
      " Epoch 27: Train Loss: 0.000629, Validation Loss: 0.000706\n",
      " Epoch 28: Train Loss: 0.000619, Validation Loss: 0.000480\n",
      " Epoch 29: Train Loss: 0.000610, Validation Loss: 0.000512\n",
      " Epoch 30: Train Loss: 0.000604, Validation Loss: 0.000516\n",
      " Epoch 31: Train Loss: 0.000592, Validation Loss: 0.000481\n",
      " Epoch 32: Train Loss: 0.000587, Validation Loss: 0.000505\n",
      " Epoch 33: Train Loss: 0.000583, Validation Loss: 0.000517\n",
      " Epoch 34: Train Loss: 0.000580, Validation Loss: 0.000505\n",
      " Epoch 35: Train Loss: 0.000575, Validation Loss: 0.000506\n",
      " Epoch 36: Train Loss: 0.000573, Validation Loss: 0.000469\n",
      " Epoch 37: Train Loss: 0.000574, Validation Loss: 0.000455\n",
      " Epoch 38: Train Loss: 0.000566, Validation Loss: 0.000442\n",
      " Epoch 39: Train Loss: 0.000563, Validation Loss: 0.000496\n",
      " Epoch 40: Train Loss: 0.000560, Validation Loss: 0.000518\n",
      " Epoch 41: Train Loss: 0.000556, Validation Loss: 0.000464\n",
      " Epoch 42: Train Loss: 0.000553, Validation Loss: 0.000478\n",
      " Epoch 43: Train Loss: 0.000550, Validation Loss: 0.000452\n",
      " Epoch 44: Train Loss: 0.000547, Validation Loss: 0.000494\n",
      " Epoch 45: Train Loss: 0.000543, Validation Loss: 0.000479\n",
      " Epoch 46: Train Loss: 0.000541, Validation Loss: 0.000546\n",
      " Epoch 47: Train Loss: 0.000539, Validation Loss: 0.000570\n",
      " Epoch 48: Train Loss: 0.000535, Validation Loss: 0.000562\n",
      " Epoch 49: Train Loss: 0.000534, Validation Loss: 0.000518\n",
      " Epoch 50: Train Loss: 0.000529, Validation Loss: 0.000471\n",
      " Epoch 51: Train Loss: 0.000526, Validation Loss: 0.000500\n",
      " Epoch 52: Train Loss: 0.000524, Validation Loss: 0.000554\n",
      " Epoch 53: Train Loss: 0.000521, Validation Loss: 0.000524\n",
      " Epoch 54: Train Loss: 0.000520, Validation Loss: 0.000509\n",
      " Epoch 55: Train Loss: 0.000517, Validation Loss: 0.000495\n",
      " Epoch 56: Train Loss: 0.000512, Validation Loss: 0.000575\n",
      " Epoch 57: Train Loss: 0.000513, Validation Loss: 0.000575\n",
      " Epoch 58: Train Loss: 0.000512, Validation Loss: 0.000591\n",
      "Early stopping at epoch 58 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.019321, Validation Loss: 0.016324\n",
      " Epoch 2: Train Loss: 0.005691, Validation Loss: 0.004294\n",
      " Epoch 3: Train Loss: 0.003345, Validation Loss: 0.002339\n",
      " Epoch 4: Train Loss: 0.002448, Validation Loss: 0.001944\n",
      " Epoch 5: Train Loss: 0.001899, Validation Loss: 0.001329\n",
      " Epoch 6: Train Loss: 0.001405, Validation Loss: 0.000974\n",
      " Epoch 7: Train Loss: 0.001301, Validation Loss: 0.000908\n",
      " Epoch 8: Train Loss: 0.001166, Validation Loss: 0.000850\n",
      " Epoch 9: Train Loss: 0.001097, Validation Loss: 0.000794\n",
      " Epoch 10: Train Loss: 0.001047, Validation Loss: 0.000752\n",
      " Epoch 11: Train Loss: 0.001001, Validation Loss: 0.000733\n",
      " Epoch 12: Train Loss: 0.000965, Validation Loss: 0.000677\n",
      " Epoch 13: Train Loss: 0.000929, Validation Loss: 0.000656\n",
      " Epoch 14: Train Loss: 0.000895, Validation Loss: 0.000640\n",
      " Epoch 15: Train Loss: 0.000870, Validation Loss: 0.000608\n",
      " Epoch 16: Train Loss: 0.000856, Validation Loss: 0.000600\n",
      " Epoch 17: Train Loss: 0.000825, Validation Loss: 0.000601\n",
      " Epoch 18: Train Loss: 0.000800, Validation Loss: 0.000564\n",
      " Epoch 19: Train Loss: 0.000783, Validation Loss: 0.000558\n",
      " Epoch 20: Train Loss: 0.000767, Validation Loss: 0.000551\n",
      " Epoch 21: Train Loss: 0.000749, Validation Loss: 0.000559\n",
      " Epoch 22: Train Loss: 0.000737, Validation Loss: 0.000529\n",
      " Epoch 23: Train Loss: 0.000733, Validation Loss: 0.000528\n",
      " Epoch 24: Train Loss: 0.000714, Validation Loss: 0.000507\n",
      " Epoch 25: Train Loss: 0.000700, Validation Loss: 0.000498\n",
      " Epoch 26: Train Loss: 0.000685, Validation Loss: 0.000489\n",
      " Epoch 27: Train Loss: 0.000674, Validation Loss: 0.000492\n",
      " Epoch 28: Train Loss: 0.000666, Validation Loss: 0.000478\n",
      " Epoch 29: Train Loss: 0.000656, Validation Loss: 0.000475\n",
      " Epoch 30: Train Loss: 0.000646, Validation Loss: 0.000477\n",
      " Epoch 31: Train Loss: 0.000637, Validation Loss: 0.000462\n",
      " Epoch 32: Train Loss: 0.000633, Validation Loss: 0.000472\n",
      " Epoch 33: Train Loss: 0.000629, Validation Loss: 0.000466\n",
      " Epoch 34: Train Loss: 0.000624, Validation Loss: 0.000461\n",
      " Epoch 35: Train Loss: 0.000620, Validation Loss: 0.000458\n",
      " Epoch 36: Train Loss: 0.000616, Validation Loss: 0.000448\n",
      " Epoch 37: Train Loss: 0.000613, Validation Loss: 0.000459\n",
      " Epoch 38: Train Loss: 0.000608, Validation Loss: 0.000452\n",
      " Epoch 39: Train Loss: 0.000605, Validation Loss: 0.000447\n",
      " Epoch 40: Train Loss: 0.000601, Validation Loss: 0.000451\n",
      " Epoch 41: Train Loss: 0.000598, Validation Loss: 0.000443\n",
      " Epoch 42: Train Loss: 0.000594, Validation Loss: 0.000460\n",
      " Epoch 43: Train Loss: 0.000590, Validation Loss: 0.000448\n",
      " Epoch 44: Train Loss: 0.000587, Validation Loss: 0.000444\n",
      " Epoch 45: Train Loss: 0.000584, Validation Loss: 0.000455\n",
      " Epoch 46: Train Loss: 0.000579, Validation Loss: 0.000437\n",
      " Epoch 47: Train Loss: 0.000576, Validation Loss: 0.000449\n",
      " Epoch 48: Train Loss: 0.000575, Validation Loss: 0.000446\n",
      " Epoch 49: Train Loss: 0.000570, Validation Loss: 0.000433\n",
      " Epoch 50: Train Loss: 0.000567, Validation Loss: 0.000452\n",
      " Epoch 51: Train Loss: 0.000561, Validation Loss: 0.000463\n",
      " Epoch 52: Train Loss: 0.000558, Validation Loss: 0.000432\n",
      " Epoch 53: Train Loss: 0.000555, Validation Loss: 0.000455\n",
      " Epoch 54: Train Loss: 0.000553, Validation Loss: 0.000437\n",
      " Epoch 55: Train Loss: 0.000549, Validation Loss: 0.000447\n",
      " Epoch 56: Train Loss: 0.000547, Validation Loss: 0.000442\n",
      " Epoch 57: Train Loss: 0.000544, Validation Loss: 0.000438\n",
      " Epoch 58: Train Loss: 0.000541, Validation Loss: 0.000450\n",
      " Epoch 59: Train Loss: 0.000538, Validation Loss: 0.000472\n",
      " Epoch 60: Train Loss: 0.000535, Validation Loss: 0.000464\n",
      " Epoch 61: Train Loss: 0.000531, Validation Loss: 0.000456\n",
      " Epoch 62: Train Loss: 0.000530, Validation Loss: 0.000473\n",
      " Epoch 63: Train Loss: 0.000528, Validation Loss: 0.000464\n",
      " Epoch 64: Train Loss: 0.000526, Validation Loss: 0.000447\n",
      " Epoch 65: Train Loss: 0.000525, Validation Loss: 0.000467\n",
      " Epoch 66: Train Loss: 0.000523, Validation Loss: 0.000470\n",
      " Epoch 67: Train Loss: 0.000522, Validation Loss: 0.000474\n",
      " Epoch 68: Train Loss: 0.000521, Validation Loss: 0.000451\n",
      " Epoch 69: Train Loss: 0.000519, Validation Loss: 0.000473\n",
      " Epoch 70: Train Loss: 0.000519, Validation Loss: 0.000481\n",
      " Epoch 71: Train Loss: 0.000517, Validation Loss: 0.000465\n",
      " Epoch 72: Train Loss: 0.000515, Validation Loss: 0.000472\n",
      "Early stopping at epoch 72 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.021752, Validation Loss: 0.018197\n",
      " Epoch 2: Train Loss: 0.006159, Validation Loss: 0.005203\n",
      " Epoch 3: Train Loss: 0.003791, Validation Loss: 0.002905\n",
      " Epoch 4: Train Loss: 0.002792, Validation Loss: 0.002076\n",
      " Epoch 5: Train Loss: 0.002283, Validation Loss: 0.001810\n",
      " Epoch 6: Train Loss: 0.002049, Validation Loss: 0.001268\n",
      " Epoch 7: Train Loss: 0.001395, Validation Loss: 0.000981\n",
      " Epoch 8: Train Loss: 0.001210, Validation Loss: 0.000871\n",
      " Epoch 9: Train Loss: 0.001124, Validation Loss: 0.000824\n",
      " Epoch 10: Train Loss: 0.001086, Validation Loss: 0.000747\n",
      " Epoch 11: Train Loss: 0.001015, Validation Loss: 0.000719\n",
      " Epoch 12: Train Loss: 0.000977, Validation Loss: 0.000711\n",
      " Epoch 13: Train Loss: 0.000936, Validation Loss: 0.000664\n",
      " Epoch 14: Train Loss: 0.000917, Validation Loss: 0.000641\n",
      " Epoch 15: Train Loss: 0.000884, Validation Loss: 0.000623\n",
      " Epoch 16: Train Loss: 0.000859, Validation Loss: 0.000615\n",
      " Epoch 17: Train Loss: 0.000840, Validation Loss: 0.000585\n",
      " Epoch 18: Train Loss: 0.000814, Validation Loss: 0.000578\n",
      " Epoch 19: Train Loss: 0.000792, Validation Loss: 0.000572\n",
      " Epoch 20: Train Loss: 0.000798, Validation Loss: 0.000555\n",
      " Epoch 21: Train Loss: 0.000766, Validation Loss: 0.000540\n",
      " Epoch 22: Train Loss: 0.000748, Validation Loss: 0.000525\n",
      " Epoch 23: Train Loss: 0.000733, Validation Loss: 0.000518\n",
      " Epoch 24: Train Loss: 0.000721, Validation Loss: 0.000528\n",
      " Epoch 25: Train Loss: 0.000710, Validation Loss: 0.000504\n",
      " Epoch 26: Train Loss: 0.000695, Validation Loss: 0.000504\n",
      " Epoch 27: Train Loss: 0.000686, Validation Loss: 0.000512\n",
      " Epoch 28: Train Loss: 0.000674, Validation Loss: 0.000521\n",
      " Epoch 29: Train Loss: 0.000667, Validation Loss: 0.000489\n",
      " Epoch 30: Train Loss: 0.000657, Validation Loss: 0.000476\n",
      " Epoch 31: Train Loss: 0.000644, Validation Loss: 0.000486\n",
      " Epoch 32: Train Loss: 0.000637, Validation Loss: 0.000466\n",
      " Epoch 33: Train Loss: 0.000633, Validation Loss: 0.000481\n",
      " Epoch 34: Train Loss: 0.000627, Validation Loss: 0.000467\n",
      " Epoch 35: Train Loss: 0.000627, Validation Loss: 0.000482\n",
      " Epoch 36: Train Loss: 0.000620, Validation Loss: 0.000468\n",
      " Epoch 37: Train Loss: 0.000617, Validation Loss: 0.000465\n",
      " Epoch 38: Train Loss: 0.000613, Validation Loss: 0.000473\n",
      " Epoch 39: Train Loss: 0.000608, Validation Loss: 0.000464\n",
      " Epoch 40: Train Loss: 0.000604, Validation Loss: 0.000450\n",
      " Epoch 41: Train Loss: 0.000600, Validation Loss: 0.000456\n",
      " Epoch 42: Train Loss: 0.000598, Validation Loss: 0.000449\n",
      " Epoch 43: Train Loss: 0.000593, Validation Loss: 0.000474\n",
      " Epoch 44: Train Loss: 0.000590, Validation Loss: 0.000444\n",
      " Epoch 45: Train Loss: 0.000589, Validation Loss: 0.000437\n",
      " Epoch 46: Train Loss: 0.000586, Validation Loss: 0.000491\n",
      " Epoch 47: Train Loss: 0.000579, Validation Loss: 0.000430\n",
      " Epoch 48: Train Loss: 0.000577, Validation Loss: 0.000466\n",
      " Epoch 49: Train Loss: 0.000571, Validation Loss: 0.000489\n",
      " Epoch 50: Train Loss: 0.000568, Validation Loss: 0.000466\n",
      " Epoch 51: Train Loss: 0.000566, Validation Loss: 0.000465\n",
      " Epoch 52: Train Loss: 0.000561, Validation Loss: 0.000435\n",
      " Epoch 53: Train Loss: 0.000561, Validation Loss: 0.000497\n",
      " Epoch 54: Train Loss: 0.000556, Validation Loss: 0.000471\n",
      " Epoch 55: Train Loss: 0.000555, Validation Loss: 0.000459\n",
      " Epoch 56: Train Loss: 0.000550, Validation Loss: 0.000511\n",
      " Epoch 57: Train Loss: 0.000550, Validation Loss: 0.000544\n",
      " Epoch 58: Train Loss: 0.000545, Validation Loss: 0.000473\n",
      " Epoch 59: Train Loss: 0.000540, Validation Loss: 0.000493\n",
      " Epoch 60: Train Loss: 0.000536, Validation Loss: 0.000499\n",
      " Epoch 61: Train Loss: 0.000533, Validation Loss: 0.000532\n",
      " Epoch 62: Train Loss: 0.000531, Validation Loss: 0.000479\n",
      " Epoch 63: Train Loss: 0.000532, Validation Loss: 0.000452\n",
      " Epoch 64: Train Loss: 0.000529, Validation Loss: 0.000569\n",
      " Epoch 65: Train Loss: 0.000528, Validation Loss: 0.000541\n",
      " Epoch 66: Train Loss: 0.000527, Validation Loss: 0.000540\n",
      " Epoch 67: Train Loss: 0.000523, Validation Loss: 0.000542\n",
      "Early stopping at epoch 67 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015414, Validation Loss: 0.017947\n",
      " Epoch 2: Train Loss: 0.004488, Validation Loss: 0.003097\n",
      " Epoch 3: Train Loss: 0.002660, Validation Loss: 0.001567\n",
      " Epoch 4: Train Loss: 0.001710, Validation Loss: 0.001099\n",
      " Epoch 5: Train Loss: 0.001426, Validation Loss: 0.000985\n",
      " Epoch 6: Train Loss: 0.001239, Validation Loss: 0.000897\n",
      " Epoch 7: Train Loss: 0.001145, Validation Loss: 0.000814\n",
      " Epoch 8: Train Loss: 0.001079, Validation Loss: 0.000767\n",
      " Epoch 9: Train Loss: 0.001028, Validation Loss: 0.000731\n",
      " Epoch 10: Train Loss: 0.001014, Validation Loss: 0.000683\n",
      " Epoch 11: Train Loss: 0.000936, Validation Loss: 0.000662\n",
      " Epoch 12: Train Loss: 0.000902, Validation Loss: 0.000629\n",
      " Epoch 13: Train Loss: 0.000879, Validation Loss: 0.000612\n",
      " Epoch 14: Train Loss: 0.000847, Validation Loss: 0.000601\n",
      " Epoch 15: Train Loss: 0.000824, Validation Loss: 0.000578\n",
      " Epoch 16: Train Loss: 0.000801, Validation Loss: 0.000560\n",
      " Epoch 17: Train Loss: 0.000782, Validation Loss: 0.000557\n",
      " Epoch 18: Train Loss: 0.000765, Validation Loss: 0.000527\n",
      " Epoch 19: Train Loss: 0.000750, Validation Loss: 0.000549\n",
      " Epoch 20: Train Loss: 0.000745, Validation Loss: 0.000513\n",
      " Epoch 21: Train Loss: 0.000719, Validation Loss: 0.000497\n",
      " Epoch 22: Train Loss: 0.000704, Validation Loss: 0.000484\n",
      " Epoch 23: Train Loss: 0.000690, Validation Loss: 0.000485\n",
      " Epoch 24: Train Loss: 0.000677, Validation Loss: 0.000476\n",
      " Epoch 25: Train Loss: 0.000669, Validation Loss: 0.000479\n",
      " Epoch 26: Train Loss: 0.000657, Validation Loss: 0.000455\n",
      " Epoch 27: Train Loss: 0.000648, Validation Loss: 0.000465\n",
      " Epoch 28: Train Loss: 0.000652, Validation Loss: 0.000447\n",
      " Epoch 29: Train Loss: 0.000628, Validation Loss: 0.000436\n",
      " Epoch 30: Train Loss: 0.000625, Validation Loss: 0.000433\n",
      " Epoch 31: Train Loss: 0.000611, Validation Loss: 0.000427\n",
      " Epoch 32: Train Loss: 0.000606, Validation Loss: 0.000429\n",
      " Epoch 33: Train Loss: 0.000603, Validation Loss: 0.000427\n",
      " Epoch 34: Train Loss: 0.000598, Validation Loss: 0.000420\n",
      " Epoch 35: Train Loss: 0.000595, Validation Loss: 0.000423\n",
      " Epoch 36: Train Loss: 0.000590, Validation Loss: 0.000419\n",
      " Epoch 37: Train Loss: 0.000588, Validation Loss: 0.000417\n",
      " Epoch 38: Train Loss: 0.000584, Validation Loss: 0.000417\n",
      " Epoch 39: Train Loss: 0.000580, Validation Loss: 0.000417\n",
      " Epoch 40: Train Loss: 0.000577, Validation Loss: 0.000409\n",
      " Epoch 41: Train Loss: 0.000573, Validation Loss: 0.000422\n",
      " Epoch 42: Train Loss: 0.000571, Validation Loss: 0.000402\n",
      " Epoch 43: Train Loss: 0.000567, Validation Loss: 0.000403\n",
      " Epoch 44: Train Loss: 0.000563, Validation Loss: 0.000410\n",
      " Epoch 45: Train Loss: 0.000561, Validation Loss: 0.000401\n",
      " Epoch 46: Train Loss: 0.000556, Validation Loss: 0.000407\n",
      " Epoch 47: Train Loss: 0.000554, Validation Loss: 0.000405\n",
      " Epoch 48: Train Loss: 0.000549, Validation Loss: 0.000399\n",
      " Epoch 49: Train Loss: 0.000547, Validation Loss: 0.000410\n",
      " Epoch 50: Train Loss: 0.000544, Validation Loss: 0.000406\n",
      " Epoch 51: Train Loss: 0.000541, Validation Loss: 0.000394\n",
      " Epoch 52: Train Loss: 0.000537, Validation Loss: 0.000408\n",
      " Epoch 53: Train Loss: 0.000534, Validation Loss: 0.000395\n",
      " Epoch 54: Train Loss: 0.000532, Validation Loss: 0.000390\n",
      " Epoch 55: Train Loss: 0.000529, Validation Loss: 0.000409\n",
      " Epoch 56: Train Loss: 0.000527, Validation Loss: 0.000400\n",
      " Epoch 57: Train Loss: 0.000523, Validation Loss: 0.000417\n",
      " Epoch 58: Train Loss: 0.000521, Validation Loss: 0.000390\n",
      " Epoch 59: Train Loss: 0.000517, Validation Loss: 0.000394\n",
      " Epoch 60: Train Loss: 0.000514, Validation Loss: 0.000391\n",
      " Epoch 61: Train Loss: 0.000511, Validation Loss: 0.000417\n",
      " Epoch 62: Train Loss: 0.000510, Validation Loss: 0.000398\n",
      " Epoch 63: Train Loss: 0.000508, Validation Loss: 0.000412\n",
      " Epoch 64: Train Loss: 0.000506, Validation Loss: 0.000421\n",
      " Epoch 65: Train Loss: 0.000505, Validation Loss: 0.000431\n",
      " Epoch 66: Train Loss: 0.000503, Validation Loss: 0.000414\n",
      " Epoch 67: Train Loss: 0.000502, Validation Loss: 0.000410\n",
      " Epoch 68: Train Loss: 0.000501, Validation Loss: 0.000417\n",
      " Epoch 69: Train Loss: 0.000500, Validation Loss: 0.000408\n",
      " Epoch 70: Train Loss: 0.000498, Validation Loss: 0.000422\n",
      " Epoch 71: Train Loss: 0.000497, Validation Loss: 0.000429\n",
      " Epoch 72: Train Loss: 0.000495, Validation Loss: 0.000443\n",
      " Epoch 73: Train Loss: 0.000493, Validation Loss: 0.000438\n",
      " Epoch 74: Train Loss: 0.000493, Validation Loss: 0.000472\n",
      "Early stopping at epoch 74 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015742, Validation Loss: 0.029084\n",
      " Epoch 2: Train Loss: 0.005612, Validation Loss: 0.006089\n",
      " Epoch 3: Train Loss: 0.002477, Validation Loss: 0.001569\n",
      " Epoch 4: Train Loss: 0.002425, Validation Loss: 0.001940\n",
      " Epoch 5: Train Loss: 0.001798, Validation Loss: 0.001282\n",
      " Epoch 6: Train Loss: 0.001604, Validation Loss: 0.001039\n",
      " Epoch 7: Train Loss: 0.001292, Validation Loss: 0.000887\n",
      " Epoch 8: Train Loss: 0.001273, Validation Loss: 0.001028\n",
      " Epoch 9: Train Loss: 0.001167, Validation Loss: 0.000766\n",
      " Epoch 10: Train Loss: 0.000960, Validation Loss: 0.000717\n",
      " Epoch 11: Train Loss: 0.000914, Validation Loss: 0.000734\n",
      " Epoch 12: Train Loss: 0.000930, Validation Loss: 0.000612\n",
      " Epoch 13: Train Loss: 0.000869, Validation Loss: 0.000738\n",
      " Epoch 14: Train Loss: 0.000867, Validation Loss: 0.000760\n",
      " Epoch 15: Train Loss: 0.000801, Validation Loss: 0.000697\n",
      " Epoch 16: Train Loss: 0.000760, Validation Loss: 0.000604\n",
      " Epoch 17: Train Loss: 0.000764, Validation Loss: 0.000613\n",
      " Epoch 18: Train Loss: 0.000875, Validation Loss: 0.000618\n",
      " Epoch 19: Train Loss: 0.000747, Validation Loss: 0.000524\n",
      " Epoch 20: Train Loss: 0.001823, Validation Loss: 0.003370\n",
      " Epoch 21: Train Loss: 0.001536, Validation Loss: 0.001424\n",
      " Epoch 22: Train Loss: 0.001026, Validation Loss: 0.000758\n",
      " Epoch 23: Train Loss: 0.000921, Validation Loss: 0.000678\n",
      " Epoch 24: Train Loss: 0.000856, Validation Loss: 0.000592\n",
      " Epoch 25: Train Loss: 0.000822, Validation Loss: 0.000631\n",
      " Epoch 26: Train Loss: 0.000838, Validation Loss: 0.000596\n",
      " Epoch 27: Train Loss: 0.000772, Validation Loss: 0.000553\n",
      " Epoch 28: Train Loss: 0.000737, Validation Loss: 0.000522\n",
      " Epoch 29: Train Loss: 0.000823, Validation Loss: 0.000523\n",
      " Epoch 30: Train Loss: 0.000687, Validation Loss: 0.000488\n",
      " Epoch 31: Train Loss: 0.000679, Validation Loss: 0.000534\n",
      " Epoch 32: Train Loss: 0.000646, Validation Loss: 0.000501\n",
      " Epoch 33: Train Loss: 0.000644, Validation Loss: 0.000491\n",
      " Epoch 34: Train Loss: 0.000651, Validation Loss: 0.000537\n",
      " Epoch 35: Train Loss: 0.000658, Validation Loss: 0.000555\n",
      " Epoch 36: Train Loss: 0.000651, Validation Loss: 0.000472\n",
      " Epoch 37: Train Loss: 0.000654, Validation Loss: 0.000500\n",
      " Epoch 38: Train Loss: 0.000654, Validation Loss: 0.000458\n",
      " Epoch 39: Train Loss: 0.000626, Validation Loss: 0.000499\n",
      " Epoch 40: Train Loss: 0.000603, Validation Loss: 0.000457\n",
      " Epoch 41: Train Loss: 0.000609, Validation Loss: 0.000449\n",
      " Epoch 42: Train Loss: 0.000604, Validation Loss: 0.000480\n",
      " Epoch 43: Train Loss: 0.000593, Validation Loss: 0.000490\n",
      " Epoch 44: Train Loss: 0.000592, Validation Loss: 0.000488\n",
      " Epoch 45: Train Loss: 0.000592, Validation Loss: 0.000550\n",
      " Epoch 46: Train Loss: 0.000584, Validation Loss: 0.000448\n",
      " Epoch 47: Train Loss: 0.000578, Validation Loss: 0.000436\n",
      " Epoch 48: Train Loss: 0.000580, Validation Loss: 0.000434\n",
      " Epoch 49: Train Loss: 0.000575, Validation Loss: 0.000482\n",
      " Epoch 50: Train Loss: 0.000566, Validation Loss: 0.000487\n",
      " Epoch 51: Train Loss: 0.000568, Validation Loss: 0.000433\n",
      " Epoch 52: Train Loss: 0.000560, Validation Loss: 0.000477\n",
      " Epoch 53: Train Loss: 0.000558, Validation Loss: 0.000497\n",
      " Epoch 54: Train Loss: 0.000559, Validation Loss: 0.000450\n",
      " Epoch 55: Train Loss: 0.000552, Validation Loss: 0.000433\n",
      " Epoch 56: Train Loss: 0.000550, Validation Loss: 0.000452\n",
      " Epoch 57: Train Loss: 0.000539, Validation Loss: 0.000441\n",
      " Epoch 58: Train Loss: 0.000538, Validation Loss: 0.000441\n",
      " Epoch 59: Train Loss: 0.000538, Validation Loss: 0.000481\n",
      " Epoch 60: Train Loss: 0.000537, Validation Loss: 0.000406\n",
      " Epoch 61: Train Loss: 0.000531, Validation Loss: 0.000437\n",
      " Epoch 62: Train Loss: 0.000529, Validation Loss: 0.000441\n",
      " Epoch 63: Train Loss: 0.000528, Validation Loss: 0.000425\n",
      " Epoch 64: Train Loss: 0.000528, Validation Loss: 0.000417\n",
      " Epoch 65: Train Loss: 0.000524, Validation Loss: 0.000446\n",
      " Epoch 66: Train Loss: 0.000522, Validation Loss: 0.000413\n",
      " Epoch 67: Train Loss: 0.000522, Validation Loss: 0.000413\n",
      " Epoch 68: Train Loss: 0.000522, Validation Loss: 0.000423\n",
      " Epoch 69: Train Loss: 0.000520, Validation Loss: 0.000432\n",
      " Epoch 70: Train Loss: 0.000516, Validation Loss: 0.000424\n",
      " Epoch 71: Train Loss: 0.000522, Validation Loss: 0.000473\n",
      " Epoch 72: Train Loss: 0.000518, Validation Loss: 0.000413\n",
      " Epoch 73: Train Loss: 0.000515, Validation Loss: 0.000427\n",
      " Epoch 74: Train Loss: 0.000513, Validation Loss: 0.000428\n",
      " Epoch 75: Train Loss: 0.000512, Validation Loss: 0.000425\n",
      " Epoch 76: Train Loss: 0.000510, Validation Loss: 0.000409\n",
      " Epoch 77: Train Loss: 0.000509, Validation Loss: 0.000437\n",
      " Epoch 78: Train Loss: 0.000509, Validation Loss: 0.000396\n",
      " Epoch 79: Train Loss: 0.000507, Validation Loss: 0.000432\n",
      " Epoch 80: Train Loss: 0.000505, Validation Loss: 0.000406\n",
      " Epoch 81: Train Loss: 0.000504, Validation Loss: 0.000392\n",
      " Epoch 82: Train Loss: 0.000506, Validation Loss: 0.000404\n",
      " Epoch 83: Train Loss: 0.000501, Validation Loss: 0.000424\n",
      " Epoch 84: Train Loss: 0.000500, Validation Loss: 0.000416\n",
      " Epoch 85: Train Loss: 0.000499, Validation Loss: 0.000402\n",
      " Epoch 86: Train Loss: 0.000497, Validation Loss: 0.000414\n",
      " Epoch 87: Train Loss: 0.000496, Validation Loss: 0.000421\n",
      " Epoch 88: Train Loss: 0.000495, Validation Loss: 0.000420\n",
      " Epoch 89: Train Loss: 0.000493, Validation Loss: 0.000442\n",
      " Epoch 90: Train Loss: 0.000492, Validation Loss: 0.000411\n",
      " Epoch 91: Train Loss: 0.000492, Validation Loss: 0.000405\n",
      " Epoch 92: Train Loss: 0.000490, Validation Loss: 0.000391\n",
      " Epoch 93: Train Loss: 0.000491, Validation Loss: 0.000404\n",
      " Epoch 94: Train Loss: 0.000489, Validation Loss: 0.000412\n",
      " Epoch 95: Train Loss: 0.000487, Validation Loss: 0.000411\n",
      " Epoch 96: Train Loss: 0.000487, Validation Loss: 0.000408\n",
      " Epoch 97: Train Loss: 0.000489, Validation Loss: 0.000398\n",
      " Epoch 98: Train Loss: 0.000486, Validation Loss: 0.000413\n",
      " Epoch 99: Train Loss: 0.000484, Validation Loss: 0.000415\n",
      " Epoch 100: Train Loss: 0.000483, Validation Loss: 0.000396\n",
      " Epoch 101: Train Loss: 0.000483, Validation Loss: 0.000411\n",
      " Epoch 102: Train Loss: 0.000483, Validation Loss: 0.000408\n",
      " Epoch 103: Train Loss: 0.000483, Validation Loss: 0.000417\n",
      " Epoch 104: Train Loss: 0.000481, Validation Loss: 0.000397\n",
      " Epoch 105: Train Loss: 0.000481, Validation Loss: 0.000413\n",
      " Epoch 106: Train Loss: 0.000481, Validation Loss: 0.000414\n",
      " Epoch 107: Train Loss: 0.000478, Validation Loss: 0.000395\n",
      " Epoch 108: Train Loss: 0.000478, Validation Loss: 0.000398\n",
      " Epoch 109: Train Loss: 0.000477, Validation Loss: 0.000405\n",
      " Epoch 110: Train Loss: 0.000477, Validation Loss: 0.000399\n",
      " Epoch 111: Train Loss: 0.000476, Validation Loss: 0.000399\n",
      " Epoch 112: Train Loss: 0.000476, Validation Loss: 0.000400\n",
      "Early stopping at epoch 112 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.013317, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.004838, Validation Loss: 0.005694\n",
      " Epoch 3: Train Loss: 0.002510, Validation Loss: 0.001897\n",
      " Epoch 4: Train Loss: 0.001881, Validation Loss: 0.001812\n",
      " Epoch 5: Train Loss: 0.001643, Validation Loss: 0.001067\n",
      " Epoch 6: Train Loss: 0.001365, Validation Loss: 0.000972\n",
      " Epoch 7: Train Loss: 0.001263, Validation Loss: 0.000844\n",
      " Epoch 8: Train Loss: 0.001279, Validation Loss: 0.001846\n",
      " Epoch 9: Train Loss: 0.001323, Validation Loss: 0.000752\n",
      " Epoch 10: Train Loss: 0.001109, Validation Loss: 0.000791\n",
      " Epoch 11: Train Loss: 0.000998, Validation Loss: 0.000789\n",
      " Epoch 12: Train Loss: 0.000939, Validation Loss: 0.000661\n",
      " Epoch 13: Train Loss: 0.000913, Validation Loss: 0.000670\n",
      " Epoch 14: Train Loss: 0.000942, Validation Loss: 0.000755\n",
      " Epoch 15: Train Loss: 0.000977, Validation Loss: 0.000607\n",
      " Epoch 16: Train Loss: 0.000834, Validation Loss: 0.000677\n",
      " Epoch 17: Train Loss: 0.001982, Validation Loss: 0.002386\n",
      " Epoch 18: Train Loss: 0.001153, Validation Loss: 0.000794\n",
      " Epoch 19: Train Loss: 0.001080, Validation Loss: 0.000778\n",
      " Epoch 20: Train Loss: 0.001289, Validation Loss: 0.000701\n",
      " Epoch 21: Train Loss: 0.000954, Validation Loss: 0.000870\n",
      " Epoch 22: Train Loss: 0.000807, Validation Loss: 0.000649\n",
      " Epoch 23: Train Loss: 0.000784, Validation Loss: 0.000688\n",
      " Epoch 24: Train Loss: 0.000741, Validation Loss: 0.000583\n",
      " Epoch 25: Train Loss: 0.000694, Validation Loss: 0.000567\n",
      " Epoch 26: Train Loss: 0.000671, Validation Loss: 0.000521\n",
      " Epoch 27: Train Loss: 0.000666, Validation Loss: 0.000505\n",
      " Epoch 28: Train Loss: 0.000647, Validation Loss: 0.000500\n",
      " Epoch 29: Train Loss: 0.000632, Validation Loss: 0.000527\n",
      " Epoch 30: Train Loss: 0.000832, Validation Loss: 0.006806\n",
      " Epoch 31: Train Loss: 0.000932, Validation Loss: 0.004668\n",
      " Epoch 32: Train Loss: 0.001152, Validation Loss: 0.000676\n",
      " Epoch 33: Train Loss: 0.000817, Validation Loss: 0.000560\n",
      " Epoch 34: Train Loss: 0.000750, Validation Loss: 0.000567\n",
      " Epoch 35: Train Loss: 0.000739, Validation Loss: 0.000533\n",
      " Epoch 36: Train Loss: 0.000659, Validation Loss: 0.000643\n",
      " Epoch 37: Train Loss: 0.000651, Validation Loss: 0.002191\n",
      " Epoch 38: Train Loss: 0.000819, Validation Loss: 0.000596\n",
      " Epoch 39: Train Loss: 0.000746, Validation Loss: 0.000703\n",
      " Epoch 40: Train Loss: 0.000697, Validation Loss: 0.000512\n",
      " Epoch 41: Train Loss: 0.000663, Validation Loss: 0.000486\n",
      " Epoch 42: Train Loss: 0.000689, Validation Loss: 0.000485\n",
      " Epoch 43: Train Loss: 0.000660, Validation Loss: 0.000694\n",
      " Epoch 44: Train Loss: 0.000627, Validation Loss: 0.000455\n",
      " Epoch 45: Train Loss: 0.000820, Validation Loss: 0.000557\n",
      " Epoch 46: Train Loss: 0.000784, Validation Loss: 0.000601\n",
      " Epoch 47: Train Loss: 0.000693, Validation Loss: 0.000684\n",
      " Epoch 48: Train Loss: 0.000658, Validation Loss: 0.000496\n",
      " Epoch 49: Train Loss: 0.000647, Validation Loss: 0.000496\n",
      " Epoch 50: Train Loss: 0.000662, Validation Loss: 0.000690\n",
      " Epoch 51: Train Loss: 0.000613, Validation Loss: 0.000546\n",
      " Epoch 52: Train Loss: 0.000603, Validation Loss: 0.000580\n",
      " Epoch 53: Train Loss: 0.000595, Validation Loss: 0.000476\n",
      " Epoch 54: Train Loss: 0.000585, Validation Loss: 0.000466\n",
      " Epoch 55: Train Loss: 0.000576, Validation Loss: 0.000437\n",
      " Epoch 56: Train Loss: 0.000576, Validation Loss: 0.000470\n",
      " Epoch 57: Train Loss: 0.000583, Validation Loss: 0.000554\n",
      " Epoch 58: Train Loss: 0.000560, Validation Loss: 0.000443\n",
      " Epoch 59: Train Loss: 0.000554, Validation Loss: 0.000577\n",
      " Epoch 60: Train Loss: 0.000555, Validation Loss: 0.000423\n",
      " Epoch 61: Train Loss: 0.000539, Validation Loss: 0.000458\n",
      " Epoch 62: Train Loss: 0.000535, Validation Loss: 0.000439\n",
      " Epoch 63: Train Loss: 0.000534, Validation Loss: 0.000456\n",
      " Epoch 64: Train Loss: 0.000532, Validation Loss: 0.000463\n",
      " Epoch 65: Train Loss: 0.000532, Validation Loss: 0.000431\n",
      " Epoch 66: Train Loss: 0.000528, Validation Loss: 0.000430\n",
      " Epoch 67: Train Loss: 0.000529, Validation Loss: 0.000485\n",
      " Epoch 68: Train Loss: 0.000527, Validation Loss: 0.000433\n",
      " Epoch 69: Train Loss: 0.000527, Validation Loss: 0.000445\n",
      " Epoch 70: Train Loss: 0.000523, Validation Loss: 0.000436\n",
      " Epoch 71: Train Loss: 0.000523, Validation Loss: 0.000408\n",
      " Epoch 72: Train Loss: 0.000522, Validation Loss: 0.000408\n",
      " Epoch 73: Train Loss: 0.000518, Validation Loss: 0.000433\n",
      " Epoch 74: Train Loss: 0.000518, Validation Loss: 0.000424\n",
      " Epoch 75: Train Loss: 0.000518, Validation Loss: 0.000429\n",
      " Epoch 76: Train Loss: 0.000517, Validation Loss: 0.000426\n",
      " Epoch 77: Train Loss: 0.000515, Validation Loss: 0.000411\n",
      " Epoch 78: Train Loss: 0.000516, Validation Loss: 0.000433\n",
      " Epoch 79: Train Loss: 0.000513, Validation Loss: 0.000440\n",
      " Epoch 80: Train Loss: 0.000510, Validation Loss: 0.000412\n",
      " Epoch 81: Train Loss: 0.000508, Validation Loss: 0.000429\n",
      " Epoch 82: Train Loss: 0.000506, Validation Loss: 0.000419\n",
      " Epoch 83: Train Loss: 0.000505, Validation Loss: 0.000406\n",
      " Epoch 84: Train Loss: 0.000506, Validation Loss: 0.000413\n",
      " Epoch 85: Train Loss: 0.000504, Validation Loss: 0.000427\n",
      " Epoch 86: Train Loss: 0.000505, Validation Loss: 0.000436\n",
      " Epoch 87: Train Loss: 0.000501, Validation Loss: 0.000402\n",
      " Epoch 88: Train Loss: 0.000498, Validation Loss: 0.000431\n",
      " Epoch 89: Train Loss: 0.000544, Validation Loss: 0.000449\n",
      " Epoch 90: Train Loss: 0.000529, Validation Loss: 0.000457\n",
      " Epoch 91: Train Loss: 0.000519, Validation Loss: 0.000417\n",
      " Epoch 92: Train Loss: 0.000516, Validation Loss: 0.000416\n",
      " Epoch 93: Train Loss: 0.000512, Validation Loss: 0.000460\n",
      " Epoch 94: Train Loss: 0.000509, Validation Loss: 0.000414\n",
      " Epoch 95: Train Loss: 0.000506, Validation Loss: 0.000424\n",
      " Epoch 96: Train Loss: 0.000503, Validation Loss: 0.000404\n",
      " Epoch 97: Train Loss: 0.000504, Validation Loss: 0.000420\n",
      " Epoch 98: Train Loss: 0.000499, Validation Loss: 0.000419\n",
      " Epoch 99: Train Loss: 0.000499, Validation Loss: 0.000413\n",
      " Epoch 100: Train Loss: 0.000496, Validation Loss: 0.000409\n",
      " Epoch 101: Train Loss: 0.000494, Validation Loss: 0.000408\n",
      " Epoch 102: Train Loss: 0.000494, Validation Loss: 0.000437\n",
      " Epoch 103: Train Loss: 0.000492, Validation Loss: 0.000414\n",
      " Epoch 104: Train Loss: 0.000492, Validation Loss: 0.000434\n",
      " Epoch 105: Train Loss: 0.000490, Validation Loss: 0.000413\n",
      " Epoch 106: Train Loss: 0.000490, Validation Loss: 0.000393\n",
      " Epoch 107: Train Loss: 0.000490, Validation Loss: 0.000416\n",
      " Epoch 108: Train Loss: 0.000487, Validation Loss: 0.000409\n",
      " Epoch 109: Train Loss: 0.000491, Validation Loss: 0.000400\n",
      " Epoch 110: Train Loss: 0.000489, Validation Loss: 0.000420\n",
      " Epoch 111: Train Loss: 0.000488, Validation Loss: 0.000416\n",
      " Epoch 112: Train Loss: 0.000487, Validation Loss: 0.000411\n",
      " Epoch 113: Train Loss: 0.000483, Validation Loss: 0.000405\n",
      " Epoch 114: Train Loss: 0.000484, Validation Loss: 0.000414\n",
      " Epoch 115: Train Loss: 0.000491, Validation Loss: 0.000421\n",
      " Epoch 116: Train Loss: 0.000490, Validation Loss: 0.000394\n",
      " Epoch 117: Train Loss: 0.000487, Validation Loss: 0.000412\n",
      " Epoch 118: Train Loss: 0.000485, Validation Loss: 0.000391\n",
      " Epoch 119: Train Loss: 0.000482, Validation Loss: 0.000404\n",
      " Epoch 120: Train Loss: 0.000481, Validation Loss: 0.000394\n",
      " Epoch 121: Train Loss: 0.000480, Validation Loss: 0.000412\n",
      " Epoch 122: Train Loss: 0.000479, Validation Loss: 0.000391\n",
      " Epoch 123: Train Loss: 0.000478, Validation Loss: 0.000389\n",
      " Epoch 124: Train Loss: 0.000477, Validation Loss: 0.000382\n",
      " Epoch 125: Train Loss: 0.000477, Validation Loss: 0.000390\n",
      " Epoch 126: Train Loss: 0.000476, Validation Loss: 0.000407\n",
      " Epoch 127: Train Loss: 0.000476, Validation Loss: 0.000410\n",
      " Epoch 128: Train Loss: 0.000476, Validation Loss: 0.000398\n",
      " Epoch 129: Train Loss: 0.000474, Validation Loss: 0.000395\n",
      " Epoch 130: Train Loss: 0.000474, Validation Loss: 0.000388\n",
      " Epoch 131: Train Loss: 0.000473, Validation Loss: 0.000380\n",
      " Epoch 132: Train Loss: 0.000474, Validation Loss: 0.000397\n",
      " Epoch 133: Train Loss: 0.000473, Validation Loss: 0.000389\n",
      " Epoch 134: Train Loss: 0.000472, Validation Loss: 0.000396\n",
      " Epoch 135: Train Loss: 0.000472, Validation Loss: 0.000393\n",
      " Epoch 136: Train Loss: 0.000471, Validation Loss: 0.000378\n",
      " Epoch 137: Train Loss: 0.000471, Validation Loss: 0.000383\n",
      " Epoch 138: Train Loss: 0.000471, Validation Loss: 0.000390\n",
      " Epoch 139: Train Loss: 0.000470, Validation Loss: 0.000397\n",
      " Epoch 140: Train Loss: 0.000470, Validation Loss: 0.000388\n",
      " Epoch 141: Train Loss: 0.000470, Validation Loss: 0.000379\n",
      " Epoch 142: Train Loss: 0.000470, Validation Loss: 0.000400\n",
      " Epoch 143: Train Loss: 0.000468, Validation Loss: 0.000396\n",
      " Epoch 144: Train Loss: 0.000467, Validation Loss: 0.000398\n",
      " Epoch 145: Train Loss: 0.000466, Validation Loss: 0.000394\n",
      " Epoch 146: Train Loss: 0.000466, Validation Loss: 0.000391\n",
      " Epoch 147: Train Loss: 0.000466, Validation Loss: 0.000374\n",
      " Epoch 148: Train Loss: 0.000466, Validation Loss: 0.000391\n",
      " Epoch 149: Train Loss: 0.000465, Validation Loss: 0.000398\n",
      " Epoch 150: Train Loss: 0.000465, Validation Loss: 0.000398\n",
      " Epoch 151: Train Loss: 0.000464, Validation Loss: 0.000384\n",
      " Epoch 152: Train Loss: 0.000463, Validation Loss: 0.000385\n",
      " Epoch 153: Train Loss: 0.000463, Validation Loss: 0.000385\n",
      " Epoch 154: Train Loss: 0.000462, Validation Loss: 0.000383\n",
      " Epoch 155: Train Loss: 0.000463, Validation Loss: 0.000380\n",
      " Epoch 156: Train Loss: 0.000462, Validation Loss: 0.000379\n",
      " Epoch 157: Train Loss: 0.000462, Validation Loss: 0.000377\n",
      " Epoch 158: Train Loss: 0.000462, Validation Loss: 0.000382\n",
      " Epoch 159: Train Loss: 0.000461, Validation Loss: 0.000382\n",
      " Epoch 160: Train Loss: 0.000461, Validation Loss: 0.000384\n",
      " Epoch 161: Train Loss: 0.000461, Validation Loss: 0.000377\n",
      " Epoch 162: Train Loss: 0.000461, Validation Loss: 0.000378\n",
      " Epoch 163: Train Loss: 0.000462, Validation Loss: 0.000405\n",
      " Epoch 164: Train Loss: 0.000460, Validation Loss: 0.000384\n",
      " Epoch 165: Train Loss: 0.000460, Validation Loss: 0.000380\n",
      " Epoch 166: Train Loss: 0.000459, Validation Loss: 0.000374\n",
      " Epoch 167: Train Loss: 0.000460, Validation Loss: 0.000381\n",
      "Early stopping at epoch 167 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016363, Validation Loss: 0.029336\n",
      " Epoch 2: Train Loss: 0.006913, Validation Loss: 0.016202\n",
      " Epoch 3: Train Loss: 0.003262, Validation Loss: 0.013464\n",
      " Epoch 4: Train Loss: 0.003189, Validation Loss: 0.002104\n",
      " Epoch 5: Train Loss: 0.002020, Validation Loss: 0.001983\n",
      " Epoch 6: Train Loss: 0.001742, Validation Loss: 0.001140\n",
      " Epoch 7: Train Loss: 0.001365, Validation Loss: 0.000914\n",
      " Epoch 8: Train Loss: 0.001172, Validation Loss: 0.019138\n",
      " Epoch 9: Train Loss: 0.001202, Validation Loss: 0.001910\n",
      " Epoch 10: Train Loss: 0.001118, Validation Loss: 0.000835\n",
      " Epoch 11: Train Loss: 0.000967, Validation Loss: 0.000723\n",
      " Epoch 12: Train Loss: 0.000954, Validation Loss: 0.000686\n",
      " Epoch 13: Train Loss: 0.000879, Validation Loss: 0.000807\n",
      " Epoch 14: Train Loss: 0.000837, Validation Loss: 0.000669\n",
      " Epoch 15: Train Loss: 0.000795, Validation Loss: 0.000627\n",
      " Epoch 16: Train Loss: 0.000801, Validation Loss: 0.000599\n",
      " Epoch 17: Train Loss: 0.000757, Validation Loss: 0.000656\n",
      " Epoch 18: Train Loss: 0.000741, Validation Loss: 0.000589\n",
      " Epoch 19: Train Loss: 0.000969, Validation Loss: 0.008106\n",
      " Epoch 20: Train Loss: 0.001901, Validation Loss: 0.000907\n",
      " Epoch 21: Train Loss: 0.000906, Validation Loss: 0.000712\n",
      " Epoch 22: Train Loss: 0.000883, Validation Loss: 0.001240\n",
      " Epoch 23: Train Loss: 0.000821, Validation Loss: 0.006130\n",
      " Epoch 24: Train Loss: 0.002665, Validation Loss: 0.001552\n",
      " Epoch 25: Train Loss: 0.001809, Validation Loss: 0.001683\n",
      " Epoch 26: Train Loss: 0.001507, Validation Loss: 0.001239\n",
      " Epoch 27: Train Loss: 0.001045, Validation Loss: 0.000825\n",
      " Epoch 28: Train Loss: 0.000950, Validation Loss: 0.000740\n",
      " Epoch 29: Train Loss: 0.000865, Validation Loss: 0.000638\n",
      " Epoch 30: Train Loss: 0.000810, Validation Loss: 0.000614\n",
      " Epoch 31: Train Loss: 0.000789, Validation Loss: 0.000566\n",
      " Epoch 32: Train Loss: 0.000786, Validation Loss: 0.000616\n",
      " Epoch 33: Train Loss: 0.000814, Validation Loss: 0.000615\n",
      " Epoch 34: Train Loss: 0.000818, Validation Loss: 0.000668\n",
      " Epoch 35: Train Loss: 0.000790, Validation Loss: 0.000606\n",
      " Epoch 36: Train Loss: 0.000777, Validation Loss: 0.000672\n",
      " Epoch 37: Train Loss: 0.000895, Validation Loss: 0.000962\n",
      " Epoch 38: Train Loss: 0.000951, Validation Loss: 0.000623\n",
      " Epoch 39: Train Loss: 0.000836, Validation Loss: 0.000816\n",
      " Epoch 40: Train Loss: 0.000848, Validation Loss: 0.000741\n",
      " Epoch 41: Train Loss: 0.000824, Validation Loss: 0.000546\n",
      " Epoch 42: Train Loss: 0.000759, Validation Loss: 0.000535\n",
      " Epoch 43: Train Loss: 0.000720, Validation Loss: 0.000636\n",
      " Epoch 44: Train Loss: 0.000717, Validation Loss: 0.000568\n",
      " Epoch 45: Train Loss: 0.000701, Validation Loss: 0.000764\n",
      " Epoch 46: Train Loss: 0.000759, Validation Loss: 0.000630\n",
      " Epoch 47: Train Loss: 0.000735, Validation Loss: 0.000597\n",
      " Epoch 48: Train Loss: 0.000689, Validation Loss: 0.000655\n",
      " Epoch 49: Train Loss: 0.000680, Validation Loss: 0.000503\n",
      " Epoch 50: Train Loss: 0.000712, Validation Loss: 0.000823\n",
      " Epoch 51: Train Loss: 0.000741, Validation Loss: 0.000517\n",
      " Epoch 52: Train Loss: 0.001499, Validation Loss: 0.001144\n",
      " Epoch 53: Train Loss: 0.001158, Validation Loss: 0.000800\n",
      " Epoch 54: Train Loss: 0.000939, Validation Loss: 0.000679\n",
      " Epoch 55: Train Loss: 0.000844, Validation Loss: 0.000636\n",
      " Epoch 56: Train Loss: 0.000812, Validation Loss: 0.000655\n",
      " Epoch 57: Train Loss: 0.001956, Validation Loss: 0.000980\n",
      " Epoch 58: Train Loss: 0.001046, Validation Loss: 0.000622\n",
      " Epoch 59: Train Loss: 0.000882, Validation Loss: 0.000705\n",
      " Epoch 60: Train Loss: 0.000866, Validation Loss: 0.000689\n",
      " Epoch 61: Train Loss: 0.000805, Validation Loss: 0.000590\n",
      " Epoch 62: Train Loss: 0.000777, Validation Loss: 0.000571\n",
      " Epoch 63: Train Loss: 0.000771, Validation Loss: 0.000633\n",
      " Epoch 64: Train Loss: 0.000746, Validation Loss: 0.000621\n",
      " Epoch 65: Train Loss: 0.000742, Validation Loss: 0.000580\n",
      " Epoch 66: Train Loss: 0.000731, Validation Loss: 0.000646\n",
      " Epoch 67: Train Loss: 0.000717, Validation Loss: 0.000544\n",
      " Epoch 68: Train Loss: 0.000743, Validation Loss: 0.000645\n",
      " Epoch 69: Train Loss: 0.000746, Validation Loss: 0.000659\n",
      "Early stopping at epoch 69 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014991, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.005867, Validation Loss: 0.018649\n",
      " Epoch 3: Train Loss: 0.003130, Validation Loss: 0.003276\n",
      " Epoch 4: Train Loss: 0.002249, Validation Loss: 0.002179\n",
      " Epoch 5: Train Loss: 0.001717, Validation Loss: 0.001243\n",
      " Epoch 6: Train Loss: 0.001552, Validation Loss: 0.001331\n",
      " Epoch 7: Train Loss: 0.001284, Validation Loss: 0.000914\n",
      " Epoch 8: Train Loss: 0.001293, Validation Loss: 0.001077\n",
      " Epoch 9: Train Loss: 0.001197, Validation Loss: 0.000916\n",
      " Epoch 10: Train Loss: 0.001125, Validation Loss: 0.000846\n",
      " Epoch 11: Train Loss: 0.001056, Validation Loss: 0.000976\n",
      " Epoch 12: Train Loss: 0.000952, Validation Loss: 0.000696\n",
      " Epoch 13: Train Loss: 0.000877, Validation Loss: 0.000671\n",
      " Epoch 14: Train Loss: 0.001043, Validation Loss: 0.002039\n",
      " Epoch 15: Train Loss: 0.000889, Validation Loss: 0.000637\n",
      " Epoch 16: Train Loss: 0.000931, Validation Loss: 0.000640\n",
      " Epoch 17: Train Loss: 0.000871, Validation Loss: 0.000568\n",
      " Epoch 18: Train Loss: 0.000785, Validation Loss: 0.000943\n",
      " Epoch 19: Train Loss: 0.000862, Validation Loss: 0.000796\n",
      " Epoch 20: Train Loss: 0.000730, Validation Loss: 0.000607\n",
      " Epoch 21: Train Loss: 0.000698, Validation Loss: 0.000591\n",
      " Epoch 22: Train Loss: 0.000682, Validation Loss: 0.000494\n",
      " Epoch 23: Train Loss: 0.000672, Validation Loss: 0.000513\n",
      " Epoch 24: Train Loss: 0.000664, Validation Loss: 0.000553\n",
      " Epoch 25: Train Loss: 0.000621, Validation Loss: 0.000491\n",
      " Epoch 26: Train Loss: 0.000610, Validation Loss: 0.000823\n",
      " Epoch 27: Train Loss: 0.000604, Validation Loss: 0.000621\n",
      " Epoch 28: Train Loss: 0.000676, Validation Loss: 0.000965\n",
      " Epoch 29: Train Loss: 0.000574, Validation Loss: 0.000546\n",
      " Epoch 30: Train Loss: 0.000568, Validation Loss: 0.000454\n",
      " Epoch 31: Train Loss: 0.000551, Validation Loss: 0.000546\n",
      " Epoch 32: Train Loss: 0.000545, Validation Loss: 0.000472\n",
      " Epoch 33: Train Loss: 0.000541, Validation Loss: 0.000477\n",
      " Epoch 34: Train Loss: 0.000537, Validation Loss: 0.000473\n",
      " Epoch 35: Train Loss: 0.000537, Validation Loss: 0.000494\n",
      " Epoch 36: Train Loss: 0.000530, Validation Loss: 0.000500\n",
      " Epoch 37: Train Loss: 0.000529, Validation Loss: 0.000460\n",
      " Epoch 38: Train Loss: 0.000524, Validation Loss: 0.000471\n",
      " Epoch 39: Train Loss: 0.000519, Validation Loss: 0.000532\n",
      " Epoch 40: Train Loss: 0.000518, Validation Loss: 0.000507\n",
      " Epoch 41: Train Loss: 0.000517, Validation Loss: 0.000407\n",
      " Epoch 42: Train Loss: 0.000515, Validation Loss: 0.000478\n",
      " Epoch 43: Train Loss: 0.000511, Validation Loss: 0.000453\n",
      " Epoch 44: Train Loss: 0.000506, Validation Loss: 0.000488\n",
      " Epoch 45: Train Loss: 0.000507, Validation Loss: 0.001129\n",
      " Epoch 46: Train Loss: 0.000578, Validation Loss: 0.000581\n",
      " Epoch 47: Train Loss: 0.000780, Validation Loss: 0.000654\n",
      " Epoch 48: Train Loss: 0.000585, Validation Loss: 0.000486\n",
      " Epoch 49: Train Loss: 0.000533, Validation Loss: 0.000500\n",
      " Epoch 50: Train Loss: 0.000507, Validation Loss: 0.000594\n",
      " Epoch 51: Train Loss: 0.000519, Validation Loss: 0.000419\n",
      " Epoch 52: Train Loss: 0.000498, Validation Loss: 0.000496\n",
      " Epoch 53: Train Loss: 0.000492, Validation Loss: 0.000446\n",
      " Epoch 54: Train Loss: 0.000493, Validation Loss: 0.000379\n",
      " Epoch 55: Train Loss: 0.000491, Validation Loss: 0.000432\n",
      " Epoch 56: Train Loss: 0.000483, Validation Loss: 0.000466\n",
      " Epoch 57: Train Loss: 0.000483, Validation Loss: 0.000390\n",
      " Epoch 58: Train Loss: 0.000484, Validation Loss: 0.000435\n",
      " Epoch 59: Train Loss: 0.000477, Validation Loss: 0.000406\n",
      " Epoch 60: Train Loss: 0.000475, Validation Loss: 0.000491\n",
      " Epoch 61: Train Loss: 0.000467, Validation Loss: 0.000423\n",
      " Epoch 62: Train Loss: 0.000466, Validation Loss: 0.000412\n",
      " Epoch 63: Train Loss: 0.000467, Validation Loss: 0.000438\n",
      " Epoch 64: Train Loss: 0.000464, Validation Loss: 0.000392\n",
      " Epoch 65: Train Loss: 0.000463, Validation Loss: 0.000429\n",
      " Epoch 66: Train Loss: 0.000461, Validation Loss: 0.000424\n",
      " Epoch 67: Train Loss: 0.000461, Validation Loss: 0.000406\n",
      " Epoch 68: Train Loss: 0.000462, Validation Loss: 0.000388\n",
      " Epoch 69: Train Loss: 0.000459, Validation Loss: 0.000451\n",
      " Epoch 70: Train Loss: 0.000458, Validation Loss: 0.000380\n",
      " Epoch 71: Train Loss: 0.000463, Validation Loss: 0.000401\n",
      " Epoch 72: Train Loss: 0.000455, Validation Loss: 0.000405\n",
      " Epoch 73: Train Loss: 0.000453, Validation Loss: 0.000407\n",
      " Epoch 74: Train Loss: 0.000453, Validation Loss: 0.000420\n",
      "Early stopping at epoch 74 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015731, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.006168, Validation Loss: 0.009796\n",
      " Epoch 3: Train Loss: 0.003118, Validation Loss: 0.016693\n",
      " Epoch 4: Train Loss: 0.001920, Validation Loss: 0.001212\n",
      " Epoch 5: Train Loss: 0.001476, Validation Loss: 0.002175\n",
      " Epoch 6: Train Loss: 0.001287, Validation Loss: 0.000910\n",
      " Epoch 7: Train Loss: 0.001233, Validation Loss: 0.000864\n",
      " Epoch 8: Train Loss: 0.001079, Validation Loss: 0.000911\n",
      " Epoch 9: Train Loss: 0.001466, Validation Loss: 0.019374\n",
      " Epoch 10: Train Loss: 0.002274, Validation Loss: 0.001047\n",
      " Epoch 11: Train Loss: 0.001518, Validation Loss: 0.001938\n",
      " Epoch 12: Train Loss: 0.001393, Validation Loss: 0.001339\n",
      " Epoch 13: Train Loss: 0.001267, Validation Loss: 0.000784\n",
      " Epoch 14: Train Loss: 0.001078, Validation Loss: 0.000752\n",
      " Epoch 15: Train Loss: 0.001077, Validation Loss: 0.000907\n",
      " Epoch 16: Train Loss: 0.001092, Validation Loss: 0.000792\n",
      " Epoch 17: Train Loss: 0.000998, Validation Loss: 0.000682\n",
      " Epoch 18: Train Loss: 0.000958, Validation Loss: 0.000660\n",
      " Epoch 19: Train Loss: 0.000896, Validation Loss: 0.000798\n",
      " Epoch 20: Train Loss: 0.000825, Validation Loss: 0.000612\n",
      " Epoch 21: Train Loss: 0.001040, Validation Loss: 0.003761\n",
      " Epoch 22: Train Loss: 0.001142, Validation Loss: 0.001808\n",
      " Epoch 23: Train Loss: 0.001354, Validation Loss: 0.001563\n",
      " Epoch 24: Train Loss: 0.001640, Validation Loss: 0.011301\n",
      " Epoch 25: Train Loss: 0.001056, Validation Loss: 0.003644\n",
      " Epoch 26: Train Loss: 0.000858, Validation Loss: 0.000796\n",
      " Epoch 27: Train Loss: 0.000844, Validation Loss: 0.000936\n",
      " Epoch 28: Train Loss: 0.000793, Validation Loss: 0.000571\n",
      " Epoch 29: Train Loss: 0.000781, Validation Loss: 0.000641\n",
      " Epoch 30: Train Loss: 0.000768, Validation Loss: 0.000574\n",
      " Epoch 31: Train Loss: 0.000724, Validation Loss: 0.000556\n",
      " Epoch 32: Train Loss: 0.000705, Validation Loss: 0.000596\n",
      " Epoch 33: Train Loss: 0.000710, Validation Loss: 0.000552\n",
      " Epoch 34: Train Loss: 0.000703, Validation Loss: 0.000581\n",
      " Epoch 35: Train Loss: 0.000728, Validation Loss: 0.000644\n",
      " Epoch 36: Train Loss: 0.000683, Validation Loss: 0.000557\n",
      " Epoch 37: Train Loss: 0.000678, Validation Loss: 0.000530\n",
      " Epoch 38: Train Loss: 0.000693, Validation Loss: 0.000523\n",
      " Epoch 39: Train Loss: 0.000691, Validation Loss: 0.000530\n",
      " Epoch 40: Train Loss: 0.000662, Validation Loss: 0.000491\n",
      " Epoch 41: Train Loss: 0.000680, Validation Loss: 0.000860\n",
      " Epoch 42: Train Loss: 0.000682, Validation Loss: 0.000506\n",
      " Epoch 43: Train Loss: 0.000651, Validation Loss: 0.000582\n",
      " Epoch 44: Train Loss: 0.000655, Validation Loss: 0.000522\n",
      " Epoch 45: Train Loss: 0.000645, Validation Loss: 0.000762\n",
      " Epoch 46: Train Loss: 0.000639, Validation Loss: 0.000490\n",
      " Epoch 47: Train Loss: 0.000631, Validation Loss: 0.001088\n",
      " Epoch 48: Train Loss: 0.000641, Validation Loss: 0.000461\n",
      " Epoch 49: Train Loss: 0.000640, Validation Loss: 0.000538\n",
      " Epoch 50: Train Loss: 0.000628, Validation Loss: 0.000874\n",
      " Epoch 51: Train Loss: 0.000622, Validation Loss: 0.000454\n",
      " Epoch 52: Train Loss: 0.000778, Validation Loss: 0.000597\n",
      " Epoch 53: Train Loss: 0.000667, Validation Loss: 0.000489\n",
      " Epoch 54: Train Loss: 0.000651, Validation Loss: 0.000489\n",
      " Epoch 55: Train Loss: 0.000616, Validation Loss: 0.000514\n",
      " Epoch 56: Train Loss: 0.000619, Validation Loss: 0.000602\n",
      " Epoch 57: Train Loss: 0.000609, Validation Loss: 0.000463\n",
      " Epoch 58: Train Loss: 0.000615, Validation Loss: 0.000458\n",
      " Epoch 59: Train Loss: 0.000605, Validation Loss: 0.000444\n",
      " Epoch 60: Train Loss: 0.000593, Validation Loss: 0.000481\n",
      " Epoch 61: Train Loss: 0.000595, Validation Loss: 0.000438\n",
      " Epoch 62: Train Loss: 0.000585, Validation Loss: 0.000464\n",
      " Epoch 63: Train Loss: 0.000582, Validation Loss: 0.000456\n",
      " Epoch 64: Train Loss: 0.000574, Validation Loss: 0.000519\n",
      " Epoch 65: Train Loss: 0.000572, Validation Loss: 0.000456\n",
      " Epoch 66: Train Loss: 0.000571, Validation Loss: 0.000524\n",
      " Epoch 67: Train Loss: 0.000568, Validation Loss: 0.000423\n",
      " Epoch 68: Train Loss: 0.000583, Validation Loss: 0.000435\n",
      " Epoch 69: Train Loss: 0.000565, Validation Loss: 0.000466\n",
      " Epoch 70: Train Loss: 0.000569, Validation Loss: 0.000439\n",
      " Epoch 71: Train Loss: 0.000565, Validation Loss: 0.000508\n",
      " Epoch 72: Train Loss: 0.000571, Validation Loss: 0.000453\n",
      " Epoch 73: Train Loss: 0.000566, Validation Loss: 0.000453\n",
      " Epoch 74: Train Loss: 0.000562, Validation Loss: 0.000454\n",
      " Epoch 75: Train Loss: 0.000560, Validation Loss: 0.000463\n",
      " Epoch 76: Train Loss: 0.000559, Validation Loss: 0.000466\n",
      " Epoch 77: Train Loss: 0.000565, Validation Loss: 0.000475\n",
      " Epoch 78: Train Loss: 0.000561, Validation Loss: 0.000450\n",
      " Epoch 79: Train Loss: 0.000564, Validation Loss: 0.000477\n",
      " Epoch 80: Train Loss: 0.000550, Validation Loss: 0.000422\n",
      " Epoch 81: Train Loss: 0.000560, Validation Loss: 0.000431\n",
      " Epoch 82: Train Loss: 0.000575, Validation Loss: 0.000412\n",
      " Epoch 83: Train Loss: 0.000560, Validation Loss: 0.000433\n",
      " Epoch 84: Train Loss: 0.000541, Validation Loss: 0.000444\n",
      " Epoch 85: Train Loss: 0.000540, Validation Loss: 0.000451\n",
      " Epoch 86: Train Loss: 0.000551, Validation Loss: 0.000479\n",
      " Epoch 87: Train Loss: 0.000545, Validation Loss: 0.000421\n",
      " Epoch 88: Train Loss: 0.000541, Validation Loss: 0.000428\n",
      " Epoch 89: Train Loss: 0.000541, Validation Loss: 0.000404\n",
      " Epoch 90: Train Loss: 0.000531, Validation Loss: 0.000456\n",
      " Epoch 91: Train Loss: 0.000532, Validation Loss: 0.000415\n",
      " Epoch 92: Train Loss: 0.000529, Validation Loss: 0.000458\n",
      " Epoch 93: Train Loss: 0.000526, Validation Loss: 0.000443\n",
      " Epoch 94: Train Loss: 0.000526, Validation Loss: 0.000442\n",
      " Epoch 95: Train Loss: 0.000524, Validation Loss: 0.000423\n",
      " Epoch 96: Train Loss: 0.000527, Validation Loss: 0.000418\n",
      " Epoch 97: Train Loss: 0.000522, Validation Loss: 0.000450\n",
      " Epoch 98: Train Loss: 0.000525, Validation Loss: 0.000417\n",
      " Epoch 99: Train Loss: 0.000523, Validation Loss: 0.000447\n",
      " Epoch 100: Train Loss: 0.000520, Validation Loss: 0.000444\n",
      " Epoch 101: Train Loss: 0.000526, Validation Loss: 0.000449\n",
      " Epoch 102: Train Loss: 0.000519, Validation Loss: 0.000422\n",
      " Epoch 103: Train Loss: 0.000519, Validation Loss: 0.000401\n",
      " Epoch 104: Train Loss: 0.000519, Validation Loss: 0.000457\n",
      " Epoch 105: Train Loss: 0.000519, Validation Loss: 0.000417\n",
      " Epoch 106: Train Loss: 0.000514, Validation Loss: 0.000405\n",
      " Epoch 107: Train Loss: 0.000522, Validation Loss: 0.000420\n",
      " Epoch 108: Train Loss: 0.000522, Validation Loss: 0.000475\n",
      " Epoch 109: Train Loss: 0.000516, Validation Loss: 0.000416\n",
      " Epoch 110: Train Loss: 0.000511, Validation Loss: 0.000420\n",
      " Epoch 111: Train Loss: 0.000511, Validation Loss: 0.000397\n",
      " Epoch 112: Train Loss: 0.000519, Validation Loss: 0.000418\n",
      " Epoch 113: Train Loss: 0.000517, Validation Loss: 0.000434\n",
      " Epoch 114: Train Loss: 0.000510, Validation Loss: 0.000439\n",
      " Epoch 115: Train Loss: 0.000520, Validation Loss: 0.000402\n",
      " Epoch 116: Train Loss: 0.000513, Validation Loss: 0.000404\n",
      " Epoch 117: Train Loss: 0.000507, Validation Loss: 0.000406\n",
      " Epoch 118: Train Loss: 0.000504, Validation Loss: 0.000404\n",
      " Epoch 119: Train Loss: 0.000506, Validation Loss: 0.000399\n",
      " Epoch 120: Train Loss: 0.000503, Validation Loss: 0.000439\n",
      " Epoch 121: Train Loss: 0.000502, Validation Loss: 0.000433\n",
      " Epoch 122: Train Loss: 0.000500, Validation Loss: 0.000426\n",
      " Epoch 123: Train Loss: 0.000498, Validation Loss: 0.000404\n",
      " Epoch 124: Train Loss: 0.000506, Validation Loss: 0.000453\n",
      " Epoch 125: Train Loss: 0.000503, Validation Loss: 0.000408\n",
      " Epoch 126: Train Loss: 0.000498, Validation Loss: 0.000408\n",
      " Epoch 127: Train Loss: 0.000496, Validation Loss: 0.000406\n",
      " Epoch 128: Train Loss: 0.000497, Validation Loss: 0.000407\n",
      " Epoch 129: Train Loss: 0.000495, Validation Loss: 0.000426\n",
      " Epoch 130: Train Loss: 0.000497, Validation Loss: 0.000430\n",
      " Epoch 131: Train Loss: 0.000497, Validation Loss: 0.000406\n",
      "Early stopping at epoch 131 (no improvement in validation loss for 20 epochs).\n",
      "Model: UNet_1\n",
      "Validation Loss: 0.0013852879637852311\n",
      "Training Time: 65.14629077911377\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_1\n",
      "Validation Loss: 0.0015117586590349674\n",
      "Training Time: 42.778557777404785\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_1\n",
      "Validation Loss: 0.0012239086208865047\n",
      "Training Time: 83.29359245300293\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_1\n",
      "Validation Loss: 0.00125120987650007\n",
      "Training Time: 57.33808708190918\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D_1\n",
      "Validation Loss: 0.0013200602261349559\n",
      "Training Time: 49.36181354522705\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_1\n",
      "Validation Loss: 0.001144576701335609\n",
      "Training Time: 110.65421080589294\n",
      "--------------------------------------------------\n",
      "Model: UNet_2\n",
      "Validation Loss: 0.0012221460929140449\n",
      "Training Time: 54.41052556037903\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_2\n",
      "Validation Loss: 0.0012559882597997785\n",
      "Training Time: 42.712170362472534\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_2\n",
      "Validation Loss: 0.0011413675965741277\n",
      "Training Time: 55.86231279373169\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_2\n",
      "Validation Loss: 0.0012320546666160226\n",
      "Training Time: 55.061806440353394\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D_2\n",
      "Validation Loss: 0.0011493167839944363\n",
      "Training Time: 68.79355931282043\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_2\n",
      "Validation Loss: 0.0010140802478417754\n",
      "Training Time: 88.06958842277527\n",
      "--------------------------------------------------\n",
      "Model: UNet_3\n",
      "Validation Loss: 0.0006192747387103736\n",
      "Training Time: 159.7641246318817\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_3\n",
      "Validation Loss: 0.0006338394596241415\n",
      "Training Time: 186.06696248054504\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_3\n",
      "Validation Loss: 0.00046008368371985853\n",
      "Training Time: 563.3110420703888\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_3\n",
      "Validation Loss: 0.0005644108168780804\n",
      "Training Time: 178.69626712799072\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D_3\n",
      "Validation Loss: 0.0005332701839506626\n",
      "Training Time: 205.17079901695251\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_3\n",
      "Validation Loss: 0.0005190306110307574\n",
      "Training Time: 182.3110888004303\n",
      "--------------------------------------------------\n",
      "Model: UNet_4\n",
      "Validation Loss: 0.0006548911915160716\n",
      "Training Time: 281.0220968723297\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_4\n",
      "Validation Loss: 0.0006534650456160307\n",
      "Training Time: 179.0708532333374\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_4\n",
      "Validation Loss: 0.0005529473419301212\n",
      "Training Time: 331.9300606250763\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_4\n",
      "Validation Loss: 0.0005097584798932076\n",
      "Training Time: 221.68041253089905\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D_4\n",
      "Validation Loss: 0.0005188959767110646\n",
      "Training Time: 222.4261598587036\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_4\n",
      "Validation Loss: 0.0005620697047561407\n",
      "Training Time: 252.52454900741577\n",
      "--------------------------------------------------\n",
      "Model: UNet_5\n",
      "Validation Loss: 0.00039903083234094083\n",
      "Training Time: 835.2395956516266\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_5\n",
      "Validation Loss: 0.000409658532589674\n",
      "Training Time: 986.7127969264984\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_5\n",
      "Validation Loss: 0.0004421977500896901\n",
      "Training Time: 650.3599400520325\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_5\n",
      "Validation Loss: 0.0004324871115386486\n",
      "Training Time: 808.4191992282867\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D_5\n",
      "Validation Loss: 0.0004300957079976797\n",
      "Training Time: 755.4320533275604\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_5\n",
      "Validation Loss: 0.0003896298003382981\n",
      "Training Time: 867.9521448612213\n",
      "--------------------------------------------------\n",
      "Model: UNet_6\n",
      "Validation Loss: 0.00039133266545832157\n",
      "Training Time: 3710.277172803879\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock_6\n",
      "Validation Loss: 0.00037359949783422053\n",
      "Training Time: 5545.858352422714\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention_6\n",
      "Validation Loss: 0.0005027744336985052\n",
      "Training Time: 2385.3178791999817\n",
      "--------------------------------------------------\n",
      "Model: UNet3D_6\n",
      "Validation Loss: 0.00037887069629505277\n",
      "Training Time: 2500.943601846695\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D_6\n",
      "Validation Loss: 0.0003972827107645571\n",
      "Training Time: 4606.106536626816\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from model_UNet import UNet_1,UNetwithSEBlock_1,UNetwithSelfattention_1,UNet3D_1,UNetwithSEBlock3D_1,UNetwithSelfattention3D_1,UNet_2,UNetwithSEBlock_2,UNetwithSelfattention_2,UNet3D_2,UNetwithSEBlock3D_2,UNetwithSelfattention3D_2,UNet_3,UNetwithSEBlock_3,UNetwithSelfattention_3,UNet3D_3,UNetwithSEBlock3D_3,UNetwithSelfattention3D_3,UNet_4,UNetwithSEBlock_4,UNetwithSelfattention_4,UNet3D_4,UNetwithSEBlock3D_4,UNetwithSelfattention3D_4,UNet_5,UNetwithSEBlock_5,UNetwithSelfattention_5,UNet3D_5,UNetwithSEBlock3D_5,UNetwithSelfattention3D_5,UNet_6,UNetwithSEBlock_6,UNetwithSelfattention_6,UNet3D_6,UNetwithSelfattention3D_6\n",
    "# from model_UNet import UNetwithSEBlock3D_6\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, WeightedMSELoss\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "model_dict = {\n",
    "    'UNet_1': UNet_1,\n",
    "    'UNetwithSEBlock_1': UNetwithSEBlock_1,\n",
    "    'UNetwithSelfattention_1': UNetwithSelfattention_1,\n",
    "    'UNet3D_1': UNet3D_1,\n",
    "    'UNetwithSEBlock3D_1': UNetwithSEBlock3D_1,\n",
    "    'UNetwithSelfattention3D_1': UNetwithSelfattention3D_1,\n",
    "    'UNet_2': UNet_2,\n",
    "    'UNetwithSEBlock_2': UNetwithSEBlock_2,\n",
    "    'UNetwithSelfattention_2': UNetwithSelfattention_2,\n",
    "    'UNet3D_2': UNet3D_2,\n",
    "    'UNetwithSEBlock3D_2': UNetwithSEBlock3D_2,\n",
    "    'UNetwithSelfattention3D_2': UNetwithSelfattention3D_2,\n",
    "    'UNet_3': UNet_3,\n",
    "    'UNetwithSEBlock_3': UNetwithSEBlock_3,\n",
    "    'UNetwithSelfattention_3': UNetwithSelfattention_3,\n",
    "    'UNet3D_3': UNet3D_3,\n",
    "    'UNetwithSEBlock3D_3': UNetwithSEBlock3D_3,\n",
    "    'UNetwithSelfattention3D_3': UNetwithSelfattention3D_3,\n",
    "    'UNet_4': UNet_4,\n",
    "    'UNetwithSEBlock_4': UNetwithSEBlock_4,\n",
    "    'UNetwithSelfattention_4': UNetwithSelfattention_4,\n",
    "    'UNet3D_4': UNet3D_4,\n",
    "    'UNetwithSEBlock3D_4': UNetwithSEBlock3D_4,\n",
    "    'UNetwithSelfattention3D_4': UNetwithSelfattention3D_4,\n",
    "    'UNet_5': UNet_5,\n",
    "    'UNetwithSEBlock_5': UNetwithSEBlock_5,\n",
    "    'UNetwithSelfattention_5': UNetwithSelfattention_5,\n",
    "    'UNet3D_5': UNet3D_5,\n",
    "    'UNetwithSEBlock3D_5': UNetwithSEBlock3D_5,\n",
    "    'UNetwithSelfattention3D_5': UNetwithSelfattention3D_5,\n",
    "    'UNet_6': UNet_6,\n",
    "    'UNetwithSEBlock_6': UNetwithSEBlock_6,\n",
    "    'UNetwithSelfattention_6': UNetwithSelfattention_6,\n",
    "    'UNet3D_6': UNet3D_6,\n",
    "    # 'UNetwithSEBlock3D_6': UNetwithSEBlock3D_6,\n",
    "    'UNetwithSelfattention3D_6': UNetwithSelfattention3D_6,\n",
    "}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = WeightedMSELoss()\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/CNN/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1994cd1d-fe63-4672-8321-fac5de76cfa7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.017449, Validation Loss: 0.005693\n",
      " Epoch 2: Train Loss: 0.005709, Validation Loss: 0.005692\n",
      " Epoch 3: Train Loss: 0.005709, Validation Loss: 0.005691\n",
      " Epoch 4: Train Loss: 0.005709, Validation Loss: 0.005690\n",
      " Epoch 5: Train Loss: 0.005708, Validation Loss: 0.005689\n",
      " Epoch 6: Train Loss: 0.005707, Validation Loss: 0.005687\n",
      " Epoch 7: Train Loss: 0.005704, Validation Loss: 0.005684\n",
      " Epoch 8: Train Loss: 0.005701, Validation Loss: 0.005678\n",
      " Epoch 9: Train Loss: 0.005694, Validation Loss: 0.005667\n",
      " Epoch 10: Train Loss: 0.005681, Validation Loss: 0.005634\n",
      " Epoch 11: Train Loss: 0.005625, Validation Loss: 0.005124\n",
      " Epoch 12: Train Loss: 0.005277, Validation Loss: 0.004839\n",
      " Epoch 13: Train Loss: 0.004907, Validation Loss: 0.004739\n",
      " Epoch 14: Train Loss: 0.004373, Validation Loss: 0.004535\n",
      " Epoch 15: Train Loss: 0.002750, Validation Loss: 0.002471\n",
      " Epoch 16: Train Loss: 0.001630, Validation Loss: 0.001496\n",
      " Epoch 17: Train Loss: 0.001203, Validation Loss: 0.001060\n",
      " Epoch 18: Train Loss: 0.000958, Validation Loss: 0.000874\n",
      " Epoch 19: Train Loss: 0.000816, Validation Loss: 0.000764\n",
      " Epoch 20: Train Loss: 0.000728, Validation Loss: 0.000693\n",
      " Epoch 21: Train Loss: 0.000669, Validation Loss: 0.000643\n",
      " Epoch 22: Train Loss: 0.000625, Validation Loss: 0.000606\n",
      " Epoch 23: Train Loss: 0.000591, Validation Loss: 0.000575\n",
      " Epoch 24: Train Loss: 0.000563, Validation Loss: 0.000550\n",
      " Epoch 25: Train Loss: 0.000539, Validation Loss: 0.000527\n",
      " Epoch 26: Train Loss: 0.000518, Validation Loss: 0.000507\n",
      " Epoch 27: Train Loss: 0.000498, Validation Loss: 0.000488\n",
      " Epoch 28: Train Loss: 0.000480, Validation Loss: 0.000470\n",
      " Epoch 29: Train Loss: 0.000462, Validation Loss: 0.000453\n",
      " Epoch 30: Train Loss: 0.000444, Validation Loss: 0.000435\n",
      " Epoch 31: Train Loss: 0.000431, Validation Loss: 0.000426\n",
      " Epoch 32: Train Loss: 0.000422, Validation Loss: 0.000417\n",
      " Epoch 33: Train Loss: 0.000412, Validation Loss: 0.000407\n",
      " Epoch 34: Train Loss: 0.000402, Validation Loss: 0.000398\n",
      " Epoch 35: Train Loss: 0.000392, Validation Loss: 0.000387\n",
      " Epoch 36: Train Loss: 0.000383, Validation Loss: 0.000377\n",
      " Epoch 37: Train Loss: 0.000373, Validation Loss: 0.000368\n",
      " Epoch 38: Train Loss: 0.000364, Validation Loss: 0.000360\n",
      " Epoch 39: Train Loss: 0.000356, Validation Loss: 0.000352\n",
      " Epoch 40: Train Loss: 0.000349, Validation Loss: 0.000345\n",
      " Epoch 41: Train Loss: 0.000343, Validation Loss: 0.000339\n",
      " Epoch 42: Train Loss: 0.000337, Validation Loss: 0.000334\n",
      " Epoch 43: Train Loss: 0.000331, Validation Loss: 0.000329\n",
      " Epoch 44: Train Loss: 0.000326, Validation Loss: 0.000323\n",
      " Epoch 45: Train Loss: 0.000321, Validation Loss: 0.000318\n",
      " Epoch 46: Train Loss: 0.000316, Validation Loss: 0.000314\n",
      " Epoch 47: Train Loss: 0.000312, Validation Loss: 0.000309\n",
      " Epoch 48: Train Loss: 0.000308, Validation Loss: 0.000305\n",
      " Epoch 49: Train Loss: 0.000304, Validation Loss: 0.000301\n",
      " Epoch 50: Train Loss: 0.000300, Validation Loss: 0.000298\n",
      " Epoch 51: Train Loss: 0.000296, Validation Loss: 0.000294\n",
      " Epoch 52: Train Loss: 0.000292, Validation Loss: 0.000291\n",
      " Epoch 53: Train Loss: 0.000289, Validation Loss: 0.000287\n",
      " Epoch 54: Train Loss: 0.000285, Validation Loss: 0.000284\n",
      " Epoch 55: Train Loss: 0.000282, Validation Loss: 0.000280\n",
      " Epoch 56: Train Loss: 0.000279, Validation Loss: 0.000277\n",
      " Epoch 57: Train Loss: 0.000276, Validation Loss: 0.000274\n",
      " Epoch 58: Train Loss: 0.000273, Validation Loss: 0.000271\n",
      " Epoch 59: Train Loss: 0.000270, Validation Loss: 0.000268\n",
      " Epoch 60: Train Loss: 0.000267, Validation Loss: 0.000265\n",
      " Epoch 61: Train Loss: 0.000264, Validation Loss: 0.000263\n",
      " Epoch 62: Train Loss: 0.000263, Validation Loss: 0.000262\n",
      " Epoch 63: Train Loss: 0.000261, Validation Loss: 0.000260\n",
      " Epoch 64: Train Loss: 0.000260, Validation Loss: 0.000259\n",
      " Epoch 65: Train Loss: 0.000259, Validation Loss: 0.000258\n",
      " Epoch 66: Train Loss: 0.000257, Validation Loss: 0.000256\n",
      " Epoch 67: Train Loss: 0.000256, Validation Loss: 0.000255\n",
      " Epoch 68: Train Loss: 0.000255, Validation Loss: 0.000254\n",
      " Epoch 69: Train Loss: 0.000253, Validation Loss: 0.000252\n",
      " Epoch 70: Train Loss: 0.000252, Validation Loss: 0.000251\n",
      " Epoch 71: Train Loss: 0.000251, Validation Loss: 0.000249\n",
      " Epoch 72: Train Loss: 0.000249, Validation Loss: 0.000248\n",
      " Epoch 73: Train Loss: 0.000248, Validation Loss: 0.000247\n",
      " Epoch 74: Train Loss: 0.000247, Validation Loss: 0.000246\n",
      " Epoch 75: Train Loss: 0.000245, Validation Loss: 0.000244\n",
      " Epoch 76: Train Loss: 0.000244, Validation Loss: 0.000243\n",
      " Epoch 77: Train Loss: 0.000243, Validation Loss: 0.000242\n",
      " Epoch 78: Train Loss: 0.000242, Validation Loss: 0.000241\n",
      " Epoch 79: Train Loss: 0.000241, Validation Loss: 0.000240\n",
      " Epoch 80: Train Loss: 0.000239, Validation Loss: 0.000239\n",
      " Epoch 81: Train Loss: 0.000238, Validation Loss: 0.000237\n",
      " Epoch 82: Train Loss: 0.000237, Validation Loss: 0.000236\n",
      " Epoch 83: Train Loss: 0.000236, Validation Loss: 0.000236\n",
      " Epoch 84: Train Loss: 0.000235, Validation Loss: 0.000234\n",
      " Epoch 85: Train Loss: 0.000234, Validation Loss: 0.000233\n",
      " Epoch 86: Train Loss: 0.000232, Validation Loss: 0.000232\n",
      " Epoch 87: Train Loss: 0.000231, Validation Loss: 0.000230\n",
      " Epoch 88: Train Loss: 0.000230, Validation Loss: 0.000229\n",
      " Epoch 89: Train Loss: 0.000229, Validation Loss: 0.000229\n",
      " Epoch 90: Train Loss: 0.000228, Validation Loss: 0.000227\n",
      " Epoch 91: Train Loss: 0.000227, Validation Loss: 0.000226\n",
      " Epoch 92: Train Loss: 0.000226, Validation Loss: 0.000226\n",
      " Epoch 93: Train Loss: 0.000226, Validation Loss: 0.000226\n",
      " Epoch 94: Train Loss: 0.000225, Validation Loss: 0.000225\n",
      " Epoch 95: Train Loss: 0.000225, Validation Loss: 0.000224\n",
      " Epoch 96: Train Loss: 0.000224, Validation Loss: 0.000224\n",
      " Epoch 97: Train Loss: 0.000224, Validation Loss: 0.000223\n",
      " Epoch 98: Train Loss: 0.000223, Validation Loss: 0.000223\n",
      " Epoch 99: Train Loss: 0.000222, Validation Loss: 0.000222\n",
      " Epoch 100: Train Loss: 0.000222, Validation Loss: 0.000222\n",
      " Epoch 101: Train Loss: 0.000221, Validation Loss: 0.000221\n",
      " Epoch 102: Train Loss: 0.000221, Validation Loss: 0.000220\n",
      " Epoch 103: Train Loss: 0.000220, Validation Loss: 0.000220\n",
      " Epoch 104: Train Loss: 0.000220, Validation Loss: 0.000219\n",
      " Epoch 105: Train Loss: 0.000219, Validation Loss: 0.000219\n",
      " Epoch 106: Train Loss: 0.000218, Validation Loss: 0.000218\n",
      " Epoch 107: Train Loss: 0.000218, Validation Loss: 0.000218\n",
      " Epoch 108: Train Loss: 0.000217, Validation Loss: 0.000217\n",
      " Epoch 109: Train Loss: 0.000217, Validation Loss: 0.000216\n",
      " Epoch 110: Train Loss: 0.000216, Validation Loss: 0.000216\n",
      " Epoch 111: Train Loss: 0.000215, Validation Loss: 0.000215\n",
      " Epoch 112: Train Loss: 0.000215, Validation Loss: 0.000215\n",
      " Epoch 113: Train Loss: 0.000214, Validation Loss: 0.000214\n",
      " Epoch 114: Train Loss: 0.000214, Validation Loss: 0.000213\n",
      " Epoch 115: Train Loss: 0.000213, Validation Loss: 0.000213\n",
      " Epoch 116: Train Loss: 0.000213, Validation Loss: 0.000212\n",
      " Epoch 117: Train Loss: 0.000212, Validation Loss: 0.000212\n",
      " Epoch 118: Train Loss: 0.000211, Validation Loss: 0.000211\n",
      " Epoch 119: Train Loss: 0.000211, Validation Loss: 0.000210\n",
      " Epoch 120: Train Loss: 0.000210, Validation Loss: 0.000210\n",
      " Epoch 121: Train Loss: 0.000210, Validation Loss: 0.000210\n",
      " Epoch 122: Train Loss: 0.000209, Validation Loss: 0.000209\n",
      " Epoch 123: Train Loss: 0.000209, Validation Loss: 0.000209\n",
      " Epoch 124: Train Loss: 0.000209, Validation Loss: 0.000209\n",
      " Epoch 125: Train Loss: 0.000209, Validation Loss: 0.000208\n",
      " Epoch 126: Train Loss: 0.000208, Validation Loss: 0.000208\n",
      " Epoch 127: Train Loss: 0.000208, Validation Loss: 0.000208\n",
      " Epoch 128: Train Loss: 0.000208, Validation Loss: 0.000208\n",
      " Epoch 129: Train Loss: 0.000207, Validation Loss: 0.000207\n",
      " Epoch 130: Train Loss: 0.000207, Validation Loss: 0.000207\n",
      " Epoch 131: Train Loss: 0.000207, Validation Loss: 0.000207\n",
      " Epoch 132: Train Loss: 0.000206, Validation Loss: 0.000206\n",
      " Epoch 133: Train Loss: 0.000206, Validation Loss: 0.000206\n",
      " Epoch 134: Train Loss: 0.000206, Validation Loss: 0.000206\n",
      " Epoch 135: Train Loss: 0.000205, Validation Loss: 0.000205\n",
      " Epoch 136: Train Loss: 0.000205, Validation Loss: 0.000205\n",
      " Epoch 137: Train Loss: 0.000205, Validation Loss: 0.000205\n",
      " Epoch 138: Train Loss: 0.000204, Validation Loss: 0.000204\n",
      " Epoch 139: Train Loss: 0.000204, Validation Loss: 0.000204\n",
      " Epoch 140: Train Loss: 0.000204, Validation Loss: 0.000204\n",
      " Epoch 141: Train Loss: 0.000204, Validation Loss: 0.000203\n",
      " Epoch 142: Train Loss: 0.000203, Validation Loss: 0.000203\n",
      " Epoch 143: Train Loss: 0.000203, Validation Loss: 0.000203\n",
      " Epoch 144: Train Loss: 0.000203, Validation Loss: 0.000203\n",
      " Epoch 145: Train Loss: 0.000202, Validation Loss: 0.000202\n",
      " Epoch 146: Train Loss: 0.000202, Validation Loss: 0.000202\n",
      " Epoch 147: Train Loss: 0.000202, Validation Loss: 0.000201\n",
      " Epoch 148: Train Loss: 0.000201, Validation Loss: 0.000201\n",
      " Epoch 149: Train Loss: 0.000201, Validation Loss: 0.000201\n",
      " Epoch 150: Train Loss: 0.000201, Validation Loss: 0.000200\n",
      " Epoch 151: Train Loss: 0.000200, Validation Loss: 0.000200\n",
      " Epoch 152: Train Loss: 0.000200, Validation Loss: 0.000200\n",
      " Epoch 153: Train Loss: 0.000200, Validation Loss: 0.000200\n",
      " Epoch 154: Train Loss: 0.000200, Validation Loss: 0.000200\n",
      " Epoch 155: Train Loss: 0.000200, Validation Loss: 0.000199\n",
      " Epoch 156: Train Loss: 0.000199, Validation Loss: 0.000199\n",
      " Epoch 157: Train Loss: 0.000199, Validation Loss: 0.000199\n",
      " Epoch 158: Train Loss: 0.000199, Validation Loss: 0.000199\n",
      " Epoch 159: Train Loss: 0.000199, Validation Loss: 0.000199\n",
      " Epoch 160: Train Loss: 0.000199, Validation Loss: 0.000199\n",
      " Epoch 161: Train Loss: 0.000199, Validation Loss: 0.000198\n",
      " Epoch 162: Train Loss: 0.000198, Validation Loss: 0.000198\n",
      " Epoch 163: Train Loss: 0.000198, Validation Loss: 0.000198\n",
      " Epoch 164: Train Loss: 0.000198, Validation Loss: 0.000199\n",
      " Epoch 165: Train Loss: 0.000198, Validation Loss: 0.000198\n",
      " Epoch 166: Train Loss: 0.000198, Validation Loss: 0.000197\n",
      " Epoch 167: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 168: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 169: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 170: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 171: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 172: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 173: Train Loss: 0.000196, Validation Loss: 0.000196\n",
      " Epoch 174: Train Loss: 0.000196, Validation Loss: 0.000196\n",
      " Epoch 175: Train Loss: 0.000196, Validation Loss: 0.000196\n",
      " Epoch 176: Train Loss: 0.000196, Validation Loss: 0.000196\n",
      " Epoch 177: Train Loss: 0.000196, Validation Loss: 0.000196\n",
      " Epoch 178: Train Loss: 0.000196, Validation Loss: 0.000195\n",
      " Epoch 179: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 180: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 181: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 182: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 183: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 184: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 185: Train Loss: 0.000195, Validation Loss: 0.000194\n",
      " Epoch 186: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 187: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 188: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 189: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 190: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 191: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 192: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 193: Train Loss: 0.000194, Validation Loss: 0.000194\n",
      " Epoch 194: Train Loss: 0.000194, Validation Loss: 0.000193\n",
      " Epoch 195: Train Loss: 0.000194, Validation Loss: 0.000193\n",
      " Epoch 196: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 197: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 198: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 199: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 200: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 201: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 202: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 203: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 204: Train Loss: 0.000193, Validation Loss: 0.000192\n",
      " Epoch 205: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 206: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 207: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 208: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 209: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 210: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 211: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 212: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 213: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 214: Train Loss: 0.000192, Validation Loss: 0.000191\n",
      " Epoch 215: Train Loss: 0.000192, Validation Loss: 0.000191\n",
      " Epoch 216: Train Loss: 0.000192, Validation Loss: 0.000191\n",
      " Epoch 217: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 218: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 219: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 220: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 221: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 222: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 223: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 224: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 225: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 226: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 227: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 228: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 229: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 230: Train Loss: 0.000191, Validation Loss: 0.000191\n",
      " Epoch 231: Train Loss: 0.000191, Validation Loss: 0.000190\n",
      " Epoch 232: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 233: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 234: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 235: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 236: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 237: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 238: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 239: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 240: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 241: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 242: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 243: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 244: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 245: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 246: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 247: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 248: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 249: Train Loss: 0.000190, Validation Loss: 0.000190\n",
      " Epoch 250: Train Loss: 0.000190, Validation Loss: 0.000189\n",
      " Epoch 251: Train Loss: 0.000190, Validation Loss: 0.000189\n",
      " Epoch 252: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 253: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 254: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 255: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 256: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 257: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 258: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 259: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 260: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 261: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 262: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 263: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 264: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 265: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 266: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 267: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 268: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 269: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 270: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 271: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 272: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 273: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 274: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 275: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 276: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 277: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 278: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 279: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 280: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 281: Train Loss: 0.000189, Validation Loss: 0.000188\n",
      " Epoch 282: Train Loss: 0.000189, Validation Loss: 0.000188\n",
      " Epoch 283: Train Loss: 0.000189, Validation Loss: 0.000188\n",
      " Epoch 284: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 285: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 286: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 287: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 288: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 289: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 290: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 291: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 292: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 293: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 294: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 295: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 296: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 297: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 298: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 299: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 300: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 301: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 302: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 303: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 304: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 305: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 306: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 307: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 308: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 309: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 310: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 311: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 312: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 313: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 314: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 315: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 316: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 317: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 318: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 319: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 320: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 321: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 322: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 323: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 324: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 325: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 326: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 327: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 328: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 329: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 330: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 331: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 332: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 333: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 334: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 335: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 336: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 337: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 338: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 339: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 340: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 341: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 342: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 343: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 344: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 345: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 346: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 347: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 348: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 349: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 350: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 351: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 352: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 353: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 354: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 355: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 356: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 357: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 358: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 359: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 360: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 361: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 362: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 363: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 364: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 365: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 366: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 367: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 368: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 369: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 370: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 371: Train Loss: 0.000188, Validation Loss: 0.000188\n",
      " Epoch 372: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 373: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 374: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 375: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 376: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 377: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 378: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 379: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 380: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 381: Train Loss: 0.000188, Validation Loss: 0.000187\n",
      " Epoch 382: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 383: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 384: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 385: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 386: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 387: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 388: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 389: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 390: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 391: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 392: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 393: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 394: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 395: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 396: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 397: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 398: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 399: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 400: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 401: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 402: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 403: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 404: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 405: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 406: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 407: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 408: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 409: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 410: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 411: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 412: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 413: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 414: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 415: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 416: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 417: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 418: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 419: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 420: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 421: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 422: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 423: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 424: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 425: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 426: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 427: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 428: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 429: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 430: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 431: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 432: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 433: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 434: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 435: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 436: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 437: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 438: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 439: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 440: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 441: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 442: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 443: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 444: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 445: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 446: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 447: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 448: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 449: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 450: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 451: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 452: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 453: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 454: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 455: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 456: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 457: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 458: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 459: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 460: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 461: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 462: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 463: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 464: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 465: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 466: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 467: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 468: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 469: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 470: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 471: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 472: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 473: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 474: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 475: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 476: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 477: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 478: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 479: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 480: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 481: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 482: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 483: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 484: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 485: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 486: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 487: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 488: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 489: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 490: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 491: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 492: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 493: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 494: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 495: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 496: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 497: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 498: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 499: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 500: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 501: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 502: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 503: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 504: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 505: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 506: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 507: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 508: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 509: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 510: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 511: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 512: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 513: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 514: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 515: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 516: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 517: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 518: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 519: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 520: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 521: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 522: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 523: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 524: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 525: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 526: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 527: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 528: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 529: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 530: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 531: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 532: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 533: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 534: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 535: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 536: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 537: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 538: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 539: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 540: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 541: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 542: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 543: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 544: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 545: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 546: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 547: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 548: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 549: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 550: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 551: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 552: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 553: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 554: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 555: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 556: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 557: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      "Early stopping at epoch 557 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012280, Validation Loss: 0.005693\n",
      " Epoch 2: Train Loss: 0.004472, Validation Loss: 0.004835\n",
      " Epoch 3: Train Loss: 0.003752, Validation Loss: 0.003730\n",
      " Epoch 4: Train Loss: 0.002589, Validation Loss: 0.003589\n",
      " Epoch 5: Train Loss: 0.001897, Validation Loss: 0.001671\n",
      " Epoch 6: Train Loss: 0.001516, Validation Loss: 0.001408\n",
      " Epoch 7: Train Loss: 0.001286, Validation Loss: 0.001207\n",
      " Epoch 8: Train Loss: 0.001038, Validation Loss: 0.000974\n",
      " Epoch 9: Train Loss: 0.000889, Validation Loss: 0.000792\n",
      " Epoch 10: Train Loss: 0.000703, Validation Loss: 0.000665\n",
      " Epoch 11: Train Loss: 0.000607, Validation Loss: 0.000538\n",
      " Epoch 12: Train Loss: 0.000515, Validation Loss: 0.000497\n",
      " Epoch 13: Train Loss: 0.000485, Validation Loss: 0.000474\n",
      " Epoch 14: Train Loss: 0.000449, Validation Loss: 0.000447\n",
      " Epoch 15: Train Loss: 0.000370, Validation Loss: 0.000340\n",
      " Epoch 16: Train Loss: 0.000314, Validation Loss: 0.000303\n",
      " Epoch 17: Train Loss: 0.000294, Validation Loss: 0.000290\n",
      " Epoch 18: Train Loss: 0.000282, Validation Loss: 0.000279\n",
      " Epoch 19: Train Loss: 0.000272, Validation Loss: 0.000269\n",
      " Epoch 20: Train Loss: 0.000264, Validation Loss: 0.000260\n",
      " Epoch 21: Train Loss: 0.000256, Validation Loss: 0.000253\n",
      " Epoch 22: Train Loss: 0.000249, Validation Loss: 0.000246\n",
      " Epoch 23: Train Loss: 0.000243, Validation Loss: 0.000241\n",
      " Epoch 24: Train Loss: 0.000237, Validation Loss: 0.000237\n",
      " Epoch 25: Train Loss: 0.000232, Validation Loss: 0.000230\n",
      " Epoch 26: Train Loss: 0.000227, Validation Loss: 0.000225\n",
      " Epoch 27: Train Loss: 0.000223, Validation Loss: 0.000221\n",
      " Epoch 28: Train Loss: 0.000218, Validation Loss: 0.000217\n",
      " Epoch 29: Train Loss: 0.000214, Validation Loss: 0.000216\n",
      " Epoch 30: Train Loss: 0.000211, Validation Loss: 0.000209\n",
      " Epoch 31: Train Loss: 0.000207, Validation Loss: 0.000209\n",
      " Epoch 32: Train Loss: 0.000205, Validation Loss: 0.000205\n",
      " Epoch 33: Train Loss: 0.000204, Validation Loss: 0.000203\n",
      " Epoch 34: Train Loss: 0.000202, Validation Loss: 0.000202\n",
      " Epoch 35: Train Loss: 0.000200, Validation Loss: 0.000200\n",
      " Epoch 36: Train Loss: 0.000198, Validation Loss: 0.000199\n",
      " Epoch 37: Train Loss: 0.000197, Validation Loss: 0.000197\n",
      " Epoch 38: Train Loss: 0.000195, Validation Loss: 0.000195\n",
      " Epoch 39: Train Loss: 0.000193, Validation Loss: 0.000193\n",
      " Epoch 40: Train Loss: 0.000192, Validation Loss: 0.000192\n",
      " Epoch 41: Train Loss: 0.000190, Validation Loss: 0.000191\n",
      " Epoch 42: Train Loss: 0.000189, Validation Loss: 0.000189\n",
      " Epoch 43: Train Loss: 0.000187, Validation Loss: 0.000187\n",
      " Epoch 44: Train Loss: 0.000186, Validation Loss: 0.000187\n",
      " Epoch 45: Train Loss: 0.000184, Validation Loss: 0.000186\n",
      " Epoch 46: Train Loss: 0.000183, Validation Loss: 0.000183\n",
      " Epoch 47: Train Loss: 0.000182, Validation Loss: 0.000182\n",
      " Epoch 48: Train Loss: 0.000180, Validation Loss: 0.000180\n",
      " Epoch 49: Train Loss: 0.000179, Validation Loss: 0.000179\n",
      " Epoch 50: Train Loss: 0.000179, Validation Loss: 0.000178\n",
      " Epoch 51: Train Loss: 0.000177, Validation Loss: 0.000177\n",
      " Epoch 52: Train Loss: 0.000176, Validation Loss: 0.000176\n",
      " Epoch 53: Train Loss: 0.000175, Validation Loss: 0.000177\n",
      " Epoch 54: Train Loss: 0.000174, Validation Loss: 0.000173\n",
      " Epoch 55: Train Loss: 0.000172, Validation Loss: 0.000172\n",
      " Epoch 56: Train Loss: 0.000171, Validation Loss: 0.000171\n",
      " Epoch 57: Train Loss: 0.000170, Validation Loss: 0.000171\n",
      " Epoch 58: Train Loss: 0.000170, Validation Loss: 0.000168\n",
      " Epoch 59: Train Loss: 0.000167, Validation Loss: 0.000168\n",
      " Epoch 60: Train Loss: 0.000166, Validation Loss: 0.000168\n",
      " Epoch 61: Train Loss: 0.000165, Validation Loss: 0.000168\n",
      " Epoch 62: Train Loss: 0.000165, Validation Loss: 0.000165\n",
      " Epoch 63: Train Loss: 0.000164, Validation Loss: 0.000166\n",
      " Epoch 64: Train Loss: 0.000163, Validation Loss: 0.000164\n",
      " Epoch 65: Train Loss: 0.000163, Validation Loss: 0.000163\n",
      " Epoch 66: Train Loss: 0.000162, Validation Loss: 0.000163\n",
      " Epoch 67: Train Loss: 0.000162, Validation Loss: 0.000162\n",
      " Epoch 68: Train Loss: 0.000161, Validation Loss: 0.000162\n",
      " Epoch 69: Train Loss: 0.000161, Validation Loss: 0.000162\n",
      " Epoch 70: Train Loss: 0.000160, Validation Loss: 0.000161\n",
      " Epoch 71: Train Loss: 0.000160, Validation Loss: 0.000160\n",
      " Epoch 72: Train Loss: 0.000159, Validation Loss: 0.000160\n",
      " Epoch 73: Train Loss: 0.000159, Validation Loss: 0.000160\n",
      " Epoch 74: Train Loss: 0.000158, Validation Loss: 0.000159\n",
      " Epoch 75: Train Loss: 0.000157, Validation Loss: 0.000158\n",
      " Epoch 76: Train Loss: 0.000157, Validation Loss: 0.000159\n",
      " Epoch 77: Train Loss: 0.000156, Validation Loss: 0.000157\n",
      " Epoch 78: Train Loss: 0.000156, Validation Loss: 0.000157\n",
      " Epoch 79: Train Loss: 0.000155, Validation Loss: 0.000157\n",
      " Epoch 80: Train Loss: 0.000155, Validation Loss: 0.000156\n",
      " Epoch 81: Train Loss: 0.000155, Validation Loss: 0.000155\n",
      " Epoch 82: Train Loss: 0.000154, Validation Loss: 0.000155\n",
      " Epoch 83: Train Loss: 0.000153, Validation Loss: 0.000154\n",
      " Epoch 84: Train Loss: 0.000153, Validation Loss: 0.000154\n",
      " Epoch 85: Train Loss: 0.000152, Validation Loss: 0.000153\n",
      " Epoch 86: Train Loss: 0.000152, Validation Loss: 0.000153\n",
      " Epoch 87: Train Loss: 0.000152, Validation Loss: 0.000153\n",
      " Epoch 88: Train Loss: 0.000151, Validation Loss: 0.000152\n",
      " Epoch 89: Train Loss: 0.000150, Validation Loss: 0.000152\n",
      " Epoch 90: Train Loss: 0.000150, Validation Loss: 0.000153\n",
      " Epoch 91: Train Loss: 0.000149, Validation Loss: 0.000151\n",
      " Epoch 92: Train Loss: 0.000149, Validation Loss: 0.000150\n",
      " Epoch 93: Train Loss: 0.000149, Validation Loss: 0.000150\n",
      " Epoch 94: Train Loss: 0.000149, Validation Loss: 0.000150\n",
      " Epoch 95: Train Loss: 0.000148, Validation Loss: 0.000149\n",
      " Epoch 96: Train Loss: 0.000148, Validation Loss: 0.000149\n",
      " Epoch 97: Train Loss: 0.000148, Validation Loss: 0.000149\n",
      " Epoch 98: Train Loss: 0.000147, Validation Loss: 0.000149\n",
      " Epoch 99: Train Loss: 0.000147, Validation Loss: 0.000148\n",
      " Epoch 100: Train Loss: 0.000147, Validation Loss: 0.000148\n",
      " Epoch 101: Train Loss: 0.000147, Validation Loss: 0.000148\n",
      " Epoch 102: Train Loss: 0.000146, Validation Loss: 0.000147\n",
      " Epoch 103: Train Loss: 0.000146, Validation Loss: 0.000147\n",
      " Epoch 104: Train Loss: 0.000146, Validation Loss: 0.000147\n",
      " Epoch 105: Train Loss: 0.000146, Validation Loss: 0.000147\n",
      " Epoch 106: Train Loss: 0.000145, Validation Loss: 0.000146\n",
      " Epoch 107: Train Loss: 0.000145, Validation Loss: 0.000146\n",
      " Epoch 108: Train Loss: 0.000145, Validation Loss: 0.000146\n",
      " Epoch 109: Train Loss: 0.000144, Validation Loss: 0.000146\n",
      " Epoch 110: Train Loss: 0.000144, Validation Loss: 0.000145\n",
      " Epoch 111: Train Loss: 0.000144, Validation Loss: 0.000145\n",
      " Epoch 112: Train Loss: 0.000144, Validation Loss: 0.000144\n",
      " Epoch 113: Train Loss: 0.000143, Validation Loss: 0.000145\n",
      " Epoch 114: Train Loss: 0.000143, Validation Loss: 0.000143\n",
      " Epoch 115: Train Loss: 0.000142, Validation Loss: 0.000143\n",
      " Epoch 116: Train Loss: 0.000142, Validation Loss: 0.000143\n",
      " Epoch 117: Train Loss: 0.000142, Validation Loss: 0.000142\n",
      " Epoch 118: Train Loss: 0.000141, Validation Loss: 0.000142\n",
      " Epoch 119: Train Loss: 0.000141, Validation Loss: 0.000142\n",
      " Epoch 120: Train Loss: 0.000140, Validation Loss: 0.000141\n",
      " Epoch 121: Train Loss: 0.000140, Validation Loss: 0.000141\n",
      " Epoch 122: Train Loss: 0.000140, Validation Loss: 0.000141\n",
      " Epoch 123: Train Loss: 0.000140, Validation Loss: 0.000141\n",
      " Epoch 124: Train Loss: 0.000140, Validation Loss: 0.000141\n",
      " Epoch 125: Train Loss: 0.000139, Validation Loss: 0.000141\n",
      " Epoch 126: Train Loss: 0.000139, Validation Loss: 0.000141\n",
      " Epoch 127: Train Loss: 0.000139, Validation Loss: 0.000140\n",
      " Epoch 128: Train Loss: 0.000139, Validation Loss: 0.000140\n",
      " Epoch 129: Train Loss: 0.000139, Validation Loss: 0.000140\n",
      " Epoch 130: Train Loss: 0.000139, Validation Loss: 0.000140\n",
      " Epoch 131: Train Loss: 0.000139, Validation Loss: 0.000140\n",
      " Epoch 132: Train Loss: 0.000138, Validation Loss: 0.000139\n",
      " Epoch 133: Train Loss: 0.000138, Validation Loss: 0.000139\n",
      " Epoch 134: Train Loss: 0.000138, Validation Loss: 0.000139\n",
      " Epoch 135: Train Loss: 0.000138, Validation Loss: 0.000139\n",
      " Epoch 136: Train Loss: 0.000138, Validation Loss: 0.000139\n",
      " Epoch 137: Train Loss: 0.000137, Validation Loss: 0.000139\n",
      " Epoch 138: Train Loss: 0.000137, Validation Loss: 0.000139\n",
      " Epoch 139: Train Loss: 0.000137, Validation Loss: 0.000138\n",
      " Epoch 140: Train Loss: 0.000137, Validation Loss: 0.000139\n",
      " Epoch 141: Train Loss: 0.000137, Validation Loss: 0.000138\n",
      " Epoch 142: Train Loss: 0.000137, Validation Loss: 0.000138\n",
      " Epoch 143: Train Loss: 0.000136, Validation Loss: 0.000138\n",
      " Epoch 144: Train Loss: 0.000136, Validation Loss: 0.000137\n",
      " Epoch 145: Train Loss: 0.000136, Validation Loss: 0.000138\n",
      " Epoch 146: Train Loss: 0.000136, Validation Loss: 0.000137\n",
      " Epoch 147: Train Loss: 0.000136, Validation Loss: 0.000137\n",
      " Epoch 148: Train Loss: 0.000136, Validation Loss: 0.000137\n",
      " Epoch 149: Train Loss: 0.000136, Validation Loss: 0.000137\n",
      " Epoch 150: Train Loss: 0.000136, Validation Loss: 0.000136\n",
      " Epoch 151: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 152: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 153: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 154: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 155: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 156: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 157: Train Loss: 0.000135, Validation Loss: 0.000136\n",
      " Epoch 158: Train Loss: 0.000134, Validation Loss: 0.000136\n",
      " Epoch 159: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 160: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 161: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 162: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 163: Train Loss: 0.000134, Validation Loss: 0.000136\n",
      " Epoch 164: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 165: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 166: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 167: Train Loss: 0.000134, Validation Loss: 0.000135\n",
      " Epoch 168: Train Loss: 0.000133, Validation Loss: 0.000135\n",
      " Epoch 169: Train Loss: 0.000133, Validation Loss: 0.000135\n",
      " Epoch 170: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 171: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 172: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 173: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 174: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 175: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 176: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 177: Train Loss: 0.000133, Validation Loss: 0.000134\n",
      " Epoch 178: Train Loss: 0.000132, Validation Loss: 0.000134\n",
      " Epoch 179: Train Loss: 0.000132, Validation Loss: 0.000134\n",
      " Epoch 180: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 181: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 182: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 183: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 184: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 185: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 186: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 187: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 188: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 189: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 190: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 191: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 192: Train Loss: 0.000132, Validation Loss: 0.000133\n",
      " Epoch 193: Train Loss: 0.000131, Validation Loss: 0.000133\n",
      " Epoch 194: Train Loss: 0.000131, Validation Loss: 0.000133\n",
      " Epoch 195: Train Loss: 0.000131, Validation Loss: 0.000133\n",
      " Epoch 196: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 197: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 198: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 199: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 200: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 201: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 202: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 203: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 204: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 205: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 206: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 207: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 208: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 209: Train Loss: 0.000131, Validation Loss: 0.000132\n",
      " Epoch 210: Train Loss: 0.000130, Validation Loss: 0.000132\n",
      " Epoch 211: Train Loss: 0.000130, Validation Loss: 0.000132\n",
      " Epoch 212: Train Loss: 0.000130, Validation Loss: 0.000132\n",
      " Epoch 213: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 214: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 215: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 216: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 217: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 218: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 219: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 220: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 221: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 222: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 223: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 224: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 225: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 226: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 227: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 228: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 229: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 230: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 231: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 232: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 233: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 234: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 235: Train Loss: 0.000130, Validation Loss: 0.000131\n",
      " Epoch 236: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 237: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 238: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 239: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 240: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 241: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 242: Train Loss: 0.000129, Validation Loss: 0.000131\n",
      " Epoch 243: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 244: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 245: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 246: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 247: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 248: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 249: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 250: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 251: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 252: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 253: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 254: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 255: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 256: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 257: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 258: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 259: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 260: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 261: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 262: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 263: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 264: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 265: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 266: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 267: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 268: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 269: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 270: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 271: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 272: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 273: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 274: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 275: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 276: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 277: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 278: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 279: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 280: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 281: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 282: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 283: Train Loss: 0.000129, Validation Loss: 0.000130\n",
      " Epoch 284: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 285: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 286: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 287: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 288: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 289: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 290: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 291: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 292: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 293: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 294: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 295: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 296: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 297: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 298: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 299: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 300: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 301: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 302: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 303: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 304: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 305: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 306: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 307: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 308: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 309: Train Loss: 0.000128, Validation Loss: 0.000130\n",
      " Epoch 310: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 311: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 312: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 313: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 314: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 315: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 316: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 317: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 318: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 319: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 320: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 321: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 322: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 323: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 324: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 325: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 326: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 327: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 328: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 329: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 330: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 331: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 332: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 333: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 334: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 335: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 336: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 337: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 338: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 339: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 340: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 341: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 342: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 343: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 344: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 345: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 346: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 347: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 348: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 349: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 350: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 351: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 352: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 353: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 354: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 355: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 356: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 357: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 358: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 359: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 360: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 361: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 362: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 363: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 364: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 365: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 366: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 367: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 368: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 369: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 370: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 371: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 372: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 373: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 374: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 375: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 376: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 377: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 378: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 379: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 380: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 381: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 382: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 383: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 384: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 385: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 386: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 387: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 388: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 389: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 390: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 391: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 392: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 393: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 394: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 395: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 396: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 397: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 398: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 399: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 400: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 401: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 402: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 403: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 404: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 405: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 406: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 407: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 408: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 409: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 410: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 411: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 412: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 413: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 414: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 415: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 416: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 417: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 418: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 419: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 420: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 421: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 422: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 423: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 424: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 425: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 426: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 427: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 428: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 429: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 430: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 431: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 432: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 433: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 434: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 435: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 436: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 437: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 438: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 439: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 440: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 441: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 442: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 443: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 444: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 445: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 446: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 447: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 448: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 449: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 450: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 451: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 452: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 453: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 454: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 455: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 456: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 457: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 458: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 459: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 460: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 461: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 462: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 463: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 464: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 465: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 466: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 467: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 468: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 469: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 470: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 471: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 472: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 473: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 474: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 475: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 476: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 477: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 478: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 479: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 480: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 481: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 482: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 483: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 484: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 485: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 486: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 487: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 488: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 489: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 490: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 491: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 492: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 493: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 494: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 495: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 496: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 497: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 498: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 499: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 500: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 501: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 502: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 503: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 504: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 505: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 506: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 507: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 508: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 509: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 510: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 511: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 512: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 513: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 514: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 515: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 516: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 517: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 518: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 519: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 520: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 521: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 522: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 523: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 524: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 525: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 526: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 527: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 528: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 529: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 530: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 531: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 532: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 533: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 534: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 535: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 536: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      " Epoch 537: Train Loss: 0.000128, Validation Loss: 0.000129\n",
      "Early stopping at epoch 537 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015860, Validation Loss: 0.005693\n",
      " Epoch 2: Train Loss: 0.004623, Validation Loss: 0.004984\n",
      " Epoch 3: Train Loss: 0.004238, Validation Loss: 0.004305\n",
      " Epoch 4: Train Loss: 0.002749, Validation Loss: 0.002009\n",
      " Epoch 5: Train Loss: 0.001525, Validation Loss: 0.001395\n",
      " Epoch 6: Train Loss: 0.001075, Validation Loss: 0.001369\n",
      " Epoch 7: Train Loss: 0.000845, Validation Loss: 0.000985\n",
      " Epoch 8: Train Loss: 0.000689, Validation Loss: 0.000701\n",
      " Epoch 9: Train Loss: 0.000560, Validation Loss: 0.000553\n",
      " Epoch 10: Train Loss: 0.000477, Validation Loss: 0.000474\n",
      " Epoch 11: Train Loss: 0.000408, Validation Loss: 0.000434\n",
      " Epoch 12: Train Loss: 0.000360, Validation Loss: 0.000351\n",
      " Epoch 13: Train Loss: 0.000328, Validation Loss: 0.000320\n",
      " Epoch 14: Train Loss: 0.000312, Validation Loss: 0.000306\n",
      " Epoch 15: Train Loss: 0.000295, Validation Loss: 0.000293\n",
      " Epoch 16: Train Loss: 0.000284, Validation Loss: 0.000279\n",
      " Epoch 17: Train Loss: 0.000277, Validation Loss: 0.000271\n",
      " Epoch 18: Train Loss: 0.000268, Validation Loss: 0.000263\n",
      " Epoch 19: Train Loss: 0.000262, Validation Loss: 0.000256\n",
      " Epoch 20: Train Loss: 0.000253, Validation Loss: 0.000250\n",
      " Epoch 21: Train Loss: 0.000247, Validation Loss: 0.000246\n",
      " Epoch 22: Train Loss: 0.000243, Validation Loss: 0.000249\n",
      " Epoch 23: Train Loss: 0.000238, Validation Loss: 0.000236\n",
      " Epoch 24: Train Loss: 0.000238, Validation Loss: 0.000236\n",
      " Epoch 25: Train Loss: 0.000229, Validation Loss: 0.000228\n",
      " Epoch 26: Train Loss: 0.000226, Validation Loss: 0.000226\n",
      " Epoch 27: Train Loss: 0.000223, Validation Loss: 0.000221\n",
      " Epoch 28: Train Loss: 0.000218, Validation Loss: 0.000223\n",
      " Epoch 29: Train Loss: 0.000215, Validation Loss: 0.000214\n",
      " Epoch 30: Train Loss: 0.000212, Validation Loss: 0.000211\n",
      " Epoch 31: Train Loss: 0.000208, Validation Loss: 0.000210\n",
      " Epoch 32: Train Loss: 0.000206, Validation Loss: 0.000208\n",
      " Epoch 33: Train Loss: 0.000205, Validation Loss: 0.000211\n",
      " Epoch 34: Train Loss: 0.000203, Validation Loss: 0.000205\n",
      " Epoch 35: Train Loss: 0.000202, Validation Loss: 0.000206\n",
      " Epoch 36: Train Loss: 0.000201, Validation Loss: 0.000202\n",
      " Epoch 37: Train Loss: 0.000199, Validation Loss: 0.000201\n",
      " Epoch 38: Train Loss: 0.000198, Validation Loss: 0.000199\n",
      " Epoch 39: Train Loss: 0.000196, Validation Loss: 0.000198\n",
      " Epoch 40: Train Loss: 0.000195, Validation Loss: 0.000197\n",
      " Epoch 41: Train Loss: 0.000194, Validation Loss: 0.000200\n",
      " Epoch 42: Train Loss: 0.000192, Validation Loss: 0.000195\n",
      " Epoch 43: Train Loss: 0.000191, Validation Loss: 0.000193\n",
      " Epoch 44: Train Loss: 0.000190, Validation Loss: 0.000192\n",
      " Epoch 45: Train Loss: 0.000189, Validation Loss: 0.000191\n",
      " Epoch 46: Train Loss: 0.000187, Validation Loss: 0.000190\n",
      " Epoch 47: Train Loss: 0.000186, Validation Loss: 0.000188\n",
      " Epoch 48: Train Loss: 0.000185, Validation Loss: 0.000189\n",
      " Epoch 49: Train Loss: 0.000184, Validation Loss: 0.000186\n",
      " Epoch 50: Train Loss: 0.000182, Validation Loss: 0.000192\n",
      " Epoch 51: Train Loss: 0.000182, Validation Loss: 0.000184\n",
      " Epoch 52: Train Loss: 0.000181, Validation Loss: 0.000182\n",
      " Epoch 53: Train Loss: 0.000179, Validation Loss: 0.000181\n",
      " Epoch 54: Train Loss: 0.000178, Validation Loss: 0.000181\n",
      " Epoch 55: Train Loss: 0.000177, Validation Loss: 0.000180\n",
      " Epoch 56: Train Loss: 0.000176, Validation Loss: 0.000181\n",
      " Epoch 57: Train Loss: 0.000174, Validation Loss: 0.000183\n",
      " Epoch 58: Train Loss: 0.000174, Validation Loss: 0.000176\n",
      " Epoch 59: Train Loss: 0.000172, Validation Loss: 0.000175\n",
      " Epoch 60: Train Loss: 0.000171, Validation Loss: 0.000174\n",
      " Epoch 61: Train Loss: 0.000169, Validation Loss: 0.000172\n",
      " Epoch 62: Train Loss: 0.000168, Validation Loss: 0.000172\n",
      " Epoch 63: Train Loss: 0.000168, Validation Loss: 0.000172\n",
      " Epoch 64: Train Loss: 0.000167, Validation Loss: 0.000171\n",
      " Epoch 65: Train Loss: 0.000167, Validation Loss: 0.000170\n",
      " Epoch 66: Train Loss: 0.000166, Validation Loss: 0.000170\n",
      " Epoch 67: Train Loss: 0.000166, Validation Loss: 0.000169\n",
      " Epoch 68: Train Loss: 0.000165, Validation Loss: 0.000169\n",
      " Epoch 69: Train Loss: 0.000164, Validation Loss: 0.000168\n",
      " Epoch 70: Train Loss: 0.000163, Validation Loss: 0.000167\n",
      " Epoch 71: Train Loss: 0.000163, Validation Loss: 0.000166\n",
      " Epoch 72: Train Loss: 0.000162, Validation Loss: 0.000166\n",
      " Epoch 73: Train Loss: 0.000161, Validation Loss: 0.000165\n",
      " Epoch 74: Train Loss: 0.000161, Validation Loss: 0.000164\n",
      " Epoch 75: Train Loss: 0.000161, Validation Loss: 0.000167\n",
      " Epoch 76: Train Loss: 0.000160, Validation Loss: 0.000164\n",
      " Epoch 77: Train Loss: 0.000159, Validation Loss: 0.000163\n",
      " Epoch 78: Train Loss: 0.000158, Validation Loss: 0.000162\n",
      " Epoch 79: Train Loss: 0.000157, Validation Loss: 0.000162\n",
      " Epoch 80: Train Loss: 0.000157, Validation Loss: 0.000161\n",
      " Epoch 81: Train Loss: 0.000157, Validation Loss: 0.000160\n",
      " Epoch 82: Train Loss: 0.000156, Validation Loss: 0.000160\n",
      " Epoch 83: Train Loss: 0.000155, Validation Loss: 0.000159\n",
      " Epoch 84: Train Loss: 0.000154, Validation Loss: 0.000158\n",
      " Epoch 85: Train Loss: 0.000154, Validation Loss: 0.000158\n",
      " Epoch 86: Train Loss: 0.000153, Validation Loss: 0.000159\n",
      " Epoch 87: Train Loss: 0.000152, Validation Loss: 0.000156\n",
      " Epoch 88: Train Loss: 0.000152, Validation Loss: 0.000156\n",
      " Epoch 89: Train Loss: 0.000151, Validation Loss: 0.000155\n",
      " Epoch 90: Train Loss: 0.000151, Validation Loss: 0.000159\n",
      " Epoch 91: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 92: Train Loss: 0.000149, Validation Loss: 0.000154\n",
      " Epoch 93: Train Loss: 0.000149, Validation Loss: 0.000154\n",
      " Epoch 94: Train Loss: 0.000148, Validation Loss: 0.000153\n",
      " Epoch 95: Train Loss: 0.000148, Validation Loss: 0.000153\n",
      " Epoch 96: Train Loss: 0.000148, Validation Loss: 0.000153\n",
      " Epoch 97: Train Loss: 0.000147, Validation Loss: 0.000154\n",
      " Epoch 98: Train Loss: 0.000147, Validation Loss: 0.000152\n",
      " Epoch 99: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 100: Train Loss: 0.000146, Validation Loss: 0.000151\n",
      " Epoch 101: Train Loss: 0.000146, Validation Loss: 0.000151\n",
      " Epoch 102: Train Loss: 0.000146, Validation Loss: 0.000150\n",
      " Epoch 103: Train Loss: 0.000145, Validation Loss: 0.000150\n",
      " Epoch 104: Train Loss: 0.000145, Validation Loss: 0.000150\n",
      " Epoch 105: Train Loss: 0.000145, Validation Loss: 0.000149\n",
      " Epoch 106: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 107: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 108: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 109: Train Loss: 0.000143, Validation Loss: 0.000148\n",
      " Epoch 110: Train Loss: 0.000143, Validation Loss: 0.000148\n",
      " Epoch 111: Train Loss: 0.000142, Validation Loss: 0.000148\n",
      " Epoch 112: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 113: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 114: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 115: Train Loss: 0.000141, Validation Loss: 0.000147\n",
      " Epoch 116: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 117: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 118: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 119: Train Loss: 0.000140, Validation Loss: 0.000146\n",
      " Epoch 120: Train Loss: 0.000139, Validation Loss: 0.000146\n",
      " Epoch 121: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 122: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 123: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 124: Train Loss: 0.000138, Validation Loss: 0.000144\n",
      " Epoch 125: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 126: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 127: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 128: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 129: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 130: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 131: Train Loss: 0.000136, Validation Loss: 0.000142\n",
      " Epoch 132: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 133: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 134: Train Loss: 0.000136, Validation Loss: 0.000142\n",
      " Epoch 135: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 136: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 137: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 138: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 139: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 140: Train Loss: 0.000134, Validation Loss: 0.000140\n",
      " Epoch 141: Train Loss: 0.000134, Validation Loss: 0.000140\n",
      " Epoch 142: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 143: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 144: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 145: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 146: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 147: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 148: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 149: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 150: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 151: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 152: Train Loss: 0.000131, Validation Loss: 0.000138\n",
      " Epoch 153: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 154: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 155: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 156: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 157: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 158: Train Loss: 0.000131, Validation Loss: 0.000136\n",
      " Epoch 159: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 160: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 161: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 162: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 163: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 164: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 165: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 166: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 167: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 168: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 169: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 170: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 171: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 172: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 173: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 174: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 175: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 176: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 177: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 178: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 179: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 180: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 181: Train Loss: 0.000127, Validation Loss: 0.000134\n",
      " Epoch 182: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 183: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 184: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 185: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 186: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 187: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 188: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 189: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 190: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 191: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 192: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 193: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 194: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 195: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 196: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 197: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 198: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 199: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 200: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 201: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 202: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 203: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 204: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 205: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 206: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 207: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 208: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 209: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 210: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 211: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 212: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 213: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 214: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 215: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 216: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 217: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 218: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 219: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 220: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 221: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 222: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 223: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 224: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 225: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 226: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 227: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 228: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 229: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 230: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 231: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 232: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 233: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 234: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 235: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 236: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 237: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 238: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 239: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 240: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 241: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 242: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 243: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 244: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 245: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 246: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 247: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 248: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 249: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 250: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 251: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 252: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 253: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 254: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 255: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 256: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 257: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 258: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 259: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 260: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 261: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 262: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 263: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 264: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 265: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 266: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 267: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 268: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 269: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 270: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 271: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 272: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 273: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 274: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 275: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 276: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 277: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 278: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 279: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 280: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 281: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 282: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 283: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 284: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 285: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 286: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 287: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 288: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 289: Train Loss: 0.000122, Validation Loss: 0.000128\n",
      " Epoch 290: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 291: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 292: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 293: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 294: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 295: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 296: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 297: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 298: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 299: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 300: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 301: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 302: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 303: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 304: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 305: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 306: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 307: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 308: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 309: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 310: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 311: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 312: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 313: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 314: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 315: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 316: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 317: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 318: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 319: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 320: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 321: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 322: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 323: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 324: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 325: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 326: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 327: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 328: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 329: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 330: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 331: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 332: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 333: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 334: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 335: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 336: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 337: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 338: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 339: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 340: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 341: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 342: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 343: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 344: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 345: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 346: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 347: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 348: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 349: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 350: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 351: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 352: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 353: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 354: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 355: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 356: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 357: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 358: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 359: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 360: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 361: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 362: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 363: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 364: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 365: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 366: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 367: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 368: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 369: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 370: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 371: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 372: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 373: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 374: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 375: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 376: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 377: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 378: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 379: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 380: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 381: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 382: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 383: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 384: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 385: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 386: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 387: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 388: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 389: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 390: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 391: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 392: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 393: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 394: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 395: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 396: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 397: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 398: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 399: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 400: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 401: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 402: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 403: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 404: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 405: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 406: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 407: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 408: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 409: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 410: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 411: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 412: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 413: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 414: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 415: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 416: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 417: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 418: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 419: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 420: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 421: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 422: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 423: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 424: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 425: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 426: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 427: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 428: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 429: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 430: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 431: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 432: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 433: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 434: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 435: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 436: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 437: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 438: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 439: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 440: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 441: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 442: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 443: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 444: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 445: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 446: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 447: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 448: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 449: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 450: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 451: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 452: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 453: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 454: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 455: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 456: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 457: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 458: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 459: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 460: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 461: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 462: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 463: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 464: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 465: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 466: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 467: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 468: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 469: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 470: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 471: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 472: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 473: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 474: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 475: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 476: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 477: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 478: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 479: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 480: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 481: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 482: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 483: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 484: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 485: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 486: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 487: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 488: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 489: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 490: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 491: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 492: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 493: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 494: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 495: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 496: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 497: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 498: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 499: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 500: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 501: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 502: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 503: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 504: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 505: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 506: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 507: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 508: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 509: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 510: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 511: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 512: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 513: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 514: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 515: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 516: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 517: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 518: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 519: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 520: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 521: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 522: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 523: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 524: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 525: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 526: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 527: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 528: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 529: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 530: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 531: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 532: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 533: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 534: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 535: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 536: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 537: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 538: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 539: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 540: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 541: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 542: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 543: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 544: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 545: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 546: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 547: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 548: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 549: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 550: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 551: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 552: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      "Early stopping at epoch 552 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.015118, Validation Loss: 0.005680\n",
      " Epoch 2: Train Loss: 0.004317, Validation Loss: 0.004559\n",
      " Epoch 3: Train Loss: 0.004111, Validation Loss: 0.004007\n",
      " Epoch 4: Train Loss: 0.003928, Validation Loss: 0.003812\n",
      " Epoch 5: Train Loss: 0.003599, Validation Loss: 0.003530\n",
      " Epoch 6: Train Loss: 0.002855, Validation Loss: 0.002356\n",
      " Epoch 7: Train Loss: 0.001411, Validation Loss: 0.001521\n",
      " Epoch 8: Train Loss: 0.000703, Validation Loss: 0.000638\n",
      " Epoch 9: Train Loss: 0.000495, Validation Loss: 0.000441\n",
      " Epoch 10: Train Loss: 0.000398, Validation Loss: 0.000366\n",
      " Epoch 11: Train Loss: 0.000344, Validation Loss: 0.000327\n",
      " Epoch 12: Train Loss: 0.000313, Validation Loss: 0.000301\n",
      " Epoch 13: Train Loss: 0.000291, Validation Loss: 0.000291\n",
      " Epoch 14: Train Loss: 0.000276, Validation Loss: 0.000275\n",
      " Epoch 15: Train Loss: 0.000263, Validation Loss: 0.000260\n",
      " Epoch 16: Train Loss: 0.000250, Validation Loss: 0.000249\n",
      " Epoch 17: Train Loss: 0.000242, Validation Loss: 0.000242\n",
      " Epoch 18: Train Loss: 0.000233, Validation Loss: 0.000231\n",
      " Epoch 19: Train Loss: 0.000225, Validation Loss: 0.000226\n",
      " Epoch 20: Train Loss: 0.000219, Validation Loss: 0.000224\n",
      " Epoch 21: Train Loss: 0.000212, Validation Loss: 0.000217\n",
      " Epoch 22: Train Loss: 0.000206, Validation Loss: 0.000213\n",
      " Epoch 23: Train Loss: 0.000203, Validation Loss: 0.000205\n",
      " Epoch 24: Train Loss: 0.000196, Validation Loss: 0.000199\n",
      " Epoch 25: Train Loss: 0.000193, Validation Loss: 0.000195\n",
      " Epoch 26: Train Loss: 0.000189, Validation Loss: 0.000199\n",
      " Epoch 27: Train Loss: 0.000185, Validation Loss: 0.000188\n",
      " Epoch 28: Train Loss: 0.000182, Validation Loss: 0.000184\n",
      " Epoch 29: Train Loss: 0.000177, Validation Loss: 0.000181\n",
      " Epoch 30: Train Loss: 0.000175, Validation Loss: 0.000177\n",
      " Epoch 31: Train Loss: 0.000171, Validation Loss: 0.000175\n",
      " Epoch 32: Train Loss: 0.000169, Validation Loss: 0.000174\n",
      " Epoch 33: Train Loss: 0.000167, Validation Loss: 0.000172\n",
      " Epoch 34: Train Loss: 0.000166, Validation Loss: 0.000170\n",
      " Epoch 35: Train Loss: 0.000164, Validation Loss: 0.000169\n",
      " Epoch 36: Train Loss: 0.000163, Validation Loss: 0.000167\n",
      " Epoch 37: Train Loss: 0.000161, Validation Loss: 0.000166\n",
      " Epoch 38: Train Loss: 0.000159, Validation Loss: 0.000165\n",
      " Epoch 39: Train Loss: 0.000158, Validation Loss: 0.000164\n",
      " Epoch 40: Train Loss: 0.000157, Validation Loss: 0.000162\n",
      " Epoch 41: Train Loss: 0.000155, Validation Loss: 0.000161\n",
      " Epoch 42: Train Loss: 0.000154, Validation Loss: 0.000160\n",
      " Epoch 43: Train Loss: 0.000152, Validation Loss: 0.000158\n",
      " Epoch 44: Train Loss: 0.000151, Validation Loss: 0.000158\n",
      " Epoch 45: Train Loss: 0.000150, Validation Loss: 0.000157\n",
      " Epoch 46: Train Loss: 0.000149, Validation Loss: 0.000156\n",
      " Epoch 47: Train Loss: 0.000147, Validation Loss: 0.000155\n",
      " Epoch 48: Train Loss: 0.000146, Validation Loss: 0.000153\n",
      " Epoch 49: Train Loss: 0.000145, Validation Loss: 0.000160\n",
      " Epoch 50: Train Loss: 0.000144, Validation Loss: 0.000151\n",
      " Epoch 51: Train Loss: 0.000143, Validation Loss: 0.000150\n",
      " Epoch 52: Train Loss: 0.000142, Validation Loss: 0.000154\n",
      " Epoch 53: Train Loss: 0.000141, Validation Loss: 0.000148\n",
      " Epoch 54: Train Loss: 0.000139, Validation Loss: 0.000147\n",
      " Epoch 55: Train Loss: 0.000139, Validation Loss: 0.000146\n",
      " Epoch 56: Train Loss: 0.000137, Validation Loss: 0.000146\n",
      " Epoch 57: Train Loss: 0.000137, Validation Loss: 0.000145\n",
      " Epoch 58: Train Loss: 0.000135, Validation Loss: 0.000145\n",
      " Epoch 59: Train Loss: 0.000135, Validation Loss: 0.000143\n",
      " Epoch 60: Train Loss: 0.000133, Validation Loss: 0.000141\n",
      " Epoch 61: Train Loss: 0.000131, Validation Loss: 0.000140\n",
      " Epoch 62: Train Loss: 0.000130, Validation Loss: 0.000140\n",
      " Epoch 63: Train Loss: 0.000129, Validation Loss: 0.000139\n",
      " Epoch 64: Train Loss: 0.000129, Validation Loss: 0.000139\n",
      " Epoch 65: Train Loss: 0.000128, Validation Loss: 0.000138\n",
      " Epoch 66: Train Loss: 0.000128, Validation Loss: 0.000138\n",
      " Epoch 67: Train Loss: 0.000127, Validation Loss: 0.000137\n",
      " Epoch 68: Train Loss: 0.000127, Validation Loss: 0.000137\n",
      " Epoch 69: Train Loss: 0.000126, Validation Loss: 0.000136\n",
      " Epoch 70: Train Loss: 0.000125, Validation Loss: 0.000136\n",
      " Epoch 71: Train Loss: 0.000125, Validation Loss: 0.000135\n",
      " Epoch 72: Train Loss: 0.000124, Validation Loss: 0.000135\n",
      " Epoch 73: Train Loss: 0.000124, Validation Loss: 0.000135\n",
      " Epoch 74: Train Loss: 0.000123, Validation Loss: 0.000134\n",
      " Epoch 75: Train Loss: 0.000123, Validation Loss: 0.000134\n",
      " Epoch 76: Train Loss: 0.000122, Validation Loss: 0.000134\n",
      " Epoch 77: Train Loss: 0.000122, Validation Loss: 0.000133\n",
      " Epoch 78: Train Loss: 0.000121, Validation Loss: 0.000133\n",
      " Epoch 79: Train Loss: 0.000120, Validation Loss: 0.000133\n",
      " Epoch 80: Train Loss: 0.000120, Validation Loss: 0.000133\n",
      " Epoch 81: Train Loss: 0.000120, Validation Loss: 0.000131\n",
      " Epoch 82: Train Loss: 0.000119, Validation Loss: 0.000131\n",
      " Epoch 83: Train Loss: 0.000118, Validation Loss: 0.000131\n",
      " Epoch 84: Train Loss: 0.000118, Validation Loss: 0.000132\n",
      " Epoch 85: Train Loss: 0.000118, Validation Loss: 0.000130\n",
      " Epoch 86: Train Loss: 0.000117, Validation Loss: 0.000132\n",
      " Epoch 87: Train Loss: 0.000116, Validation Loss: 0.000129\n",
      " Epoch 88: Train Loss: 0.000116, Validation Loss: 0.000128\n",
      " Epoch 89: Train Loss: 0.000115, Validation Loss: 0.000131\n",
      " Epoch 90: Train Loss: 0.000115, Validation Loss: 0.000128\n",
      " Epoch 91: Train Loss: 0.000113, Validation Loss: 0.000127\n",
      " Epoch 92: Train Loss: 0.000112, Validation Loss: 0.000127\n",
      " Epoch 93: Train Loss: 0.000112, Validation Loss: 0.000126\n",
      " Epoch 94: Train Loss: 0.000112, Validation Loss: 0.000126\n",
      " Epoch 95: Train Loss: 0.000111, Validation Loss: 0.000126\n",
      " Epoch 96: Train Loss: 0.000111, Validation Loss: 0.000126\n",
      " Epoch 97: Train Loss: 0.000111, Validation Loss: 0.000126\n",
      " Epoch 98: Train Loss: 0.000110, Validation Loss: 0.000126\n",
      " Epoch 99: Train Loss: 0.000110, Validation Loss: 0.000125\n",
      " Epoch 100: Train Loss: 0.000110, Validation Loss: 0.000125\n",
      " Epoch 101: Train Loss: 0.000109, Validation Loss: 0.000125\n",
      " Epoch 102: Train Loss: 0.000109, Validation Loss: 0.000125\n",
      " Epoch 103: Train Loss: 0.000109, Validation Loss: 0.000124\n",
      " Epoch 104: Train Loss: 0.000108, Validation Loss: 0.000124\n",
      " Epoch 105: Train Loss: 0.000108, Validation Loss: 0.000124\n",
      " Epoch 106: Train Loss: 0.000108, Validation Loss: 0.000124\n",
      " Epoch 107: Train Loss: 0.000108, Validation Loss: 0.000125\n",
      " Epoch 108: Train Loss: 0.000108, Validation Loss: 0.000124\n",
      " Epoch 109: Train Loss: 0.000107, Validation Loss: 0.000123\n",
      " Epoch 110: Train Loss: 0.000106, Validation Loss: 0.000124\n",
      " Epoch 111: Train Loss: 0.000106, Validation Loss: 0.000123\n",
      " Epoch 112: Train Loss: 0.000106, Validation Loss: 0.000122\n",
      " Epoch 113: Train Loss: 0.000105, Validation Loss: 0.000123\n",
      " Epoch 114: Train Loss: 0.000105, Validation Loss: 0.000122\n",
      " Epoch 115: Train Loss: 0.000105, Validation Loss: 0.000122\n",
      " Epoch 116: Train Loss: 0.000104, Validation Loss: 0.000122\n",
      " Epoch 117: Train Loss: 0.000104, Validation Loss: 0.000123\n",
      " Epoch 118: Train Loss: 0.000104, Validation Loss: 0.000122\n",
      " Epoch 119: Train Loss: 0.000103, Validation Loss: 0.000121\n",
      " Epoch 120: Train Loss: 0.000103, Validation Loss: 0.000121\n",
      " Epoch 121: Train Loss: 0.000102, Validation Loss: 0.000120\n",
      " Epoch 122: Train Loss: 0.000101, Validation Loss: 0.000120\n",
      " Epoch 123: Train Loss: 0.000101, Validation Loss: 0.000120\n",
      " Epoch 124: Train Loss: 0.000101, Validation Loss: 0.000120\n",
      " Epoch 125: Train Loss: 0.000101, Validation Loss: 0.000120\n",
      " Epoch 126: Train Loss: 0.000100, Validation Loss: 0.000120\n",
      " Epoch 127: Train Loss: 0.000100, Validation Loss: 0.000120\n",
      " Epoch 128: Train Loss: 0.000100, Validation Loss: 0.000120\n",
      " Epoch 129: Train Loss: 0.000100, Validation Loss: 0.000120\n",
      " Epoch 130: Train Loss: 0.000099, Validation Loss: 0.000120\n",
      " Epoch 131: Train Loss: 0.000099, Validation Loss: 0.000119\n",
      " Epoch 132: Train Loss: 0.000099, Validation Loss: 0.000119\n",
      " Epoch 133: Train Loss: 0.000099, Validation Loss: 0.000120\n",
      " Epoch 134: Train Loss: 0.000099, Validation Loss: 0.000119\n",
      " Epoch 135: Train Loss: 0.000099, Validation Loss: 0.000120\n",
      " Epoch 136: Train Loss: 0.000098, Validation Loss: 0.000119\n",
      " Epoch 137: Train Loss: 0.000098, Validation Loss: 0.000119\n",
      " Epoch 138: Train Loss: 0.000098, Validation Loss: 0.000119\n",
      " Epoch 139: Train Loss: 0.000097, Validation Loss: 0.000119\n",
      " Epoch 140: Train Loss: 0.000097, Validation Loss: 0.000120\n",
      " Epoch 141: Train Loss: 0.000097, Validation Loss: 0.000119\n",
      " Epoch 142: Train Loss: 0.000097, Validation Loss: 0.000118\n",
      " Epoch 143: Train Loss: 0.000097, Validation Loss: 0.000118\n",
      " Epoch 144: Train Loss: 0.000096, Validation Loss: 0.000118\n",
      " Epoch 145: Train Loss: 0.000096, Validation Loss: 0.000118\n",
      " Epoch 146: Train Loss: 0.000096, Validation Loss: 0.000118\n",
      " Epoch 147: Train Loss: 0.000096, Validation Loss: 0.000118\n",
      " Epoch 148: Train Loss: 0.000095, Validation Loss: 0.000118\n",
      " Epoch 149: Train Loss: 0.000095, Validation Loss: 0.000118\n",
      " Epoch 150: Train Loss: 0.000095, Validation Loss: 0.000118\n",
      " Epoch 151: Train Loss: 0.000094, Validation Loss: 0.000117\n",
      " Epoch 152: Train Loss: 0.000094, Validation Loss: 0.000117\n",
      " Epoch 153: Train Loss: 0.000094, Validation Loss: 0.000117\n",
      " Epoch 154: Train Loss: 0.000094, Validation Loss: 0.000117\n",
      " Epoch 155: Train Loss: 0.000094, Validation Loss: 0.000117\n",
      " Epoch 156: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 157: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 158: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 159: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 160: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 161: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 162: Train Loss: 0.000093, Validation Loss: 0.000117\n",
      " Epoch 163: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 164: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 165: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 166: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 167: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 168: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 169: Train Loss: 0.000092, Validation Loss: 0.000117\n",
      " Epoch 170: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 171: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 172: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 173: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 174: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 175: Train Loss: 0.000091, Validation Loss: 0.000117\n",
      " Epoch 176: Train Loss: 0.000090, Validation Loss: 0.000117\n",
      " Epoch 177: Train Loss: 0.000090, Validation Loss: 0.000117\n",
      " Epoch 178: Train Loss: 0.000090, Validation Loss: 0.000116\n",
      " Epoch 179: Train Loss: 0.000090, Validation Loss: 0.000117\n",
      " Epoch 180: Train Loss: 0.000090, Validation Loss: 0.000117\n",
      " Epoch 181: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 182: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 183: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 184: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 185: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 186: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 187: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 188: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 189: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 190: Train Loss: 0.000089, Validation Loss: 0.000116\n",
      " Epoch 191: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 192: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 193: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 194: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 195: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 196: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 197: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 198: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 199: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 200: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 201: Train Loss: 0.000088, Validation Loss: 0.000116\n",
      " Epoch 202: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 203: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 204: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 205: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 206: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 207: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 208: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 209: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 210: Train Loss: 0.000087, Validation Loss: 0.000116\n",
      " Epoch 211: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 212: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 213: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 214: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 215: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 216: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 217: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 218: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 219: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 220: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 221: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 222: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 223: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 224: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 225: Train Loss: 0.000086, Validation Loss: 0.000116\n",
      " Epoch 226: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 227: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 228: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 229: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 230: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 231: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 232: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 233: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 234: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 235: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 236: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 237: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 238: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 239: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 240: Train Loss: 0.000085, Validation Loss: 0.000116\n",
      " Epoch 241: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 242: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 243: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 244: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 245: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 246: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 247: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 248: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 249: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 250: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 251: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 252: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 253: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 254: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 255: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 256: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 257: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 258: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 259: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 260: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 261: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 262: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 263: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 264: Train Loss: 0.000084, Validation Loss: 0.000115\n",
      " Epoch 265: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 266: Train Loss: 0.000084, Validation Loss: 0.000115\n",
      " Epoch 267: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 268: Train Loss: 0.000084, Validation Loss: 0.000115\n",
      " Epoch 269: Train Loss: 0.000084, Validation Loss: 0.000116\n",
      " Epoch 270: Train Loss: 0.000084, Validation Loss: 0.000115\n",
      " Epoch 271: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 272: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 273: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 274: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 275: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 276: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 277: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 278: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 279: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 280: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 281: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 282: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 283: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 284: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 285: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 286: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 287: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 288: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 289: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 290: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 291: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 292: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 293: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 294: Train Loss: 0.000083, Validation Loss: 0.000116\n",
      " Epoch 295: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 296: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 297: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 298: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 299: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 300: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 301: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 302: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 303: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 304: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 305: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 306: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 307: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 308: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 309: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 310: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 311: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 312: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 313: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 314: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 315: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 316: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 317: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 318: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 319: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      " Epoch 320: Train Loss: 0.000083, Validation Loss: 0.000115\n",
      "Early stopping at epoch 320 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN_1\n",
      "Validation Loss: 0.00018733713659457862\n",
      "Training Time: 614.113926410675\n",
      "--------------------------------------------------\n",
      "Model: CNN_2\n",
      "Validation Loss: 0.00012914366379845887\n",
      "Training Time: 953.5974335670471\n",
      "--------------------------------------------------\n",
      "Model: CNN_3\n",
      "Validation Loss: 0.00012755960051435977\n",
      "Training Time: 4025.7549879550934\n",
      "--------------------------------------------------\n",
      "Model: CNN_4\n",
      "Validation Loss: 0.00011539513798197731\n",
      "Training Time: 8960.361079216003\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_CNN import CNN_1, CNN_2, CNN_3, CNN_4\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN_1': CNN_1,\n",
    "    'CNN_2': CNN_2,\n",
    "    'CNN_3': CNN_3,\n",
    "    'CNN_4': CNN_4,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/Old_MSE/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40515111-0714-4a75-a871-ab483916b322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.016758, Validation Loss: 0.005693\n",
      " Epoch 2: Train Loss: 0.004611, Validation Loss: 0.004888\n",
      " Epoch 3: Train Loss: 0.004371, Validation Loss: 0.004483\n",
      " Epoch 4: Train Loss: 0.003857, Validation Loss: 0.003659\n",
      " Epoch 5: Train Loss: 0.002448, Validation Loss: 0.002053\n",
      " Epoch 6: Train Loss: 0.001607, Validation Loss: 0.001492\n",
      " Epoch 7: Train Loss: 0.001181, Validation Loss: 0.001173\n",
      " Epoch 8: Train Loss: 0.000899, Validation Loss: 0.000841\n",
      " Epoch 9: Train Loss: 0.000706, Validation Loss: 0.000646\n",
      " Epoch 10: Train Loss: 0.000577, Validation Loss: 0.000529\n",
      " Epoch 11: Train Loss: 0.000496, Validation Loss: 0.000457\n",
      " Epoch 12: Train Loss: 0.000419, Validation Loss: 0.000400\n",
      " Epoch 13: Train Loss: 0.000377, Validation Loss: 0.000366\n",
      " Epoch 14: Train Loss: 0.000350, Validation Loss: 0.000346\n",
      " Epoch 15: Train Loss: 0.000332, Validation Loss: 0.000326\n",
      " Epoch 16: Train Loss: 0.000313, Validation Loss: 0.000307\n",
      " Epoch 17: Train Loss: 0.000303, Validation Loss: 0.000314\n",
      " Epoch 18: Train Loss: 0.000292, Validation Loss: 0.000288\n",
      " Epoch 19: Train Loss: 0.000289, Validation Loss: 0.000304\n",
      " Epoch 20: Train Loss: 0.000277, Validation Loss: 0.000275\n",
      " Epoch 21: Train Loss: 0.000269, Validation Loss: 0.000267\n",
      " Epoch 22: Train Loss: 0.000265, Validation Loss: 0.000261\n",
      " Epoch 23: Train Loss: 0.000258, Validation Loss: 0.000259\n",
      " Epoch 24: Train Loss: 0.000254, Validation Loss: 0.000251\n",
      " Epoch 25: Train Loss: 0.000250, Validation Loss: 0.000252\n",
      " Epoch 26: Train Loss: 0.000245, Validation Loss: 0.000255\n",
      " Epoch 27: Train Loss: 0.000242, Validation Loss: 0.000243\n",
      " Epoch 28: Train Loss: 0.000237, Validation Loss: 0.000242\n",
      " Epoch 29: Train Loss: 0.000236, Validation Loss: 0.000232\n",
      " Epoch 30: Train Loss: 0.000232, Validation Loss: 0.000231\n",
      " Epoch 31: Train Loss: 0.000226, Validation Loss: 0.000227\n",
      " Epoch 32: Train Loss: 0.000224, Validation Loss: 0.000226\n",
      " Epoch 33: Train Loss: 0.000223, Validation Loss: 0.000224\n",
      " Epoch 34: Train Loss: 0.000221, Validation Loss: 0.000223\n",
      " Epoch 35: Train Loss: 0.000220, Validation Loss: 0.000221\n",
      " Epoch 36: Train Loss: 0.000219, Validation Loss: 0.000219\n",
      " Epoch 37: Train Loss: 0.000217, Validation Loss: 0.000218\n",
      " Epoch 38: Train Loss: 0.000215, Validation Loss: 0.000220\n",
      " Epoch 39: Train Loss: 0.000215, Validation Loss: 0.000216\n",
      " Epoch 40: Train Loss: 0.000213, Validation Loss: 0.000214\n",
      " Epoch 41: Train Loss: 0.000211, Validation Loss: 0.000212\n",
      " Epoch 42: Train Loss: 0.000210, Validation Loss: 0.000211\n",
      " Epoch 43: Train Loss: 0.000209, Validation Loss: 0.000211\n",
      " Epoch 44: Train Loss: 0.000208, Validation Loss: 0.000209\n",
      " Epoch 45: Train Loss: 0.000208, Validation Loss: 0.000208\n",
      " Epoch 46: Train Loss: 0.000205, Validation Loss: 0.000206\n",
      " Epoch 47: Train Loss: 0.000204, Validation Loss: 0.000204\n",
      " Epoch 48: Train Loss: 0.000202, Validation Loss: 0.000204\n",
      " Epoch 49: Train Loss: 0.000201, Validation Loss: 0.000202\n",
      " Epoch 50: Train Loss: 0.000201, Validation Loss: 0.000201\n",
      " Epoch 51: Train Loss: 0.000198, Validation Loss: 0.000202\n",
      " Epoch 52: Train Loss: 0.000197, Validation Loss: 0.000199\n",
      " Epoch 53: Train Loss: 0.000195, Validation Loss: 0.000196\n",
      " Epoch 54: Train Loss: 0.000195, Validation Loss: 0.000196\n",
      " Epoch 55: Train Loss: 0.000193, Validation Loss: 0.000196\n",
      " Epoch 56: Train Loss: 0.000194, Validation Loss: 0.000199\n",
      " Epoch 57: Train Loss: 0.000190, Validation Loss: 0.000191\n",
      " Epoch 58: Train Loss: 0.000191, Validation Loss: 0.000197\n",
      " Epoch 59: Train Loss: 0.000188, Validation Loss: 0.000190\n",
      " Epoch 60: Train Loss: 0.000186, Validation Loss: 0.000191\n",
      " Epoch 61: Train Loss: 0.000184, Validation Loss: 0.000187\n",
      " Epoch 62: Train Loss: 0.000183, Validation Loss: 0.000185\n",
      " Epoch 63: Train Loss: 0.000182, Validation Loss: 0.000185\n",
      " Epoch 64: Train Loss: 0.000182, Validation Loss: 0.000184\n",
      " Epoch 65: Train Loss: 0.000181, Validation Loss: 0.000184\n",
      " Epoch 66: Train Loss: 0.000180, Validation Loss: 0.000183\n",
      " Epoch 67: Train Loss: 0.000180, Validation Loss: 0.000183\n",
      " Epoch 68: Train Loss: 0.000179, Validation Loss: 0.000183\n",
      " Epoch 69: Train Loss: 0.000178, Validation Loss: 0.000181\n",
      " Epoch 70: Train Loss: 0.000178, Validation Loss: 0.000181\n",
      " Epoch 71: Train Loss: 0.000177, Validation Loss: 0.000180\n",
      " Epoch 72: Train Loss: 0.000176, Validation Loss: 0.000178\n",
      " Epoch 73: Train Loss: 0.000176, Validation Loss: 0.000178\n",
      " Epoch 74: Train Loss: 0.000175, Validation Loss: 0.000178\n",
      " Epoch 75: Train Loss: 0.000174, Validation Loss: 0.000177\n",
      " Epoch 76: Train Loss: 0.000174, Validation Loss: 0.000176\n",
      " Epoch 77: Train Loss: 0.000173, Validation Loss: 0.000176\n",
      " Epoch 78: Train Loss: 0.000172, Validation Loss: 0.000177\n",
      " Epoch 79: Train Loss: 0.000172, Validation Loss: 0.000174\n",
      " Epoch 80: Train Loss: 0.000171, Validation Loss: 0.000174\n",
      " Epoch 81: Train Loss: 0.000170, Validation Loss: 0.000175\n",
      " Epoch 82: Train Loss: 0.000170, Validation Loss: 0.000173\n",
      " Epoch 83: Train Loss: 0.000169, Validation Loss: 0.000177\n",
      " Epoch 84: Train Loss: 0.000169, Validation Loss: 0.000171\n",
      " Epoch 85: Train Loss: 0.000168, Validation Loss: 0.000171\n",
      " Epoch 86: Train Loss: 0.000167, Validation Loss: 0.000169\n",
      " Epoch 87: Train Loss: 0.000166, Validation Loss: 0.000169\n",
      " Epoch 88: Train Loss: 0.000165, Validation Loss: 0.000169\n",
      " Epoch 89: Train Loss: 0.000165, Validation Loss: 0.000172\n",
      " Epoch 90: Train Loss: 0.000164, Validation Loss: 0.000167\n",
      " Epoch 91: Train Loss: 0.000164, Validation Loss: 0.000167\n",
      " Epoch 92: Train Loss: 0.000163, Validation Loss: 0.000166\n",
      " Epoch 93: Train Loss: 0.000162, Validation Loss: 0.000166\n",
      " Epoch 94: Train Loss: 0.000162, Validation Loss: 0.000165\n",
      " Epoch 95: Train Loss: 0.000162, Validation Loss: 0.000165\n",
      " Epoch 96: Train Loss: 0.000162, Validation Loss: 0.000165\n",
      " Epoch 97: Train Loss: 0.000161, Validation Loss: 0.000164\n",
      " Epoch 98: Train Loss: 0.000161, Validation Loss: 0.000164\n",
      " Epoch 99: Train Loss: 0.000160, Validation Loss: 0.000164\n",
      " Epoch 100: Train Loss: 0.000160, Validation Loss: 0.000163\n",
      " Epoch 101: Train Loss: 0.000159, Validation Loss: 0.000163\n",
      " Epoch 102: Train Loss: 0.000159, Validation Loss: 0.000162\n",
      " Epoch 103: Train Loss: 0.000159, Validation Loss: 0.000162\n",
      " Epoch 104: Train Loss: 0.000158, Validation Loss: 0.000162\n",
      " Epoch 105: Train Loss: 0.000158, Validation Loss: 0.000161\n",
      " Epoch 106: Train Loss: 0.000158, Validation Loss: 0.000161\n",
      " Epoch 107: Train Loss: 0.000157, Validation Loss: 0.000160\n",
      " Epoch 108: Train Loss: 0.000157, Validation Loss: 0.000160\n",
      " Epoch 109: Train Loss: 0.000156, Validation Loss: 0.000161\n",
      " Epoch 110: Train Loss: 0.000156, Validation Loss: 0.000164\n",
      " Epoch 111: Train Loss: 0.000156, Validation Loss: 0.000159\n",
      " Epoch 112: Train Loss: 0.000155, Validation Loss: 0.000158\n",
      " Epoch 113: Train Loss: 0.000155, Validation Loss: 0.000158\n",
      " Epoch 114: Train Loss: 0.000154, Validation Loss: 0.000158\n",
      " Epoch 115: Train Loss: 0.000154, Validation Loss: 0.000159\n",
      " Epoch 116: Train Loss: 0.000154, Validation Loss: 0.000157\n",
      " Epoch 117: Train Loss: 0.000153, Validation Loss: 0.000157\n",
      " Epoch 118: Train Loss: 0.000153, Validation Loss: 0.000156\n",
      " Epoch 119: Train Loss: 0.000152, Validation Loss: 0.000155\n",
      " Epoch 120: Train Loss: 0.000152, Validation Loss: 0.000155\n",
      " Epoch 121: Train Loss: 0.000151, Validation Loss: 0.000155\n",
      " Epoch 122: Train Loss: 0.000151, Validation Loss: 0.000157\n",
      " Epoch 123: Train Loss: 0.000151, Validation Loss: 0.000154\n",
      " Epoch 124: Train Loss: 0.000151, Validation Loss: 0.000154\n",
      " Epoch 125: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 126: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 127: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 128: Train Loss: 0.000150, Validation Loss: 0.000155\n",
      " Epoch 129: Train Loss: 0.000150, Validation Loss: 0.000153\n",
      " Epoch 130: Train Loss: 0.000149, Validation Loss: 0.000153\n",
      " Epoch 131: Train Loss: 0.000149, Validation Loss: 0.000153\n",
      " Epoch 132: Train Loss: 0.000149, Validation Loss: 0.000152\n",
      " Epoch 133: Train Loss: 0.000149, Validation Loss: 0.000152\n",
      " Epoch 134: Train Loss: 0.000148, Validation Loss: 0.000152\n",
      " Epoch 135: Train Loss: 0.000148, Validation Loss: 0.000152\n",
      " Epoch 136: Train Loss: 0.000148, Validation Loss: 0.000152\n",
      " Epoch 137: Train Loss: 0.000148, Validation Loss: 0.000151\n",
      " Epoch 138: Train Loss: 0.000148, Validation Loss: 0.000151\n",
      " Epoch 139: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 140: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 141: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 142: Train Loss: 0.000147, Validation Loss: 0.000150\n",
      " Epoch 143: Train Loss: 0.000146, Validation Loss: 0.000151\n",
      " Epoch 144: Train Loss: 0.000146, Validation Loss: 0.000152\n",
      " Epoch 145: Train Loss: 0.000146, Validation Loss: 0.000150\n",
      " Epoch 146: Train Loss: 0.000146, Validation Loss: 0.000149\n",
      " Epoch 147: Train Loss: 0.000146, Validation Loss: 0.000149\n",
      " Epoch 148: Train Loss: 0.000146, Validation Loss: 0.000153\n",
      " Epoch 149: Train Loss: 0.000145, Validation Loss: 0.000149\n",
      " Epoch 150: Train Loss: 0.000145, Validation Loss: 0.000148\n",
      " Epoch 151: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 152: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 153: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 154: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 155: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 156: Train Loss: 0.000144, Validation Loss: 0.000148\n",
      " Epoch 157: Train Loss: 0.000143, Validation Loss: 0.000148\n",
      " Epoch 158: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 159: Train Loss: 0.000143, Validation Loss: 0.000148\n",
      " Epoch 160: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 161: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 162: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 163: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 164: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 165: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 166: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 167: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 168: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 169: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 170: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 171: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 172: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 173: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 174: Train Loss: 0.000141, Validation Loss: 0.000145\n",
      " Epoch 175: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 176: Train Loss: 0.000141, Validation Loss: 0.000145\n",
      " Epoch 177: Train Loss: 0.000141, Validation Loss: 0.000145\n",
      " Epoch 178: Train Loss: 0.000141, Validation Loss: 0.000145\n",
      " Epoch 179: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 180: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 181: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 182: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 183: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 184: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 185: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 186: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 187: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 188: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 189: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 190: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 191: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 192: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 193: Train Loss: 0.000139, Validation Loss: 0.000143\n",
      " Epoch 194: Train Loss: 0.000139, Validation Loss: 0.000143\n",
      " Epoch 195: Train Loss: 0.000139, Validation Loss: 0.000143\n",
      " Epoch 196: Train Loss: 0.000139, Validation Loss: 0.000143\n",
      " Epoch 197: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 198: Train Loss: 0.000139, Validation Loss: 0.000143\n",
      " Epoch 199: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 200: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 201: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 202: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 203: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 204: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 205: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 206: Train Loss: 0.000138, Validation Loss: 0.000142\n",
      " Epoch 207: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 208: Train Loss: 0.000138, Validation Loss: 0.000142\n",
      " Epoch 209: Train Loss: 0.000138, Validation Loss: 0.000142\n",
      " Epoch 210: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 211: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 212: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 213: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 214: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 215: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 216: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 217: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 218: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 219: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 220: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 221: Train Loss: 0.000137, Validation Loss: 0.000141\n",
      " Epoch 222: Train Loss: 0.000137, Validation Loss: 0.000141\n",
      " Epoch 223: Train Loss: 0.000137, Validation Loss: 0.000141\n",
      " Epoch 224: Train Loss: 0.000137, Validation Loss: 0.000141\n",
      " Epoch 225: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 226: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 227: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 228: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 229: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 230: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 231: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 232: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 233: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 234: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 235: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 236: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 237: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 238: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 239: Train Loss: 0.000136, Validation Loss: 0.000140\n",
      " Epoch 240: Train Loss: 0.000136, Validation Loss: 0.000140\n",
      " Epoch 241: Train Loss: 0.000136, Validation Loss: 0.000140\n",
      " Epoch 242: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 243: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 244: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 245: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 246: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 247: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 248: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 249: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 250: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 251: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 252: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 253: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 254: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 255: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 256: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 257: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 258: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 259: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 260: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 261: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 262: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 263: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 264: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 265: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 266: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 267: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 268: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 269: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 270: Train Loss: 0.000135, Validation Loss: 0.000139\n",
      " Epoch 271: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 272: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 273: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 274: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 275: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 276: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 277: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 278: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 279: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 280: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 281: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 282: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 283: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 284: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 285: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 286: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 287: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 288: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 289: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 290: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 291: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 292: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 293: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 294: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 295: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 296: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 297: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 298: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 299: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 300: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 301: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 302: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 303: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 304: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 305: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 306: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 307: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 308: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 309: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 310: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 311: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 312: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 313: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 314: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 315: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 316: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 317: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 318: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 319: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 320: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 321: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 322: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 323: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 324: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 325: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 326: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 327: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 328: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 329: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 330: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 331: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 332: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 333: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 334: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 335: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 336: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 337: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 338: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 339: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 340: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 341: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 342: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 343: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 344: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 345: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 346: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 347: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 348: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 349: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 350: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 351: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 352: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 353: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 354: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 355: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 356: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 357: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 358: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 359: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 360: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 361: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 362: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 363: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 364: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 365: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 366: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 367: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 368: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 369: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 370: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 371: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 372: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 373: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 374: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 375: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 376: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 377: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 378: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 379: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 380: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 381: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 382: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 383: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 384: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 385: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 386: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 387: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 388: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 389: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 390: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 391: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 392: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 393: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 394: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 395: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 396: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 397: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 398: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 399: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 400: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 401: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 402: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 403: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 404: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 405: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 406: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 407: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 408: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 409: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 410: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 411: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 412: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 413: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 414: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 415: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 416: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 417: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 418: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 419: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 420: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 421: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 422: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 423: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 424: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 425: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 426: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 427: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 428: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 429: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 430: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 431: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 432: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 433: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 434: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 435: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 436: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 437: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 438: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 439: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 440: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 441: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 442: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 443: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 444: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 445: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 446: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 447: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 448: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 449: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 450: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 451: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 452: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 453: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 454: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 455: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 456: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 457: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 458: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 459: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 460: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 461: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 462: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 463: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 464: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 465: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 466: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 467: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 468: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 469: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 470: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 471: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 472: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 473: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 474: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 475: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 476: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 477: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 478: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 479: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 480: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 481: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 482: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 483: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 484: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 485: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 486: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 487: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 488: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 489: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 490: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 491: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 492: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 493: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 494: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 495: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 496: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 497: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 498: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 499: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 500: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 501: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 502: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 503: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 504: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 505: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 506: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 507: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 508: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 509: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 510: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 511: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 512: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 513: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 514: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 515: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 516: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 517: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 518: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 519: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 520: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 521: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 522: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 523: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 524: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 525: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 526: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 527: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 528: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 529: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 530: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 531: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 532: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 533: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 534: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 535: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 536: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 537: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 538: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 539: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 540: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 541: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 542: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 543: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 544: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 545: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 546: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 547: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 548: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 549: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 550: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 551: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 552: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 553: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 554: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 555: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 556: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 557: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 558: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      "Early stopping at epoch 558 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.017700, Validation Loss: 0.005693\n",
      " Epoch 2: Train Loss: 0.004226, Validation Loss: 0.004613\n",
      " Epoch 3: Train Loss: 0.003998, Validation Loss: 0.003988\n",
      " Epoch 4: Train Loss: 0.003793, Validation Loss: 0.003662\n",
      " Epoch 5: Train Loss: 0.003408, Validation Loss: 0.003097\n",
      " Epoch 6: Train Loss: 0.002638, Validation Loss: 0.002380\n",
      " Epoch 7: Train Loss: 0.001478, Validation Loss: 0.001194\n",
      " Epoch 8: Train Loss: 0.000769, Validation Loss: 0.000646\n",
      " Epoch 9: Train Loss: 0.000539, Validation Loss: 0.000484\n",
      " Epoch 10: Train Loss: 0.000438, Validation Loss: 0.000410\n",
      " Epoch 11: Train Loss: 0.000392, Validation Loss: 0.000372\n",
      " Epoch 12: Train Loss: 0.000345, Validation Loss: 0.000331\n",
      " Epoch 13: Train Loss: 0.000320, Validation Loss: 0.000311\n",
      " Epoch 14: Train Loss: 0.000301, Validation Loss: 0.000294\n",
      " Epoch 15: Train Loss: 0.000286, Validation Loss: 0.000282\n",
      " Epoch 16: Train Loss: 0.000274, Validation Loss: 0.000272\n",
      " Epoch 17: Train Loss: 0.000269, Validation Loss: 0.000305\n",
      " Epoch 18: Train Loss: 0.000259, Validation Loss: 0.000258\n",
      " Epoch 19: Train Loss: 0.000246, Validation Loss: 0.000245\n",
      " Epoch 20: Train Loss: 0.000239, Validation Loss: 0.000238\n",
      " Epoch 21: Train Loss: 0.000232, Validation Loss: 0.000234\n",
      " Epoch 22: Train Loss: 0.000226, Validation Loss: 0.000231\n",
      " Epoch 23: Train Loss: 0.000221, Validation Loss: 0.000226\n",
      " Epoch 24: Train Loss: 0.000216, Validation Loss: 0.000222\n",
      " Epoch 25: Train Loss: 0.000212, Validation Loss: 0.000213\n",
      " Epoch 26: Train Loss: 0.000207, Validation Loss: 0.000210\n",
      " Epoch 27: Train Loss: 0.000203, Validation Loss: 0.000208\n",
      " Epoch 28: Train Loss: 0.000199, Validation Loss: 0.000206\n",
      " Epoch 29: Train Loss: 0.000196, Validation Loss: 0.000199\n",
      " Epoch 30: Train Loss: 0.000193, Validation Loss: 0.000195\n",
      " Epoch 31: Train Loss: 0.000189, Validation Loss: 0.000193\n",
      " Epoch 32: Train Loss: 0.000187, Validation Loss: 0.000192\n",
      " Epoch 33: Train Loss: 0.000186, Validation Loss: 0.000191\n",
      " Epoch 34: Train Loss: 0.000184, Validation Loss: 0.000190\n",
      " Epoch 35: Train Loss: 0.000183, Validation Loss: 0.000190\n",
      " Epoch 36: Train Loss: 0.000182, Validation Loss: 0.000188\n",
      " Epoch 37: Train Loss: 0.000180, Validation Loss: 0.000186\n",
      " Epoch 38: Train Loss: 0.000178, Validation Loss: 0.000185\n",
      " Epoch 39: Train Loss: 0.000177, Validation Loss: 0.000182\n",
      " Epoch 40: Train Loss: 0.000175, Validation Loss: 0.000182\n",
      " Epoch 41: Train Loss: 0.000174, Validation Loss: 0.000181\n",
      " Epoch 42: Train Loss: 0.000173, Validation Loss: 0.000179\n",
      " Epoch 43: Train Loss: 0.000172, Validation Loss: 0.000180\n",
      " Epoch 44: Train Loss: 0.000170, Validation Loss: 0.000176\n",
      " Epoch 45: Train Loss: 0.000168, Validation Loss: 0.000175\n",
      " Epoch 46: Train Loss: 0.000167, Validation Loss: 0.000174\n",
      " Epoch 47: Train Loss: 0.000166, Validation Loss: 0.000172\n",
      " Epoch 48: Train Loss: 0.000164, Validation Loss: 0.000171\n",
      " Epoch 49: Train Loss: 0.000162, Validation Loss: 0.000169\n",
      " Epoch 50: Train Loss: 0.000161, Validation Loss: 0.000170\n",
      " Epoch 51: Train Loss: 0.000160, Validation Loss: 0.000167\n",
      " Epoch 52: Train Loss: 0.000159, Validation Loss: 0.000166\n",
      " Epoch 53: Train Loss: 0.000158, Validation Loss: 0.000170\n",
      " Epoch 54: Train Loss: 0.000156, Validation Loss: 0.000164\n",
      " Epoch 55: Train Loss: 0.000154, Validation Loss: 0.000162\n",
      " Epoch 56: Train Loss: 0.000153, Validation Loss: 0.000162\n",
      " Epoch 57: Train Loss: 0.000152, Validation Loss: 0.000162\n",
      " Epoch 58: Train Loss: 0.000152, Validation Loss: 0.000158\n",
      " Epoch 59: Train Loss: 0.000149, Validation Loss: 0.000158\n",
      " Epoch 60: Train Loss: 0.000148, Validation Loss: 0.000156\n",
      " Epoch 61: Train Loss: 0.000146, Validation Loss: 0.000155\n",
      " Epoch 62: Train Loss: 0.000145, Validation Loss: 0.000155\n",
      " Epoch 63: Train Loss: 0.000144, Validation Loss: 0.000154\n",
      " Epoch 64: Train Loss: 0.000144, Validation Loss: 0.000153\n",
      " Epoch 65: Train Loss: 0.000143, Validation Loss: 0.000153\n",
      " Epoch 66: Train Loss: 0.000143, Validation Loss: 0.000152\n",
      " Epoch 67: Train Loss: 0.000142, Validation Loss: 0.000152\n",
      " Epoch 68: Train Loss: 0.000141, Validation Loss: 0.000151\n",
      " Epoch 69: Train Loss: 0.000141, Validation Loss: 0.000151\n",
      " Epoch 70: Train Loss: 0.000140, Validation Loss: 0.000150\n",
      " Epoch 71: Train Loss: 0.000139, Validation Loss: 0.000150\n",
      " Epoch 72: Train Loss: 0.000139, Validation Loss: 0.000149\n",
      " Epoch 73: Train Loss: 0.000138, Validation Loss: 0.000148\n",
      " Epoch 74: Train Loss: 0.000138, Validation Loss: 0.000148\n",
      " Epoch 75: Train Loss: 0.000137, Validation Loss: 0.000148\n",
      " Epoch 76: Train Loss: 0.000136, Validation Loss: 0.000147\n",
      " Epoch 77: Train Loss: 0.000136, Validation Loss: 0.000146\n",
      " Epoch 78: Train Loss: 0.000135, Validation Loss: 0.000146\n",
      " Epoch 79: Train Loss: 0.000134, Validation Loss: 0.000145\n",
      " Epoch 80: Train Loss: 0.000134, Validation Loss: 0.000145\n",
      " Epoch 81: Train Loss: 0.000133, Validation Loss: 0.000145\n",
      " Epoch 82: Train Loss: 0.000133, Validation Loss: 0.000144\n",
      " Epoch 83: Train Loss: 0.000132, Validation Loss: 0.000143\n",
      " Epoch 84: Train Loss: 0.000131, Validation Loss: 0.000144\n",
      " Epoch 85: Train Loss: 0.000131, Validation Loss: 0.000142\n",
      " Epoch 86: Train Loss: 0.000130, Validation Loss: 0.000142\n",
      " Epoch 87: Train Loss: 0.000129, Validation Loss: 0.000141\n",
      " Epoch 88: Train Loss: 0.000129, Validation Loss: 0.000141\n",
      " Epoch 89: Train Loss: 0.000128, Validation Loss: 0.000141\n",
      " Epoch 90: Train Loss: 0.000128, Validation Loss: 0.000140\n",
      " Epoch 91: Train Loss: 0.000126, Validation Loss: 0.000139\n",
      " Epoch 92: Train Loss: 0.000126, Validation Loss: 0.000138\n",
      " Epoch 93: Train Loss: 0.000126, Validation Loss: 0.000138\n",
      " Epoch 94: Train Loss: 0.000125, Validation Loss: 0.000138\n",
      " Epoch 95: Train Loss: 0.000125, Validation Loss: 0.000138\n",
      " Epoch 96: Train Loss: 0.000125, Validation Loss: 0.000138\n",
      " Epoch 97: Train Loss: 0.000124, Validation Loss: 0.000138\n",
      " Epoch 98: Train Loss: 0.000124, Validation Loss: 0.000137\n",
      " Epoch 99: Train Loss: 0.000124, Validation Loss: 0.000137\n",
      " Epoch 100: Train Loss: 0.000123, Validation Loss: 0.000137\n",
      " Epoch 101: Train Loss: 0.000123, Validation Loss: 0.000137\n",
      " Epoch 102: Train Loss: 0.000123, Validation Loss: 0.000137\n",
      " Epoch 103: Train Loss: 0.000122, Validation Loss: 0.000136\n",
      " Epoch 104: Train Loss: 0.000122, Validation Loss: 0.000136\n",
      " Epoch 105: Train Loss: 0.000122, Validation Loss: 0.000136\n",
      " Epoch 106: Train Loss: 0.000121, Validation Loss: 0.000135\n",
      " Epoch 107: Train Loss: 0.000121, Validation Loss: 0.000135\n",
      " Epoch 108: Train Loss: 0.000121, Validation Loss: 0.000135\n",
      " Epoch 109: Train Loss: 0.000120, Validation Loss: 0.000135\n",
      " Epoch 110: Train Loss: 0.000120, Validation Loss: 0.000134\n",
      " Epoch 111: Train Loss: 0.000120, Validation Loss: 0.000134\n",
      " Epoch 112: Train Loss: 0.000119, Validation Loss: 0.000134\n",
      " Epoch 113: Train Loss: 0.000119, Validation Loss: 0.000135\n",
      " Epoch 114: Train Loss: 0.000119, Validation Loss: 0.000134\n",
      " Epoch 115: Train Loss: 0.000118, Validation Loss: 0.000133\n",
      " Epoch 116: Train Loss: 0.000118, Validation Loss: 0.000133\n",
      " Epoch 117: Train Loss: 0.000118, Validation Loss: 0.000133\n",
      " Epoch 118: Train Loss: 0.000117, Validation Loss: 0.000133\n",
      " Epoch 119: Train Loss: 0.000117, Validation Loss: 0.000133\n",
      " Epoch 120: Train Loss: 0.000117, Validation Loss: 0.000133\n",
      " Epoch 121: Train Loss: 0.000116, Validation Loss: 0.000131\n",
      " Epoch 122: Train Loss: 0.000115, Validation Loss: 0.000131\n",
      " Epoch 123: Train Loss: 0.000115, Validation Loss: 0.000132\n",
      " Epoch 124: Train Loss: 0.000115, Validation Loss: 0.000131\n",
      " Epoch 125: Train Loss: 0.000115, Validation Loss: 0.000131\n",
      " Epoch 126: Train Loss: 0.000115, Validation Loss: 0.000131\n",
      " Epoch 127: Train Loss: 0.000114, Validation Loss: 0.000131\n",
      " Epoch 128: Train Loss: 0.000114, Validation Loss: 0.000131\n",
      " Epoch 129: Train Loss: 0.000114, Validation Loss: 0.000131\n",
      " Epoch 130: Train Loss: 0.000114, Validation Loss: 0.000131\n",
      " Epoch 131: Train Loss: 0.000114, Validation Loss: 0.000131\n",
      " Epoch 132: Train Loss: 0.000113, Validation Loss: 0.000130\n",
      " Epoch 133: Train Loss: 0.000113, Validation Loss: 0.000130\n",
      " Epoch 134: Train Loss: 0.000113, Validation Loss: 0.000130\n",
      " Epoch 135: Train Loss: 0.000113, Validation Loss: 0.000130\n",
      " Epoch 136: Train Loss: 0.000113, Validation Loss: 0.000130\n",
      " Epoch 137: Train Loss: 0.000112, Validation Loss: 0.000130\n",
      " Epoch 138: Train Loss: 0.000112, Validation Loss: 0.000130\n",
      " Epoch 139: Train Loss: 0.000112, Validation Loss: 0.000130\n",
      " Epoch 140: Train Loss: 0.000112, Validation Loss: 0.000130\n",
      " Epoch 141: Train Loss: 0.000111, Validation Loss: 0.000130\n",
      " Epoch 142: Train Loss: 0.000111, Validation Loss: 0.000129\n",
      " Epoch 143: Train Loss: 0.000111, Validation Loss: 0.000129\n",
      " Epoch 144: Train Loss: 0.000111, Validation Loss: 0.000129\n",
      " Epoch 145: Train Loss: 0.000111, Validation Loss: 0.000129\n",
      " Epoch 146: Train Loss: 0.000110, Validation Loss: 0.000129\n",
      " Epoch 147: Train Loss: 0.000110, Validation Loss: 0.000129\n",
      " Epoch 148: Train Loss: 0.000110, Validation Loss: 0.000129\n",
      " Epoch 149: Train Loss: 0.000110, Validation Loss: 0.000128\n",
      " Epoch 150: Train Loss: 0.000109, Validation Loss: 0.000128\n",
      " Epoch 151: Train Loss: 0.000109, Validation Loss: 0.000128\n",
      " Epoch 152: Train Loss: 0.000109, Validation Loss: 0.000128\n",
      " Epoch 153: Train Loss: 0.000109, Validation Loss: 0.000128\n",
      " Epoch 154: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 155: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 156: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 157: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 158: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 159: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 160: Train Loss: 0.000108, Validation Loss: 0.000128\n",
      " Epoch 161: Train Loss: 0.000108, Validation Loss: 0.000127\n",
      " Epoch 162: Train Loss: 0.000107, Validation Loss: 0.000128\n",
      " Epoch 163: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 164: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 165: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 166: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 167: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 168: Train Loss: 0.000107, Validation Loss: 0.000127\n",
      " Epoch 169: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 170: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 171: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 172: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 173: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 174: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 175: Train Loss: 0.000106, Validation Loss: 0.000127\n",
      " Epoch 176: Train Loss: 0.000105, Validation Loss: 0.000127\n",
      " Epoch 177: Train Loss: 0.000105, Validation Loss: 0.000126\n",
      " Epoch 178: Train Loss: 0.000105, Validation Loss: 0.000127\n",
      " Epoch 179: Train Loss: 0.000105, Validation Loss: 0.000127\n",
      " Epoch 180: Train Loss: 0.000105, Validation Loss: 0.000126\n",
      " Epoch 181: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 182: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 183: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 184: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 185: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 186: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 187: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 188: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 189: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 190: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 191: Train Loss: 0.000104, Validation Loss: 0.000126\n",
      " Epoch 192: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 193: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 194: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 195: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 196: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 197: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 198: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 199: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 200: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 201: Train Loss: 0.000103, Validation Loss: 0.000126\n",
      " Epoch 202: Train Loss: 0.000102, Validation Loss: 0.000126\n",
      " Epoch 203: Train Loss: 0.000102, Validation Loss: 0.000126\n",
      " Epoch 204: Train Loss: 0.000102, Validation Loss: 0.000126\n",
      " Epoch 205: Train Loss: 0.000102, Validation Loss: 0.000126\n",
      " Epoch 206: Train Loss: 0.000102, Validation Loss: 0.000125\n",
      " Epoch 207: Train Loss: 0.000102, Validation Loss: 0.000125\n",
      " Epoch 208: Train Loss: 0.000102, Validation Loss: 0.000126\n",
      " Epoch 209: Train Loss: 0.000102, Validation Loss: 0.000125\n",
      " Epoch 210: Train Loss: 0.000102, Validation Loss: 0.000125\n",
      " Epoch 211: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 212: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 213: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 214: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 215: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 216: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 217: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 218: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 219: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 220: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 221: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 222: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 223: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 224: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 225: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 226: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 227: Train Loss: 0.000101, Validation Loss: 0.000125\n",
      " Epoch 228: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 229: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 230: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 231: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 232: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 233: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 234: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 235: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 236: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 237: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 238: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 239: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 240: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 241: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 242: Train Loss: 0.000100, Validation Loss: 0.000125\n",
      " Epoch 243: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 244: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 245: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 246: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 247: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 248: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 249: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 250: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 251: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 252: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 253: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 254: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 255: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 256: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 257: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 258: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 259: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 260: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 261: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 262: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 263: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 264: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 265: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 266: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 267: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 268: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 269: Train Loss: 0.000099, Validation Loss: 0.000125\n",
      " Epoch 270: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 271: Train Loss: 0.000098, Validation Loss: 0.000125\n",
      " Epoch 272: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 273: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 274: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 275: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 276: Train Loss: 0.000098, Validation Loss: 0.000125\n",
      " Epoch 277: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 278: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 279: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 280: Train Loss: 0.000098, Validation Loss: 0.000125\n",
      " Epoch 281: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 282: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 283: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 284: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 285: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 286: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 287: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 288: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 289: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 290: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 291: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 292: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 293: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 294: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 295: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 296: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 297: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 298: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 299: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 300: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 301: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 302: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 303: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 304: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 305: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 306: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 307: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 308: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 309: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 310: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 311: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 312: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 313: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 314: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 315: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 316: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 317: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 318: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 319: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 320: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 321: Train Loss: 0.000098, Validation Loss: 0.000124\n",
      " Epoch 322: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 323: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 324: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 325: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 326: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 327: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 328: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 329: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 330: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 331: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 332: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 333: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 334: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 335: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 336: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 337: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 338: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 339: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 340: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 341: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 342: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 343: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 344: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 345: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 346: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 347: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 348: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 349: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 350: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 351: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 352: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 353: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 354: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 355: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 356: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 357: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 358: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 359: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 360: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 361: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 362: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 363: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 364: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 365: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 366: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 367: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 368: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 369: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 370: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 371: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 372: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 373: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 374: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 375: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 376: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 377: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 378: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 379: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 380: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 381: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 382: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 383: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 384: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 385: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 386: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 387: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 388: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 389: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 390: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 391: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 392: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 393: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 394: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 395: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 396: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 397: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 398: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 399: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 400: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 401: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 402: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 403: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 404: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 405: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 406: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 407: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 408: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 409: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 410: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 411: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 412: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 413: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 414: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 415: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 416: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 417: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 418: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 419: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 420: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 421: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 422: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 423: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 424: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 425: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 426: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 427: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 428: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 429: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 430: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 431: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 432: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 433: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 434: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 435: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 436: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 437: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 438: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 439: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 440: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 441: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 442: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 443: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 444: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 445: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 446: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 447: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 448: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 449: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 450: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 451: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 452: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 453: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 454: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 455: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 456: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 457: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 458: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 459: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 460: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 461: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 462: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 463: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 464: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 465: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 466: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 467: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 468: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 469: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 470: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 471: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 472: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 473: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 474: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 475: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 476: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 477: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 478: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 479: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 480: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 481: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 482: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 483: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 484: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 485: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 486: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 487: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 488: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 489: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 490: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 491: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 492: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      " Epoch 493: Train Loss: 0.000097, Validation Loss: 0.000124\n",
      "Early stopping at epoch 493 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.013774, Validation Loss: 0.005668\n",
      " Epoch 2: Train Loss: 0.002843, Validation Loss: 0.002498\n",
      " Epoch 3: Train Loss: 0.001805, Validation Loss: 0.001614\n",
      " Epoch 4: Train Loss: 0.001315, Validation Loss: 0.001178\n",
      " Epoch 5: Train Loss: 0.001068, Validation Loss: 0.001015\n",
      " Epoch 6: Train Loss: 0.000908, Validation Loss: 0.000982\n",
      " Epoch 7: Train Loss: 0.000792, Validation Loss: 0.000764\n",
      " Epoch 8: Train Loss: 0.000736, Validation Loss: 0.000714\n",
      " Epoch 9: Train Loss: 0.000697, Validation Loss: 0.000680\n",
      " Epoch 10: Train Loss: 0.000665, Validation Loss: 0.000650\n",
      " Epoch 11: Train Loss: 0.000636, Validation Loss: 0.000608\n",
      " Epoch 12: Train Loss: 0.000539, Validation Loss: 0.000529\n",
      " Epoch 13: Train Loss: 0.000483, Validation Loss: 0.000470\n",
      " Epoch 14: Train Loss: 0.000459, Validation Loss: 0.000450\n",
      " Epoch 15: Train Loss: 0.000442, Validation Loss: 0.000434\n",
      " Epoch 16: Train Loss: 0.000427, Validation Loss: 0.000420\n",
      " Epoch 17: Train Loss: 0.000407, Validation Loss: 0.000385\n",
      " Epoch 18: Train Loss: 0.000359, Validation Loss: 0.000343\n",
      " Epoch 19: Train Loss: 0.000293, Validation Loss: 0.000346\n",
      " Epoch 20: Train Loss: 0.000257, Validation Loss: 0.000256\n",
      " Epoch 21: Train Loss: 0.000247, Validation Loss: 0.000245\n",
      " Epoch 22: Train Loss: 0.000240, Validation Loss: 0.000238\n",
      " Epoch 23: Train Loss: 0.000234, Validation Loss: 0.000232\n",
      " Epoch 24: Train Loss: 0.000227, Validation Loss: 0.000227\n",
      " Epoch 25: Train Loss: 0.000223, Validation Loss: 0.000224\n",
      " Epoch 26: Train Loss: 0.000219, Validation Loss: 0.000218\n",
      " Epoch 27: Train Loss: 0.000214, Validation Loss: 0.000215\n",
      " Epoch 28: Train Loss: 0.000211, Validation Loss: 0.000212\n",
      " Epoch 29: Train Loss: 0.000207, Validation Loss: 0.000210\n",
      " Epoch 30: Train Loss: 0.000204, Validation Loss: 0.000204\n",
      " Epoch 31: Train Loss: 0.000200, Validation Loss: 0.000202\n",
      " Epoch 32: Train Loss: 0.000199, Validation Loss: 0.000201\n",
      " Epoch 33: Train Loss: 0.000197, Validation Loss: 0.000199\n",
      " Epoch 34: Train Loss: 0.000196, Validation Loss: 0.000198\n",
      " Epoch 35: Train Loss: 0.000194, Validation Loss: 0.000197\n",
      " Epoch 36: Train Loss: 0.000193, Validation Loss: 0.000195\n",
      " Epoch 37: Train Loss: 0.000191, Validation Loss: 0.000194\n",
      " Epoch 38: Train Loss: 0.000190, Validation Loss: 0.000192\n",
      " Epoch 39: Train Loss: 0.000188, Validation Loss: 0.000191\n",
      " Epoch 40: Train Loss: 0.000187, Validation Loss: 0.000190\n",
      " Epoch 41: Train Loss: 0.000186, Validation Loss: 0.000189\n",
      " Epoch 42: Train Loss: 0.000185, Validation Loss: 0.000188\n",
      " Epoch 43: Train Loss: 0.000183, Validation Loss: 0.000186\n",
      " Epoch 44: Train Loss: 0.000182, Validation Loss: 0.000185\n",
      " Epoch 45: Train Loss: 0.000181, Validation Loss: 0.000184\n",
      " Epoch 46: Train Loss: 0.000180, Validation Loss: 0.000182\n",
      " Epoch 47: Train Loss: 0.000178, Validation Loss: 0.000181\n",
      " Epoch 48: Train Loss: 0.000177, Validation Loss: 0.000180\n",
      " Epoch 49: Train Loss: 0.000176, Validation Loss: 0.000180\n",
      " Epoch 50: Train Loss: 0.000175, Validation Loss: 0.000178\n",
      " Epoch 51: Train Loss: 0.000173, Validation Loss: 0.000177\n",
      " Epoch 52: Train Loss: 0.000173, Validation Loss: 0.000178\n",
      " Epoch 53: Train Loss: 0.000171, Validation Loss: 0.000175\n",
      " Epoch 54: Train Loss: 0.000169, Validation Loss: 0.000174\n",
      " Epoch 55: Train Loss: 0.000169, Validation Loss: 0.000172\n",
      " Epoch 56: Train Loss: 0.000167, Validation Loss: 0.000174\n",
      " Epoch 57: Train Loss: 0.000166, Validation Loss: 0.000169\n",
      " Epoch 58: Train Loss: 0.000165, Validation Loss: 0.000172\n",
      " Epoch 59: Train Loss: 0.000164, Validation Loss: 0.000167\n",
      " Epoch 60: Train Loss: 0.000162, Validation Loss: 0.000167\n",
      " Epoch 61: Train Loss: 0.000161, Validation Loss: 0.000165\n",
      " Epoch 62: Train Loss: 0.000160, Validation Loss: 0.000165\n",
      " Epoch 63: Train Loss: 0.000160, Validation Loss: 0.000164\n",
      " Epoch 64: Train Loss: 0.000159, Validation Loss: 0.000164\n",
      " Epoch 65: Train Loss: 0.000159, Validation Loss: 0.000163\n",
      " Epoch 66: Train Loss: 0.000158, Validation Loss: 0.000163\n",
      " Epoch 67: Train Loss: 0.000158, Validation Loss: 0.000162\n",
      " Epoch 68: Train Loss: 0.000157, Validation Loss: 0.000162\n",
      " Epoch 69: Train Loss: 0.000156, Validation Loss: 0.000161\n",
      " Epoch 70: Train Loss: 0.000156, Validation Loss: 0.000161\n",
      " Epoch 71: Train Loss: 0.000155, Validation Loss: 0.000160\n",
      " Epoch 72: Train Loss: 0.000155, Validation Loss: 0.000160\n",
      " Epoch 73: Train Loss: 0.000154, Validation Loss: 0.000158\n",
      " Epoch 74: Train Loss: 0.000153, Validation Loss: 0.000158\n",
      " Epoch 75: Train Loss: 0.000153, Validation Loss: 0.000157\n",
      " Epoch 76: Train Loss: 0.000152, Validation Loss: 0.000157\n",
      " Epoch 77: Train Loss: 0.000152, Validation Loss: 0.000157\n",
      " Epoch 78: Train Loss: 0.000151, Validation Loss: 0.000156\n",
      " Epoch 79: Train Loss: 0.000150, Validation Loss: 0.000155\n",
      " Epoch 80: Train Loss: 0.000150, Validation Loss: 0.000156\n",
      " Epoch 81: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 82: Train Loss: 0.000149, Validation Loss: 0.000154\n",
      " Epoch 83: Train Loss: 0.000148, Validation Loss: 0.000153\n",
      " Epoch 84: Train Loss: 0.000147, Validation Loss: 0.000152\n",
      " Epoch 85: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 86: Train Loss: 0.000146, Validation Loss: 0.000153\n",
      " Epoch 87: Train Loss: 0.000146, Validation Loss: 0.000150\n",
      " Epoch 88: Train Loss: 0.000145, Validation Loss: 0.000151\n",
      " Epoch 89: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 90: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 91: Train Loss: 0.000143, Validation Loss: 0.000148\n",
      " Epoch 92: Train Loss: 0.000142, Validation Loss: 0.000148\n",
      " Epoch 93: Train Loss: 0.000142, Validation Loss: 0.000148\n",
      " Epoch 94: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 95: Train Loss: 0.000141, Validation Loss: 0.000147\n",
      " Epoch 96: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 97: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 98: Train Loss: 0.000140, Validation Loss: 0.000146\n",
      " Epoch 99: Train Loss: 0.000140, Validation Loss: 0.000146\n",
      " Epoch 100: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 101: Train Loss: 0.000139, Validation Loss: 0.000145\n",
      " Epoch 102: Train Loss: 0.000139, Validation Loss: 0.000145\n",
      " Epoch 103: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 104: Train Loss: 0.000138, Validation Loss: 0.000144\n",
      " Epoch 105: Train Loss: 0.000138, Validation Loss: 0.000144\n",
      " Epoch 106: Train Loss: 0.000138, Validation Loss: 0.000144\n",
      " Epoch 107: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 108: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 109: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 110: Train Loss: 0.000136, Validation Loss: 0.000142\n",
      " Epoch 111: Train Loss: 0.000136, Validation Loss: 0.000142\n",
      " Epoch 112: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 113: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 114: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 115: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 116: Train Loss: 0.000134, Validation Loss: 0.000140\n",
      " Epoch 117: Train Loss: 0.000134, Validation Loss: 0.000140\n",
      " Epoch 118: Train Loss: 0.000134, Validation Loss: 0.000140\n",
      " Epoch 119: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 120: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 121: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 122: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 123: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 124: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 125: Train Loss: 0.000131, Validation Loss: 0.000138\n",
      " Epoch 126: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 127: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 128: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 129: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 130: Train Loss: 0.000130, Validation Loss: 0.000137\n",
      " Epoch 131: Train Loss: 0.000130, Validation Loss: 0.000137\n",
      " Epoch 132: Train Loss: 0.000130, Validation Loss: 0.000137\n",
      " Epoch 133: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 134: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 135: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 136: Train Loss: 0.000129, Validation Loss: 0.000136\n",
      " Epoch 137: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 138: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 139: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 140: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 141: Train Loss: 0.000128, Validation Loss: 0.000135\n",
      " Epoch 142: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 143: Train Loss: 0.000128, Validation Loss: 0.000135\n",
      " Epoch 144: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 145: Train Loss: 0.000127, Validation Loss: 0.000134\n",
      " Epoch 146: Train Loss: 0.000127, Validation Loss: 0.000134\n",
      " Epoch 147: Train Loss: 0.000127, Validation Loss: 0.000134\n",
      " Epoch 148: Train Loss: 0.000127, Validation Loss: 0.000134\n",
      " Epoch 149: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 150: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 151: Train Loss: 0.000126, Validation Loss: 0.000133\n",
      " Epoch 152: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 153: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 154: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 155: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 156: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 157: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 158: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 159: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 160: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 161: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 162: Train Loss: 0.000125, Validation Loss: 0.000132\n",
      " Epoch 163: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 164: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 165: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 166: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 167: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 168: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 169: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 170: Train Loss: 0.000124, Validation Loss: 0.000131\n",
      " Epoch 171: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 172: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 173: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 174: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 175: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 176: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 177: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 178: Train Loss: 0.000123, Validation Loss: 0.000130\n",
      " Epoch 179: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 180: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 181: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 182: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 183: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 184: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 185: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 186: Train Loss: 0.000122, Validation Loss: 0.000129\n",
      " Epoch 187: Train Loss: 0.000121, Validation Loss: 0.000129\n",
      " Epoch 188: Train Loss: 0.000121, Validation Loss: 0.000129\n",
      " Epoch 189: Train Loss: 0.000121, Validation Loss: 0.000129\n",
      " Epoch 190: Train Loss: 0.000121, Validation Loss: 0.000129\n",
      " Epoch 191: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 192: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 193: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 194: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 195: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 196: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 197: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 198: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 199: Train Loss: 0.000121, Validation Loss: 0.000128\n",
      " Epoch 200: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 201: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 202: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 203: Train Loss: 0.000120, Validation Loss: 0.000128\n",
      " Epoch 204: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 205: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 206: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 207: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 208: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 209: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 210: Train Loss: 0.000120, Validation Loss: 0.000127\n",
      " Epoch 211: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 212: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 213: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 214: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 215: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 216: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 217: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 218: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 219: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 220: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 221: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 222: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 223: Train Loss: 0.000119, Validation Loss: 0.000127\n",
      " Epoch 224: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 225: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 226: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 227: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 228: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 229: Train Loss: 0.000119, Validation Loss: 0.000126\n",
      " Epoch 230: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 231: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 232: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 233: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 234: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 235: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 236: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 237: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 238: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 239: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 240: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 241: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 242: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 243: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 244: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 245: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 246: Train Loss: 0.000118, Validation Loss: 0.000126\n",
      " Epoch 247: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 248: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 249: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 250: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 251: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 252: Train Loss: 0.000118, Validation Loss: 0.000125\n",
      " Epoch 253: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 254: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 255: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 256: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 257: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 258: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 259: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 260: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 261: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 262: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 263: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 264: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 265: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 266: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 267: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 268: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 269: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 270: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 271: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 272: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 273: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 274: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 275: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 276: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 277: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 278: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 279: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 280: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 281: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 282: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 283: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 284: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 285: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 286: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 287: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 288: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 289: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 290: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 291: Train Loss: 0.000117, Validation Loss: 0.000125\n",
      " Epoch 292: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 293: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 294: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 295: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 296: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 297: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 298: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 299: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 300: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 301: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 302: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 303: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 304: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 305: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 306: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 307: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 308: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 309: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 310: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 311: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 312: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 313: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 314: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 315: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 316: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 317: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 318: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 319: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 320: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 321: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 322: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 323: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 324: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 325: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 326: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 327: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 328: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 329: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 330: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 331: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 332: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 333: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 334: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 335: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 336: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 337: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 338: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 339: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 340: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 341: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 342: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 343: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 344: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 345: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 346: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 347: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 348: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 349: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 350: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 351: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 352: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 353: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 354: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 355: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 356: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 357: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 358: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 359: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 360: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 361: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 362: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 363: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 364: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 365: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 366: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 367: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 368: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 369: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 370: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 371: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 372: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 373: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 374: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 375: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 376: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 377: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 378: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 379: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 380: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 381: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 382: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 383: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 384: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 385: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 386: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 387: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 388: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 389: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 390: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 391: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 392: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 393: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 394: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 395: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 396: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 397: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 398: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 399: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 400: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 401: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 402: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 403: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 404: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 405: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 406: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 407: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 408: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 409: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 410: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 411: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 412: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 413: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 414: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 415: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 416: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 417: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 418: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 419: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 420: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 421: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 422: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 423: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 424: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 425: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 426: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 427: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 428: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 429: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 430: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 431: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 432: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 433: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 434: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 435: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 436: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 437: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 438: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 439: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 440: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 441: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 442: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 443: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 444: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 445: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 446: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 447: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 448: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 449: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 450: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 451: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 452: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 453: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 454: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 455: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 456: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 457: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 458: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 459: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 460: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 461: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 462: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 463: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 464: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 465: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 466: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 467: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 468: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 469: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 470: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 471: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 472: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 473: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 474: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 475: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 476: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 477: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 478: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 479: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 480: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 481: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 482: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 483: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 484: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 485: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 486: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 487: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 488: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 489: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 490: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 491: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 492: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 493: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 494: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 495: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 496: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 497: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 498: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 499: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 500: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 501: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 502: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 503: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 504: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 505: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 506: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 507: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 508: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 509: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 510: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 511: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 512: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 513: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 514: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 515: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 516: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 517: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 518: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 519: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 520: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 521: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 522: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 523: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 524: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 525: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 526: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 527: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      " Epoch 528: Train Loss: 0.000116, Validation Loss: 0.000124\n",
      "Early stopping at epoch 528 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.017893, Validation Loss: 0.005259\n",
      " Epoch 2: Train Loss: 0.004654, Validation Loss: 0.004881\n",
      " Epoch 3: Train Loss: 0.003375, Validation Loss: 0.002809\n",
      " Epoch 4: Train Loss: 0.002070, Validation Loss: 0.001856\n",
      " Epoch 5: Train Loss: 0.001473, Validation Loss: 0.001300\n",
      " Epoch 6: Train Loss: 0.001128, Validation Loss: 0.001040\n",
      " Epoch 7: Train Loss: 0.000894, Validation Loss: 0.000911\n",
      " Epoch 8: Train Loss: 0.000743, Validation Loss: 0.000739\n",
      " Epoch 9: Train Loss: 0.000653, Validation Loss: 0.000663\n",
      " Epoch 10: Train Loss: 0.000519, Validation Loss: 0.000553\n",
      " Epoch 11: Train Loss: 0.000456, Validation Loss: 0.000439\n",
      " Epoch 12: Train Loss: 0.000419, Validation Loss: 0.000402\n",
      " Epoch 13: Train Loss: 0.000388, Validation Loss: 0.000373\n",
      " Epoch 14: Train Loss: 0.000361, Validation Loss: 0.000353\n",
      " Epoch 15: Train Loss: 0.000339, Validation Loss: 0.000329\n",
      " Epoch 16: Train Loss: 0.000323, Validation Loss: 0.000327\n",
      " Epoch 17: Train Loss: 0.000308, Validation Loss: 0.000300\n",
      " Epoch 18: Train Loss: 0.000291, Validation Loss: 0.000286\n",
      " Epoch 19: Train Loss: 0.000280, Validation Loss: 0.000276\n",
      " Epoch 20: Train Loss: 0.000272, Validation Loss: 0.000269\n",
      " Epoch 21: Train Loss: 0.000263, Validation Loss: 0.000261\n",
      " Epoch 22: Train Loss: 0.000255, Validation Loss: 0.000252\n",
      " Epoch 23: Train Loss: 0.000247, Validation Loss: 0.000247\n",
      " Epoch 24: Train Loss: 0.000243, Validation Loss: 0.000241\n",
      " Epoch 25: Train Loss: 0.000236, Validation Loss: 0.000235\n",
      " Epoch 26: Train Loss: 0.000231, Validation Loss: 0.000230\n",
      " Epoch 27: Train Loss: 0.000227, Validation Loss: 0.000228\n",
      " Epoch 28: Train Loss: 0.000222, Validation Loss: 0.000223\n",
      " Epoch 29: Train Loss: 0.000219, Validation Loss: 0.000218\n",
      " Epoch 30: Train Loss: 0.000215, Validation Loss: 0.000215\n",
      " Epoch 31: Train Loss: 0.000211, Validation Loss: 0.000213\n",
      " Epoch 32: Train Loss: 0.000209, Validation Loss: 0.000212\n",
      " Epoch 33: Train Loss: 0.000208, Validation Loss: 0.000210\n",
      " Epoch 34: Train Loss: 0.000206, Validation Loss: 0.000208\n",
      " Epoch 35: Train Loss: 0.000205, Validation Loss: 0.000207\n",
      " Epoch 36: Train Loss: 0.000203, Validation Loss: 0.000205\n",
      " Epoch 37: Train Loss: 0.000202, Validation Loss: 0.000204\n",
      " Epoch 38: Train Loss: 0.000200, Validation Loss: 0.000202\n",
      " Epoch 39: Train Loss: 0.000199, Validation Loss: 0.000202\n",
      " Epoch 40: Train Loss: 0.000197, Validation Loss: 0.000200\n",
      " Epoch 41: Train Loss: 0.000196, Validation Loss: 0.000198\n",
      " Epoch 42: Train Loss: 0.000195, Validation Loss: 0.000197\n",
      " Epoch 43: Train Loss: 0.000193, Validation Loss: 0.000196\n",
      " Epoch 44: Train Loss: 0.000192, Validation Loss: 0.000194\n",
      " Epoch 45: Train Loss: 0.000191, Validation Loss: 0.000194\n",
      " Epoch 46: Train Loss: 0.000190, Validation Loss: 0.000193\n",
      " Epoch 47: Train Loss: 0.000188, Validation Loss: 0.000191\n",
      " Epoch 48: Train Loss: 0.000187, Validation Loss: 0.000190\n",
      " Epoch 49: Train Loss: 0.000186, Validation Loss: 0.000189\n",
      " Epoch 50: Train Loss: 0.000185, Validation Loss: 0.000188\n",
      " Epoch 51: Train Loss: 0.000183, Validation Loss: 0.000186\n",
      " Epoch 52: Train Loss: 0.000182, Validation Loss: 0.000185\n",
      " Epoch 53: Train Loss: 0.000181, Validation Loss: 0.000184\n",
      " Epoch 54: Train Loss: 0.000180, Validation Loss: 0.000183\n",
      " Epoch 55: Train Loss: 0.000179, Validation Loss: 0.000183\n",
      " Epoch 56: Train Loss: 0.000177, Validation Loss: 0.000180\n",
      " Epoch 57: Train Loss: 0.000176, Validation Loss: 0.000183\n",
      " Epoch 58: Train Loss: 0.000176, Validation Loss: 0.000180\n",
      " Epoch 59: Train Loss: 0.000174, Validation Loss: 0.000177\n",
      " Epoch 60: Train Loss: 0.000173, Validation Loss: 0.000176\n",
      " Epoch 61: Train Loss: 0.000171, Validation Loss: 0.000175\n",
      " Epoch 62: Train Loss: 0.000170, Validation Loss: 0.000174\n",
      " Epoch 63: Train Loss: 0.000170, Validation Loss: 0.000174\n",
      " Epoch 64: Train Loss: 0.000169, Validation Loss: 0.000174\n",
      " Epoch 65: Train Loss: 0.000169, Validation Loss: 0.000173\n",
      " Epoch 66: Train Loss: 0.000168, Validation Loss: 0.000172\n",
      " Epoch 67: Train Loss: 0.000167, Validation Loss: 0.000171\n",
      " Epoch 68: Train Loss: 0.000167, Validation Loss: 0.000171\n",
      " Epoch 69: Train Loss: 0.000166, Validation Loss: 0.000170\n",
      " Epoch 70: Train Loss: 0.000166, Validation Loss: 0.000169\n",
      " Epoch 71: Train Loss: 0.000165, Validation Loss: 0.000169\n",
      " Epoch 72: Train Loss: 0.000164, Validation Loss: 0.000168\n",
      " Epoch 73: Train Loss: 0.000164, Validation Loss: 0.000168\n",
      " Epoch 74: Train Loss: 0.000163, Validation Loss: 0.000167\n",
      " Epoch 75: Train Loss: 0.000162, Validation Loss: 0.000166\n",
      " Epoch 76: Train Loss: 0.000162, Validation Loss: 0.000166\n",
      " Epoch 77: Train Loss: 0.000161, Validation Loss: 0.000165\n",
      " Epoch 78: Train Loss: 0.000161, Validation Loss: 0.000164\n",
      " Epoch 79: Train Loss: 0.000160, Validation Loss: 0.000164\n",
      " Epoch 80: Train Loss: 0.000159, Validation Loss: 0.000163\n",
      " Epoch 81: Train Loss: 0.000158, Validation Loss: 0.000162\n",
      " Epoch 82: Train Loss: 0.000158, Validation Loss: 0.000162\n",
      " Epoch 83: Train Loss: 0.000157, Validation Loss: 0.000161\n",
      " Epoch 84: Train Loss: 0.000157, Validation Loss: 0.000161\n",
      " Epoch 85: Train Loss: 0.000156, Validation Loss: 0.000161\n",
      " Epoch 86: Train Loss: 0.000156, Validation Loss: 0.000160\n",
      " Epoch 87: Train Loss: 0.000155, Validation Loss: 0.000159\n",
      " Epoch 88: Train Loss: 0.000154, Validation Loss: 0.000162\n",
      " Epoch 89: Train Loss: 0.000154, Validation Loss: 0.000159\n",
      " Epoch 90: Train Loss: 0.000153, Validation Loss: 0.000159\n",
      " Epoch 91: Train Loss: 0.000152, Validation Loss: 0.000156\n",
      " Epoch 92: Train Loss: 0.000152, Validation Loss: 0.000156\n",
      " Epoch 93: Train Loss: 0.000151, Validation Loss: 0.000156\n",
      " Epoch 94: Train Loss: 0.000151, Validation Loss: 0.000156\n",
      " Epoch 95: Train Loss: 0.000151, Validation Loss: 0.000155\n",
      " Epoch 96: Train Loss: 0.000150, Validation Loss: 0.000155\n",
      " Epoch 97: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 98: Train Loss: 0.000150, Validation Loss: 0.000154\n",
      " Epoch 99: Train Loss: 0.000149, Validation Loss: 0.000154\n",
      " Epoch 100: Train Loss: 0.000149, Validation Loss: 0.000154\n",
      " Epoch 101: Train Loss: 0.000149, Validation Loss: 0.000153\n",
      " Epoch 102: Train Loss: 0.000148, Validation Loss: 0.000153\n",
      " Epoch 103: Train Loss: 0.000148, Validation Loss: 0.000152\n",
      " Epoch 104: Train Loss: 0.000147, Validation Loss: 0.000152\n",
      " Epoch 105: Train Loss: 0.000147, Validation Loss: 0.000152\n",
      " Epoch 106: Train Loss: 0.000147, Validation Loss: 0.000153\n",
      " Epoch 107: Train Loss: 0.000147, Validation Loss: 0.000151\n",
      " Epoch 108: Train Loss: 0.000146, Validation Loss: 0.000151\n",
      " Epoch 109: Train Loss: 0.000146, Validation Loss: 0.000150\n",
      " Epoch 110: Train Loss: 0.000145, Validation Loss: 0.000150\n",
      " Epoch 111: Train Loss: 0.000145, Validation Loss: 0.000149\n",
      " Epoch 112: Train Loss: 0.000145, Validation Loss: 0.000149\n",
      " Epoch 113: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 114: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 115: Train Loss: 0.000144, Validation Loss: 0.000149\n",
      " Epoch 116: Train Loss: 0.000143, Validation Loss: 0.000149\n",
      " Epoch 117: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 118: Train Loss: 0.000143, Validation Loss: 0.000147\n",
      " Epoch 119: Train Loss: 0.000142, Validation Loss: 0.000146\n",
      " Epoch 120: Train Loss: 0.000142, Validation Loss: 0.000147\n",
      " Epoch 121: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 122: Train Loss: 0.000141, Validation Loss: 0.000146\n",
      " Epoch 123: Train Loss: 0.000141, Validation Loss: 0.000145\n",
      " Epoch 124: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 125: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 126: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 127: Train Loss: 0.000140, Validation Loss: 0.000145\n",
      " Epoch 128: Train Loss: 0.000140, Validation Loss: 0.000144\n",
      " Epoch 129: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 130: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 131: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 132: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 133: Train Loss: 0.000139, Validation Loss: 0.000144\n",
      " Epoch 134: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 135: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 136: Train Loss: 0.000138, Validation Loss: 0.000143\n",
      " Epoch 137: Train Loss: 0.000138, Validation Loss: 0.000142\n",
      " Epoch 138: Train Loss: 0.000137, Validation Loss: 0.000143\n",
      " Epoch 139: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 140: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 141: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 142: Train Loss: 0.000137, Validation Loss: 0.000142\n",
      " Epoch 143: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 144: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 145: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 146: Train Loss: 0.000136, Validation Loss: 0.000141\n",
      " Epoch 147: Train Loss: 0.000135, Validation Loss: 0.000141\n",
      " Epoch 148: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 149: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 150: Train Loss: 0.000135, Validation Loss: 0.000140\n",
      " Epoch 151: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 152: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 153: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 154: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 155: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 156: Train Loss: 0.000134, Validation Loss: 0.000139\n",
      " Epoch 157: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 158: Train Loss: 0.000133, Validation Loss: 0.000139\n",
      " Epoch 159: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 160: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 161: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 162: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 163: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 164: Train Loss: 0.000133, Validation Loss: 0.000138\n",
      " Epoch 165: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 166: Train Loss: 0.000132, Validation Loss: 0.000138\n",
      " Epoch 167: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 168: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 169: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 170: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 171: Train Loss: 0.000132, Validation Loss: 0.000137\n",
      " Epoch 172: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 173: Train Loss: 0.000131, Validation Loss: 0.000137\n",
      " Epoch 174: Train Loss: 0.000131, Validation Loss: 0.000136\n",
      " Epoch 175: Train Loss: 0.000131, Validation Loss: 0.000136\n",
      " Epoch 176: Train Loss: 0.000131, Validation Loss: 0.000136\n",
      " Epoch 177: Train Loss: 0.000131, Validation Loss: 0.000136\n",
      " Epoch 178: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 179: Train Loss: 0.000130, Validation Loss: 0.000136\n",
      " Epoch 180: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 181: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 182: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 183: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 184: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 185: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 186: Train Loss: 0.000130, Validation Loss: 0.000135\n",
      " Epoch 187: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 188: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 189: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 190: Train Loss: 0.000129, Validation Loss: 0.000135\n",
      " Epoch 191: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 192: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 193: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 194: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 195: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 196: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 197: Train Loss: 0.000129, Validation Loss: 0.000134\n",
      " Epoch 198: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 199: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 200: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 201: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 202: Train Loss: 0.000128, Validation Loss: 0.000134\n",
      " Epoch 203: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 204: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 205: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 206: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 207: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 208: Train Loss: 0.000128, Validation Loss: 0.000133\n",
      " Epoch 209: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 210: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 211: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 212: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 213: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 214: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 215: Train Loss: 0.000127, Validation Loss: 0.000133\n",
      " Epoch 216: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 217: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 218: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 219: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 220: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 221: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 222: Train Loss: 0.000127, Validation Loss: 0.000132\n",
      " Epoch 223: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 224: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 225: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 226: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 227: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 228: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 229: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 230: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 231: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 232: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 233: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 234: Train Loss: 0.000126, Validation Loss: 0.000132\n",
      " Epoch 235: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 236: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 237: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 238: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 239: Train Loss: 0.000126, Validation Loss: 0.000131\n",
      " Epoch 240: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 241: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 242: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 243: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 244: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 245: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 246: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 247: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 248: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 249: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 250: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 251: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 252: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 253: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 254: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 255: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 256: Train Loss: 0.000125, Validation Loss: 0.000131\n",
      " Epoch 257: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 258: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 259: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 260: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 261: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 262: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 263: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 264: Train Loss: 0.000125, Validation Loss: 0.000130\n",
      " Epoch 265: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 266: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 267: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 268: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 269: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 270: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 271: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 272: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 273: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 274: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 275: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 276: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 277: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 278: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 279: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 280: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 281: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 282: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 283: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 284: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 285: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 286: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 287: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 288: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 289: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 290: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 291: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 292: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 293: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 294: Train Loss: 0.000124, Validation Loss: 0.000130\n",
      " Epoch 295: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 296: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 297: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 298: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 299: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 300: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 301: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 302: Train Loss: 0.000124, Validation Loss: 0.000129\n",
      " Epoch 303: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 304: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 305: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 306: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 307: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 308: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 309: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 310: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 311: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 312: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 313: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 314: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 315: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 316: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 317: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 318: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 319: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 320: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 321: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 322: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 323: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 324: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 325: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 326: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 327: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 328: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 329: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 330: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 331: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 332: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 333: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 334: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 335: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 336: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 337: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 338: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 339: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 340: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 341: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 342: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 343: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 344: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 345: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 346: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 347: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 348: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 349: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 350: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 351: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 352: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 353: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 354: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 355: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 356: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 357: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 358: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 359: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 360: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 361: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 362: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 363: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 364: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 365: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 366: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 367: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 368: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 369: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 370: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 371: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 372: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 373: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 374: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 375: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 376: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 377: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 378: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 379: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 380: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 381: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 382: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 383: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 384: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 385: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 386: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 387: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 388: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 389: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 390: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 391: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 392: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 393: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 394: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 395: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 396: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 397: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 398: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 399: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 400: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 401: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 402: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 403: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 404: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 405: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 406: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 407: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 408: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 409: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 410: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 411: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 412: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 413: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 414: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 415: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 416: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 417: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 418: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 419: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 420: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 421: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 422: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 423: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 424: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 425: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 426: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 427: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 428: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 429: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 430: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 431: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 432: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 433: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 434: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 435: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 436: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 437: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 438: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 439: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 440: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 441: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 442: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 443: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 444: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 445: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 446: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 447: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 448: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 449: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 450: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 451: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 452: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 453: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 454: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 455: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 456: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 457: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 458: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 459: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 460: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 461: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 462: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 463: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 464: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 465: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 466: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 467: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 468: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 469: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 470: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 471: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 472: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 473: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 474: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 475: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 476: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 477: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 478: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 479: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 480: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 481: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 482: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 483: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 484: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 485: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 486: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 487: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 488: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 489: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 490: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 491: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 492: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 493: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 494: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 495: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 496: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 497: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 498: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 499: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 500: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 501: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 502: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 503: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 504: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 505: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 506: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 507: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 508: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 509: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 510: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 511: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 512: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 513: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 514: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 515: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 516: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 517: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 518: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 519: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 520: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 521: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 522: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 523: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 524: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 525: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 526: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 527: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 528: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 529: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 530: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 531: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 532: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 533: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 534: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 535: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 536: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 537: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 538: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 539: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 540: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 541: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 542: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 543: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 544: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 545: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 546: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 547: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 548: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 549: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 550: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 551: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 552: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 553: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 554: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 555: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 556: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 557: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 558: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 559: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 560: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 561: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 562: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 563: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 564: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 565: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 566: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 567: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 568: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 569: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 570: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 571: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 572: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 573: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 574: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 575: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 576: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 577: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 578: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 579: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 580: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 581: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 582: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 583: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 584: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 585: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 586: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 587: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 588: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 589: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 590: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 591: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 592: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 593: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 594: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 595: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 596: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 597: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 598: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 599: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 600: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 601: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 602: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 603: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 604: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 605: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 606: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      " Epoch 607: Train Loss: 0.000123, Validation Loss: 0.000129\n",
      "Early stopping at epoch 607 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.024763, Validation Loss: 0.005674\n",
      " Epoch 2: Train Loss: 0.001712, Validation Loss: 0.001534\n",
      " Epoch 3: Train Loss: 0.001194, Validation Loss: 0.000908\n",
      " Epoch 4: Train Loss: 0.000970, Validation Loss: 0.000782\n",
      " Epoch 5: Train Loss: 0.000844, Validation Loss: 0.000624\n",
      " Epoch 6: Train Loss: 0.000747, Validation Loss: 0.000604\n",
      " Epoch 7: Train Loss: 0.000697, Validation Loss: 0.000574\n",
      " Epoch 8: Train Loss: 0.000660, Validation Loss: 0.000551\n",
      " Epoch 9: Train Loss: 0.000630, Validation Loss: 0.000526\n",
      " Epoch 10: Train Loss: 0.000607, Validation Loss: 0.000513\n",
      " Epoch 11: Train Loss: 0.000587, Validation Loss: 0.000494\n",
      " Epoch 12: Train Loss: 0.000569, Validation Loss: 0.000480\n",
      " Epoch 13: Train Loss: 0.000554, Validation Loss: 0.000464\n",
      " Epoch 14: Train Loss: 0.000540, Validation Loss: 0.000456\n",
      " Epoch 15: Train Loss: 0.000521, Validation Loss: 0.000466\n",
      " Epoch 16: Train Loss: 0.000479, Validation Loss: 0.000407\n",
      " Epoch 17: Train Loss: 0.000448, Validation Loss: 0.000367\n",
      " Epoch 18: Train Loss: 0.000437, Validation Loss: 0.000356\n",
      " Epoch 19: Train Loss: 0.000426, Validation Loss: 0.000337\n",
      " Epoch 20: Train Loss: 0.000418, Validation Loss: 0.000340\n",
      " Epoch 21: Train Loss: 0.000409, Validation Loss: 0.000328\n",
      " Epoch 22: Train Loss: 0.000402, Validation Loss: 0.000326\n",
      " Epoch 23: Train Loss: 0.000395, Validation Loss: 0.000314\n",
      " Epoch 24: Train Loss: 0.000389, Validation Loss: 0.000297\n",
      " Epoch 25: Train Loss: 0.000383, Validation Loss: 0.000292\n",
      " Epoch 26: Train Loss: 0.000377, Validation Loss: 0.000283\n",
      " Epoch 27: Train Loss: 0.000371, Validation Loss: 0.000294\n",
      " Epoch 28: Train Loss: 0.000366, Validation Loss: 0.000287\n",
      " Epoch 29: Train Loss: 0.000361, Validation Loss: 0.000277\n",
      " Epoch 30: Train Loss: 0.000356, Validation Loss: 0.000275\n",
      " Epoch 31: Train Loss: 0.000353, Validation Loss: 0.000269\n",
      " Epoch 32: Train Loss: 0.000350, Validation Loss: 0.000272\n",
      " Epoch 33: Train Loss: 0.000348, Validation Loss: 0.000265\n",
      " Epoch 34: Train Loss: 0.000346, Validation Loss: 0.000266\n",
      " Epoch 35: Train Loss: 0.000343, Validation Loss: 0.000265\n",
      " Epoch 36: Train Loss: 0.000341, Validation Loss: 0.000263\n",
      " Epoch 37: Train Loss: 0.000339, Validation Loss: 0.000255\n",
      " Epoch 38: Train Loss: 0.000336, Validation Loss: 0.000264\n",
      " Epoch 39: Train Loss: 0.000334, Validation Loss: 0.000256\n",
      " Epoch 40: Train Loss: 0.000332, Validation Loss: 0.000251\n",
      " Epoch 41: Train Loss: 0.000330, Validation Loss: 0.000251\n",
      " Epoch 42: Train Loss: 0.000328, Validation Loss: 0.000252\n",
      " Epoch 43: Train Loss: 0.000325, Validation Loss: 0.000249\n",
      " Epoch 44: Train Loss: 0.000323, Validation Loss: 0.000244\n",
      " Epoch 45: Train Loss: 0.000321, Validation Loss: 0.000240\n",
      " Epoch 46: Train Loss: 0.000319, Validation Loss: 0.000242\n",
      " Epoch 47: Train Loss: 0.000316, Validation Loss: 0.000236\n",
      " Epoch 48: Train Loss: 0.000314, Validation Loss: 0.000232\n",
      " Epoch 49: Train Loss: 0.000312, Validation Loss: 0.000236\n",
      " Epoch 50: Train Loss: 0.000310, Validation Loss: 0.000233\n",
      " Epoch 51: Train Loss: 0.000308, Validation Loss: 0.000232\n",
      " Epoch 52: Train Loss: 0.000306, Validation Loss: 0.000229\n",
      " Epoch 53: Train Loss: 0.000304, Validation Loss: 0.000227\n",
      " Epoch 54: Train Loss: 0.000302, Validation Loss: 0.000226\n",
      " Epoch 55: Train Loss: 0.000299, Validation Loss: 0.000224\n",
      " Epoch 56: Train Loss: 0.000298, Validation Loss: 0.000224\n",
      " Epoch 57: Train Loss: 0.000296, Validation Loss: 0.000219\n",
      " Epoch 58: Train Loss: 0.000294, Validation Loss: 0.000219\n",
      " Epoch 59: Train Loss: 0.000292, Validation Loss: 0.000219\n",
      " Epoch 60: Train Loss: 0.000290, Validation Loss: 0.000220\n",
      " Epoch 61: Train Loss: 0.000288, Validation Loss: 0.000216\n",
      " Epoch 62: Train Loss: 0.000287, Validation Loss: 0.000215\n",
      " Epoch 63: Train Loss: 0.000286, Validation Loss: 0.000212\n",
      " Epoch 64: Train Loss: 0.000285, Validation Loss: 0.000210\n",
      " Epoch 65: Train Loss: 0.000284, Validation Loss: 0.000213\n",
      " Epoch 66: Train Loss: 0.000283, Validation Loss: 0.000209\n",
      " Epoch 67: Train Loss: 0.000282, Validation Loss: 0.000209\n",
      " Epoch 68: Train Loss: 0.000281, Validation Loss: 0.000206\n",
      " Epoch 69: Train Loss: 0.000281, Validation Loss: 0.000206\n",
      " Epoch 70: Train Loss: 0.000280, Validation Loss: 0.000207\n",
      " Epoch 71: Train Loss: 0.000279, Validation Loss: 0.000205\n",
      " Epoch 72: Train Loss: 0.000278, Validation Loss: 0.000208\n",
      " Epoch 73: Train Loss: 0.000277, Validation Loss: 0.000204\n",
      " Epoch 74: Train Loss: 0.000276, Validation Loss: 0.000204\n",
      " Epoch 75: Train Loss: 0.000275, Validation Loss: 0.000204\n",
      " Epoch 76: Train Loss: 0.000274, Validation Loss: 0.000202\n",
      " Epoch 77: Train Loss: 0.000273, Validation Loss: 0.000201\n",
      " Epoch 78: Train Loss: 0.000272, Validation Loss: 0.000201\n",
      " Epoch 79: Train Loss: 0.000271, Validation Loss: 0.000200\n",
      " Epoch 80: Train Loss: 0.000270, Validation Loss: 0.000200\n",
      " Epoch 81: Train Loss: 0.000269, Validation Loss: 0.000198\n",
      " Epoch 82: Train Loss: 0.000268, Validation Loss: 0.000197\n",
      " Epoch 83: Train Loss: 0.000267, Validation Loss: 0.000199\n",
      " Epoch 84: Train Loss: 0.000266, Validation Loss: 0.000197\n",
      " Epoch 85: Train Loss: 0.000265, Validation Loss: 0.000193\n",
      " Epoch 86: Train Loss: 0.000264, Validation Loss: 0.000197\n",
      " Epoch 87: Train Loss: 0.000263, Validation Loss: 0.000196\n",
      " Epoch 88: Train Loss: 0.000262, Validation Loss: 0.000195\n",
      " Epoch 89: Train Loss: 0.000261, Validation Loss: 0.000192\n",
      " Epoch 90: Train Loss: 0.000259, Validation Loss: 0.000192\n",
      " Epoch 91: Train Loss: 0.000258, Validation Loss: 0.000191\n",
      " Epoch 92: Train Loss: 0.000258, Validation Loss: 0.000189\n",
      " Epoch 93: Train Loss: 0.000257, Validation Loss: 0.000189\n",
      " Epoch 94: Train Loss: 0.000257, Validation Loss: 0.000188\n",
      " Epoch 95: Train Loss: 0.000256, Validation Loss: 0.000187\n",
      " Epoch 96: Train Loss: 0.000256, Validation Loss: 0.000187\n",
      " Epoch 97: Train Loss: 0.000255, Validation Loss: 0.000186\n",
      " Epoch 98: Train Loss: 0.000255, Validation Loss: 0.000187\n",
      " Epoch 99: Train Loss: 0.000254, Validation Loss: 0.000187\n",
      " Epoch 100: Train Loss: 0.000254, Validation Loss: 0.000186\n",
      " Epoch 101: Train Loss: 0.000253, Validation Loss: 0.000184\n",
      " Epoch 102: Train Loss: 0.000253, Validation Loss: 0.000184\n",
      " Epoch 103: Train Loss: 0.000252, Validation Loss: 0.000184\n",
      " Epoch 104: Train Loss: 0.000251, Validation Loss: 0.000183\n",
      " Epoch 105: Train Loss: 0.000251, Validation Loss: 0.000185\n",
      " Epoch 106: Train Loss: 0.000250, Validation Loss: 0.000182\n",
      " Epoch 107: Train Loss: 0.000249, Validation Loss: 0.000182\n",
      " Epoch 108: Train Loss: 0.000249, Validation Loss: 0.000181\n",
      " Epoch 109: Train Loss: 0.000248, Validation Loss: 0.000183\n",
      " Epoch 110: Train Loss: 0.000248, Validation Loss: 0.000182\n",
      " Epoch 111: Train Loss: 0.000247, Validation Loss: 0.000181\n",
      " Epoch 112: Train Loss: 0.000246, Validation Loss: 0.000180\n",
      " Epoch 113: Train Loss: 0.000246, Validation Loss: 0.000180\n",
      " Epoch 114: Train Loss: 0.000245, Validation Loss: 0.000178\n",
      " Epoch 115: Train Loss: 0.000245, Validation Loss: 0.000180\n",
      " Epoch 116: Train Loss: 0.000244, Validation Loss: 0.000179\n",
      " Epoch 117: Train Loss: 0.000243, Validation Loss: 0.000177\n",
      " Epoch 118: Train Loss: 0.000243, Validation Loss: 0.000180\n",
      " Epoch 119: Train Loss: 0.000242, Validation Loss: 0.000178\n",
      " Epoch 120: Train Loss: 0.000241, Validation Loss: 0.000177\n",
      " Epoch 121: Train Loss: 0.000241, Validation Loss: 0.000176\n",
      " Epoch 122: Train Loss: 0.000240, Validation Loss: 0.000175\n",
      " Epoch 123: Train Loss: 0.000240, Validation Loss: 0.000176\n",
      " Epoch 124: Train Loss: 0.000240, Validation Loss: 0.000175\n",
      " Epoch 125: Train Loss: 0.000239, Validation Loss: 0.000174\n",
      " Epoch 126: Train Loss: 0.000239, Validation Loss: 0.000175\n",
      " Epoch 127: Train Loss: 0.000239, Validation Loss: 0.000174\n",
      " Epoch 128: Train Loss: 0.000238, Validation Loss: 0.000174\n",
      " Epoch 129: Train Loss: 0.000238, Validation Loss: 0.000173\n",
      " Epoch 130: Train Loss: 0.000238, Validation Loss: 0.000174\n",
      " Epoch 131: Train Loss: 0.000237, Validation Loss: 0.000173\n",
      " Epoch 132: Train Loss: 0.000237, Validation Loss: 0.000173\n",
      " Epoch 133: Train Loss: 0.000236, Validation Loss: 0.000172\n",
      " Epoch 134: Train Loss: 0.000236, Validation Loss: 0.000172\n",
      " Epoch 135: Train Loss: 0.000236, Validation Loss: 0.000172\n",
      " Epoch 136: Train Loss: 0.000235, Validation Loss: 0.000171\n",
      " Epoch 137: Train Loss: 0.000235, Validation Loss: 0.000171\n",
      " Epoch 138: Train Loss: 0.000235, Validation Loss: 0.000171\n",
      " Epoch 139: Train Loss: 0.000234, Validation Loss: 0.000172\n",
      " Epoch 140: Train Loss: 0.000234, Validation Loss: 0.000170\n",
      " Epoch 141: Train Loss: 0.000234, Validation Loss: 0.000171\n",
      " Epoch 142: Train Loss: 0.000233, Validation Loss: 0.000170\n",
      " Epoch 143: Train Loss: 0.000233, Validation Loss: 0.000169\n",
      " Epoch 144: Train Loss: 0.000232, Validation Loss: 0.000170\n",
      " Epoch 145: Train Loss: 0.000232, Validation Loss: 0.000170\n",
      " Epoch 146: Train Loss: 0.000231, Validation Loss: 0.000170\n",
      " Epoch 147: Train Loss: 0.000231, Validation Loss: 0.000171\n",
      " Epoch 148: Train Loss: 0.000231, Validation Loss: 0.000167\n",
      " Epoch 149: Train Loss: 0.000230, Validation Loss: 0.000168\n",
      " Epoch 150: Train Loss: 0.000230, Validation Loss: 0.000168\n",
      " Epoch 151: Train Loss: 0.000229, Validation Loss: 0.000168\n",
      " Epoch 152: Train Loss: 0.000229, Validation Loss: 0.000168\n",
      " Epoch 153: Train Loss: 0.000229, Validation Loss: 0.000168\n",
      " Epoch 154: Train Loss: 0.000229, Validation Loss: 0.000168\n",
      " Epoch 155: Train Loss: 0.000229, Validation Loss: 0.000167\n",
      " Epoch 156: Train Loss: 0.000228, Validation Loss: 0.000167\n",
      " Epoch 157: Train Loss: 0.000228, Validation Loss: 0.000167\n",
      " Epoch 158: Train Loss: 0.000228, Validation Loss: 0.000166\n",
      " Epoch 159: Train Loss: 0.000228, Validation Loss: 0.000167\n",
      " Epoch 160: Train Loss: 0.000227, Validation Loss: 0.000167\n",
      " Epoch 161: Train Loss: 0.000227, Validation Loss: 0.000167\n",
      " Epoch 162: Train Loss: 0.000227, Validation Loss: 0.000165\n",
      " Epoch 163: Train Loss: 0.000227, Validation Loss: 0.000166\n",
      " Epoch 164: Train Loss: 0.000226, Validation Loss: 0.000166\n",
      " Epoch 165: Train Loss: 0.000226, Validation Loss: 0.000165\n",
      " Epoch 166: Train Loss: 0.000226, Validation Loss: 0.000165\n",
      " Epoch 167: Train Loss: 0.000226, Validation Loss: 0.000165\n",
      " Epoch 168: Train Loss: 0.000225, Validation Loss: 0.000165\n",
      " Epoch 169: Train Loss: 0.000225, Validation Loss: 0.000165\n",
      " Epoch 170: Train Loss: 0.000225, Validation Loss: 0.000164\n",
      " Epoch 171: Train Loss: 0.000225, Validation Loss: 0.000165\n",
      " Epoch 172: Train Loss: 0.000225, Validation Loss: 0.000164\n",
      " Epoch 173: Train Loss: 0.000224, Validation Loss: 0.000164\n",
      " Epoch 174: Train Loss: 0.000224, Validation Loss: 0.000164\n",
      " Epoch 175: Train Loss: 0.000224, Validation Loss: 0.000165\n",
      " Epoch 176: Train Loss: 0.000224, Validation Loss: 0.000164\n",
      " Epoch 177: Train Loss: 0.000223, Validation Loss: 0.000163\n",
      " Epoch 178: Train Loss: 0.000223, Validation Loss: 0.000163\n",
      " Epoch 179: Train Loss: 0.000223, Validation Loss: 0.000163\n",
      " Epoch 180: Train Loss: 0.000222, Validation Loss: 0.000163\n",
      " Epoch 181: Train Loss: 0.000222, Validation Loss: 0.000163\n",
      " Epoch 182: Train Loss: 0.000222, Validation Loss: 0.000163\n",
      " Epoch 183: Train Loss: 0.000222, Validation Loss: 0.000163\n",
      " Epoch 184: Train Loss: 0.000222, Validation Loss: 0.000162\n",
      " Epoch 185: Train Loss: 0.000222, Validation Loss: 0.000162\n",
      " Epoch 186: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 187: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 188: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 189: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 190: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 191: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 192: Train Loss: 0.000221, Validation Loss: 0.000162\n",
      " Epoch 193: Train Loss: 0.000220, Validation Loss: 0.000162\n",
      " Epoch 194: Train Loss: 0.000220, Validation Loss: 0.000162\n",
      " Epoch 195: Train Loss: 0.000220, Validation Loss: 0.000161\n",
      " Epoch 196: Train Loss: 0.000220, Validation Loss: 0.000162\n",
      " Epoch 197: Train Loss: 0.000220, Validation Loss: 0.000161\n",
      " Epoch 198: Train Loss: 0.000220, Validation Loss: 0.000161\n",
      " Epoch 199: Train Loss: 0.000219, Validation Loss: 0.000162\n",
      " Epoch 200: Train Loss: 0.000219, Validation Loss: 0.000161\n",
      " Epoch 201: Train Loss: 0.000219, Validation Loss: 0.000161\n",
      " Epoch 202: Train Loss: 0.000219, Validation Loss: 0.000161\n",
      " Epoch 203: Train Loss: 0.000219, Validation Loss: 0.000161\n",
      " Epoch 204: Train Loss: 0.000219, Validation Loss: 0.000161\n",
      " Epoch 205: Train Loss: 0.000218, Validation Loss: 0.000160\n",
      " Epoch 206: Train Loss: 0.000218, Validation Loss: 0.000160\n",
      " Epoch 207: Train Loss: 0.000218, Validation Loss: 0.000161\n",
      " Epoch 208: Train Loss: 0.000218, Validation Loss: 0.000160\n",
      " Epoch 209: Train Loss: 0.000218, Validation Loss: 0.000160\n",
      " Epoch 210: Train Loss: 0.000218, Validation Loss: 0.000160\n",
      " Epoch 211: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 212: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 213: Train Loss: 0.000217, Validation Loss: 0.000159\n",
      " Epoch 214: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 215: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 216: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 217: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 218: Train Loss: 0.000217, Validation Loss: 0.000160\n",
      " Epoch 219: Train Loss: 0.000217, Validation Loss: 0.000159\n",
      " Epoch 220: Train Loss: 0.000216, Validation Loss: 0.000160\n",
      " Epoch 221: Train Loss: 0.000216, Validation Loss: 0.000160\n",
      " Epoch 222: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 223: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 224: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 225: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 226: Train Loss: 0.000216, Validation Loss: 0.000160\n",
      " Epoch 227: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 228: Train Loss: 0.000216, Validation Loss: 0.000158\n",
      " Epoch 229: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 230: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 231: Train Loss: 0.000216, Validation Loss: 0.000159\n",
      " Epoch 232: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 233: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 234: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 235: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 236: Train Loss: 0.000215, Validation Loss: 0.000158\n",
      " Epoch 237: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 238: Train Loss: 0.000215, Validation Loss: 0.000159\n",
      " Epoch 239: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 240: Train Loss: 0.000214, Validation Loss: 0.000159\n",
      " Epoch 241: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 242: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 243: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 244: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 245: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 246: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 247: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 248: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 249: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 250: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 251: Train Loss: 0.000214, Validation Loss: 0.000158\n",
      " Epoch 252: Train Loss: 0.000214, Validation Loss: 0.000157\n",
      " Epoch 253: Train Loss: 0.000214, Validation Loss: 0.000157\n",
      " Epoch 254: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 255: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 256: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 257: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 258: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 259: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 260: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 261: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 262: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 263: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 264: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 265: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 266: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 267: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 268: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 269: Train Loss: 0.000213, Validation Loss: 0.000157\n",
      " Epoch 270: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 271: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 272: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 273: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 274: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 275: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 276: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 277: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 278: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 279: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 280: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 281: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 282: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 283: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 284: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 285: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 286: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 287: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 288: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 289: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 290: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 291: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 292: Train Loss: 0.000212, Validation Loss: 0.000157\n",
      " Epoch 293: Train Loss: 0.000212, Validation Loss: 0.000156\n",
      " Epoch 294: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 295: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 296: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 297: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 298: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 299: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 300: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 301: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 302: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 303: Train Loss: 0.000211, Validation Loss: 0.000157\n",
      " Epoch 304: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 305: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 306: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 307: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 308: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 309: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 310: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 311: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 312: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 313: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 314: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 315: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 316: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 317: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 318: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 319: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 320: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 321: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 322: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 323: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 324: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 325: Train Loss: 0.000211, Validation Loss: 0.000156\n",
      " Epoch 326: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 327: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 328: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 329: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 330: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 331: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 332: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 333: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 334: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 335: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 336: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 337: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 338: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 339: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 340: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 341: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 342: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 343: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 344: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 345: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 346: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 347: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 348: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 349: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 350: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 351: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 352: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 353: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 354: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 355: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 356: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 357: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 358: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 359: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 360: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 361: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 362: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 363: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 364: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 365: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 366: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 367: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 368: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 369: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 370: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 371: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 372: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 373: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 374: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 375: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 376: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 377: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 378: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 379: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 380: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 381: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 382: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 383: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 384: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 385: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 386: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 387: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 388: Train Loss: 0.000209, Validation Loss: 0.000156\n",
      " Epoch 389: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 390: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 391: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 392: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 393: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 394: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 395: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      " Epoch 396: Train Loss: 0.000210, Validation Loss: 0.000156\n",
      "Early stopping at epoch 396 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014383, Validation Loss: 0.005678\n",
      " Epoch 2: Train Loss: 0.001548, Validation Loss: 0.001433\n",
      " Epoch 3: Train Loss: 0.001056, Validation Loss: 0.000906\n",
      " Epoch 4: Train Loss: 0.000836, Validation Loss: 0.000628\n",
      " Epoch 5: Train Loss: 0.000720, Validation Loss: 0.000555\n",
      " Epoch 6: Train Loss: 0.000650, Validation Loss: 0.000523\n",
      " Epoch 7: Train Loss: 0.000582, Validation Loss: 0.000471\n",
      " Epoch 8: Train Loss: 0.000540, Validation Loss: 0.000425\n",
      " Epoch 9: Train Loss: 0.000513, Validation Loss: 0.000427\n",
      " Epoch 10: Train Loss: 0.000493, Validation Loss: 0.000402\n",
      " Epoch 11: Train Loss: 0.000476, Validation Loss: 0.000387\n",
      " Epoch 12: Train Loss: 0.000461, Validation Loss: 0.000374\n",
      " Epoch 13: Train Loss: 0.000448, Validation Loss: 0.000364\n",
      " Epoch 14: Train Loss: 0.000437, Validation Loss: 0.000332\n",
      " Epoch 15: Train Loss: 0.000426, Validation Loss: 0.000329\n",
      " Epoch 16: Train Loss: 0.000417, Validation Loss: 0.000328\n",
      " Epoch 17: Train Loss: 0.000408, Validation Loss: 0.000321\n",
      " Epoch 18: Train Loss: 0.000400, Validation Loss: 0.000300\n",
      " Epoch 19: Train Loss: 0.000393, Validation Loss: 0.000302\n",
      " Epoch 20: Train Loss: 0.000386, Validation Loss: 0.000293\n",
      " Epoch 21: Train Loss: 0.000379, Validation Loss: 0.000288\n",
      " Epoch 22: Train Loss: 0.000372, Validation Loss: 0.000282\n",
      " Epoch 23: Train Loss: 0.000366, Validation Loss: 0.000275\n",
      " Epoch 24: Train Loss: 0.000361, Validation Loss: 0.000272\n",
      " Epoch 25: Train Loss: 0.000355, Validation Loss: 0.000265\n",
      " Epoch 26: Train Loss: 0.000349, Validation Loss: 0.000266\n",
      " Epoch 27: Train Loss: 0.000344, Validation Loss: 0.000275\n",
      " Epoch 28: Train Loss: 0.000345, Validation Loss: 0.000301\n",
      " Epoch 29: Train Loss: 0.000337, Validation Loss: 0.000245\n",
      " Epoch 30: Train Loss: 0.000330, Validation Loss: 0.000246\n",
      " Epoch 31: Train Loss: 0.000326, Validation Loss: 0.000248\n",
      " Epoch 32: Train Loss: 0.000323, Validation Loss: 0.000243\n",
      " Epoch 33: Train Loss: 0.000321, Validation Loss: 0.000240\n",
      " Epoch 34: Train Loss: 0.000319, Validation Loss: 0.000239\n",
      " Epoch 35: Train Loss: 0.000316, Validation Loss: 0.000237\n",
      " Epoch 36: Train Loss: 0.000314, Validation Loss: 0.000230\n",
      " Epoch 37: Train Loss: 0.000312, Validation Loss: 0.000235\n",
      " Epoch 38: Train Loss: 0.000309, Validation Loss: 0.000233\n",
      " Epoch 39: Train Loss: 0.000307, Validation Loss: 0.000227\n",
      " Epoch 40: Train Loss: 0.000305, Validation Loss: 0.000228\n",
      " Epoch 41: Train Loss: 0.000303, Validation Loss: 0.000227\n",
      " Epoch 42: Train Loss: 0.000301, Validation Loss: 0.000227\n",
      " Epoch 43: Train Loss: 0.000298, Validation Loss: 0.000223\n",
      " Epoch 44: Train Loss: 0.000296, Validation Loss: 0.000220\n",
      " Epoch 45: Train Loss: 0.000294, Validation Loss: 0.000219\n",
      " Epoch 46: Train Loss: 0.000292, Validation Loss: 0.000218\n",
      " Epoch 47: Train Loss: 0.000290, Validation Loss: 0.000218\n",
      " Epoch 48: Train Loss: 0.000288, Validation Loss: 0.000212\n",
      " Epoch 49: Train Loss: 0.000286, Validation Loss: 0.000210\n",
      " Epoch 50: Train Loss: 0.000284, Validation Loss: 0.000211\n",
      " Epoch 51: Train Loss: 0.000282, Validation Loss: 0.000208\n",
      " Epoch 52: Train Loss: 0.000280, Validation Loss: 0.000215\n",
      " Epoch 53: Train Loss: 0.000279, Validation Loss: 0.000204\n",
      " Epoch 54: Train Loss: 0.000277, Validation Loss: 0.000209\n",
      " Epoch 55: Train Loss: 0.000275, Validation Loss: 0.000202\n",
      " Epoch 56: Train Loss: 0.000273, Validation Loss: 0.000199\n",
      " Epoch 57: Train Loss: 0.000271, Validation Loss: 0.000201\n",
      " Epoch 58: Train Loss: 0.000269, Validation Loss: 0.000201\n",
      " Epoch 59: Train Loss: 0.000267, Validation Loss: 0.000195\n",
      " Epoch 60: Train Loss: 0.000266, Validation Loss: 0.000196\n",
      " Epoch 61: Train Loss: 0.000264, Validation Loss: 0.000194\n",
      " Epoch 62: Train Loss: 0.000263, Validation Loss: 0.000197\n",
      " Epoch 63: Train Loss: 0.000262, Validation Loss: 0.000195\n",
      " Epoch 64: Train Loss: 0.000261, Validation Loss: 0.000193\n",
      " Epoch 65: Train Loss: 0.000260, Validation Loss: 0.000195\n",
      " Epoch 66: Train Loss: 0.000259, Validation Loss: 0.000191\n",
      " Epoch 67: Train Loss: 0.000258, Validation Loss: 0.000190\n",
      " Epoch 68: Train Loss: 0.000257, Validation Loss: 0.000191\n",
      " Epoch 69: Train Loss: 0.000256, Validation Loss: 0.000193\n",
      " Epoch 70: Train Loss: 0.000256, Validation Loss: 0.000190\n",
      " Epoch 71: Train Loss: 0.000254, Validation Loss: 0.000190\n",
      " Epoch 72: Train Loss: 0.000254, Validation Loss: 0.000189\n",
      " Epoch 73: Train Loss: 0.000253, Validation Loss: 0.000187\n",
      " Epoch 74: Train Loss: 0.000252, Validation Loss: 0.000186\n",
      " Epoch 75: Train Loss: 0.000251, Validation Loss: 0.000186\n",
      " Epoch 76: Train Loss: 0.000250, Validation Loss: 0.000185\n",
      " Epoch 77: Train Loss: 0.000249, Validation Loss: 0.000185\n",
      " Epoch 78: Train Loss: 0.000248, Validation Loss: 0.000184\n",
      " Epoch 79: Train Loss: 0.000247, Validation Loss: 0.000182\n",
      " Epoch 80: Train Loss: 0.000246, Validation Loss: 0.000182\n",
      " Epoch 81: Train Loss: 0.000245, Validation Loss: 0.000184\n",
      " Epoch 82: Train Loss: 0.000244, Validation Loss: 0.000184\n",
      " Epoch 83: Train Loss: 0.000243, Validation Loss: 0.000182\n",
      " Epoch 84: Train Loss: 0.000242, Validation Loss: 0.000180\n",
      " Epoch 85: Train Loss: 0.000241, Validation Loss: 0.000185\n",
      " Epoch 86: Train Loss: 0.000240, Validation Loss: 0.000180\n",
      " Epoch 87: Train Loss: 0.000239, Validation Loss: 0.000179\n",
      " Epoch 88: Train Loss: 0.000238, Validation Loss: 0.000177\n",
      " Epoch 89: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 90: Train Loss: 0.000236, Validation Loss: 0.000173\n",
      " Epoch 91: Train Loss: 0.000235, Validation Loss: 0.000176\n",
      " Epoch 92: Train Loss: 0.000235, Validation Loss: 0.000174\n",
      " Epoch 93: Train Loss: 0.000234, Validation Loss: 0.000177\n",
      " Epoch 94: Train Loss: 0.000234, Validation Loss: 0.000175\n",
      " Epoch 95: Train Loss: 0.000233, Validation Loss: 0.000174\n",
      " Epoch 96: Train Loss: 0.000233, Validation Loss: 0.000175\n",
      " Epoch 97: Train Loss: 0.000232, Validation Loss: 0.000174\n",
      " Epoch 98: Train Loss: 0.000232, Validation Loss: 0.000173\n",
      " Epoch 99: Train Loss: 0.000231, Validation Loss: 0.000174\n",
      " Epoch 100: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 101: Train Loss: 0.000230, Validation Loss: 0.000173\n",
      " Epoch 102: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 103: Train Loss: 0.000229, Validation Loss: 0.000174\n",
      " Epoch 104: Train Loss: 0.000229, Validation Loss: 0.000174\n",
      " Epoch 105: Train Loss: 0.000228, Validation Loss: 0.000169\n",
      " Epoch 106: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 107: Train Loss: 0.000227, Validation Loss: 0.000171\n",
      " Epoch 108: Train Loss: 0.000227, Validation Loss: 0.000168\n",
      " Epoch 109: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 110: Train Loss: 0.000225, Validation Loss: 0.000166\n",
      " Epoch 111: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 112: Train Loss: 0.000224, Validation Loss: 0.000170\n",
      " Epoch 113: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 114: Train Loss: 0.000224, Validation Loss: 0.000164\n",
      " Epoch 115: Train Loss: 0.000223, Validation Loss: 0.000166\n",
      " Epoch 116: Train Loss: 0.000222, Validation Loss: 0.000167\n",
      " Epoch 117: Train Loss: 0.000222, Validation Loss: 0.000165\n",
      " Epoch 118: Train Loss: 0.000221, Validation Loss: 0.000167\n",
      " Epoch 119: Train Loss: 0.000221, Validation Loss: 0.000165\n",
      " Epoch 120: Train Loss: 0.000220, Validation Loss: 0.000165\n",
      " Epoch 121: Train Loss: 0.000219, Validation Loss: 0.000163\n",
      " Epoch 122: Train Loss: 0.000219, Validation Loss: 0.000164\n",
      " Epoch 123: Train Loss: 0.000219, Validation Loss: 0.000165\n",
      " Epoch 124: Train Loss: 0.000218, Validation Loss: 0.000165\n",
      " Epoch 125: Train Loss: 0.000218, Validation Loss: 0.000164\n",
      " Epoch 126: Train Loss: 0.000218, Validation Loss: 0.000161\n",
      " Epoch 127: Train Loss: 0.000218, Validation Loss: 0.000162\n",
      " Epoch 128: Train Loss: 0.000217, Validation Loss: 0.000162\n",
      " Epoch 129: Train Loss: 0.000217, Validation Loss: 0.000163\n",
      " Epoch 130: Train Loss: 0.000217, Validation Loss: 0.000162\n",
      " Epoch 131: Train Loss: 0.000216, Validation Loss: 0.000162\n",
      " Epoch 132: Train Loss: 0.000216, Validation Loss: 0.000160\n",
      " Epoch 133: Train Loss: 0.000216, Validation Loss: 0.000163\n",
      " Epoch 134: Train Loss: 0.000215, Validation Loss: 0.000161\n",
      " Epoch 135: Train Loss: 0.000215, Validation Loss: 0.000160\n",
      " Epoch 136: Train Loss: 0.000215, Validation Loss: 0.000162\n",
      " Epoch 137: Train Loss: 0.000214, Validation Loss: 0.000160\n",
      " Epoch 138: Train Loss: 0.000214, Validation Loss: 0.000160\n",
      " Epoch 139: Train Loss: 0.000214, Validation Loss: 0.000161\n",
      " Epoch 140: Train Loss: 0.000213, Validation Loss: 0.000161\n",
      " Epoch 141: Train Loss: 0.000213, Validation Loss: 0.000158\n",
      " Epoch 142: Train Loss: 0.000213, Validation Loss: 0.000160\n",
      " Epoch 143: Train Loss: 0.000212, Validation Loss: 0.000159\n",
      " Epoch 144: Train Loss: 0.000212, Validation Loss: 0.000160\n",
      " Epoch 145: Train Loss: 0.000212, Validation Loss: 0.000158\n",
      " Epoch 146: Train Loss: 0.000211, Validation Loss: 0.000158\n",
      " Epoch 147: Train Loss: 0.000211, Validation Loss: 0.000159\n",
      " Epoch 148: Train Loss: 0.000211, Validation Loss: 0.000158\n",
      " Epoch 149: Train Loss: 0.000210, Validation Loss: 0.000157\n",
      " Epoch 150: Train Loss: 0.000210, Validation Loss: 0.000158\n",
      " Epoch 151: Train Loss: 0.000210, Validation Loss: 0.000158\n",
      " Epoch 152: Train Loss: 0.000209, Validation Loss: 0.000157\n",
      " Epoch 153: Train Loss: 0.000209, Validation Loss: 0.000158\n",
      " Epoch 154: Train Loss: 0.000209, Validation Loss: 0.000157\n",
      " Epoch 155: Train Loss: 0.000209, Validation Loss: 0.000157\n",
      " Epoch 156: Train Loss: 0.000209, Validation Loss: 0.000157\n",
      " Epoch 157: Train Loss: 0.000208, Validation Loss: 0.000157\n",
      " Epoch 158: Train Loss: 0.000208, Validation Loss: 0.000157\n",
      " Epoch 159: Train Loss: 0.000208, Validation Loss: 0.000156\n",
      " Epoch 160: Train Loss: 0.000208, Validation Loss: 0.000156\n",
      " Epoch 161: Train Loss: 0.000208, Validation Loss: 0.000156\n",
      " Epoch 162: Train Loss: 0.000208, Validation Loss: 0.000156\n",
      " Epoch 163: Train Loss: 0.000207, Validation Loss: 0.000155\n",
      " Epoch 164: Train Loss: 0.000207, Validation Loss: 0.000156\n",
      " Epoch 165: Train Loss: 0.000207, Validation Loss: 0.000157\n",
      " Epoch 166: Train Loss: 0.000207, Validation Loss: 0.000156\n",
      " Epoch 167: Train Loss: 0.000206, Validation Loss: 0.000156\n",
      " Epoch 168: Train Loss: 0.000206, Validation Loss: 0.000154\n",
      " Epoch 169: Train Loss: 0.000206, Validation Loss: 0.000154\n",
      " Epoch 170: Train Loss: 0.000206, Validation Loss: 0.000154\n",
      " Epoch 171: Train Loss: 0.000206, Validation Loss: 0.000156\n",
      " Epoch 172: Train Loss: 0.000205, Validation Loss: 0.000154\n",
      " Epoch 173: Train Loss: 0.000205, Validation Loss: 0.000155\n",
      " Epoch 174: Train Loss: 0.000205, Validation Loss: 0.000154\n",
      " Epoch 175: Train Loss: 0.000205, Validation Loss: 0.000155\n",
      " Epoch 176: Train Loss: 0.000205, Validation Loss: 0.000154\n",
      " Epoch 177: Train Loss: 0.000205, Validation Loss: 0.000155\n",
      " Epoch 178: Train Loss: 0.000204, Validation Loss: 0.000154\n",
      " Epoch 179: Train Loss: 0.000204, Validation Loss: 0.000153\n",
      " Epoch 180: Train Loss: 0.000204, Validation Loss: 0.000155\n",
      " Epoch 181: Train Loss: 0.000204, Validation Loss: 0.000154\n",
      " Epoch 182: Train Loss: 0.000203, Validation Loss: 0.000154\n",
      " Epoch 183: Train Loss: 0.000203, Validation Loss: 0.000153\n",
      " Epoch 184: Train Loss: 0.000203, Validation Loss: 0.000154\n",
      " Epoch 185: Train Loss: 0.000203, Validation Loss: 0.000153\n",
      " Epoch 186: Train Loss: 0.000203, Validation Loss: 0.000154\n",
      " Epoch 187: Train Loss: 0.000203, Validation Loss: 0.000153\n",
      " Epoch 188: Train Loss: 0.000203, Validation Loss: 0.000154\n",
      " Epoch 189: Train Loss: 0.000203, Validation Loss: 0.000154\n",
      " Epoch 190: Train Loss: 0.000202, Validation Loss: 0.000154\n",
      " Epoch 191: Train Loss: 0.000202, Validation Loss: 0.000153\n",
      " Epoch 192: Train Loss: 0.000202, Validation Loss: 0.000152\n",
      " Epoch 193: Train Loss: 0.000202, Validation Loss: 0.000154\n",
      " Epoch 194: Train Loss: 0.000202, Validation Loss: 0.000153\n",
      " Epoch 195: Train Loss: 0.000202, Validation Loss: 0.000153\n",
      " Epoch 196: Train Loss: 0.000202, Validation Loss: 0.000153\n",
      " Epoch 197: Train Loss: 0.000202, Validation Loss: 0.000153\n",
      " Epoch 198: Train Loss: 0.000202, Validation Loss: 0.000154\n",
      " Epoch 199: Train Loss: 0.000201, Validation Loss: 0.000153\n",
      " Epoch 200: Train Loss: 0.000201, Validation Loss: 0.000153\n",
      " Epoch 201: Train Loss: 0.000201, Validation Loss: 0.000151\n",
      " Epoch 202: Train Loss: 0.000201, Validation Loss: 0.000152\n",
      " Epoch 203: Train Loss: 0.000201, Validation Loss: 0.000151\n",
      " Epoch 204: Train Loss: 0.000201, Validation Loss: 0.000152\n",
      " Epoch 205: Train Loss: 0.000201, Validation Loss: 0.000152\n",
      " Epoch 206: Train Loss: 0.000200, Validation Loss: 0.000153\n",
      " Epoch 207: Train Loss: 0.000200, Validation Loss: 0.000152\n",
      " Epoch 208: Train Loss: 0.000200, Validation Loss: 0.000154\n",
      " Epoch 209: Train Loss: 0.000200, Validation Loss: 0.000153\n",
      " Epoch 210: Train Loss: 0.000200, Validation Loss: 0.000152\n",
      " Epoch 211: Train Loss: 0.000200, Validation Loss: 0.000151\n",
      " Epoch 212: Train Loss: 0.000200, Validation Loss: 0.000152\n",
      " Epoch 213: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 214: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 215: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 216: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 217: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 218: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 219: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 220: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 221: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 222: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 223: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 224: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 225: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 226: Train Loss: 0.000199, Validation Loss: 0.000152\n",
      " Epoch 227: Train Loss: 0.000199, Validation Loss: 0.000151\n",
      " Epoch 228: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 229: Train Loss: 0.000198, Validation Loss: 0.000152\n",
      " Epoch 230: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 231: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 232: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 233: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 234: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 235: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 236: Train Loss: 0.000198, Validation Loss: 0.000150\n",
      " Epoch 237: Train Loss: 0.000198, Validation Loss: 0.000151\n",
      " Epoch 238: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 239: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 240: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 241: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 242: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 243: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 244: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 245: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 246: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 247: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 248: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 249: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 250: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 251: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 252: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 253: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 254: Train Loss: 0.000197, Validation Loss: 0.000151\n",
      " Epoch 255: Train Loss: 0.000196, Validation Loss: 0.000151\n",
      " Epoch 256: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 257: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 258: Train Loss: 0.000196, Validation Loss: 0.000151\n",
      " Epoch 259: Train Loss: 0.000197, Validation Loss: 0.000150\n",
      " Epoch 260: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 261: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 262: Train Loss: 0.000196, Validation Loss: 0.000151\n",
      " Epoch 263: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 264: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 265: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 266: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 267: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 268: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 269: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 270: Train Loss: 0.000196, Validation Loss: 0.000151\n",
      " Epoch 271: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 272: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 273: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 274: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 275: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 276: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 277: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 278: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 279: Train Loss: 0.000195, Validation Loss: 0.000150\n",
      " Epoch 280: Train Loss: 0.000195, Validation Loss: 0.000150\n",
      " Epoch 281: Train Loss: 0.000195, Validation Loss: 0.000150\n",
      " Epoch 282: Train Loss: 0.000196, Validation Loss: 0.000150\n",
      " Epoch 283: Train Loss: 0.000195, Validation Loss: 0.000150\n",
      " Epoch 284: Train Loss: 0.000195, Validation Loss: 0.000150\n",
      "Early stopping at epoch 284 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.023875, Validation Loss: 0.005514\n",
      " Epoch 2: Train Loss: 0.001981, Validation Loss: 0.002014\n",
      " Epoch 3: Train Loss: 0.001321, Validation Loss: 0.001090\n",
      " Epoch 4: Train Loss: 0.001032, Validation Loss: 0.000806\n",
      " Epoch 5: Train Loss: 0.000889, Validation Loss: 0.000701\n",
      " Epoch 6: Train Loss: 0.000810, Validation Loss: 0.000644\n",
      " Epoch 7: Train Loss: 0.000750, Validation Loss: 0.000582\n",
      " Epoch 8: Train Loss: 0.000677, Validation Loss: 0.000497\n",
      " Epoch 9: Train Loss: 0.000612, Validation Loss: 0.000445\n",
      " Epoch 10: Train Loss: 0.000561, Validation Loss: 0.000407\n",
      " Epoch 11: Train Loss: 0.000529, Validation Loss: 0.000391\n",
      " Epoch 12: Train Loss: 0.000508, Validation Loss: 0.000377\n",
      " Epoch 13: Train Loss: 0.000491, Validation Loss: 0.000372\n",
      " Epoch 14: Train Loss: 0.000477, Validation Loss: 0.000364\n",
      " Epoch 15: Train Loss: 0.000464, Validation Loss: 0.000349\n",
      " Epoch 16: Train Loss: 0.000454, Validation Loss: 0.000340\n",
      " Epoch 17: Train Loss: 0.000443, Validation Loss: 0.000338\n",
      " Epoch 18: Train Loss: 0.000434, Validation Loss: 0.000328\n",
      " Epoch 19: Train Loss: 0.000426, Validation Loss: 0.000325\n",
      " Epoch 20: Train Loss: 0.000418, Validation Loss: 0.000321\n",
      " Epoch 21: Train Loss: 0.000412, Validation Loss: 0.000314\n",
      " Epoch 22: Train Loss: 0.000405, Validation Loss: 0.000310\n",
      " Epoch 23: Train Loss: 0.000398, Validation Loss: 0.000305\n",
      " Epoch 24: Train Loss: 0.000393, Validation Loss: 0.000300\n",
      " Epoch 25: Train Loss: 0.000387, Validation Loss: 0.000296\n",
      " Epoch 26: Train Loss: 0.000382, Validation Loss: 0.000292\n",
      " Epoch 27: Train Loss: 0.000377, Validation Loss: 0.000292\n",
      " Epoch 28: Train Loss: 0.000372, Validation Loss: 0.000285\n",
      " Epoch 29: Train Loss: 0.000368, Validation Loss: 0.000284\n",
      " Epoch 30: Train Loss: 0.000363, Validation Loss: 0.000275\n",
      " Epoch 31: Train Loss: 0.000360, Validation Loss: 0.000275\n",
      " Epoch 32: Train Loss: 0.000358, Validation Loss: 0.000276\n",
      " Epoch 33: Train Loss: 0.000356, Validation Loss: 0.000272\n",
      " Epoch 34: Train Loss: 0.000354, Validation Loss: 0.000272\n",
      " Epoch 35: Train Loss: 0.000352, Validation Loss: 0.000272\n",
      " Epoch 36: Train Loss: 0.000350, Validation Loss: 0.000268\n",
      " Epoch 37: Train Loss: 0.000348, Validation Loss: 0.000271\n",
      " Epoch 38: Train Loss: 0.000346, Validation Loss: 0.000265\n",
      " Epoch 39: Train Loss: 0.000344, Validation Loss: 0.000264\n",
      " Epoch 40: Train Loss: 0.000342, Validation Loss: 0.000262\n",
      " Epoch 41: Train Loss: 0.000340, Validation Loss: 0.000262\n",
      " Epoch 42: Train Loss: 0.000338, Validation Loss: 0.000260\n",
      " Epoch 43: Train Loss: 0.000336, Validation Loss: 0.000258\n",
      " Epoch 44: Train Loss: 0.000334, Validation Loss: 0.000256\n",
      " Epoch 45: Train Loss: 0.000332, Validation Loss: 0.000257\n",
      " Epoch 46: Train Loss: 0.000331, Validation Loss: 0.000253\n",
      " Epoch 47: Train Loss: 0.000329, Validation Loss: 0.000256\n",
      " Epoch 48: Train Loss: 0.000327, Validation Loss: 0.000250\n",
      " Epoch 49: Train Loss: 0.000325, Validation Loss: 0.000249\n",
      " Epoch 50: Train Loss: 0.000323, Validation Loss: 0.000245\n",
      " Epoch 51: Train Loss: 0.000321, Validation Loss: 0.000246\n",
      " Epoch 52: Train Loss: 0.000319, Validation Loss: 0.000244\n",
      " Epoch 53: Train Loss: 0.000318, Validation Loss: 0.000245\n",
      " Epoch 54: Train Loss: 0.000316, Validation Loss: 0.000244\n",
      " Epoch 55: Train Loss: 0.000314, Validation Loss: 0.000241\n",
      " Epoch 56: Train Loss: 0.000312, Validation Loss: 0.000241\n",
      " Epoch 57: Train Loss: 0.000311, Validation Loss: 0.000240\n",
      " Epoch 58: Train Loss: 0.000309, Validation Loss: 0.000237\n",
      " Epoch 59: Train Loss: 0.000307, Validation Loss: 0.000235\n",
      " Epoch 60: Train Loss: 0.000305, Validation Loss: 0.000233\n",
      " Epoch 61: Train Loss: 0.000304, Validation Loss: 0.000233\n",
      " Epoch 62: Train Loss: 0.000303, Validation Loss: 0.000234\n",
      " Epoch 63: Train Loss: 0.000302, Validation Loss: 0.000230\n",
      " Epoch 64: Train Loss: 0.000301, Validation Loss: 0.000232\n",
      " Epoch 65: Train Loss: 0.000300, Validation Loss: 0.000230\n",
      " Epoch 66: Train Loss: 0.000300, Validation Loss: 0.000231\n",
      " Epoch 67: Train Loss: 0.000299, Validation Loss: 0.000229\n",
      " Epoch 68: Train Loss: 0.000298, Validation Loss: 0.000228\n",
      " Epoch 69: Train Loss: 0.000297, Validation Loss: 0.000227\n",
      " Epoch 70: Train Loss: 0.000296, Validation Loss: 0.000226\n",
      " Epoch 71: Train Loss: 0.000295, Validation Loss: 0.000227\n",
      " Epoch 72: Train Loss: 0.000294, Validation Loss: 0.000226\n",
      " Epoch 73: Train Loss: 0.000293, Validation Loss: 0.000224\n",
      " Epoch 74: Train Loss: 0.000292, Validation Loss: 0.000222\n",
      " Epoch 75: Train Loss: 0.000291, Validation Loss: 0.000223\n",
      " Epoch 76: Train Loss: 0.000290, Validation Loss: 0.000222\n",
      " Epoch 77: Train Loss: 0.000289, Validation Loss: 0.000222\n",
      " Epoch 78: Train Loss: 0.000288, Validation Loss: 0.000219\n",
      " Epoch 79: Train Loss: 0.000287, Validation Loss: 0.000220\n",
      " Epoch 80: Train Loss: 0.000286, Validation Loss: 0.000218\n",
      " Epoch 81: Train Loss: 0.000285, Validation Loss: 0.000219\n",
      " Epoch 82: Train Loss: 0.000284, Validation Loss: 0.000219\n",
      " Epoch 83: Train Loss: 0.000284, Validation Loss: 0.000218\n",
      " Epoch 84: Train Loss: 0.000282, Validation Loss: 0.000218\n",
      " Epoch 85: Train Loss: 0.000281, Validation Loss: 0.000216\n",
      " Epoch 86: Train Loss: 0.000280, Validation Loss: 0.000216\n",
      " Epoch 87: Train Loss: 0.000279, Validation Loss: 0.000214\n",
      " Epoch 88: Train Loss: 0.000278, Validation Loss: 0.000214\n",
      " Epoch 89: Train Loss: 0.000277, Validation Loss: 0.000213\n",
      " Epoch 90: Train Loss: 0.000276, Validation Loss: 0.000213\n",
      " Epoch 91: Train Loss: 0.000275, Validation Loss: 0.000212\n",
      " Epoch 92: Train Loss: 0.000275, Validation Loss: 0.000211\n",
      " Epoch 93: Train Loss: 0.000274, Validation Loss: 0.000211\n",
      " Epoch 94: Train Loss: 0.000274, Validation Loss: 0.000211\n",
      " Epoch 95: Train Loss: 0.000273, Validation Loss: 0.000210\n",
      " Epoch 96: Train Loss: 0.000273, Validation Loss: 0.000209\n",
      " Epoch 97: Train Loss: 0.000272, Validation Loss: 0.000207\n",
      " Epoch 98: Train Loss: 0.000271, Validation Loss: 0.000209\n",
      " Epoch 99: Train Loss: 0.000271, Validation Loss: 0.000209\n",
      " Epoch 100: Train Loss: 0.000270, Validation Loss: 0.000208\n",
      " Epoch 101: Train Loss: 0.000270, Validation Loss: 0.000207\n",
      " Epoch 102: Train Loss: 0.000269, Validation Loss: 0.000206\n",
      " Epoch 103: Train Loss: 0.000268, Validation Loss: 0.000206\n",
      " Epoch 104: Train Loss: 0.000268, Validation Loss: 0.000205\n",
      " Epoch 105: Train Loss: 0.000267, Validation Loss: 0.000204\n",
      " Epoch 106: Train Loss: 0.000267, Validation Loss: 0.000202\n",
      " Epoch 107: Train Loss: 0.000266, Validation Loss: 0.000205\n",
      " Epoch 108: Train Loss: 0.000265, Validation Loss: 0.000204\n",
      " Epoch 109: Train Loss: 0.000265, Validation Loss: 0.000202\n",
      " Epoch 110: Train Loss: 0.000264, Validation Loss: 0.000201\n",
      " Epoch 111: Train Loss: 0.000264, Validation Loss: 0.000202\n",
      " Epoch 112: Train Loss: 0.000263, Validation Loss: 0.000202\n",
      " Epoch 113: Train Loss: 0.000262, Validation Loss: 0.000201\n",
      " Epoch 114: Train Loss: 0.000262, Validation Loss: 0.000200\n",
      " Epoch 115: Train Loss: 0.000261, Validation Loss: 0.000199\n",
      " Epoch 116: Train Loss: 0.000260, Validation Loss: 0.000200\n",
      " Epoch 117: Train Loss: 0.000260, Validation Loss: 0.000198\n",
      " Epoch 118: Train Loss: 0.000259, Validation Loss: 0.000197\n",
      " Epoch 119: Train Loss: 0.000258, Validation Loss: 0.000199\n",
      " Epoch 120: Train Loss: 0.000258, Validation Loss: 0.000195\n",
      " Epoch 121: Train Loss: 0.000257, Validation Loss: 0.000196\n",
      " Epoch 122: Train Loss: 0.000257, Validation Loss: 0.000196\n",
      " Epoch 123: Train Loss: 0.000256, Validation Loss: 0.000195\n",
      " Epoch 124: Train Loss: 0.000256, Validation Loss: 0.000195\n",
      " Epoch 125: Train Loss: 0.000256, Validation Loss: 0.000194\n",
      " Epoch 126: Train Loss: 0.000255, Validation Loss: 0.000193\n",
      " Epoch 127: Train Loss: 0.000255, Validation Loss: 0.000194\n",
      " Epoch 128: Train Loss: 0.000255, Validation Loss: 0.000193\n",
      " Epoch 129: Train Loss: 0.000254, Validation Loss: 0.000192\n",
      " Epoch 130: Train Loss: 0.000254, Validation Loss: 0.000194\n",
      " Epoch 131: Train Loss: 0.000253, Validation Loss: 0.000192\n",
      " Epoch 132: Train Loss: 0.000253, Validation Loss: 0.000192\n",
      " Epoch 133: Train Loss: 0.000253, Validation Loss: 0.000192\n",
      " Epoch 134: Train Loss: 0.000252, Validation Loss: 0.000191\n",
      " Epoch 135: Train Loss: 0.000252, Validation Loss: 0.000192\n",
      " Epoch 136: Train Loss: 0.000251, Validation Loss: 0.000191\n",
      " Epoch 137: Train Loss: 0.000251, Validation Loss: 0.000192\n",
      " Epoch 138: Train Loss: 0.000251, Validation Loss: 0.000190\n",
      " Epoch 139: Train Loss: 0.000250, Validation Loss: 0.000189\n",
      " Epoch 140: Train Loss: 0.000250, Validation Loss: 0.000189\n",
      " Epoch 141: Train Loss: 0.000249, Validation Loss: 0.000190\n",
      " Epoch 142: Train Loss: 0.000249, Validation Loss: 0.000189\n",
      " Epoch 143: Train Loss: 0.000249, Validation Loss: 0.000188\n",
      " Epoch 144: Train Loss: 0.000248, Validation Loss: 0.000188\n",
      " Epoch 145: Train Loss: 0.000248, Validation Loss: 0.000187\n",
      " Epoch 146: Train Loss: 0.000247, Validation Loss: 0.000186\n",
      " Epoch 147: Train Loss: 0.000247, Validation Loss: 0.000186\n",
      " Epoch 148: Train Loss: 0.000247, Validation Loss: 0.000186\n",
      " Epoch 149: Train Loss: 0.000246, Validation Loss: 0.000186\n",
      " Epoch 150: Train Loss: 0.000246, Validation Loss: 0.000186\n",
      " Epoch 151: Train Loss: 0.000245, Validation Loss: 0.000185\n",
      " Epoch 152: Train Loss: 0.000245, Validation Loss: 0.000185\n",
      " Epoch 153: Train Loss: 0.000245, Validation Loss: 0.000185\n",
      " Epoch 154: Train Loss: 0.000244, Validation Loss: 0.000185\n",
      " Epoch 155: Train Loss: 0.000244, Validation Loss: 0.000184\n",
      " Epoch 156: Train Loss: 0.000244, Validation Loss: 0.000184\n",
      " Epoch 157: Train Loss: 0.000244, Validation Loss: 0.000185\n",
      " Epoch 158: Train Loss: 0.000244, Validation Loss: 0.000184\n",
      " Epoch 159: Train Loss: 0.000243, Validation Loss: 0.000183\n",
      " Epoch 160: Train Loss: 0.000243, Validation Loss: 0.000184\n",
      " Epoch 161: Train Loss: 0.000243, Validation Loss: 0.000183\n",
      " Epoch 162: Train Loss: 0.000243, Validation Loss: 0.000183\n",
      " Epoch 163: Train Loss: 0.000242, Validation Loss: 0.000184\n",
      " Epoch 164: Train Loss: 0.000242, Validation Loss: 0.000182\n",
      " Epoch 165: Train Loss: 0.000242, Validation Loss: 0.000181\n",
      " Epoch 166: Train Loss: 0.000241, Validation Loss: 0.000182\n",
      " Epoch 167: Train Loss: 0.000241, Validation Loss: 0.000182\n",
      " Epoch 168: Train Loss: 0.000241, Validation Loss: 0.000181\n",
      " Epoch 169: Train Loss: 0.000241, Validation Loss: 0.000181\n",
      " Epoch 170: Train Loss: 0.000240, Validation Loss: 0.000180\n",
      " Epoch 171: Train Loss: 0.000240, Validation Loss: 0.000181\n",
      " Epoch 172: Train Loss: 0.000240, Validation Loss: 0.000181\n",
      " Epoch 173: Train Loss: 0.000240, Validation Loss: 0.000180\n",
      " Epoch 174: Train Loss: 0.000239, Validation Loss: 0.000180\n",
      " Epoch 175: Train Loss: 0.000239, Validation Loss: 0.000179\n",
      " Epoch 176: Train Loss: 0.000239, Validation Loss: 0.000180\n",
      " Epoch 177: Train Loss: 0.000238, Validation Loss: 0.000180\n",
      " Epoch 178: Train Loss: 0.000238, Validation Loss: 0.000179\n",
      " Epoch 179: Train Loss: 0.000238, Validation Loss: 0.000179\n",
      " Epoch 180: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 181: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 182: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 183: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 184: Train Loss: 0.000237, Validation Loss: 0.000178\n",
      " Epoch 185: Train Loss: 0.000237, Validation Loss: 0.000177\n",
      " Epoch 186: Train Loss: 0.000236, Validation Loss: 0.000178\n",
      " Epoch 187: Train Loss: 0.000236, Validation Loss: 0.000178\n",
      " Epoch 188: Train Loss: 0.000236, Validation Loss: 0.000177\n",
      " Epoch 189: Train Loss: 0.000236, Validation Loss: 0.000177\n",
      " Epoch 190: Train Loss: 0.000236, Validation Loss: 0.000177\n",
      " Epoch 191: Train Loss: 0.000236, Validation Loss: 0.000177\n",
      " Epoch 192: Train Loss: 0.000235, Validation Loss: 0.000177\n",
      " Epoch 193: Train Loss: 0.000235, Validation Loss: 0.000177\n",
      " Epoch 194: Train Loss: 0.000235, Validation Loss: 0.000176\n",
      " Epoch 195: Train Loss: 0.000235, Validation Loss: 0.000176\n",
      " Epoch 196: Train Loss: 0.000235, Validation Loss: 0.000176\n",
      " Epoch 197: Train Loss: 0.000235, Validation Loss: 0.000176\n",
      " Epoch 198: Train Loss: 0.000234, Validation Loss: 0.000176\n",
      " Epoch 199: Train Loss: 0.000234, Validation Loss: 0.000176\n",
      " Epoch 200: Train Loss: 0.000234, Validation Loss: 0.000176\n",
      " Epoch 201: Train Loss: 0.000234, Validation Loss: 0.000175\n",
      " Epoch 202: Train Loss: 0.000234, Validation Loss: 0.000175\n",
      " Epoch 203: Train Loss: 0.000233, Validation Loss: 0.000175\n",
      " Epoch 204: Train Loss: 0.000233, Validation Loss: 0.000175\n",
      " Epoch 205: Train Loss: 0.000233, Validation Loss: 0.000175\n",
      " Epoch 206: Train Loss: 0.000233, Validation Loss: 0.000175\n",
      " Epoch 207: Train Loss: 0.000233, Validation Loss: 0.000174\n",
      " Epoch 208: Train Loss: 0.000232, Validation Loss: 0.000174\n",
      " Epoch 209: Train Loss: 0.000232, Validation Loss: 0.000174\n",
      " Epoch 210: Train Loss: 0.000232, Validation Loss: 0.000174\n",
      " Epoch 211: Train Loss: 0.000232, Validation Loss: 0.000173\n",
      " Epoch 212: Train Loss: 0.000232, Validation Loss: 0.000174\n",
      " Epoch 213: Train Loss: 0.000232, Validation Loss: 0.000173\n",
      " Epoch 214: Train Loss: 0.000232, Validation Loss: 0.000173\n",
      " Epoch 215: Train Loss: 0.000232, Validation Loss: 0.000173\n",
      " Epoch 216: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 217: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 218: Train Loss: 0.000231, Validation Loss: 0.000174\n",
      " Epoch 219: Train Loss: 0.000231, Validation Loss: 0.000172\n",
      " Epoch 220: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 221: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 222: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 223: Train Loss: 0.000231, Validation Loss: 0.000173\n",
      " Epoch 224: Train Loss: 0.000231, Validation Loss: 0.000172\n",
      " Epoch 225: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 226: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 227: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 228: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 229: Train Loss: 0.000230, Validation Loss: 0.000171\n",
      " Epoch 230: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 231: Train Loss: 0.000230, Validation Loss: 0.000172\n",
      " Epoch 232: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 233: Train Loss: 0.000229, Validation Loss: 0.000172\n",
      " Epoch 234: Train Loss: 0.000229, Validation Loss: 0.000172\n",
      " Epoch 235: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 236: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 237: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 238: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 239: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 240: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 241: Train Loss: 0.000229, Validation Loss: 0.000171\n",
      " Epoch 242: Train Loss: 0.000228, Validation Loss: 0.000171\n",
      " Epoch 243: Train Loss: 0.000228, Validation Loss: 0.000171\n",
      " Epoch 244: Train Loss: 0.000228, Validation Loss: 0.000171\n",
      " Epoch 245: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 246: Train Loss: 0.000228, Validation Loss: 0.000171\n",
      " Epoch 247: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 248: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 249: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 250: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 251: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 252: Train Loss: 0.000228, Validation Loss: 0.000170\n",
      " Epoch 253: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 254: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 255: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 256: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 257: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 258: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 259: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 260: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 261: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 262: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 263: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 264: Train Loss: 0.000227, Validation Loss: 0.000169\n",
      " Epoch 265: Train Loss: 0.000227, Validation Loss: 0.000170\n",
      " Epoch 266: Train Loss: 0.000227, Validation Loss: 0.000169\n",
      " Epoch 267: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 268: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 269: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 270: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 271: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 272: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 273: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 274: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 275: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 276: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 277: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 278: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 279: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 280: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 281: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 282: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 283: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 284: Train Loss: 0.000226, Validation Loss: 0.000169\n",
      " Epoch 285: Train Loss: 0.000225, Validation Loss: 0.000169\n",
      " Epoch 286: Train Loss: 0.000225, Validation Loss: 0.000169\n",
      " Epoch 287: Train Loss: 0.000225, Validation Loss: 0.000169\n",
      " Epoch 288: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 289: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 290: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 291: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 292: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 293: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 294: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 295: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 296: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 297: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 298: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 299: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 300: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 301: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 302: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 303: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 304: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 305: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 306: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 307: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 308: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 309: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 310: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 311: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 312: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 313: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 314: Train Loss: 0.000225, Validation Loss: 0.000168\n",
      " Epoch 315: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 316: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 317: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 318: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 319: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 320: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 321: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 322: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 323: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 324: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 325: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 326: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 327: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 328: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 329: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 330: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 331: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 332: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 333: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 334: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 335: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 336: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 337: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 338: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 339: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 340: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 341: Train Loss: 0.000224, Validation Loss: 0.000168\n",
      " Epoch 342: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 343: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 344: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 345: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 346: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 347: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 348: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 349: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 350: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 351: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 352: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 353: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 354: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 355: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 356: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 357: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 358: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 359: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 360: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 361: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 362: Train Loss: 0.000224, Validation Loss: 0.000167\n",
      " Epoch 363: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 364: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 365: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 366: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 367: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 368: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 369: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 370: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 371: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 372: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 373: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 374: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 375: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 376: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 377: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 378: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 379: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 380: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 381: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 382: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 383: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 384: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 385: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 386: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 387: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 388: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 389: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 390: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 391: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 392: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 393: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 394: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 395: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 396: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 397: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 398: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 399: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 400: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 401: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 402: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 403: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 404: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 405: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 406: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 407: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 408: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 409: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 410: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 411: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 412: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 413: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 414: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 415: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 416: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 417: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 418: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 419: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 420: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 421: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 422: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 423: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 424: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 425: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 426: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 427: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 428: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 429: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 430: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 431: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 432: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 433: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 434: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 435: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 436: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 437: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 438: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 439: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 440: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 441: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 442: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 443: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 444: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 445: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 446: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 447: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 448: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 449: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 450: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 451: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 452: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 453: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 454: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 455: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 456: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 457: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      " Epoch 458: Train Loss: 0.000223, Validation Loss: 0.000167\n",
      "Early stopping at epoch 458 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.018406, Validation Loss: 0.004389\n",
      " Epoch 2: Train Loss: 0.001417, Validation Loss: 0.001322\n",
      " Epoch 3: Train Loss: 0.001074, Validation Loss: 0.000965\n",
      " Epoch 4: Train Loss: 0.000880, Validation Loss: 0.000824\n",
      " Epoch 5: Train Loss: 0.000762, Validation Loss: 0.000691\n",
      " Epoch 6: Train Loss: 0.000695, Validation Loss: 0.000634\n",
      " Epoch 7: Train Loss: 0.000648, Validation Loss: 0.000565\n",
      " Epoch 8: Train Loss: 0.000599, Validation Loss: 0.000466\n",
      " Epoch 9: Train Loss: 0.000535, Validation Loss: 0.000441\n",
      " Epoch 10: Train Loss: 0.000505, Validation Loss: 0.000413\n",
      " Epoch 11: Train Loss: 0.000482, Validation Loss: 0.000394\n",
      " Epoch 12: Train Loss: 0.000464, Validation Loss: 0.000377\n",
      " Epoch 13: Train Loss: 0.000447, Validation Loss: 0.000372\n",
      " Epoch 14: Train Loss: 0.000432, Validation Loss: 0.000351\n",
      " Epoch 15: Train Loss: 0.000419, Validation Loss: 0.000343\n",
      " Epoch 16: Train Loss: 0.000408, Validation Loss: 0.000328\n",
      " Epoch 17: Train Loss: 0.000398, Validation Loss: 0.000321\n",
      " Epoch 18: Train Loss: 0.000388, Validation Loss: 0.000311\n",
      " Epoch 19: Train Loss: 0.000379, Validation Loss: 0.000297\n",
      " Epoch 20: Train Loss: 0.000371, Validation Loss: 0.000295\n",
      " Epoch 21: Train Loss: 0.000363, Validation Loss: 0.000287\n",
      " Epoch 22: Train Loss: 0.000357, Validation Loss: 0.000278\n",
      " Epoch 23: Train Loss: 0.000350, Validation Loss: 0.000278\n",
      " Epoch 24: Train Loss: 0.000344, Validation Loss: 0.000266\n",
      " Epoch 25: Train Loss: 0.000338, Validation Loss: 0.000256\n",
      " Epoch 26: Train Loss: 0.000332, Validation Loss: 0.000248\n",
      " Epoch 27: Train Loss: 0.000327, Validation Loss: 0.000244\n",
      " Epoch 28: Train Loss: 0.000322, Validation Loss: 0.000250\n",
      " Epoch 29: Train Loss: 0.000318, Validation Loss: 0.000238\n",
      " Epoch 30: Train Loss: 0.000312, Validation Loss: 0.000242\n",
      " Epoch 31: Train Loss: 0.000309, Validation Loss: 0.000234\n",
      " Epoch 32: Train Loss: 0.000307, Validation Loss: 0.000232\n",
      " Epoch 33: Train Loss: 0.000305, Validation Loss: 0.000225\n",
      " Epoch 34: Train Loss: 0.000302, Validation Loss: 0.000225\n",
      " Epoch 35: Train Loss: 0.000300, Validation Loss: 0.000222\n",
      " Epoch 36: Train Loss: 0.000298, Validation Loss: 0.000221\n",
      " Epoch 37: Train Loss: 0.000296, Validation Loss: 0.000218\n",
      " Epoch 38: Train Loss: 0.000294, Validation Loss: 0.000216\n",
      " Epoch 39: Train Loss: 0.000292, Validation Loss: 0.000213\n",
      " Epoch 40: Train Loss: 0.000290, Validation Loss: 0.000213\n",
      " Epoch 41: Train Loss: 0.000288, Validation Loss: 0.000209\n",
      " Epoch 42: Train Loss: 0.000287, Validation Loss: 0.000207\n",
      " Epoch 43: Train Loss: 0.000284, Validation Loss: 0.000209\n",
      " Epoch 44: Train Loss: 0.000282, Validation Loss: 0.000206\n",
      " Epoch 45: Train Loss: 0.000280, Validation Loss: 0.000205\n",
      " Epoch 46: Train Loss: 0.000279, Validation Loss: 0.000202\n",
      " Epoch 47: Train Loss: 0.000279, Validation Loss: 0.000201\n",
      " Epoch 48: Train Loss: 0.000275, Validation Loss: 0.000203\n",
      " Epoch 49: Train Loss: 0.000273, Validation Loss: 0.000199\n",
      " Epoch 50: Train Loss: 0.000271, Validation Loss: 0.000199\n",
      " Epoch 51: Train Loss: 0.000271, Validation Loss: 0.000200\n",
      " Epoch 52: Train Loss: 0.000268, Validation Loss: 0.000201\n",
      " Epoch 53: Train Loss: 0.000266, Validation Loss: 0.000195\n",
      " Epoch 54: Train Loss: 0.000264, Validation Loss: 0.000197\n",
      " Epoch 55: Train Loss: 0.000263, Validation Loss: 0.000194\n",
      " Epoch 56: Train Loss: 0.000261, Validation Loss: 0.000195\n",
      " Epoch 57: Train Loss: 0.000260, Validation Loss: 0.000195\n",
      " Epoch 58: Train Loss: 0.000258, Validation Loss: 0.000194\n",
      " Epoch 59: Train Loss: 0.000257, Validation Loss: 0.000193\n",
      " Epoch 60: Train Loss: 0.000255, Validation Loss: 0.000194\n",
      " Epoch 61: Train Loss: 0.000254, Validation Loss: 0.000192\n",
      " Epoch 62: Train Loss: 0.000253, Validation Loss: 0.000191\n",
      " Epoch 63: Train Loss: 0.000252, Validation Loss: 0.000190\n",
      " Epoch 64: Train Loss: 0.000252, Validation Loss: 0.000190\n",
      " Epoch 65: Train Loss: 0.000251, Validation Loss: 0.000188\n",
      " Epoch 66: Train Loss: 0.000250, Validation Loss: 0.000190\n",
      " Epoch 67: Train Loss: 0.000249, Validation Loss: 0.000190\n",
      " Epoch 68: Train Loss: 0.000249, Validation Loss: 0.000188\n",
      " Epoch 69: Train Loss: 0.000248, Validation Loss: 0.000191\n",
      " Epoch 70: Train Loss: 0.000247, Validation Loss: 0.000189\n",
      " Epoch 71: Train Loss: 0.000246, Validation Loss: 0.000189\n",
      " Epoch 72: Train Loss: 0.000246, Validation Loss: 0.000189\n",
      " Epoch 73: Train Loss: 0.000245, Validation Loss: 0.000189\n",
      " Epoch 74: Train Loss: 0.000244, Validation Loss: 0.000189\n",
      " Epoch 75: Train Loss: 0.000244, Validation Loss: 0.000187\n",
      " Epoch 76: Train Loss: 0.000243, Validation Loss: 0.000187\n",
      " Epoch 77: Train Loss: 0.000242, Validation Loss: 0.000188\n",
      " Epoch 78: Train Loss: 0.000241, Validation Loss: 0.000189\n",
      " Epoch 79: Train Loss: 0.000241, Validation Loss: 0.000190\n",
      " Epoch 80: Train Loss: 0.000240, Validation Loss: 0.000188\n",
      " Epoch 81: Train Loss: 0.000239, Validation Loss: 0.000188\n",
      " Epoch 82: Train Loss: 0.000238, Validation Loss: 0.000188\n",
      " Epoch 83: Train Loss: 0.000238, Validation Loss: 0.000189\n",
      " Epoch 84: Train Loss: 0.000237, Validation Loss: 0.000190\n",
      " Epoch 85: Train Loss: 0.000236, Validation Loss: 0.000187\n",
      " Epoch 86: Train Loss: 0.000236, Validation Loss: 0.000190\n",
      " Epoch 87: Train Loss: 0.000235, Validation Loss: 0.000188\n",
      " Epoch 88: Train Loss: 0.000234, Validation Loss: 0.000189\n",
      " Epoch 89: Train Loss: 0.000233, Validation Loss: 0.000188\n",
      " Epoch 90: Train Loss: 0.000233, Validation Loss: 0.000187\n",
      " Epoch 91: Train Loss: 0.000232, Validation Loss: 0.000187\n",
      " Epoch 92: Train Loss: 0.000232, Validation Loss: 0.000186\n",
      " Epoch 93: Train Loss: 0.000231, Validation Loss: 0.000185\n",
      " Epoch 94: Train Loss: 0.000231, Validation Loss: 0.000188\n",
      " Epoch 95: Train Loss: 0.000231, Validation Loss: 0.000189\n",
      " Epoch 96: Train Loss: 0.000230, Validation Loss: 0.000189\n",
      " Epoch 97: Train Loss: 0.000230, Validation Loss: 0.000188\n",
      " Epoch 98: Train Loss: 0.000229, Validation Loss: 0.000187\n",
      " Epoch 99: Train Loss: 0.000229, Validation Loss: 0.000185\n",
      " Epoch 100: Train Loss: 0.000229, Validation Loss: 0.000189\n",
      " Epoch 101: Train Loss: 0.000228, Validation Loss: 0.000190\n",
      " Epoch 102: Train Loss: 0.000228, Validation Loss: 0.000188\n",
      " Epoch 103: Train Loss: 0.000228, Validation Loss: 0.000188\n",
      " Epoch 104: Train Loss: 0.000227, Validation Loss: 0.000190\n",
      " Epoch 105: Train Loss: 0.000227, Validation Loss: 0.000187\n",
      " Epoch 106: Train Loss: 0.000226, Validation Loss: 0.000183\n",
      " Epoch 107: Train Loss: 0.000226, Validation Loss: 0.000187\n",
      " Epoch 108: Train Loss: 0.000226, Validation Loss: 0.000187\n",
      " Epoch 109: Train Loss: 0.000225, Validation Loss: 0.000187\n",
      " Epoch 110: Train Loss: 0.000225, Validation Loss: 0.000189\n",
      " Epoch 111: Train Loss: 0.000224, Validation Loss: 0.000189\n",
      " Epoch 112: Train Loss: 0.000224, Validation Loss: 0.000187\n",
      " Epoch 113: Train Loss: 0.000224, Validation Loss: 0.000187\n",
      " Epoch 114: Train Loss: 0.000223, Validation Loss: 0.000190\n",
      " Epoch 115: Train Loss: 0.000223, Validation Loss: 0.000184\n",
      " Epoch 116: Train Loss: 0.000222, Validation Loss: 0.000188\n",
      " Epoch 117: Train Loss: 0.000222, Validation Loss: 0.000185\n",
      " Epoch 118: Train Loss: 0.000221, Validation Loss: 0.000187\n",
      " Epoch 119: Train Loss: 0.000221, Validation Loss: 0.000190\n",
      " Epoch 120: Train Loss: 0.000221, Validation Loss: 0.000189\n",
      " Epoch 121: Train Loss: 0.000220, Validation Loss: 0.000189\n",
      " Epoch 122: Train Loss: 0.000220, Validation Loss: 0.000189\n",
      " Epoch 123: Train Loss: 0.000220, Validation Loss: 0.000189\n",
      " Epoch 124: Train Loss: 0.000219, Validation Loss: 0.000188\n",
      " Epoch 125: Train Loss: 0.000219, Validation Loss: 0.000191\n",
      " Epoch 126: Train Loss: 0.000219, Validation Loss: 0.000187\n",
      "Early stopping at epoch 126 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014310, Validation Loss: 0.004805\n",
      " Epoch 2: Train Loss: 0.001483, Validation Loss: 0.001277\n",
      " Epoch 3: Train Loss: 0.001149, Validation Loss: 0.001009\n",
      " Epoch 4: Train Loss: 0.000975, Validation Loss: 0.000858\n",
      " Epoch 5: Train Loss: 0.000853, Validation Loss: 0.000756\n",
      " Epoch 6: Train Loss: 0.000774, Validation Loss: 0.000648\n",
      " Epoch 7: Train Loss: 0.000702, Validation Loss: 0.000602\n",
      " Epoch 8: Train Loss: 0.000650, Validation Loss: 0.000547\n",
      " Epoch 9: Train Loss: 0.000614, Validation Loss: 0.000506\n",
      " Epoch 10: Train Loss: 0.000580, Validation Loss: 0.000435\n",
      " Epoch 11: Train Loss: 0.000516, Validation Loss: 0.000393\n",
      " Epoch 12: Train Loss: 0.000485, Validation Loss: 0.000364\n",
      " Epoch 13: Train Loss: 0.000463, Validation Loss: 0.000345\n",
      " Epoch 14: Train Loss: 0.000445, Validation Loss: 0.000328\n",
      " Epoch 15: Train Loss: 0.000429, Validation Loss: 0.000313\n",
      " Epoch 16: Train Loss: 0.000415, Validation Loss: 0.000303\n",
      " Epoch 17: Train Loss: 0.000402, Validation Loss: 0.000293\n",
      " Epoch 18: Train Loss: 0.000391, Validation Loss: 0.000284\n",
      " Epoch 19: Train Loss: 0.000380, Validation Loss: 0.000272\n",
      " Epoch 20: Train Loss: 0.000370, Validation Loss: 0.000263\n",
      " Epoch 21: Train Loss: 0.000361, Validation Loss: 0.000259\n",
      " Epoch 22: Train Loss: 0.000352, Validation Loss: 0.000251\n",
      " Epoch 23: Train Loss: 0.000345, Validation Loss: 0.000245\n",
      " Epoch 24: Train Loss: 0.000338, Validation Loss: 0.000240\n",
      " Epoch 25: Train Loss: 0.000331, Validation Loss: 0.000236\n",
      " Epoch 26: Train Loss: 0.000325, Validation Loss: 0.000232\n",
      " Epoch 27: Train Loss: 0.000319, Validation Loss: 0.000228\n",
      " Epoch 28: Train Loss: 0.000314, Validation Loss: 0.000228\n",
      " Epoch 29: Train Loss: 0.000308, Validation Loss: 0.000222\n",
      " Epoch 30: Train Loss: 0.000304, Validation Loss: 0.000220\n",
      " Epoch 31: Train Loss: 0.000300, Validation Loss: 0.000220\n",
      " Epoch 32: Train Loss: 0.000298, Validation Loss: 0.000217\n",
      " Epoch 33: Train Loss: 0.000296, Validation Loss: 0.000218\n",
      " Epoch 34: Train Loss: 0.000294, Validation Loss: 0.000215\n",
      " Epoch 35: Train Loss: 0.000292, Validation Loss: 0.000216\n",
      " Epoch 36: Train Loss: 0.000290, Validation Loss: 0.000215\n",
      " Epoch 37: Train Loss: 0.000288, Validation Loss: 0.000213\n",
      " Epoch 38: Train Loss: 0.000286, Validation Loss: 0.000213\n",
      " Epoch 39: Train Loss: 0.000284, Validation Loss: 0.000212\n",
      " Epoch 40: Train Loss: 0.000282, Validation Loss: 0.000210\n",
      " Epoch 41: Train Loss: 0.000280, Validation Loss: 0.000211\n",
      " Epoch 42: Train Loss: 0.000278, Validation Loss: 0.000210\n",
      " Epoch 43: Train Loss: 0.000276, Validation Loss: 0.000211\n",
      " Epoch 44: Train Loss: 0.000274, Validation Loss: 0.000210\n",
      " Epoch 45: Train Loss: 0.000273, Validation Loss: 0.000213\n",
      " Epoch 46: Train Loss: 0.000271, Validation Loss: 0.000207\n",
      " Epoch 47: Train Loss: 0.000269, Validation Loss: 0.000207\n",
      " Epoch 48: Train Loss: 0.000267, Validation Loss: 0.000207\n",
      " Epoch 49: Train Loss: 0.000266, Validation Loss: 0.000208\n",
      " Epoch 50: Train Loss: 0.000264, Validation Loss: 0.000203\n",
      " Epoch 51: Train Loss: 0.000262, Validation Loss: 0.000207\n",
      " Epoch 52: Train Loss: 0.000261, Validation Loss: 0.000208\n",
      " Epoch 53: Train Loss: 0.000259, Validation Loss: 0.000206\n",
      " Epoch 54: Train Loss: 0.000258, Validation Loss: 0.000202\n",
      " Epoch 55: Train Loss: 0.000257, Validation Loss: 0.000212\n",
      " Epoch 56: Train Loss: 0.000255, Validation Loss: 0.000203\n",
      " Epoch 57: Train Loss: 0.000253, Validation Loss: 0.000203\n",
      " Epoch 58: Train Loss: 0.000252, Validation Loss: 0.000210\n",
      " Epoch 59: Train Loss: 0.000250, Validation Loss: 0.000206\n",
      " Epoch 60: Train Loss: 0.000249, Validation Loss: 0.000204\n",
      " Epoch 61: Train Loss: 0.000248, Validation Loss: 0.000204\n",
      " Epoch 62: Train Loss: 0.000247, Validation Loss: 0.000205\n",
      " Epoch 63: Train Loss: 0.000246, Validation Loss: 0.000201\n",
      " Epoch 64: Train Loss: 0.000246, Validation Loss: 0.000198\n",
      " Epoch 65: Train Loss: 0.000245, Validation Loss: 0.000199\n",
      " Epoch 66: Train Loss: 0.000244, Validation Loss: 0.000204\n",
      " Epoch 67: Train Loss: 0.000244, Validation Loss: 0.000201\n",
      " Epoch 68: Train Loss: 0.000243, Validation Loss: 0.000205\n",
      " Epoch 69: Train Loss: 0.000242, Validation Loss: 0.000203\n",
      " Epoch 70: Train Loss: 0.000241, Validation Loss: 0.000201\n",
      " Epoch 71: Train Loss: 0.000241, Validation Loss: 0.000201\n",
      " Epoch 72: Train Loss: 0.000240, Validation Loss: 0.000201\n",
      " Epoch 73: Train Loss: 0.000239, Validation Loss: 0.000203\n",
      " Epoch 74: Train Loss: 0.000239, Validation Loss: 0.000203\n",
      " Epoch 75: Train Loss: 0.000238, Validation Loss: 0.000199\n",
      " Epoch 76: Train Loss: 0.000238, Validation Loss: 0.000201\n",
      " Epoch 77: Train Loss: 0.000237, Validation Loss: 0.000200\n",
      " Epoch 78: Train Loss: 0.000236, Validation Loss: 0.000199\n",
      " Epoch 79: Train Loss: 0.000235, Validation Loss: 0.000202\n",
      " Epoch 80: Train Loss: 0.000235, Validation Loss: 0.000201\n",
      " Epoch 81: Train Loss: 0.000234, Validation Loss: 0.000198\n",
      " Epoch 82: Train Loss: 0.000233, Validation Loss: 0.000198\n",
      " Epoch 83: Train Loss: 0.000232, Validation Loss: 0.000200\n",
      " Epoch 84: Train Loss: 0.000232, Validation Loss: 0.000205\n",
      "Early stopping at epoch 84 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.020262, Validation Loss: 0.005626\n",
      " Epoch 2: Train Loss: 0.001379, Validation Loss: 0.001112\n",
      " Epoch 3: Train Loss: 0.001037, Validation Loss: 0.000949\n",
      " Epoch 4: Train Loss: 0.000869, Validation Loss: 0.000785\n",
      " Epoch 5: Train Loss: 0.000775, Validation Loss: 0.000675\n",
      " Epoch 6: Train Loss: 0.000713, Validation Loss: 0.000620\n",
      " Epoch 7: Train Loss: 0.000669, Validation Loss: 0.000585\n",
      " Epoch 8: Train Loss: 0.000634, Validation Loss: 0.000553\n",
      " Epoch 9: Train Loss: 0.000603, Validation Loss: 0.000525\n",
      " Epoch 10: Train Loss: 0.000562, Validation Loss: 0.000465\n",
      " Epoch 11: Train Loss: 0.000512, Validation Loss: 0.000408\n",
      " Epoch 12: Train Loss: 0.000486, Validation Loss: 0.000385\n",
      " Epoch 13: Train Loss: 0.000467, Validation Loss: 0.000377\n",
      " Epoch 14: Train Loss: 0.000450, Validation Loss: 0.000364\n",
      " Epoch 15: Train Loss: 0.000435, Validation Loss: 0.000355\n",
      " Epoch 16: Train Loss: 0.000420, Validation Loss: 0.000343\n",
      " Epoch 17: Train Loss: 0.000408, Validation Loss: 0.000333\n",
      " Epoch 18: Train Loss: 0.000395, Validation Loss: 0.000321\n",
      " Epoch 19: Train Loss: 0.000385, Validation Loss: 0.000310\n",
      " Epoch 20: Train Loss: 0.000375, Validation Loss: 0.000305\n",
      " Epoch 21: Train Loss: 0.000366, Validation Loss: 0.000303\n",
      " Epoch 22: Train Loss: 0.000357, Validation Loss: 0.000285\n",
      " Epoch 23: Train Loss: 0.000350, Validation Loss: 0.000286\n",
      " Epoch 24: Train Loss: 0.000343, Validation Loss: 0.000283\n",
      " Epoch 25: Train Loss: 0.000337, Validation Loss: 0.000261\n",
      " Epoch 26: Train Loss: 0.000330, Validation Loss: 0.000256\n",
      " Epoch 27: Train Loss: 0.000324, Validation Loss: 0.000250\n",
      " Epoch 28: Train Loss: 0.000319, Validation Loss: 0.000247\n",
      " Epoch 29: Train Loss: 0.000314, Validation Loss: 0.000241\n",
      " Epoch 30: Train Loss: 0.000310, Validation Loss: 0.000240\n",
      " Epoch 31: Train Loss: 0.000306, Validation Loss: 0.000229\n",
      " Epoch 32: Train Loss: 0.000304, Validation Loss: 0.000225\n",
      " Epoch 33: Train Loss: 0.000301, Validation Loss: 0.000226\n",
      " Epoch 34: Train Loss: 0.000300, Validation Loss: 0.000225\n",
      " Epoch 35: Train Loss: 0.000297, Validation Loss: 0.000218\n",
      " Epoch 36: Train Loss: 0.000295, Validation Loss: 0.000217\n",
      " Epoch 37: Train Loss: 0.000293, Validation Loss: 0.000215\n",
      " Epoch 38: Train Loss: 0.000291, Validation Loss: 0.000215\n",
      " Epoch 39: Train Loss: 0.000289, Validation Loss: 0.000212\n",
      " Epoch 40: Train Loss: 0.000287, Validation Loss: 0.000209\n",
      " Epoch 41: Train Loss: 0.000286, Validation Loss: 0.000211\n",
      " Epoch 42: Train Loss: 0.000284, Validation Loss: 0.000206\n",
      " Epoch 43: Train Loss: 0.000282, Validation Loss: 0.000206\n",
      " Epoch 44: Train Loss: 0.000280, Validation Loss: 0.000203\n",
      " Epoch 45: Train Loss: 0.000278, Validation Loss: 0.000208\n",
      " Epoch 46: Train Loss: 0.000277, Validation Loss: 0.000202\n",
      " Epoch 47: Train Loss: 0.000275, Validation Loss: 0.000199\n",
      " Epoch 48: Train Loss: 0.000274, Validation Loss: 0.000200\n",
      " Epoch 49: Train Loss: 0.000272, Validation Loss: 0.000200\n",
      " Epoch 50: Train Loss: 0.000270, Validation Loss: 0.000198\n",
      " Epoch 51: Train Loss: 0.000268, Validation Loss: 0.000194\n",
      " Epoch 52: Train Loss: 0.000266, Validation Loss: 0.000195\n",
      " Epoch 53: Train Loss: 0.000265, Validation Loss: 0.000193\n",
      " Epoch 54: Train Loss: 0.000263, Validation Loss: 0.000195\n",
      " Epoch 55: Train Loss: 0.000262, Validation Loss: 0.000191\n",
      " Epoch 56: Train Loss: 0.000260, Validation Loss: 0.000192\n",
      " Epoch 57: Train Loss: 0.000259, Validation Loss: 0.000194\n",
      " Epoch 58: Train Loss: 0.000257, Validation Loss: 0.000191\n",
      " Epoch 59: Train Loss: 0.000256, Validation Loss: 0.000192\n",
      " Epoch 60: Train Loss: 0.000254, Validation Loss: 0.000188\n",
      " Epoch 61: Train Loss: 0.000253, Validation Loss: 0.000189\n",
      " Epoch 62: Train Loss: 0.000252, Validation Loss: 0.000187\n",
      " Epoch 63: Train Loss: 0.000251, Validation Loss: 0.000186\n",
      " Epoch 64: Train Loss: 0.000251, Validation Loss: 0.000186\n",
      " Epoch 65: Train Loss: 0.000250, Validation Loss: 0.000185\n",
      " Epoch 66: Train Loss: 0.000249, Validation Loss: 0.000185\n",
      " Epoch 67: Train Loss: 0.000248, Validation Loss: 0.000185\n",
      " Epoch 68: Train Loss: 0.000248, Validation Loss: 0.000185\n",
      " Epoch 69: Train Loss: 0.000247, Validation Loss: 0.000183\n",
      " Epoch 70: Train Loss: 0.000246, Validation Loss: 0.000183\n",
      " Epoch 71: Train Loss: 0.000245, Validation Loss: 0.000185\n",
      " Epoch 72: Train Loss: 0.000245, Validation Loss: 0.000183\n",
      " Epoch 73: Train Loss: 0.000244, Validation Loss: 0.000183\n",
      " Epoch 74: Train Loss: 0.000243, Validation Loss: 0.000183\n",
      " Epoch 75: Train Loss: 0.000242, Validation Loss: 0.000184\n",
      " Epoch 76: Train Loss: 0.000241, Validation Loss: 0.000182\n",
      " Epoch 77: Train Loss: 0.000241, Validation Loss: 0.000181\n",
      " Epoch 78: Train Loss: 0.000240, Validation Loss: 0.000182\n",
      " Epoch 79: Train Loss: 0.000239, Validation Loss: 0.000182\n",
      " Epoch 80: Train Loss: 0.000238, Validation Loss: 0.000180\n",
      " Epoch 81: Train Loss: 0.000238, Validation Loss: 0.000181\n",
      " Epoch 82: Train Loss: 0.000237, Validation Loss: 0.000181\n",
      " Epoch 83: Train Loss: 0.000236, Validation Loss: 0.000179\n",
      " Epoch 84: Train Loss: 0.000236, Validation Loss: 0.000181\n",
      " Epoch 85: Train Loss: 0.000235, Validation Loss: 0.000182\n",
      " Epoch 86: Train Loss: 0.000234, Validation Loss: 0.000180\n",
      " Epoch 87: Train Loss: 0.000233, Validation Loss: 0.000178\n",
      " Epoch 88: Train Loss: 0.000233, Validation Loss: 0.000182\n",
      " Epoch 89: Train Loss: 0.000232, Validation Loss: 0.000179\n",
      " Epoch 90: Train Loss: 0.000231, Validation Loss: 0.000179\n",
      " Epoch 91: Train Loss: 0.000230, Validation Loss: 0.000179\n",
      " Epoch 92: Train Loss: 0.000230, Validation Loss: 0.000178\n",
      " Epoch 93: Train Loss: 0.000229, Validation Loss: 0.000178\n",
      " Epoch 94: Train Loss: 0.000229, Validation Loss: 0.000178\n",
      " Epoch 95: Train Loss: 0.000229, Validation Loss: 0.000179\n",
      " Epoch 96: Train Loss: 0.000228, Validation Loss: 0.000179\n",
      " Epoch 97: Train Loss: 0.000228, Validation Loss: 0.000177\n",
      " Epoch 98: Train Loss: 0.000227, Validation Loss: 0.000179\n",
      " Epoch 99: Train Loss: 0.000227, Validation Loss: 0.000180\n",
      " Epoch 100: Train Loss: 0.000227, Validation Loss: 0.000180\n",
      " Epoch 101: Train Loss: 0.000226, Validation Loss: 0.000180\n",
      " Epoch 102: Train Loss: 0.000226, Validation Loss: 0.000178\n",
      " Epoch 103: Train Loss: 0.000225, Validation Loss: 0.000177\n",
      " Epoch 104: Train Loss: 0.000225, Validation Loss: 0.000177\n",
      " Epoch 105: Train Loss: 0.000225, Validation Loss: 0.000178\n",
      " Epoch 106: Train Loss: 0.000224, Validation Loss: 0.000175\n",
      " Epoch 107: Train Loss: 0.000224, Validation Loss: 0.000179\n",
      " Epoch 108: Train Loss: 0.000223, Validation Loss: 0.000177\n",
      " Epoch 109: Train Loss: 0.000223, Validation Loss: 0.000180\n",
      " Epoch 110: Train Loss: 0.000222, Validation Loss: 0.000178\n",
      " Epoch 111: Train Loss: 0.000222, Validation Loss: 0.000182\n",
      " Epoch 112: Train Loss: 0.000221, Validation Loss: 0.000177\n",
      " Epoch 113: Train Loss: 0.000221, Validation Loss: 0.000180\n",
      " Epoch 114: Train Loss: 0.000221, Validation Loss: 0.000175\n",
      " Epoch 115: Train Loss: 0.000220, Validation Loss: 0.000175\n",
      " Epoch 116: Train Loss: 0.000220, Validation Loss: 0.000174\n",
      " Epoch 117: Train Loss: 0.000219, Validation Loss: 0.000179\n",
      " Epoch 118: Train Loss: 0.000219, Validation Loss: 0.000178\n",
      " Epoch 119: Train Loss: 0.000218, Validation Loss: 0.000176\n",
      " Epoch 120: Train Loss: 0.000218, Validation Loss: 0.000178\n",
      " Epoch 121: Train Loss: 0.000217, Validation Loss: 0.000177\n",
      " Epoch 122: Train Loss: 0.000217, Validation Loss: 0.000178\n",
      " Epoch 123: Train Loss: 0.000217, Validation Loss: 0.000179\n",
      " Epoch 124: Train Loss: 0.000217, Validation Loss: 0.000176\n",
      " Epoch 125: Train Loss: 0.000216, Validation Loss: 0.000177\n",
      " Epoch 126: Train Loss: 0.000216, Validation Loss: 0.000178\n",
      " Epoch 127: Train Loss: 0.000216, Validation Loss: 0.000179\n",
      " Epoch 128: Train Loss: 0.000216, Validation Loss: 0.000178\n",
      " Epoch 129: Train Loss: 0.000215, Validation Loss: 0.000177\n",
      " Epoch 130: Train Loss: 0.000215, Validation Loss: 0.000178\n",
      " Epoch 131: Train Loss: 0.000215, Validation Loss: 0.000179\n",
      " Epoch 132: Train Loss: 0.000215, Validation Loss: 0.000178\n",
      " Epoch 133: Train Loss: 0.000215, Validation Loss: 0.000176\n",
      " Epoch 134: Train Loss: 0.000214, Validation Loss: 0.000177\n",
      " Epoch 135: Train Loss: 0.000214, Validation Loss: 0.000177\n",
      " Epoch 136: Train Loss: 0.000214, Validation Loss: 0.000178\n",
      "Early stopping at epoch 136 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.00013808306539431214\n",
      "Training Time: 4113.395924329758\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.00012402543507050723\n",
      "Training Time: 14304.69074678421\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.00012373959179967642\n",
      "Training Time: 4167.102204799652\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.00012854694796260446\n",
      "Training Time: 5043.8554084300995\n",
      "--------------------------------------------------\n",
      "Model: UNet\n",
      "Validation Loss: 0.00015558619634248316\n",
      "Training Time: 4261.321540594101\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock\n",
      "Validation Loss: 0.00014965674199629575\n",
      "Training Time: 3066.611936569214\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention\n",
      "Validation Loss: 0.00016690371558070183\n",
      "Training Time: 5166.90777015686\n",
      "--------------------------------------------------\n",
      "Model: UNet3D\n",
      "Validation Loss: 0.00018337529036216438\n",
      "Training Time: 1420.0879011154175\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSEBlock3D\n",
      "Validation Loss: 0.00019768462516367435\n",
      "Training Time: 950.1964874267578\n",
      "--------------------------------------------------\n",
      "Model: UNetwithSelfattention3D\n",
      "Validation Loss: 0.00017394380120094866\n",
      "Training Time: 1605.599925994873\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    'UNet': UNet,\n",
    "    'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    'UNet3D': UNet3D,\n",
    "    'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/Old_MSE_2/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9120d6b0-b359-4c30-8fef-900a09790121",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.082360, Validation Loss: 0.099331\n",
      " Epoch 2: Train Loss: 0.016473, Validation Loss: 0.011551\n",
      " Epoch 3: Train Loss: 0.008303, Validation Loss: 0.007640\n",
      " Epoch 4: Train Loss: 0.006425, Validation Loss: 0.005983\n",
      " Epoch 5: Train Loss: 0.005379, Validation Loss: 0.005169\n",
      " Epoch 6: Train Loss: 0.004763, Validation Loss: 0.004586\n",
      " Epoch 7: Train Loss: 0.004388, Validation Loss: 0.004219\n",
      " Epoch 8: Train Loss: 0.004070, Validation Loss: 0.003970\n",
      " Epoch 9: Train Loss: 0.003853, Validation Loss: 0.003781\n",
      " Epoch 10: Train Loss: 0.003739, Validation Loss: 0.003636\n",
      " Epoch 11: Train Loss: 0.003505, Validation Loss: 0.003561\n",
      " Epoch 12: Train Loss: 0.003428, Validation Loss: 0.004237\n",
      " Epoch 13: Train Loss: 0.003297, Validation Loss: 0.003329\n",
      " Epoch 14: Train Loss: 0.003128, Validation Loss: 0.003283\n",
      " Epoch 15: Train Loss: 0.003031, Validation Loss: 0.003060\n",
      " Epoch 16: Train Loss: 0.002947, Validation Loss: 0.002930\n",
      " Epoch 17: Train Loss: 0.002851, Validation Loss: 0.002949\n",
      " Epoch 18: Train Loss: 0.002773, Validation Loss: 0.002819\n",
      " Epoch 19: Train Loss: 0.002696, Validation Loss: 0.002720\n",
      " Epoch 20: Train Loss: 0.002621, Validation Loss: 0.002672\n",
      " Epoch 21: Train Loss: 0.002565, Validation Loss: 0.002565\n",
      " Epoch 22: Train Loss: 0.002500, Validation Loss: 0.002510\n",
      " Epoch 23: Train Loss: 0.002486, Validation Loss: 0.002490\n",
      " Epoch 24: Train Loss: 0.002365, Validation Loss: 0.002410\n",
      " Epoch 25: Train Loss: 0.002424, Validation Loss: 0.002374\n",
      " Epoch 26: Train Loss: 0.002274, Validation Loss: 0.002325\n",
      " Epoch 27: Train Loss: 0.002290, Validation Loss: 0.002365\n",
      " Epoch 28: Train Loss: 0.002181, Validation Loss: 0.002230\n",
      " Epoch 29: Train Loss: 0.002163, Validation Loss: 0.002437\n",
      " Epoch 30: Train Loss: 0.002119, Validation Loss: 0.002244\n",
      " Epoch 31: Train Loss: 0.002024, Validation Loss: 0.002087\n",
      " Epoch 32: Train Loss: 0.001992, Validation Loss: 0.002067\n",
      " Epoch 33: Train Loss: 0.001973, Validation Loss: 0.002055\n",
      " Epoch 34: Train Loss: 0.001947, Validation Loss: 0.002026\n",
      " Epoch 35: Train Loss: 0.001927, Validation Loss: 0.002009\n",
      " Epoch 36: Train Loss: 0.001907, Validation Loss: 0.001987\n",
      " Epoch 37: Train Loss: 0.001888, Validation Loss: 0.001970\n",
      " Epoch 38: Train Loss: 0.001876, Validation Loss: 0.001966\n",
      " Epoch 39: Train Loss: 0.001852, Validation Loss: 0.001950\n",
      " Epoch 40: Train Loss: 0.001837, Validation Loss: 0.001958\n",
      " Epoch 41: Train Loss: 0.001815, Validation Loss: 0.001910\n",
      " Epoch 42: Train Loss: 0.001798, Validation Loss: 0.001883\n",
      " Epoch 43: Train Loss: 0.001778, Validation Loss: 0.001917\n",
      " Epoch 44: Train Loss: 0.001765, Validation Loss: 0.001852\n",
      " Epoch 45: Train Loss: 0.001752, Validation Loss: 0.001831\n",
      " Epoch 46: Train Loss: 0.001732, Validation Loss: 0.001814\n",
      " Epoch 47: Train Loss: 0.001710, Validation Loss: 0.001813\n",
      " Epoch 48: Train Loss: 0.001712, Validation Loss: 0.001815\n",
      " Epoch 49: Train Loss: 0.001676, Validation Loss: 0.001789\n",
      " Epoch 50: Train Loss: 0.001655, Validation Loss: 0.001775\n",
      " Epoch 51: Train Loss: 0.001652, Validation Loss: 0.001770\n",
      " Epoch 52: Train Loss: 0.001640, Validation Loss: 0.001734\n",
      " Epoch 53: Train Loss: 0.001617, Validation Loss: 0.001720\n",
      " Epoch 54: Train Loss: 0.001614, Validation Loss: 0.001743\n",
      " Epoch 55: Train Loss: 0.001583, Validation Loss: 0.001717\n",
      " Epoch 56: Train Loss: 0.001571, Validation Loss: 0.001677\n",
      " Epoch 57: Train Loss: 0.001565, Validation Loss: 0.001687\n",
      " Epoch 58: Train Loss: 0.001563, Validation Loss: 0.001656\n",
      " Epoch 59: Train Loss: 0.001549, Validation Loss: 0.001634\n",
      " Epoch 60: Train Loss: 0.001519, Validation Loss: 0.001650\n",
      " Epoch 61: Train Loss: 0.001482, Validation Loss: 0.001610\n",
      " Epoch 62: Train Loss: 0.001471, Validation Loss: 0.001602\n",
      " Epoch 63: Train Loss: 0.001461, Validation Loss: 0.001596\n",
      " Epoch 64: Train Loss: 0.001454, Validation Loss: 0.001586\n",
      " Epoch 65: Train Loss: 0.001447, Validation Loss: 0.001576\n",
      " Epoch 66: Train Loss: 0.001442, Validation Loss: 0.001584\n",
      " Epoch 67: Train Loss: 0.001437, Validation Loss: 0.001574\n",
      " Epoch 68: Train Loss: 0.001429, Validation Loss: 0.001560\n",
      " Epoch 69: Train Loss: 0.001423, Validation Loss: 0.001559\n",
      " Epoch 70: Train Loss: 0.001416, Validation Loss: 0.001548\n",
      " Epoch 71: Train Loss: 0.001410, Validation Loss: 0.001550\n",
      " Epoch 72: Train Loss: 0.001407, Validation Loss: 0.001540\n",
      " Epoch 73: Train Loss: 0.001398, Validation Loss: 0.001538\n",
      " Epoch 74: Train Loss: 0.001391, Validation Loss: 0.001539\n",
      " Epoch 75: Train Loss: 0.001386, Validation Loss: 0.001538\n",
      " Epoch 76: Train Loss: 0.001384, Validation Loss: 0.001520\n",
      " Epoch 77: Train Loss: 0.001379, Validation Loss: 0.001542\n",
      " Epoch 78: Train Loss: 0.001380, Validation Loss: 0.001513\n",
      " Epoch 79: Train Loss: 0.001363, Validation Loss: 0.001517\n",
      " Epoch 80: Train Loss: 0.001362, Validation Loss: 0.001543\n",
      " Epoch 81: Train Loss: 0.001355, Validation Loss: 0.001523\n",
      " Epoch 82: Train Loss: 0.001351, Validation Loss: 0.001525\n",
      " Epoch 83: Train Loss: 0.001342, Validation Loss: 0.001503\n",
      " Epoch 84: Train Loss: 0.001338, Validation Loss: 0.001497\n",
      " Epoch 85: Train Loss: 0.001337, Validation Loss: 0.001487\n",
      " Epoch 86: Train Loss: 0.001321, Validation Loss: 0.001487\n",
      " Epoch 87: Train Loss: 0.001331, Validation Loss: 0.001486\n",
      " Epoch 88: Train Loss: 0.001333, Validation Loss: 0.001474\n",
      " Epoch 89: Train Loss: 0.001308, Validation Loss: 0.001489\n",
      " Epoch 90: Train Loss: 0.001304, Validation Loss: 0.001495\n",
      " Epoch 91: Train Loss: 0.001286, Validation Loss: 0.001456\n",
      " Epoch 92: Train Loss: 0.001282, Validation Loss: 0.001453\n",
      " Epoch 93: Train Loss: 0.001276, Validation Loss: 0.001455\n",
      " Epoch 94: Train Loss: 0.001274, Validation Loss: 0.001449\n",
      " Epoch 95: Train Loss: 0.001271, Validation Loss: 0.001448\n",
      " Epoch 96: Train Loss: 0.001268, Validation Loss: 0.001449\n",
      " Epoch 97: Train Loss: 0.001264, Validation Loss: 0.001451\n",
      " Epoch 98: Train Loss: 0.001264, Validation Loss: 0.001447\n",
      " Epoch 99: Train Loss: 0.001259, Validation Loss: 0.001447\n",
      " Epoch 100: Train Loss: 0.001255, Validation Loss: 0.001443\n",
      " Epoch 101: Train Loss: 0.001254, Validation Loss: 0.001443\n",
      " Epoch 102: Train Loss: 0.001250, Validation Loss: 0.001439\n",
      " Epoch 103: Train Loss: 0.001248, Validation Loss: 0.001441\n",
      " Epoch 104: Train Loss: 0.001249, Validation Loss: 0.001450\n",
      " Epoch 105: Train Loss: 0.001241, Validation Loss: 0.001442\n",
      " Epoch 106: Train Loss: 0.001238, Validation Loss: 0.001431\n",
      " Epoch 107: Train Loss: 0.001235, Validation Loss: 0.001430\n",
      " Epoch 108: Train Loss: 0.001235, Validation Loss: 0.001440\n",
      " Epoch 109: Train Loss: 0.001231, Validation Loss: 0.001433\n",
      " Epoch 110: Train Loss: 0.001228, Validation Loss: 0.001431\n",
      " Epoch 111: Train Loss: 0.001226, Validation Loss: 0.001431\n",
      " Epoch 112: Train Loss: 0.001219, Validation Loss: 0.001419\n",
      " Epoch 113: Train Loss: 0.001218, Validation Loss: 0.001430\n",
      " Epoch 114: Train Loss: 0.001214, Validation Loss: 0.001431\n",
      " Epoch 115: Train Loss: 0.001211, Validation Loss: 0.001416\n",
      " Epoch 116: Train Loss: 0.001207, Validation Loss: 0.001426\n",
      " Epoch 117: Train Loss: 0.001202, Validation Loss: 0.001415\n",
      " Epoch 118: Train Loss: 0.001202, Validation Loss: 0.001436\n",
      " Epoch 119: Train Loss: 0.001200, Validation Loss: 0.001418\n",
      " Epoch 120: Train Loss: 0.001196, Validation Loss: 0.001413\n",
      " Epoch 121: Train Loss: 0.001182, Validation Loss: 0.001406\n",
      " Epoch 122: Train Loss: 0.001179, Validation Loss: 0.001407\n",
      " Epoch 123: Train Loss: 0.001177, Validation Loss: 0.001403\n",
      " Epoch 124: Train Loss: 0.001175, Validation Loss: 0.001403\n",
      " Epoch 125: Train Loss: 0.001174, Validation Loss: 0.001403\n",
      " Epoch 126: Train Loss: 0.001171, Validation Loss: 0.001402\n",
      " Epoch 127: Train Loss: 0.001170, Validation Loss: 0.001406\n",
      " Epoch 128: Train Loss: 0.001168, Validation Loss: 0.001405\n",
      " Epoch 129: Train Loss: 0.001167, Validation Loss: 0.001400\n",
      " Epoch 130: Train Loss: 0.001165, Validation Loss: 0.001405\n",
      " Epoch 131: Train Loss: 0.001164, Validation Loss: 0.001402\n",
      " Epoch 132: Train Loss: 0.001164, Validation Loss: 0.001401\n",
      " Epoch 133: Train Loss: 0.001159, Validation Loss: 0.001401\n",
      " Epoch 134: Train Loss: 0.001159, Validation Loss: 0.001414\n",
      " Epoch 135: Train Loss: 0.001157, Validation Loss: 0.001405\n",
      " Epoch 136: Train Loss: 0.001153, Validation Loss: 0.001404\n",
      " Epoch 137: Train Loss: 0.001152, Validation Loss: 0.001399\n",
      " Epoch 138: Train Loss: 0.001149, Validation Loss: 0.001400\n",
      " Epoch 139: Train Loss: 0.001149, Validation Loss: 0.001397\n",
      " Epoch 140: Train Loss: 0.001147, Validation Loss: 0.001399\n",
      " Epoch 141: Train Loss: 0.001144, Validation Loss: 0.001395\n",
      " Epoch 142: Train Loss: 0.001143, Validation Loss: 0.001400\n",
      " Epoch 143: Train Loss: 0.001140, Validation Loss: 0.001394\n",
      " Epoch 144: Train Loss: 0.001138, Validation Loss: 0.001398\n",
      " Epoch 145: Train Loss: 0.001137, Validation Loss: 0.001392\n",
      " Epoch 146: Train Loss: 0.001134, Validation Loss: 0.001397\n",
      " Epoch 147: Train Loss: 0.001132, Validation Loss: 0.001390\n",
      " Epoch 148: Train Loss: 0.001130, Validation Loss: 0.001393\n",
      " Epoch 149: Train Loss: 0.001131, Validation Loss: 0.001391\n",
      " Epoch 150: Train Loss: 0.001126, Validation Loss: 0.001391\n",
      " Epoch 151: Train Loss: 0.001117, Validation Loss: 0.001388\n",
      " Epoch 152: Train Loss: 0.001116, Validation Loss: 0.001391\n",
      " Epoch 153: Train Loss: 0.001115, Validation Loss: 0.001388\n",
      " Epoch 154: Train Loss: 0.001116, Validation Loss: 0.001390\n",
      " Epoch 155: Train Loss: 0.001113, Validation Loss: 0.001391\n",
      " Epoch 156: Train Loss: 0.001112, Validation Loss: 0.001391\n",
      " Epoch 157: Train Loss: 0.001110, Validation Loss: 0.001388\n",
      " Epoch 158: Train Loss: 0.001109, Validation Loss: 0.001391\n",
      " Epoch 159: Train Loss: 0.001109, Validation Loss: 0.001391\n",
      " Epoch 160: Train Loss: 0.001108, Validation Loss: 0.001388\n",
      " Epoch 161: Train Loss: 0.001106, Validation Loss: 0.001388\n",
      " Epoch 162: Train Loss: 0.001106, Validation Loss: 0.001388\n",
      " Epoch 163: Train Loss: 0.001103, Validation Loss: 0.001387\n",
      " Epoch 164: Train Loss: 0.001104, Validation Loss: 0.001391\n",
      " Epoch 165: Train Loss: 0.001103, Validation Loss: 0.001387\n",
      " Epoch 166: Train Loss: 0.001099, Validation Loss: 0.001389\n",
      " Epoch 167: Train Loss: 0.001099, Validation Loss: 0.001391\n",
      " Epoch 168: Train Loss: 0.001099, Validation Loss: 0.001389\n",
      " Epoch 169: Train Loss: 0.001096, Validation Loss: 0.001385\n",
      " Epoch 170: Train Loss: 0.001095, Validation Loss: 0.001392\n",
      " Epoch 171: Train Loss: 0.001094, Validation Loss: 0.001388\n",
      " Epoch 172: Train Loss: 0.001093, Validation Loss: 0.001385\n",
      " Epoch 173: Train Loss: 0.001092, Validation Loss: 0.001388\n",
      " Epoch 174: Train Loss: 0.001090, Validation Loss: 0.001388\n",
      " Epoch 175: Train Loss: 0.001091, Validation Loss: 0.001386\n",
      " Epoch 176: Train Loss: 0.001088, Validation Loss: 0.001390\n",
      " Epoch 177: Train Loss: 0.001088, Validation Loss: 0.001391\n",
      " Epoch 178: Train Loss: 0.001088, Validation Loss: 0.001388\n",
      " Epoch 179: Train Loss: 0.001084, Validation Loss: 0.001387\n",
      " Epoch 180: Train Loss: 0.001083, Validation Loss: 0.001386\n",
      " Epoch 181: Train Loss: 0.001078, Validation Loss: 0.001385\n",
      " Epoch 182: Train Loss: 0.001077, Validation Loss: 0.001385\n",
      " Epoch 183: Train Loss: 0.001076, Validation Loss: 0.001383\n",
      " Epoch 184: Train Loss: 0.001076, Validation Loss: 0.001385\n",
      " Epoch 185: Train Loss: 0.001075, Validation Loss: 0.001384\n",
      " Epoch 186: Train Loss: 0.001074, Validation Loss: 0.001383\n",
      " Epoch 187: Train Loss: 0.001074, Validation Loss: 0.001384\n",
      " Epoch 188: Train Loss: 0.001073, Validation Loss: 0.001385\n",
      " Epoch 189: Train Loss: 0.001072, Validation Loss: 0.001386\n",
      " Epoch 190: Train Loss: 0.001072, Validation Loss: 0.001384\n",
      " Epoch 191: Train Loss: 0.001071, Validation Loss: 0.001383\n",
      " Epoch 192: Train Loss: 0.001070, Validation Loss: 0.001384\n",
      " Epoch 193: Train Loss: 0.001069, Validation Loss: 0.001387\n",
      " Epoch 194: Train Loss: 0.001069, Validation Loss: 0.001384\n",
      " Epoch 195: Train Loss: 0.001068, Validation Loss: 0.001384\n",
      " Epoch 196: Train Loss: 0.001067, Validation Loss: 0.001385\n",
      " Epoch 197: Train Loss: 0.001067, Validation Loss: 0.001385\n",
      " Epoch 198: Train Loss: 0.001066, Validation Loss: 0.001386\n",
      " Epoch 199: Train Loss: 0.001066, Validation Loss: 0.001384\n",
      " Epoch 200: Train Loss: 0.001064, Validation Loss: 0.001385\n",
      " Epoch 201: Train Loss: 0.001064, Validation Loss: 0.001385\n",
      " Epoch 202: Train Loss: 0.001064, Validation Loss: 0.001384\n",
      " Epoch 203: Train Loss: 0.001062, Validation Loss: 0.001385\n",
      " Epoch 204: Train Loss: 0.001062, Validation Loss: 0.001383\n",
      " Epoch 205: Train Loss: 0.001061, Validation Loss: 0.001384\n",
      " Epoch 206: Train Loss: 0.001060, Validation Loss: 0.001388\n",
      "Early stopping at epoch 206 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.086815, Validation Loss: 0.082334\n",
      " Epoch 2: Train Loss: 0.064780, Validation Loss: 0.083022\n",
      " Epoch 3: Train Loss: 0.023352, Validation Loss: 0.021700\n",
      " Epoch 4: Train Loss: 0.008102, Validation Loss: 0.008123\n",
      " Epoch 5: Train Loss: 0.005828, Validation Loss: 0.005520\n",
      " Epoch 6: Train Loss: 0.004897, Validation Loss: 0.004637\n",
      " Epoch 7: Train Loss: 0.004394, Validation Loss: 0.004409\n",
      " Epoch 8: Train Loss: 0.004065, Validation Loss: 0.004290\n",
      " Epoch 9: Train Loss: 0.003792, Validation Loss: 0.003756\n",
      " Epoch 10: Train Loss: 0.004169, Validation Loss: 0.013266\n",
      " Epoch 11: Train Loss: 0.003610, Validation Loss: 0.004135\n",
      " Epoch 12: Train Loss: 0.003272, Validation Loss: 0.003244\n",
      " Epoch 13: Train Loss: 0.003114, Validation Loss: 0.003148\n",
      " Epoch 14: Train Loss: 0.002992, Validation Loss: 0.003031\n",
      " Epoch 15: Train Loss: 0.002882, Validation Loss: 0.002913\n",
      " Epoch 16: Train Loss: 0.002751, Validation Loss: 0.002762\n",
      " Epoch 17: Train Loss: 0.002674, Validation Loss: 0.002711\n",
      " Epoch 18: Train Loss: 0.002579, Validation Loss: 0.002831\n",
      " Epoch 19: Train Loss: 0.002509, Validation Loss: 0.002620\n",
      " Epoch 20: Train Loss: 0.002428, Validation Loss: 0.002485\n",
      " Epoch 21: Train Loss: 0.002365, Validation Loss: 0.002495\n",
      " Epoch 22: Train Loss: 0.002297, Validation Loss: 0.002409\n",
      " Epoch 23: Train Loss: 0.002260, Validation Loss: 0.002283\n",
      " Epoch 24: Train Loss: 0.002177, Validation Loss: 0.002303\n",
      " Epoch 25: Train Loss: 0.002164, Validation Loss: 0.002182\n",
      " Epoch 26: Train Loss: 0.002079, Validation Loss: 0.002143\n",
      " Epoch 27: Train Loss: 0.002050, Validation Loss: 0.002170\n",
      " Epoch 28: Train Loss: 0.002027, Validation Loss: 0.002116\n",
      " Epoch 29: Train Loss: 0.001980, Validation Loss: 0.002098\n",
      " Epoch 30: Train Loss: 0.001935, Validation Loss: 0.002038\n",
      " Epoch 31: Train Loss: 0.001853, Validation Loss: 0.001944\n",
      " Epoch 32: Train Loss: 0.001829, Validation Loss: 0.001943\n",
      " Epoch 33: Train Loss: 0.001811, Validation Loss: 0.001929\n",
      " Epoch 34: Train Loss: 0.001791, Validation Loss: 0.001910\n",
      " Epoch 35: Train Loss: 0.001773, Validation Loss: 0.001892\n",
      " Epoch 36: Train Loss: 0.001762, Validation Loss: 0.001872\n",
      " Epoch 37: Train Loss: 0.001746, Validation Loss: 0.001861\n",
      " Epoch 38: Train Loss: 0.001731, Validation Loss: 0.001853\n",
      " Epoch 39: Train Loss: 0.001708, Validation Loss: 0.001852\n",
      " Epoch 40: Train Loss: 0.001696, Validation Loss: 0.001812\n",
      " Epoch 41: Train Loss: 0.001685, Validation Loss: 0.001808\n",
      " Epoch 42: Train Loss: 0.001664, Validation Loss: 0.001836\n",
      " Epoch 43: Train Loss: 0.001652, Validation Loss: 0.001787\n",
      " Epoch 44: Train Loss: 0.001628, Validation Loss: 0.001765\n",
      " Epoch 45: Train Loss: 0.001618, Validation Loss: 0.001764\n",
      " Epoch 46: Train Loss: 0.001605, Validation Loss: 0.001771\n",
      " Epoch 47: Train Loss: 0.001596, Validation Loss: 0.001773\n",
      " Epoch 48: Train Loss: 0.001574, Validation Loss: 0.001770\n",
      " Epoch 49: Train Loss: 0.001560, Validation Loss: 0.001708\n",
      " Epoch 50: Train Loss: 0.001550, Validation Loss: 0.001765\n",
      " Epoch 51: Train Loss: 0.001568, Validation Loss: 0.001698\n",
      " Epoch 52: Train Loss: 0.001520, Validation Loss: 0.001759\n",
      " Epoch 53: Train Loss: 0.001526, Validation Loss: 0.001698\n",
      " Epoch 54: Train Loss: 0.001501, Validation Loss: 0.001659\n",
      " Epoch 55: Train Loss: 0.001485, Validation Loss: 0.001672\n",
      " Epoch 56: Train Loss: 0.001482, Validation Loss: 0.001670\n",
      " Epoch 57: Train Loss: 0.001476, Validation Loss: 0.001652\n",
      " Epoch 58: Train Loss: 0.001450, Validation Loss: 0.001680\n",
      " Epoch 59: Train Loss: 0.001437, Validation Loss: 0.001623\n",
      " Epoch 60: Train Loss: 0.001426, Validation Loss: 0.001611\n",
      " Epoch 61: Train Loss: 0.001377, Validation Loss: 0.001590\n",
      " Epoch 62: Train Loss: 0.001364, Validation Loss: 0.001577\n",
      " Epoch 63: Train Loss: 0.001359, Validation Loss: 0.001585\n",
      " Epoch 64: Train Loss: 0.001354, Validation Loss: 0.001584\n",
      " Epoch 65: Train Loss: 0.001349, Validation Loss: 0.001590\n",
      " Epoch 66: Train Loss: 0.001339, Validation Loss: 0.001571\n",
      " Epoch 67: Train Loss: 0.001333, Validation Loss: 0.001575\n",
      " Epoch 68: Train Loss: 0.001327, Validation Loss: 0.001572\n",
      " Epoch 69: Train Loss: 0.001319, Validation Loss: 0.001575\n",
      " Epoch 70: Train Loss: 0.001318, Validation Loss: 0.001566\n",
      " Epoch 71: Train Loss: 0.001306, Validation Loss: 0.001579\n",
      " Epoch 72: Train Loss: 0.001298, Validation Loss: 0.001552\n",
      " Epoch 73: Train Loss: 0.001297, Validation Loss: 0.001552\n",
      " Epoch 74: Train Loss: 0.001291, Validation Loss: 0.001557\n",
      " Epoch 75: Train Loss: 0.001283, Validation Loss: 0.001560\n",
      " Epoch 76: Train Loss: 0.001281, Validation Loss: 0.001549\n",
      " Epoch 77: Train Loss: 0.001269, Validation Loss: 0.001551\n",
      " Epoch 78: Train Loss: 0.001257, Validation Loss: 0.001558\n",
      " Epoch 79: Train Loss: 0.001253, Validation Loss: 0.001540\n",
      " Epoch 80: Train Loss: 0.001252, Validation Loss: 0.001554\n",
      " Epoch 81: Train Loss: 0.001249, Validation Loss: 0.001560\n",
      " Epoch 82: Train Loss: 0.001237, Validation Loss: 0.001564\n",
      " Epoch 83: Train Loss: 0.001230, Validation Loss: 0.001545\n",
      " Epoch 84: Train Loss: 0.001216, Validation Loss: 0.001531\n",
      " Epoch 85: Train Loss: 0.001213, Validation Loss: 0.001538\n",
      " Epoch 86: Train Loss: 0.001206, Validation Loss: 0.001563\n",
      " Epoch 87: Train Loss: 0.001199, Validation Loss: 0.001538\n",
      " Epoch 88: Train Loss: 0.001199, Validation Loss: 0.001538\n",
      " Epoch 89: Train Loss: 0.001188, Validation Loss: 0.001540\n",
      " Epoch 90: Train Loss: 0.001176, Validation Loss: 0.001544\n",
      " Epoch 91: Train Loss: 0.001147, Validation Loss: 0.001531\n",
      " Epoch 92: Train Loss: 0.001138, Validation Loss: 0.001525\n",
      " Epoch 93: Train Loss: 0.001134, Validation Loss: 0.001528\n",
      " Epoch 94: Train Loss: 0.001132, Validation Loss: 0.001518\n",
      " Epoch 95: Train Loss: 0.001127, Validation Loss: 0.001529\n",
      " Epoch 96: Train Loss: 0.001123, Validation Loss: 0.001526\n",
      " Epoch 97: Train Loss: 0.001122, Validation Loss: 0.001528\n",
      " Epoch 98: Train Loss: 0.001114, Validation Loss: 0.001530\n",
      " Epoch 99: Train Loss: 0.001111, Validation Loss: 0.001526\n",
      " Epoch 100: Train Loss: 0.001106, Validation Loss: 0.001527\n",
      " Epoch 101: Train Loss: 0.001103, Validation Loss: 0.001524\n",
      " Epoch 102: Train Loss: 0.001100, Validation Loss: 0.001531\n",
      " Epoch 103: Train Loss: 0.001094, Validation Loss: 0.001538\n",
      " Epoch 104: Train Loss: 0.001088, Validation Loss: 0.001534\n",
      " Epoch 105: Train Loss: 0.001087, Validation Loss: 0.001532\n",
      " Epoch 106: Train Loss: 0.001081, Validation Loss: 0.001536\n",
      " Epoch 107: Train Loss: 0.001081, Validation Loss: 0.001547\n",
      " Epoch 108: Train Loss: 0.001072, Validation Loss: 0.001529\n",
      " Epoch 109: Train Loss: 0.001066, Validation Loss: 0.001539\n",
      " Epoch 110: Train Loss: 0.001063, Validation Loss: 0.001530\n",
      " Epoch 111: Train Loss: 0.001059, Validation Loss: 0.001531\n",
      " Epoch 112: Train Loss: 0.001060, Validation Loss: 0.001534\n",
      " Epoch 113: Train Loss: 0.001048, Validation Loss: 0.001531\n",
      " Epoch 114: Train Loss: 0.001047, Validation Loss: 0.001530\n",
      "Early stopping at epoch 114 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.059072, Validation Loss: 0.056836\n",
      " Epoch 2: Train Loss: 0.013645, Validation Loss: 0.012122\n",
      " Epoch 3: Train Loss: 0.008401, Validation Loss: 0.008225\n",
      " Epoch 4: Train Loss: 0.006604, Validation Loss: 0.006564\n",
      " Epoch 5: Train Loss: 0.005609, Validation Loss: 0.005412\n",
      " Epoch 6: Train Loss: 0.004968, Validation Loss: 0.005024\n",
      " Epoch 7: Train Loss: 0.004440, Validation Loss: 0.004572\n",
      " Epoch 8: Train Loss: 0.004152, Validation Loss: 0.004199\n",
      " Epoch 9: Train Loss: 0.003881, Validation Loss: 0.003824\n",
      " Epoch 10: Train Loss: 0.003688, Validation Loss: 0.004043\n",
      " Epoch 11: Train Loss: 0.003474, Validation Loss: 0.003720\n",
      " Epoch 12: Train Loss: 0.003322, Validation Loss: 0.003308\n",
      " Epoch 13: Train Loss: 0.003208, Validation Loss: 0.003240\n",
      " Epoch 14: Train Loss: 0.003096, Validation Loss: 0.003231\n",
      " Epoch 15: Train Loss: 0.003005, Validation Loss: 0.003055\n",
      " Epoch 16: Train Loss: 0.002891, Validation Loss: 0.003056\n",
      " Epoch 17: Train Loss: 0.002782, Validation Loss: 0.002990\n",
      " Epoch 18: Train Loss: 0.002733, Validation Loss: 0.002982\n",
      " Epoch 19: Train Loss: 0.002640, Validation Loss: 0.002969\n",
      " Epoch 20: Train Loss: 0.002589, Validation Loss: 0.002581\n",
      " Epoch 21: Train Loss: 0.002555, Validation Loss: 0.002706\n",
      " Epoch 22: Train Loss: 0.002460, Validation Loss: 0.002660\n",
      " Epoch 23: Train Loss: 0.002411, Validation Loss: 0.002446\n",
      " Epoch 24: Train Loss: 0.002351, Validation Loss: 0.002442\n",
      " Epoch 25: Train Loss: 0.002338, Validation Loss: 0.002335\n",
      " Epoch 26: Train Loss: 0.002263, Validation Loss: 0.002334\n",
      " Epoch 27: Train Loss: 0.002219, Validation Loss: 0.002316\n",
      " Epoch 28: Train Loss: 0.002230, Validation Loss: 0.002601\n",
      " Epoch 29: Train Loss: 0.002135, Validation Loss: 0.002357\n",
      " Epoch 30: Train Loss: 0.002108, Validation Loss: 0.002164\n",
      " Epoch 31: Train Loss: 0.002024, Validation Loss: 0.002093\n",
      " Epoch 32: Train Loss: 0.001987, Validation Loss: 0.002091\n",
      " Epoch 33: Train Loss: 0.001970, Validation Loss: 0.002064\n",
      " Epoch 34: Train Loss: 0.001953, Validation Loss: 0.002046\n",
      " Epoch 35: Train Loss: 0.001934, Validation Loss: 0.002022\n",
      " Epoch 36: Train Loss: 0.001920, Validation Loss: 0.001999\n",
      " Epoch 37: Train Loss: 0.001904, Validation Loss: 0.002163\n",
      " Epoch 38: Train Loss: 0.001889, Validation Loss: 0.001960\n",
      " Epoch 39: Train Loss: 0.001874, Validation Loss: 0.001948\n",
      " Epoch 40: Train Loss: 0.001853, Validation Loss: 0.001994\n",
      " Epoch 41: Train Loss: 0.001851, Validation Loss: 0.001931\n",
      " Epoch 42: Train Loss: 0.001834, Validation Loss: 0.001929\n",
      " Epoch 43: Train Loss: 0.001812, Validation Loss: 0.001894\n",
      " Epoch 44: Train Loss: 0.001805, Validation Loss: 0.001891\n",
      " Epoch 45: Train Loss: 0.001795, Validation Loss: 0.001932\n",
      " Epoch 46: Train Loss: 0.001779, Validation Loss: 0.001972\n",
      " Epoch 47: Train Loss: 0.001783, Validation Loss: 0.001972\n",
      " Epoch 48: Train Loss: 0.001765, Validation Loss: 0.001837\n",
      " Epoch 49: Train Loss: 0.001761, Validation Loss: 0.001843\n",
      " Epoch 50: Train Loss: 0.001725, Validation Loss: 0.001870\n",
      " Epoch 51: Train Loss: 0.001729, Validation Loss: 0.001855\n",
      " Epoch 52: Train Loss: 0.001695, Validation Loss: 0.001938\n",
      " Epoch 53: Train Loss: 0.001692, Validation Loss: 0.001774\n",
      " Epoch 54: Train Loss: 0.001690, Validation Loss: 0.001759\n",
      " Epoch 55: Train Loss: 0.001672, Validation Loss: 0.002013\n",
      " Epoch 56: Train Loss: 0.001671, Validation Loss: 0.001789\n",
      " Epoch 57: Train Loss: 0.001654, Validation Loss: 0.001813\n",
      " Epoch 58: Train Loss: 0.001670, Validation Loss: 0.001734\n",
      " Epoch 59: Train Loss: 0.001607, Validation Loss: 0.001753\n",
      " Epoch 60: Train Loss: 0.001624, Validation Loss: 0.001825\n",
      " Epoch 61: Train Loss: 0.001570, Validation Loss: 0.001681\n",
      " Epoch 62: Train Loss: 0.001557, Validation Loss: 0.001675\n",
      " Epoch 63: Train Loss: 0.001550, Validation Loss: 0.001665\n",
      " Epoch 64: Train Loss: 0.001547, Validation Loss: 0.001676\n",
      " Epoch 65: Train Loss: 0.001540, Validation Loss: 0.001654\n",
      " Epoch 66: Train Loss: 0.001536, Validation Loss: 0.001662\n",
      " Epoch 67: Train Loss: 0.001540, Validation Loss: 0.001647\n",
      " Epoch 68: Train Loss: 0.001521, Validation Loss: 0.001640\n",
      " Epoch 69: Train Loss: 0.001516, Validation Loss: 0.001629\n",
      " Epoch 70: Train Loss: 0.001511, Validation Loss: 0.001643\n",
      " Epoch 71: Train Loss: 0.001504, Validation Loss: 0.001637\n",
      " Epoch 72: Train Loss: 0.001501, Validation Loss: 0.001634\n",
      " Epoch 73: Train Loss: 0.001495, Validation Loss: 0.001616\n",
      " Epoch 74: Train Loss: 0.001489, Validation Loss: 0.001601\n",
      " Epoch 75: Train Loss: 0.001483, Validation Loss: 0.001631\n",
      " Epoch 76: Train Loss: 0.001477, Validation Loss: 0.001627\n",
      " Epoch 77: Train Loss: 0.001479, Validation Loss: 0.001614\n",
      " Epoch 78: Train Loss: 0.001469, Validation Loss: 0.001624\n",
      " Epoch 79: Train Loss: 0.001464, Validation Loss: 0.001586\n",
      " Epoch 80: Train Loss: 0.001459, Validation Loss: 0.001594\n",
      " Epoch 81: Train Loss: 0.001449, Validation Loss: 0.001573\n",
      " Epoch 82: Train Loss: 0.001447, Validation Loss: 0.001563\n",
      " Epoch 83: Train Loss: 0.001435, Validation Loss: 0.001565\n",
      " Epoch 84: Train Loss: 0.001431, Validation Loss: 0.001562\n",
      " Epoch 85: Train Loss: 0.001427, Validation Loss: 0.001559\n",
      " Epoch 86: Train Loss: 0.001416, Validation Loss: 0.001573\n",
      " Epoch 87: Train Loss: 0.001427, Validation Loss: 0.001624\n",
      " Epoch 88: Train Loss: 0.001411, Validation Loss: 0.001547\n",
      " Epoch 89: Train Loss: 0.001403, Validation Loss: 0.001548\n",
      " Epoch 90: Train Loss: 0.001403, Validation Loss: 0.001555\n",
      " Epoch 91: Train Loss: 0.001378, Validation Loss: 0.001518\n",
      " Epoch 92: Train Loss: 0.001370, Validation Loss: 0.001515\n",
      " Epoch 93: Train Loss: 0.001367, Validation Loss: 0.001510\n",
      " Epoch 94: Train Loss: 0.001364, Validation Loss: 0.001509\n",
      " Epoch 95: Train Loss: 0.001361, Validation Loss: 0.001511\n",
      " Epoch 96: Train Loss: 0.001359, Validation Loss: 0.001501\n",
      " Epoch 97: Train Loss: 0.001356, Validation Loss: 0.001503\n",
      " Epoch 98: Train Loss: 0.001353, Validation Loss: 0.001512\n",
      " Epoch 99: Train Loss: 0.001352, Validation Loss: 0.001499\n",
      " Epoch 100: Train Loss: 0.001347, Validation Loss: 0.001514\n",
      " Epoch 101: Train Loss: 0.001345, Validation Loss: 0.001493\n",
      " Epoch 102: Train Loss: 0.001339, Validation Loss: 0.001497\n",
      " Epoch 103: Train Loss: 0.001338, Validation Loss: 0.001485\n",
      " Epoch 104: Train Loss: 0.001334, Validation Loss: 0.001501\n",
      " Epoch 105: Train Loss: 0.001329, Validation Loss: 0.001482\n",
      " Epoch 106: Train Loss: 0.001327, Validation Loss: 0.001483\n",
      " Epoch 107: Train Loss: 0.001326, Validation Loss: 0.001488\n",
      " Epoch 108: Train Loss: 0.001320, Validation Loss: 0.001478\n",
      " Epoch 109: Train Loss: 0.001320, Validation Loss: 0.001473\n",
      " Epoch 110: Train Loss: 0.001315, Validation Loss: 0.001470\n",
      " Epoch 111: Train Loss: 0.001314, Validation Loss: 0.001467\n",
      " Epoch 112: Train Loss: 0.001310, Validation Loss: 0.001482\n",
      " Epoch 113: Train Loss: 0.001306, Validation Loss: 0.001466\n",
      " Epoch 114: Train Loss: 0.001302, Validation Loss: 0.001473\n",
      " Epoch 115: Train Loss: 0.001299, Validation Loss: 0.001473\n",
      " Epoch 116: Train Loss: 0.001296, Validation Loss: 0.001474\n",
      " Epoch 117: Train Loss: 0.001296, Validation Loss: 0.001456\n",
      " Epoch 118: Train Loss: 0.001289, Validation Loss: 0.001458\n",
      " Epoch 119: Train Loss: 0.001288, Validation Loss: 0.001469\n",
      " Epoch 120: Train Loss: 0.001286, Validation Loss: 0.001453\n",
      " Epoch 121: Train Loss: 0.001273, Validation Loss: 0.001448\n",
      " Epoch 122: Train Loss: 0.001269, Validation Loss: 0.001443\n",
      " Epoch 123: Train Loss: 0.001268, Validation Loss: 0.001440\n",
      " Epoch 124: Train Loss: 0.001266, Validation Loss: 0.001438\n",
      " Epoch 125: Train Loss: 0.001264, Validation Loss: 0.001440\n",
      " Epoch 126: Train Loss: 0.001262, Validation Loss: 0.001438\n",
      " Epoch 127: Train Loss: 0.001260, Validation Loss: 0.001437\n",
      " Epoch 128: Train Loss: 0.001259, Validation Loss: 0.001437\n",
      " Epoch 129: Train Loss: 0.001257, Validation Loss: 0.001442\n",
      " Epoch 130: Train Loss: 0.001255, Validation Loss: 0.001433\n",
      " Epoch 131: Train Loss: 0.001254, Validation Loss: 0.001437\n",
      " Epoch 132: Train Loss: 0.001251, Validation Loss: 0.001431\n",
      " Epoch 133: Train Loss: 0.001250, Validation Loss: 0.001434\n",
      " Epoch 134: Train Loss: 0.001249, Validation Loss: 0.001431\n",
      " Epoch 135: Train Loss: 0.001247, Validation Loss: 0.001434\n",
      " Epoch 136: Train Loss: 0.001245, Validation Loss: 0.001433\n",
      " Epoch 137: Train Loss: 0.001242, Validation Loss: 0.001428\n",
      " Epoch 138: Train Loss: 0.001241, Validation Loss: 0.001427\n",
      " Epoch 139: Train Loss: 0.001239, Validation Loss: 0.001425\n",
      " Epoch 140: Train Loss: 0.001238, Validation Loss: 0.001427\n",
      " Epoch 141: Train Loss: 0.001236, Validation Loss: 0.001428\n",
      " Epoch 142: Train Loss: 0.001235, Validation Loss: 0.001423\n",
      " Epoch 143: Train Loss: 0.001233, Validation Loss: 0.001423\n",
      " Epoch 144: Train Loss: 0.001232, Validation Loss: 0.001423\n",
      " Epoch 145: Train Loss: 0.001229, Validation Loss: 0.001429\n",
      " Epoch 146: Train Loss: 0.001226, Validation Loss: 0.001421\n",
      " Epoch 147: Train Loss: 0.001225, Validation Loss: 0.001421\n",
      " Epoch 148: Train Loss: 0.001225, Validation Loss: 0.001445\n",
      " Epoch 149: Train Loss: 0.001223, Validation Loss: 0.001419\n",
      " Epoch 150: Train Loss: 0.001219, Validation Loss: 0.001430\n",
      " Epoch 151: Train Loss: 0.001212, Validation Loss: 0.001413\n",
      " Epoch 152: Train Loss: 0.001212, Validation Loss: 0.001416\n",
      " Epoch 153: Train Loss: 0.001210, Validation Loss: 0.001415\n",
      " Epoch 154: Train Loss: 0.001208, Validation Loss: 0.001410\n",
      " Epoch 155: Train Loss: 0.001207, Validation Loss: 0.001413\n",
      " Epoch 156: Train Loss: 0.001207, Validation Loss: 0.001412\n",
      " Epoch 157: Train Loss: 0.001206, Validation Loss: 0.001416\n",
      " Epoch 158: Train Loss: 0.001205, Validation Loss: 0.001409\n",
      " Epoch 159: Train Loss: 0.001204, Validation Loss: 0.001410\n",
      " Epoch 160: Train Loss: 0.001202, Validation Loss: 0.001408\n",
      " Epoch 161: Train Loss: 0.001202, Validation Loss: 0.001411\n",
      " Epoch 162: Train Loss: 0.001200, Validation Loss: 0.001406\n",
      " Epoch 163: Train Loss: 0.001199, Validation Loss: 0.001405\n",
      " Epoch 164: Train Loss: 0.001200, Validation Loss: 0.001407\n",
      " Epoch 165: Train Loss: 0.001198, Validation Loss: 0.001407\n",
      " Epoch 166: Train Loss: 0.001197, Validation Loss: 0.001411\n",
      " Epoch 167: Train Loss: 0.001196, Validation Loss: 0.001405\n",
      " Epoch 168: Train Loss: 0.001195, Validation Loss: 0.001405\n",
      " Epoch 169: Train Loss: 0.001193, Validation Loss: 0.001404\n",
      " Epoch 170: Train Loss: 0.001192, Validation Loss: 0.001407\n",
      " Epoch 171: Train Loss: 0.001190, Validation Loss: 0.001408\n",
      " Epoch 172: Train Loss: 0.001190, Validation Loss: 0.001406\n",
      " Epoch 173: Train Loss: 0.001188, Validation Loss: 0.001403\n",
      " Epoch 174: Train Loss: 0.001188, Validation Loss: 0.001406\n",
      " Epoch 175: Train Loss: 0.001186, Validation Loss: 0.001401\n",
      " Epoch 176: Train Loss: 0.001185, Validation Loss: 0.001409\n",
      " Epoch 177: Train Loss: 0.001184, Validation Loss: 0.001416\n",
      " Epoch 178: Train Loss: 0.001183, Validation Loss: 0.001405\n",
      " Epoch 179: Train Loss: 0.001183, Validation Loss: 0.001399\n",
      " Epoch 180: Train Loss: 0.001180, Validation Loss: 0.001400\n",
      " Epoch 181: Train Loss: 0.001176, Validation Loss: 0.001399\n",
      " Epoch 182: Train Loss: 0.001175, Validation Loss: 0.001399\n",
      " Epoch 183: Train Loss: 0.001175, Validation Loss: 0.001399\n",
      " Epoch 184: Train Loss: 0.001174, Validation Loss: 0.001400\n",
      " Epoch 185: Train Loss: 0.001174, Validation Loss: 0.001399\n",
      " Epoch 186: Train Loss: 0.001173, Validation Loss: 0.001397\n",
      " Epoch 187: Train Loss: 0.001172, Validation Loss: 0.001397\n",
      " Epoch 188: Train Loss: 0.001171, Validation Loss: 0.001399\n",
      " Epoch 189: Train Loss: 0.001171, Validation Loss: 0.001396\n",
      " Epoch 190: Train Loss: 0.001170, Validation Loss: 0.001397\n",
      " Epoch 191: Train Loss: 0.001170, Validation Loss: 0.001396\n",
      " Epoch 192: Train Loss: 0.001169, Validation Loss: 0.001397\n",
      " Epoch 193: Train Loss: 0.001168, Validation Loss: 0.001401\n",
      " Epoch 194: Train Loss: 0.001168, Validation Loss: 0.001395\n",
      " Epoch 195: Train Loss: 0.001167, Validation Loss: 0.001396\n",
      " Epoch 196: Train Loss: 0.001167, Validation Loss: 0.001395\n",
      " Epoch 197: Train Loss: 0.001166, Validation Loss: 0.001398\n",
      " Epoch 198: Train Loss: 0.001166, Validation Loss: 0.001395\n",
      " Epoch 199: Train Loss: 0.001165, Validation Loss: 0.001394\n",
      " Epoch 200: Train Loss: 0.001164, Validation Loss: 0.001398\n",
      " Epoch 201: Train Loss: 0.001164, Validation Loss: 0.001394\n",
      " Epoch 202: Train Loss: 0.001163, Validation Loss: 0.001396\n",
      " Epoch 203: Train Loss: 0.001162, Validation Loss: 0.001394\n",
      " Epoch 204: Train Loss: 0.001162, Validation Loss: 0.001394\n",
      " Epoch 205: Train Loss: 0.001161, Validation Loss: 0.001394\n",
      " Epoch 206: Train Loss: 0.001160, Validation Loss: 0.001393\n",
      " Epoch 207: Train Loss: 0.001159, Validation Loss: 0.001394\n",
      " Epoch 208: Train Loss: 0.001159, Validation Loss: 0.001395\n",
      " Epoch 209: Train Loss: 0.001158, Validation Loss: 0.001393\n",
      " Epoch 210: Train Loss: 0.001158, Validation Loss: 0.001394\n",
      " Epoch 211: Train Loss: 0.001155, Validation Loss: 0.001392\n",
      " Epoch 212: Train Loss: 0.001154, Validation Loss: 0.001392\n",
      " Epoch 213: Train Loss: 0.001154, Validation Loss: 0.001392\n",
      " Epoch 214: Train Loss: 0.001154, Validation Loss: 0.001393\n",
      " Epoch 215: Train Loss: 0.001153, Validation Loss: 0.001392\n",
      " Epoch 216: Train Loss: 0.001153, Validation Loss: 0.001391\n",
      " Epoch 217: Train Loss: 0.001152, Validation Loss: 0.001391\n",
      " Epoch 218: Train Loss: 0.001152, Validation Loss: 0.001391\n",
      " Epoch 219: Train Loss: 0.001152, Validation Loss: 0.001391\n",
      " Epoch 220: Train Loss: 0.001153, Validation Loss: 0.001393\n",
      " Epoch 221: Train Loss: 0.001151, Validation Loss: 0.001391\n",
      " Epoch 222: Train Loss: 0.001151, Validation Loss: 0.001391\n",
      " Epoch 223: Train Loss: 0.001151, Validation Loss: 0.001392\n",
      " Epoch 224: Train Loss: 0.001150, Validation Loss: 0.001390\n",
      " Epoch 225: Train Loss: 0.001150, Validation Loss: 0.001391\n",
      " Epoch 226: Train Loss: 0.001149, Validation Loss: 0.001390\n",
      " Epoch 227: Train Loss: 0.001149, Validation Loss: 0.001390\n",
      " Epoch 228: Train Loss: 0.001149, Validation Loss: 0.001390\n",
      " Epoch 229: Train Loss: 0.001148, Validation Loss: 0.001391\n",
      " Epoch 230: Train Loss: 0.001148, Validation Loss: 0.001390\n",
      " Epoch 231: Train Loss: 0.001148, Validation Loss: 0.001390\n",
      " Epoch 232: Train Loss: 0.001147, Validation Loss: 0.001390\n",
      " Epoch 233: Train Loss: 0.001147, Validation Loss: 0.001390\n",
      " Epoch 234: Train Loss: 0.001146, Validation Loss: 0.001390\n",
      " Epoch 235: Train Loss: 0.001146, Validation Loss: 0.001391\n",
      " Epoch 236: Train Loss: 0.001145, Validation Loss: 0.001390\n",
      " Epoch 237: Train Loss: 0.001145, Validation Loss: 0.001389\n",
      " Epoch 238: Train Loss: 0.001145, Validation Loss: 0.001392\n",
      " Epoch 239: Train Loss: 0.001144, Validation Loss: 0.001389\n",
      " Epoch 240: Train Loss: 0.001144, Validation Loss: 0.001390\n",
      " Epoch 241: Train Loss: 0.001143, Validation Loss: 0.001388\n",
      " Epoch 242: Train Loss: 0.001142, Validation Loss: 0.001389\n",
      " Epoch 243: Train Loss: 0.001142, Validation Loss: 0.001389\n",
      " Epoch 244: Train Loss: 0.001142, Validation Loss: 0.001389\n",
      " Epoch 245: Train Loss: 0.001142, Validation Loss: 0.001389\n",
      " Epoch 246: Train Loss: 0.001141, Validation Loss: 0.001389\n",
      " Epoch 247: Train Loss: 0.001141, Validation Loss: 0.001389\n",
      " Epoch 248: Train Loss: 0.001141, Validation Loss: 0.001388\n",
      " Epoch 249: Train Loss: 0.001141, Validation Loss: 0.001390\n",
      " Epoch 250: Train Loss: 0.001141, Validation Loss: 0.001389\n",
      " Epoch 251: Train Loss: 0.001140, Validation Loss: 0.001389\n",
      " Epoch 252: Train Loss: 0.001140, Validation Loss: 0.001388\n",
      " Epoch 253: Train Loss: 0.001140, Validation Loss: 0.001388\n",
      " Epoch 254: Train Loss: 0.001140, Validation Loss: 0.001389\n",
      " Epoch 255: Train Loss: 0.001140, Validation Loss: 0.001389\n",
      " Epoch 256: Train Loss: 0.001140, Validation Loss: 0.001388\n",
      " Epoch 257: Train Loss: 0.001139, Validation Loss: 0.001388\n",
      " Epoch 258: Train Loss: 0.001139, Validation Loss: 0.001388\n",
      " Epoch 259: Train Loss: 0.001139, Validation Loss: 0.001388\n",
      " Epoch 260: Train Loss: 0.001139, Validation Loss: 0.001388\n",
      " Epoch 261: Train Loss: 0.001138, Validation Loss: 0.001388\n",
      " Epoch 262: Train Loss: 0.001138, Validation Loss: 0.001389\n",
      " Epoch 263: Train Loss: 0.001138, Validation Loss: 0.001388\n",
      " Epoch 264: Train Loss: 0.001138, Validation Loss: 0.001390\n",
      " Epoch 265: Train Loss: 0.001138, Validation Loss: 0.001388\n",
      " Epoch 266: Train Loss: 0.001137, Validation Loss: 0.001388\n",
      " Epoch 267: Train Loss: 0.001137, Validation Loss: 0.001388\n",
      " Epoch 268: Train Loss: 0.001137, Validation Loss: 0.001388\n",
      " Epoch 269: Train Loss: 0.001137, Validation Loss: 0.001388\n",
      " Epoch 270: Train Loss: 0.001137, Validation Loss: 0.001388\n",
      " Epoch 271: Train Loss: 0.001136, Validation Loss: 0.001388\n",
      " Epoch 272: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 273: Train Loss: 0.001135, Validation Loss: 0.001388\n",
      " Epoch 274: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 275: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 276: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 277: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 278: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 279: Train Loss: 0.001135, Validation Loss: 0.001387\n",
      " Epoch 280: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 281: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 282: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 283: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 284: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 285: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 286: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 287: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 288: Train Loss: 0.001134, Validation Loss: 0.001388\n",
      " Epoch 289: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 290: Train Loss: 0.001133, Validation Loss: 0.001387\n",
      " Epoch 291: Train Loss: 0.001133, Validation Loss: 0.001387\n",
      " Epoch 292: Train Loss: 0.001134, Validation Loss: 0.001387\n",
      " Epoch 293: Train Loss: 0.001133, Validation Loss: 0.001387\n",
      " Epoch 294: Train Loss: 0.001133, Validation Loss: 0.001388\n",
      " Epoch 295: Train Loss: 0.001133, Validation Loss: 0.001387\n",
      " Epoch 296: Train Loss: 0.001133, Validation Loss: 0.001388\n",
      " Epoch 297: Train Loss: 0.001133, Validation Loss: 0.001387\n",
      " Epoch 298: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 299: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 300: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 301: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 302: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 303: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 304: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 305: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 306: Train Loss: 0.001132, Validation Loss: 0.001387\n",
      " Epoch 307: Train Loss: 0.001132, Validation Loss: 0.001386\n",
      " Epoch 308: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 309: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 310: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 311: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 312: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 313: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 314: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 315: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 316: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 317: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 318: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 319: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 320: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 321: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 322: Train Loss: 0.001131, Validation Loss: 0.001386\n",
      " Epoch 323: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 324: Train Loss: 0.001131, Validation Loss: 0.001387\n",
      " Epoch 325: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 326: Train Loss: 0.001130, Validation Loss: 0.001387\n",
      " Epoch 327: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 328: Train Loss: 0.001130, Validation Loss: 0.001387\n",
      " Epoch 329: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 330: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 331: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 332: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 333: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 334: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 335: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 336: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 337: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 338: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 339: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 340: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 341: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 342: Train Loss: 0.001130, Validation Loss: 0.001386\n",
      " Epoch 343: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 344: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 345: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 346: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 347: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 348: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 349: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 350: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 351: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 352: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 353: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 354: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 355: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 356: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 357: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 358: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 359: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 360: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 361: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 362: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 363: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 364: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 365: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 366: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 367: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 368: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 369: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 370: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 371: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 372: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 373: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 374: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 375: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 376: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 377: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 378: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 379: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 380: Train Loss: 0.001129, Validation Loss: 0.001386\n",
      " Epoch 381: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 382: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 383: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 384: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 385: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 386: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 387: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 388: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 389: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 390: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 391: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 392: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 393: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 394: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 395: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 396: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 397: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 398: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 399: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 400: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 401: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 402: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 403: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 404: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 405: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 406: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 407: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 408: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 409: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      " Epoch 410: Train Loss: 0.001128, Validation Loss: 0.001386\n",
      "Early stopping at epoch 410 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.066658, Validation Loss: 0.070591\n",
      " Epoch 2: Train Loss: 0.016392, Validation Loss: 0.016552\n",
      " Epoch 3: Train Loss: 0.009117, Validation Loss: 0.012521\n",
      " Epoch 4: Train Loss: 0.007121, Validation Loss: 0.009936\n",
      " Epoch 5: Train Loss: 0.005972, Validation Loss: 0.009695\n",
      " Epoch 6: Train Loss: 0.005193, Validation Loss: 0.007975\n",
      " Epoch 7: Train Loss: 0.004603, Validation Loss: 0.006623\n",
      " Epoch 8: Train Loss: 0.004222, Validation Loss: 0.006187\n",
      " Epoch 9: Train Loss: 0.003943, Validation Loss: 0.005441\n",
      " Epoch 10: Train Loss: 0.003737, Validation Loss: 0.004811\n",
      " Epoch 11: Train Loss: 0.003546, Validation Loss: 0.003703\n",
      " Epoch 12: Train Loss: 0.003414, Validation Loss: 0.004378\n",
      " Epoch 13: Train Loss: 0.003289, Validation Loss: 0.004246\n",
      " Epoch 14: Train Loss: 0.003157, Validation Loss: 0.003596\n",
      " Epoch 15: Train Loss: 0.003064, Validation Loss: 0.003588\n",
      " Epoch 16: Train Loss: 0.002961, Validation Loss: 0.004357\n",
      " Epoch 17: Train Loss: 0.002887, Validation Loss: 0.003455\n",
      " Epoch 18: Train Loss: 0.002796, Validation Loss: 0.003058\n",
      " Epoch 19: Train Loss: 0.002706, Validation Loss: 0.002996\n",
      " Epoch 20: Train Loss: 0.002663, Validation Loss: 0.003284\n",
      " Epoch 21: Train Loss: 0.002568, Validation Loss: 0.003451\n",
      " Epoch 22: Train Loss: 0.002508, Validation Loss: 0.002786\n",
      " Epoch 23: Train Loss: 0.002455, Validation Loss: 0.002796\n",
      " Epoch 24: Train Loss: 0.002395, Validation Loss: 0.002456\n",
      " Epoch 25: Train Loss: 0.002355, Validation Loss: 0.002716\n",
      " Epoch 26: Train Loss: 0.002280, Validation Loss: 0.002916\n",
      " Epoch 27: Train Loss: 0.002375, Validation Loss: 0.002360\n",
      " Epoch 28: Train Loss: 0.002195, Validation Loss: 0.002369\n",
      " Epoch 29: Train Loss: 0.002193, Validation Loss: 0.002254\n",
      " Epoch 30: Train Loss: 0.002165, Validation Loss: 0.002404\n",
      " Epoch 31: Train Loss: 0.002049, Validation Loss: 0.002147\n",
      " Epoch 32: Train Loss: 0.002013, Validation Loss: 0.002129\n",
      " Epoch 33: Train Loss: 0.001992, Validation Loss: 0.002104\n",
      " Epoch 34: Train Loss: 0.001975, Validation Loss: 0.002057\n",
      " Epoch 35: Train Loss: 0.001956, Validation Loss: 0.002053\n",
      " Epoch 36: Train Loss: 0.001940, Validation Loss: 0.002056\n",
      " Epoch 37: Train Loss: 0.001921, Validation Loss: 0.002053\n",
      " Epoch 38: Train Loss: 0.001908, Validation Loss: 0.002011\n",
      " Epoch 39: Train Loss: 0.001906, Validation Loss: 0.002019\n",
      " Epoch 40: Train Loss: 0.001877, Validation Loss: 0.002049\n",
      " Epoch 41: Train Loss: 0.001858, Validation Loss: 0.002133\n",
      " Epoch 42: Train Loss: 0.001848, Validation Loss: 0.001950\n",
      " Epoch 43: Train Loss: 0.001834, Validation Loss: 0.001991\n",
      " Epoch 44: Train Loss: 0.001838, Validation Loss: 0.001932\n",
      " Epoch 45: Train Loss: 0.001812, Validation Loss: 0.001913\n",
      " Epoch 46: Train Loss: 0.001788, Validation Loss: 0.001990\n",
      " Epoch 47: Train Loss: 0.001779, Validation Loss: 0.001882\n",
      " Epoch 48: Train Loss: 0.001760, Validation Loss: 0.001885\n",
      " Epoch 49: Train Loss: 0.001746, Validation Loss: 0.001907\n",
      " Epoch 50: Train Loss: 0.001742, Validation Loss: 0.001823\n",
      " Epoch 51: Train Loss: 0.001737, Validation Loss: 0.001843\n",
      " Epoch 52: Train Loss: 0.001715, Validation Loss: 0.001824\n",
      " Epoch 53: Train Loss: 0.001696, Validation Loss: 0.002083\n",
      " Epoch 54: Train Loss: 0.001740, Validation Loss: 0.001960\n",
      " Epoch 55: Train Loss: 0.001684, Validation Loss: 0.001836\n",
      " Epoch 56: Train Loss: 0.001671, Validation Loss: 0.001812\n",
      " Epoch 57: Train Loss: 0.001673, Validation Loss: 0.001753\n",
      " Epoch 58: Train Loss: 0.001639, Validation Loss: 0.001779\n",
      " Epoch 59: Train Loss: 0.001656, Validation Loss: 0.001907\n",
      " Epoch 60: Train Loss: 0.001612, Validation Loss: 0.001891\n",
      " Epoch 61: Train Loss: 0.001592, Validation Loss: 0.001696\n",
      " Epoch 62: Train Loss: 0.001577, Validation Loss: 0.001753\n",
      " Epoch 63: Train Loss: 0.001563, Validation Loss: 0.001686\n",
      " Epoch 64: Train Loss: 0.001557, Validation Loss: 0.001686\n",
      " Epoch 65: Train Loss: 0.001550, Validation Loss: 0.001678\n",
      " Epoch 66: Train Loss: 0.001546, Validation Loss: 0.001667\n",
      " Epoch 67: Train Loss: 0.001543, Validation Loss: 0.001693\n",
      " Epoch 68: Train Loss: 0.001539, Validation Loss: 0.001656\n",
      " Epoch 69: Train Loss: 0.001529, Validation Loss: 0.001667\n",
      " Epoch 70: Train Loss: 0.001522, Validation Loss: 0.001651\n",
      " Epoch 71: Train Loss: 0.001520, Validation Loss: 0.001666\n",
      " Epoch 72: Train Loss: 0.001512, Validation Loss: 0.001665\n",
      " Epoch 73: Train Loss: 0.001509, Validation Loss: 0.001654\n",
      " Epoch 74: Train Loss: 0.001502, Validation Loss: 0.001641\n",
      " Epoch 75: Train Loss: 0.001499, Validation Loss: 0.001632\n",
      " Epoch 76: Train Loss: 0.001488, Validation Loss: 0.001627\n",
      " Epoch 77: Train Loss: 0.001485, Validation Loss: 0.001639\n",
      " Epoch 78: Train Loss: 0.001476, Validation Loss: 0.001677\n",
      " Epoch 79: Train Loss: 0.001475, Validation Loss: 0.001878\n",
      " Epoch 80: Train Loss: 0.001473, Validation Loss: 0.001639\n",
      " Epoch 81: Train Loss: 0.001462, Validation Loss: 0.001679\n",
      " Epoch 82: Train Loss: 0.001459, Validation Loss: 0.001595\n",
      " Epoch 83: Train Loss: 0.001451, Validation Loss: 0.001589\n",
      " Epoch 84: Train Loss: 0.001445, Validation Loss: 0.001594\n",
      " Epoch 85: Train Loss: 0.001441, Validation Loss: 0.001612\n",
      " Epoch 86: Train Loss: 0.001439, Validation Loss: 0.001580\n",
      " Epoch 87: Train Loss: 0.001434, Validation Loss: 0.001565\n",
      " Epoch 88: Train Loss: 0.001421, Validation Loss: 0.001566\n",
      " Epoch 89: Train Loss: 0.001415, Validation Loss: 0.001646\n",
      " Epoch 90: Train Loss: 0.001411, Validation Loss: 0.001584\n",
      " Epoch 91: Train Loss: 0.001389, Validation Loss: 0.001541\n",
      " Epoch 92: Train Loss: 0.001385, Validation Loss: 0.001537\n",
      " Epoch 93: Train Loss: 0.001384, Validation Loss: 0.001560\n",
      " Epoch 94: Train Loss: 0.001382, Validation Loss: 0.001557\n",
      " Epoch 95: Train Loss: 0.001377, Validation Loss: 0.001550\n",
      " Epoch 96: Train Loss: 0.001372, Validation Loss: 0.001531\n",
      " Epoch 97: Train Loss: 0.001370, Validation Loss: 0.001530\n",
      " Epoch 98: Train Loss: 0.001367, Validation Loss: 0.001521\n",
      " Epoch 99: Train Loss: 0.001365, Validation Loss: 0.001529\n",
      " Epoch 100: Train Loss: 0.001361, Validation Loss: 0.001521\n",
      " Epoch 101: Train Loss: 0.001359, Validation Loss: 0.001528\n",
      " Epoch 102: Train Loss: 0.001355, Validation Loss: 0.001524\n",
      " Epoch 103: Train Loss: 0.001354, Validation Loss: 0.001537\n",
      " Epoch 104: Train Loss: 0.001349, Validation Loss: 0.001547\n",
      " Epoch 105: Train Loss: 0.001346, Validation Loss: 0.001514\n",
      " Epoch 106: Train Loss: 0.001344, Validation Loss: 0.001544\n",
      " Epoch 107: Train Loss: 0.001341, Validation Loss: 0.001511\n",
      " Epoch 108: Train Loss: 0.001339, Validation Loss: 0.001511\n",
      " Epoch 109: Train Loss: 0.001335, Validation Loss: 0.001511\n",
      " Epoch 110: Train Loss: 0.001331, Validation Loss: 0.001502\n",
      " Epoch 111: Train Loss: 0.001328, Validation Loss: 0.001499\n",
      " Epoch 112: Train Loss: 0.001327, Validation Loss: 0.001499\n",
      " Epoch 113: Train Loss: 0.001322, Validation Loss: 0.001629\n",
      " Epoch 114: Train Loss: 0.001322, Validation Loss: 0.001510\n",
      " Epoch 115: Train Loss: 0.001320, Validation Loss: 0.001531\n",
      " Epoch 116: Train Loss: 0.001322, Validation Loss: 0.001539\n",
      " Epoch 117: Train Loss: 0.001313, Validation Loss: 0.001486\n",
      " Epoch 118: Train Loss: 0.001310, Validation Loss: 0.001547\n",
      " Epoch 119: Train Loss: 0.001309, Validation Loss: 0.001534\n",
      " Epoch 120: Train Loss: 0.001303, Validation Loss: 0.001503\n",
      " Epoch 121: Train Loss: 0.001290, Validation Loss: 0.001481\n",
      " Epoch 122: Train Loss: 0.001287, Validation Loss: 0.001474\n",
      " Epoch 123: Train Loss: 0.001286, Validation Loss: 0.001483\n",
      " Epoch 124: Train Loss: 0.001285, Validation Loss: 0.001489\n",
      " Epoch 125: Train Loss: 0.001282, Validation Loss: 0.001477\n",
      " Epoch 126: Train Loss: 0.001280, Validation Loss: 0.001469\n",
      " Epoch 127: Train Loss: 0.001279, Validation Loss: 0.001488\n",
      " Epoch 128: Train Loss: 0.001278, Validation Loss: 0.001469\n",
      " Epoch 129: Train Loss: 0.001276, Validation Loss: 0.001465\n",
      " Epoch 130: Train Loss: 0.001274, Validation Loss: 0.001464\n",
      " Epoch 131: Train Loss: 0.001274, Validation Loss: 0.001473\n",
      " Epoch 132: Train Loss: 0.001271, Validation Loss: 0.001470\n",
      " Epoch 133: Train Loss: 0.001271, Validation Loss: 0.001500\n",
      " Epoch 134: Train Loss: 0.001270, Validation Loss: 0.001463\n",
      " Epoch 135: Train Loss: 0.001268, Validation Loss: 0.001461\n",
      " Epoch 136: Train Loss: 0.001266, Validation Loss: 0.001459\n",
      " Epoch 137: Train Loss: 0.001263, Validation Loss: 0.001472\n",
      " Epoch 138: Train Loss: 0.001261, Validation Loss: 0.001458\n",
      " Epoch 139: Train Loss: 0.001259, Validation Loss: 0.001483\n",
      " Epoch 140: Train Loss: 0.001259, Validation Loss: 0.001475\n",
      " Epoch 141: Train Loss: 0.001260, Validation Loss: 0.001492\n",
      " Epoch 142: Train Loss: 0.001255, Validation Loss: 0.001454\n",
      " Epoch 143: Train Loss: 0.001254, Validation Loss: 0.001474\n",
      " Epoch 144: Train Loss: 0.001251, Validation Loss: 0.001454\n",
      " Epoch 145: Train Loss: 0.001250, Validation Loss: 0.001452\n",
      " Epoch 146: Train Loss: 0.001247, Validation Loss: 0.001450\n",
      " Epoch 147: Train Loss: 0.001246, Validation Loss: 0.001453\n",
      " Epoch 148: Train Loss: 0.001245, Validation Loss: 0.001452\n",
      " Epoch 149: Train Loss: 0.001242, Validation Loss: 0.001455\n",
      " Epoch 150: Train Loss: 0.001240, Validation Loss: 0.001452\n",
      " Epoch 151: Train Loss: 0.001233, Validation Loss: 0.001445\n",
      " Epoch 152: Train Loss: 0.001231, Validation Loss: 0.001443\n",
      " Epoch 153: Train Loss: 0.001230, Validation Loss: 0.001444\n",
      " Epoch 154: Train Loss: 0.001229, Validation Loss: 0.001442\n",
      " Epoch 155: Train Loss: 0.001229, Validation Loss: 0.001442\n",
      " Epoch 156: Train Loss: 0.001227, Validation Loss: 0.001441\n",
      " Epoch 157: Train Loss: 0.001228, Validation Loss: 0.001443\n",
      " Epoch 158: Train Loss: 0.001227, Validation Loss: 0.001442\n",
      " Epoch 159: Train Loss: 0.001224, Validation Loss: 0.001447\n",
      " Epoch 160: Train Loss: 0.001223, Validation Loss: 0.001444\n",
      " Epoch 161: Train Loss: 0.001223, Validation Loss: 0.001444\n",
      " Epoch 162: Train Loss: 0.001221, Validation Loss: 0.001441\n",
      " Epoch 163: Train Loss: 0.001221, Validation Loss: 0.001442\n",
      " Epoch 164: Train Loss: 0.001220, Validation Loss: 0.001440\n",
      " Epoch 165: Train Loss: 0.001218, Validation Loss: 0.001437\n",
      " Epoch 166: Train Loss: 0.001218, Validation Loss: 0.001435\n",
      " Epoch 167: Train Loss: 0.001216, Validation Loss: 0.001440\n",
      " Epoch 168: Train Loss: 0.001216, Validation Loss: 0.001448\n",
      " Epoch 169: Train Loss: 0.001215, Validation Loss: 0.001435\n",
      " Epoch 170: Train Loss: 0.001214, Validation Loss: 0.001437\n",
      " Epoch 171: Train Loss: 0.001212, Validation Loss: 0.001438\n",
      " Epoch 172: Train Loss: 0.001211, Validation Loss: 0.001438\n",
      " Epoch 173: Train Loss: 0.001211, Validation Loss: 0.001438\n",
      " Epoch 174: Train Loss: 0.001210, Validation Loss: 0.001436\n",
      " Epoch 175: Train Loss: 0.001208, Validation Loss: 0.001444\n",
      " Epoch 176: Train Loss: 0.001207, Validation Loss: 0.001439\n",
      " Epoch 177: Train Loss: 0.001208, Validation Loss: 0.001437\n",
      " Epoch 178: Train Loss: 0.001204, Validation Loss: 0.001435\n",
      " Epoch 179: Train Loss: 0.001204, Validation Loss: 0.001434\n",
      " Epoch 180: Train Loss: 0.001203, Validation Loss: 0.001448\n",
      " Epoch 181: Train Loss: 0.001198, Validation Loss: 0.001435\n",
      " Epoch 182: Train Loss: 0.001198, Validation Loss: 0.001439\n",
      " Epoch 183: Train Loss: 0.001197, Validation Loss: 0.001431\n",
      " Epoch 184: Train Loss: 0.001196, Validation Loss: 0.001430\n",
      " Epoch 185: Train Loss: 0.001196, Validation Loss: 0.001431\n",
      " Epoch 186: Train Loss: 0.001195, Validation Loss: 0.001433\n",
      " Epoch 187: Train Loss: 0.001194, Validation Loss: 0.001430\n",
      " Epoch 188: Train Loss: 0.001194, Validation Loss: 0.001430\n",
      " Epoch 189: Train Loss: 0.001193, Validation Loss: 0.001433\n",
      " Epoch 190: Train Loss: 0.001193, Validation Loss: 0.001432\n",
      " Epoch 191: Train Loss: 0.001192, Validation Loss: 0.001433\n",
      " Epoch 192: Train Loss: 0.001192, Validation Loss: 0.001443\n",
      " Epoch 193: Train Loss: 0.001191, Validation Loss: 0.001433\n",
      " Epoch 194: Train Loss: 0.001191, Validation Loss: 0.001428\n",
      " Epoch 195: Train Loss: 0.001189, Validation Loss: 0.001430\n",
      " Epoch 196: Train Loss: 0.001189, Validation Loss: 0.001429\n",
      " Epoch 197: Train Loss: 0.001188, Validation Loss: 0.001430\n",
      " Epoch 198: Train Loss: 0.001188, Validation Loss: 0.001430\n",
      " Epoch 199: Train Loss: 0.001187, Validation Loss: 0.001429\n",
      " Epoch 200: Train Loss: 0.001186, Validation Loss: 0.001438\n",
      " Epoch 201: Train Loss: 0.001186, Validation Loss: 0.001432\n",
      " Epoch 202: Train Loss: 0.001185, Validation Loss: 0.001428\n",
      " Epoch 203: Train Loss: 0.001185, Validation Loss: 0.001437\n",
      " Epoch 204: Train Loss: 0.001184, Validation Loss: 0.001430\n",
      " Epoch 205: Train Loss: 0.001183, Validation Loss: 0.001428\n",
      " Epoch 206: Train Loss: 0.001182, Validation Loss: 0.001430\n",
      " Epoch 207: Train Loss: 0.001182, Validation Loss: 0.001427\n",
      " Epoch 208: Train Loss: 0.001181, Validation Loss: 0.001430\n",
      " Epoch 209: Train Loss: 0.001181, Validation Loss: 0.001428\n",
      " Epoch 210: Train Loss: 0.001180, Validation Loss: 0.001426\n",
      " Epoch 211: Train Loss: 0.001177, Validation Loss: 0.001427\n",
      " Epoch 212: Train Loss: 0.001177, Validation Loss: 0.001425\n",
      " Epoch 213: Train Loss: 0.001176, Validation Loss: 0.001426\n",
      " Epoch 214: Train Loss: 0.001177, Validation Loss: 0.001427\n",
      " Epoch 215: Train Loss: 0.001176, Validation Loss: 0.001425\n",
      " Epoch 216: Train Loss: 0.001175, Validation Loss: 0.001425\n",
      " Epoch 217: Train Loss: 0.001175, Validation Loss: 0.001425\n",
      " Epoch 218: Train Loss: 0.001175, Validation Loss: 0.001425\n",
      " Epoch 219: Train Loss: 0.001174, Validation Loss: 0.001429\n",
      " Epoch 220: Train Loss: 0.001174, Validation Loss: 0.001424\n",
      " Epoch 221: Train Loss: 0.001174, Validation Loss: 0.001426\n",
      " Epoch 222: Train Loss: 0.001173, Validation Loss: 0.001427\n",
      " Epoch 223: Train Loss: 0.001173, Validation Loss: 0.001425\n",
      " Epoch 224: Train Loss: 0.001173, Validation Loss: 0.001424\n",
      " Epoch 225: Train Loss: 0.001172, Validation Loss: 0.001426\n",
      " Epoch 226: Train Loss: 0.001172, Validation Loss: 0.001425\n",
      " Epoch 227: Train Loss: 0.001171, Validation Loss: 0.001424\n",
      " Epoch 228: Train Loss: 0.001171, Validation Loss: 0.001424\n",
      " Epoch 229: Train Loss: 0.001171, Validation Loss: 0.001427\n",
      " Epoch 230: Train Loss: 0.001170, Validation Loss: 0.001425\n",
      " Epoch 231: Train Loss: 0.001170, Validation Loss: 0.001430\n",
      " Epoch 232: Train Loss: 0.001170, Validation Loss: 0.001423\n",
      " Epoch 233: Train Loss: 0.001169, Validation Loss: 0.001424\n",
      " Epoch 234: Train Loss: 0.001169, Validation Loss: 0.001426\n",
      " Epoch 235: Train Loss: 0.001169, Validation Loss: 0.001425\n",
      " Epoch 236: Train Loss: 0.001168, Validation Loss: 0.001423\n",
      " Epoch 237: Train Loss: 0.001168, Validation Loss: 0.001424\n",
      " Epoch 238: Train Loss: 0.001167, Validation Loss: 0.001428\n",
      " Epoch 239: Train Loss: 0.001167, Validation Loss: 0.001425\n",
      " Epoch 240: Train Loss: 0.001167, Validation Loss: 0.001423\n",
      " Epoch 241: Train Loss: 0.001165, Validation Loss: 0.001423\n",
      " Epoch 242: Train Loss: 0.001165, Validation Loss: 0.001423\n",
      " Epoch 243: Train Loss: 0.001165, Validation Loss: 0.001424\n",
      " Epoch 244: Train Loss: 0.001164, Validation Loss: 0.001422\n",
      " Epoch 245: Train Loss: 0.001164, Validation Loss: 0.001423\n",
      " Epoch 246: Train Loss: 0.001164, Validation Loss: 0.001423\n",
      " Epoch 247: Train Loss: 0.001164, Validation Loss: 0.001423\n",
      " Epoch 248: Train Loss: 0.001163, Validation Loss: 0.001423\n",
      " Epoch 249: Train Loss: 0.001163, Validation Loss: 0.001423\n",
      " Epoch 250: Train Loss: 0.001163, Validation Loss: 0.001422\n",
      " Epoch 251: Train Loss: 0.001163, Validation Loss: 0.001422\n",
      " Epoch 252: Train Loss: 0.001163, Validation Loss: 0.001423\n",
      " Epoch 253: Train Loss: 0.001162, Validation Loss: 0.001424\n",
      " Epoch 254: Train Loss: 0.001162, Validation Loss: 0.001422\n",
      " Epoch 255: Train Loss: 0.001162, Validation Loss: 0.001422\n",
      " Epoch 256: Train Loss: 0.001162, Validation Loss: 0.001422\n",
      " Epoch 257: Train Loss: 0.001162, Validation Loss: 0.001423\n",
      " Epoch 258: Train Loss: 0.001162, Validation Loss: 0.001422\n",
      " Epoch 259: Train Loss: 0.001161, Validation Loss: 0.001422\n",
      " Epoch 260: Train Loss: 0.001161, Validation Loss: 0.001422\n",
      " Epoch 261: Train Loss: 0.001161, Validation Loss: 0.001422\n",
      " Epoch 262: Train Loss: 0.001161, Validation Loss: 0.001423\n",
      " Epoch 263: Train Loss: 0.001161, Validation Loss: 0.001422\n",
      " Epoch 264: Train Loss: 0.001160, Validation Loss: 0.001422\n",
      " Epoch 265: Train Loss: 0.001160, Validation Loss: 0.001425\n",
      " Epoch 266: Train Loss: 0.001160, Validation Loss: 0.001422\n",
      " Epoch 267: Train Loss: 0.001160, Validation Loss: 0.001422\n",
      " Epoch 268: Train Loss: 0.001159, Validation Loss: 0.001422\n",
      " Epoch 269: Train Loss: 0.001159, Validation Loss: 0.001421\n",
      " Epoch 270: Train Loss: 0.001159, Validation Loss: 0.001421\n",
      " Epoch 271: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 272: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 273: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 274: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 275: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 276: Train Loss: 0.001158, Validation Loss: 0.001421\n",
      " Epoch 277: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 278: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 279: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 280: Train Loss: 0.001157, Validation Loss: 0.001422\n",
      " Epoch 281: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 282: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 283: Train Loss: 0.001157, Validation Loss: 0.001422\n",
      " Epoch 284: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 285: Train Loss: 0.001157, Validation Loss: 0.001422\n",
      " Epoch 286: Train Loss: 0.001157, Validation Loss: 0.001421\n",
      " Epoch 287: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 288: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 289: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 290: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 291: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 292: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 293: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 294: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 295: Train Loss: 0.001156, Validation Loss: 0.001421\n",
      " Epoch 296: Train Loss: 0.001155, Validation Loss: 0.001421\n",
      " Epoch 297: Train Loss: 0.001155, Validation Loss: 0.001421\n",
      " Epoch 298: Train Loss: 0.001155, Validation Loss: 0.001422\n",
      " Epoch 299: Train Loss: 0.001155, Validation Loss: 0.001421\n",
      " Epoch 300: Train Loss: 0.001155, Validation Loss: 0.001421\n",
      " Epoch 301: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 302: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 303: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 304: Train Loss: 0.001154, Validation Loss: 0.001422\n",
      " Epoch 305: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 306: Train Loss: 0.001154, Validation Loss: 0.001422\n",
      " Epoch 307: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 308: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 309: Train Loss: 0.001154, Validation Loss: 0.001420\n",
      " Epoch 310: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 311: Train Loss: 0.001154, Validation Loss: 0.001420\n",
      " Epoch 312: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 313: Train Loss: 0.001154, Validation Loss: 0.001420\n",
      " Epoch 314: Train Loss: 0.001154, Validation Loss: 0.001421\n",
      " Epoch 315: Train Loss: 0.001154, Validation Loss: 0.001420\n",
      " Epoch 316: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 317: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 318: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 319: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 320: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 321: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 322: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 323: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 324: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 325: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 326: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 327: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 328: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 329: Train Loss: 0.001153, Validation Loss: 0.001421\n",
      " Epoch 330: Train Loss: 0.001153, Validation Loss: 0.001420\n",
      " Epoch 331: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 332: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 333: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 334: Train Loss: 0.001152, Validation Loss: 0.001421\n",
      " Epoch 335: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 336: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 337: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 338: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 339: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 340: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 341: Train Loss: 0.001152, Validation Loss: 0.001421\n",
      " Epoch 342: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 343: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      " Epoch 344: Train Loss: 0.001152, Validation Loss: 0.001420\n",
      "Early stopping at epoch 344 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.001382951159030199\n",
      "Training Time: 1568.0585088729858\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.0015183365903794765\n",
      "Training Time: 3336.388043165207\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.001385898096486926\n",
      "Training Time: 3323.3247883319855\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0014201077865436673\n",
      "Training Time: 2922.1655490398407\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate,MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(1,0.1)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/SSIM_test01_1x/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b704fc2-b90e-45d4-a90e-acabbdad11cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.134431, Validation Loss: 0.390555\n",
      " Epoch 2: Train Loss: 0.034158, Validation Loss: 0.028937\n",
      " Epoch 3: Train Loss: 0.024738, Validation Loss: 0.025623\n",
      " Epoch 4: Train Loss: 0.020408, Validation Loss: 0.020385\n",
      " Epoch 5: Train Loss: 0.018908, Validation Loss: 0.018437\n",
      " Epoch 6: Train Loss: 0.016665, Validation Loss: 0.016298\n",
      " Epoch 7: Train Loss: 0.015578, Validation Loss: 0.015241\n",
      " Epoch 8: Train Loss: 0.014633, Validation Loss: 0.014485\n",
      " Epoch 9: Train Loss: 0.014047, Validation Loss: 0.013915\n",
      " Epoch 10: Train Loss: 0.013289, Validation Loss: 0.013676\n",
      " Epoch 11: Train Loss: 0.012902, Validation Loss: 0.014238\n",
      " Epoch 12: Train Loss: 0.012255, Validation Loss: 0.012054\n",
      " Epoch 13: Train Loss: 0.011790, Validation Loss: 0.011790\n",
      " Epoch 14: Train Loss: 0.011371, Validation Loss: 0.011796\n",
      " Epoch 15: Train Loss: 0.010866, Validation Loss: 0.011627\n",
      " Epoch 16: Train Loss: 0.010821, Validation Loss: 0.012710\n",
      " Epoch 17: Train Loss: 0.010263, Validation Loss: 0.010262\n",
      " Epoch 18: Train Loss: 0.009788, Validation Loss: 0.010083\n",
      " Epoch 19: Train Loss: 0.009876, Validation Loss: 0.010115\n",
      " Epoch 20: Train Loss: 0.009374, Validation Loss: 0.009926\n",
      " Epoch 21: Train Loss: 0.009035, Validation Loss: 0.009361\n",
      " Epoch 22: Train Loss: 0.008884, Validation Loss: 0.008978\n",
      " Epoch 23: Train Loss: 0.008663, Validation Loss: 0.008883\n",
      " Epoch 24: Train Loss: 0.008386, Validation Loss: 0.008687\n",
      " Epoch 25: Train Loss: 0.008355, Validation Loss: 0.008557\n",
      " Epoch 26: Train Loss: 0.008093, Validation Loss: 0.009084\n",
      " Epoch 27: Train Loss: 0.008113, Validation Loss: 0.008166\n",
      " Epoch 28: Train Loss: 0.007817, Validation Loss: 0.008027\n",
      " Epoch 29: Train Loss: 0.007683, Validation Loss: 0.008425\n",
      " Epoch 30: Train Loss: 0.007525, Validation Loss: 0.007856\n",
      " Epoch 31: Train Loss: 0.007122, Validation Loss: 0.007626\n",
      " Epoch 32: Train Loss: 0.007025, Validation Loss: 0.007517\n",
      " Epoch 33: Train Loss: 0.006964, Validation Loss: 0.007491\n",
      " Epoch 34: Train Loss: 0.006884, Validation Loss: 0.007443\n",
      " Epoch 35: Train Loss: 0.006823, Validation Loss: 0.007373\n",
      " Epoch 36: Train Loss: 0.006771, Validation Loss: 0.007376\n",
      " Epoch 37: Train Loss: 0.006717, Validation Loss: 0.007279\n",
      " Epoch 38: Train Loss: 0.006670, Validation Loss: 0.007330\n",
      " Epoch 39: Train Loss: 0.006615, Validation Loss: 0.007268\n",
      " Epoch 40: Train Loss: 0.006551, Validation Loss: 0.007253\n",
      " Epoch 41: Train Loss: 0.006494, Validation Loss: 0.007126\n",
      " Epoch 42: Train Loss: 0.006453, Validation Loss: 0.007059\n",
      " Epoch 43: Train Loss: 0.006363, Validation Loss: 0.007128\n",
      " Epoch 44: Train Loss: 0.006342, Validation Loss: 0.006952\n",
      " Epoch 45: Train Loss: 0.006334, Validation Loss: 0.007203\n",
      " Epoch 46: Train Loss: 0.006235, Validation Loss: 0.006980\n",
      " Epoch 47: Train Loss: 0.006186, Validation Loss: 0.006944\n",
      " Epoch 48: Train Loss: 0.006167, Validation Loss: 0.006918\n",
      " Epoch 49: Train Loss: 0.006095, Validation Loss: 0.007027\n",
      " Epoch 50: Train Loss: 0.006008, Validation Loss: 0.006877\n",
      " Epoch 51: Train Loss: 0.005995, Validation Loss: 0.006705\n",
      " Epoch 52: Train Loss: 0.005964, Validation Loss: 0.006813\n",
      " Epoch 53: Train Loss: 0.005905, Validation Loss: 0.006681\n",
      " Epoch 54: Train Loss: 0.005869, Validation Loss: 0.006651\n",
      " Epoch 55: Train Loss: 0.005776, Validation Loss: 0.006768\n",
      " Epoch 56: Train Loss: 0.005750, Validation Loss: 0.006568\n",
      " Epoch 57: Train Loss: 0.005722, Validation Loss: 0.006628\n",
      " Epoch 58: Train Loss: 0.005740, Validation Loss: 0.006515\n",
      " Epoch 59: Train Loss: 0.005702, Validation Loss: 0.006523\n",
      " Epoch 60: Train Loss: 0.005634, Validation Loss: 0.006493\n",
      " Epoch 61: Train Loss: 0.005395, Validation Loss: 0.006361\n",
      " Epoch 62: Train Loss: 0.005351, Validation Loss: 0.006318\n",
      " Epoch 63: Train Loss: 0.005322, Validation Loss: 0.006431\n",
      " Epoch 64: Train Loss: 0.005294, Validation Loss: 0.006305\n",
      " Epoch 65: Train Loss: 0.005270, Validation Loss: 0.006277\n",
      " Epoch 66: Train Loss: 0.005257, Validation Loss: 0.006387\n",
      " Epoch 67: Train Loss: 0.005234, Validation Loss: 0.006391\n",
      " Epoch 68: Train Loss: 0.005204, Validation Loss: 0.006248\n",
      " Epoch 69: Train Loss: 0.005188, Validation Loss: 0.006293\n",
      " Epoch 70: Train Loss: 0.005162, Validation Loss: 0.006252\n",
      " Epoch 71: Train Loss: 0.005135, Validation Loss: 0.006290\n",
      " Epoch 72: Train Loss: 0.005120, Validation Loss: 0.006219\n",
      " Epoch 73: Train Loss: 0.005084, Validation Loss: 0.006239\n",
      " Epoch 74: Train Loss: 0.005059, Validation Loss: 0.006206\n",
      " Epoch 75: Train Loss: 0.005050, Validation Loss: 0.006223\n",
      " Epoch 76: Train Loss: 0.005037, Validation Loss: 0.006171\n",
      " Epoch 77: Train Loss: 0.005023, Validation Loss: 0.006218\n",
      " Epoch 78: Train Loss: 0.004991, Validation Loss: 0.006181\n",
      " Epoch 79: Train Loss: 0.004944, Validation Loss: 0.006186\n",
      " Epoch 80: Train Loss: 0.004939, Validation Loss: 0.006177\n",
      " Epoch 81: Train Loss: 0.004903, Validation Loss: 0.006231\n",
      " Epoch 82: Train Loss: 0.004913, Validation Loss: 0.006180\n",
      " Epoch 83: Train Loss: 0.004872, Validation Loss: 0.006182\n",
      " Epoch 84: Train Loss: 0.004838, Validation Loss: 0.006179\n",
      " Epoch 85: Train Loss: 0.004849, Validation Loss: 0.006163\n",
      " Epoch 86: Train Loss: 0.004783, Validation Loss: 0.006126\n",
      " Epoch 87: Train Loss: 0.004779, Validation Loss: 0.006354\n",
      " Epoch 88: Train Loss: 0.004751, Validation Loss: 0.006197\n",
      " Epoch 89: Train Loss: 0.004726, Validation Loss: 0.006155\n",
      " Epoch 90: Train Loss: 0.004703, Validation Loss: 0.006140\n",
      " Epoch 91: Train Loss: 0.004593, Validation Loss: 0.006093\n",
      " Epoch 92: Train Loss: 0.004567, Validation Loss: 0.006070\n",
      " Epoch 93: Train Loss: 0.004548, Validation Loss: 0.006064\n",
      " Epoch 94: Train Loss: 0.004537, Validation Loss: 0.006091\n",
      " Epoch 95: Train Loss: 0.004521, Validation Loss: 0.006063\n",
      " Epoch 96: Train Loss: 0.004505, Validation Loss: 0.006108\n",
      " Epoch 97: Train Loss: 0.004490, Validation Loss: 0.006083\n",
      " Epoch 98: Train Loss: 0.004483, Validation Loss: 0.006074\n",
      " Epoch 99: Train Loss: 0.004466, Validation Loss: 0.006090\n",
      " Epoch 100: Train Loss: 0.004454, Validation Loss: 0.006105\n",
      " Epoch 101: Train Loss: 0.004447, Validation Loss: 0.006076\n",
      " Epoch 102: Train Loss: 0.004428, Validation Loss: 0.006065\n",
      " Epoch 103: Train Loss: 0.004417, Validation Loss: 0.006098\n",
      " Epoch 104: Train Loss: 0.004416, Validation Loss: 0.006071\n",
      " Epoch 105: Train Loss: 0.004389, Validation Loss: 0.006158\n",
      " Epoch 106: Train Loss: 0.004381, Validation Loss: 0.006083\n",
      " Epoch 107: Train Loss: 0.004368, Validation Loss: 0.006092\n",
      " Epoch 108: Train Loss: 0.004352, Validation Loss: 0.006120\n",
      " Epoch 109: Train Loss: 0.004347, Validation Loss: 0.006102\n",
      " Epoch 110: Train Loss: 0.004323, Validation Loss: 0.006119\n",
      " Epoch 111: Train Loss: 0.004323, Validation Loss: 0.006105\n",
      " Epoch 112: Train Loss: 0.004297, Validation Loss: 0.006135\n",
      " Epoch 113: Train Loss: 0.004291, Validation Loss: 0.006084\n",
      " Epoch 114: Train Loss: 0.004276, Validation Loss: 0.006088\n",
      " Epoch 115: Train Loss: 0.004262, Validation Loss: 0.006093\n",
      "Early stopping at epoch 115 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.188018, Validation Loss: 0.196379\n",
      " Epoch 2: Train Loss: 0.037139, Validation Loss: 0.039551\n",
      " Epoch 3: Train Loss: 0.025059, Validation Loss: 0.023178\n",
      " Epoch 4: Train Loss: 0.020219, Validation Loss: 0.019753\n",
      " Epoch 5: Train Loss: 0.017756, Validation Loss: 0.017584\n",
      " Epoch 6: Train Loss: 0.016035, Validation Loss: 0.015774\n",
      " Epoch 7: Train Loss: 0.014975, Validation Loss: 0.014453\n",
      " Epoch 8: Train Loss: 0.013737, Validation Loss: 0.014245\n",
      " Epoch 9: Train Loss: 0.013039, Validation Loss: 0.013502\n",
      " Epoch 10: Train Loss: 0.012334, Validation Loss: 0.013036\n",
      " Epoch 11: Train Loss: 0.011648, Validation Loss: 0.011849\n",
      " Epoch 12: Train Loss: 0.012337, Validation Loss: 0.012554\n",
      " Epoch 13: Train Loss: 0.010735, Validation Loss: 0.011257\n",
      " Epoch 14: Train Loss: 0.010287, Validation Loss: 0.010572\n",
      " Epoch 15: Train Loss: 0.009954, Validation Loss: 0.010093\n",
      " Epoch 16: Train Loss: 0.009628, Validation Loss: 0.010091\n",
      " Epoch 17: Train Loss: 0.009250, Validation Loss: 0.009564\n",
      " Epoch 18: Train Loss: 0.009160, Validation Loss: 0.009862\n",
      " Epoch 19: Train Loss: 0.008803, Validation Loss: 0.009384\n",
      " Epoch 20: Train Loss: 0.008712, Validation Loss: 0.008990\n",
      " Epoch 21: Train Loss: 0.008291, Validation Loss: 0.009046\n",
      " Epoch 22: Train Loss: 0.008095, Validation Loss: 0.009327\n",
      " Epoch 23: Train Loss: 0.007944, Validation Loss: 0.008827\n",
      " Epoch 24: Train Loss: 0.007765, Validation Loss: 0.008340\n",
      " Epoch 25: Train Loss: 0.007554, Validation Loss: 0.009654\n",
      " Epoch 26: Train Loss: 0.007376, Validation Loss: 0.008295\n",
      " Epoch 27: Train Loss: 0.007296, Validation Loss: 0.007894\n",
      " Epoch 28: Train Loss: 0.007267, Validation Loss: 0.007840\n",
      " Epoch 29: Train Loss: 0.007000, Validation Loss: 0.078685\n",
      " Epoch 30: Train Loss: 0.087648, Validation Loss: 0.082410\n",
      " Epoch 31: Train Loss: 0.022432, Validation Loss: 0.021703\n",
      " Epoch 32: Train Loss: 0.017838, Validation Loss: 0.018141\n",
      " Epoch 33: Train Loss: 0.015990, Validation Loss: 0.015837\n",
      " Epoch 34: Train Loss: 0.014777, Validation Loss: 0.014698\n",
      " Epoch 35: Train Loss: 0.013756, Validation Loss: 0.013451\n",
      " Epoch 36: Train Loss: 0.012826, Validation Loss: 0.012748\n",
      " Epoch 37: Train Loss: 0.012027, Validation Loss: 0.011813\n",
      " Epoch 38: Train Loss: 0.011372, Validation Loss: 0.011226\n",
      " Epoch 39: Train Loss: 0.010843, Validation Loss: 0.010744\n",
      " Epoch 40: Train Loss: 0.010376, Validation Loss: 0.010377\n",
      " Epoch 41: Train Loss: 0.009966, Validation Loss: 0.009975\n",
      " Epoch 42: Train Loss: 0.009620, Validation Loss: 0.009635\n",
      " Epoch 43: Train Loss: 0.009308, Validation Loss: 0.009388\n",
      " Epoch 44: Train Loss: 0.009032, Validation Loss: 0.009239\n",
      " Epoch 45: Train Loss: 0.008780, Validation Loss: 0.008988\n",
      " Epoch 46: Train Loss: 0.008566, Validation Loss: 0.008754\n",
      " Epoch 47: Train Loss: 0.008375, Validation Loss: 0.008622\n",
      " Epoch 48: Train Loss: 0.008201, Validation Loss: 0.008394\n",
      "Early stopping at epoch 48 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.166116, Validation Loss: 0.231413\n",
      " Epoch 2: Train Loss: 0.045080, Validation Loss: 0.050914\n",
      " Epoch 3: Train Loss: 0.028620, Validation Loss: 0.026960\n",
      " Epoch 4: Train Loss: 0.022972, Validation Loss: 0.022019\n",
      " Epoch 5: Train Loss: 0.019490, Validation Loss: 0.020568\n",
      " Epoch 6: Train Loss: 0.017320, Validation Loss: 0.016962\n",
      " Epoch 7: Train Loss: 0.015987, Validation Loss: 0.016246\n",
      " Epoch 8: Train Loss: 0.014863, Validation Loss: 0.014721\n",
      " Epoch 9: Train Loss: 0.014023, Validation Loss: 0.014937\n",
      " Epoch 10: Train Loss: 0.013385, Validation Loss: 0.013486\n",
      " Epoch 11: Train Loss: 0.012592, Validation Loss: 0.012582\n",
      " Epoch 12: Train Loss: 0.012263, Validation Loss: 0.012506\n",
      " Epoch 13: Train Loss: 0.011715, Validation Loss: 0.011695\n",
      " Epoch 14: Train Loss: 0.011185, Validation Loss: 0.011281\n",
      " Epoch 15: Train Loss: 0.011076, Validation Loss: 0.011315\n",
      " Epoch 16: Train Loss: 0.010335, Validation Loss: 0.013267\n",
      " Epoch 17: Train Loss: 0.010124, Validation Loss: 0.010769\n",
      " Epoch 18: Train Loss: 0.010123, Validation Loss: 0.011794\n",
      " Epoch 19: Train Loss: 0.009474, Validation Loss: 0.016306\n",
      " Epoch 20: Train Loss: 0.009188, Validation Loss: 0.009360\n",
      " Epoch 21: Train Loss: 0.009040, Validation Loss: 0.011626\n",
      " Epoch 22: Train Loss: 0.008931, Validation Loss: 0.009042\n",
      " Epoch 23: Train Loss: 0.008613, Validation Loss: 0.010683\n",
      " Epoch 24: Train Loss: 0.008516, Validation Loss: 0.008647\n",
      " Epoch 25: Train Loss: 0.008126, Validation Loss: 0.008515\n",
      " Epoch 26: Train Loss: 0.008009, Validation Loss: 0.008558\n",
      " Epoch 27: Train Loss: 0.007890, Validation Loss: 0.008218\n",
      " Epoch 28: Train Loss: 0.007589, Validation Loss: 0.007914\n",
      " Epoch 29: Train Loss: 0.008632, Validation Loss: 0.021197\n",
      " Epoch 30: Train Loss: 0.007635, Validation Loss: 0.009693\n",
      " Epoch 31: Train Loss: 0.007151, Validation Loss: 0.007591\n",
      " Epoch 32: Train Loss: 0.007024, Validation Loss: 0.007708\n",
      " Epoch 33: Train Loss: 0.006938, Validation Loss: 0.007443\n",
      " Epoch 34: Train Loss: 0.006870, Validation Loss: 0.007304\n",
      " Epoch 35: Train Loss: 0.006802, Validation Loss: 0.007329\n",
      " Epoch 36: Train Loss: 0.006752, Validation Loss: 0.007291\n",
      " Epoch 37: Train Loss: 0.006694, Validation Loss: 0.007254\n",
      " Epoch 38: Train Loss: 0.006619, Validation Loss: 0.007314\n",
      " Epoch 39: Train Loss: 0.006588, Validation Loss: 0.007304\n",
      " Epoch 40: Train Loss: 0.006555, Validation Loss: 0.007066\n",
      " Epoch 41: Train Loss: 0.006479, Validation Loss: 0.007246\n",
      " Epoch 42: Train Loss: 0.006437, Validation Loss: 0.007181\n",
      " Epoch 43: Train Loss: 0.006352, Validation Loss: 0.007003\n",
      " Epoch 44: Train Loss: 0.006301, Validation Loss: 0.006878\n",
      " Epoch 45: Train Loss: 0.006258, Validation Loss: 0.006927\n",
      " Epoch 46: Train Loss: 0.006246, Validation Loss: 0.006864\n",
      " Epoch 47: Train Loss: 0.006183, Validation Loss: 0.006846\n",
      " Epoch 48: Train Loss: 0.006167, Validation Loss: 0.006789\n",
      " Epoch 49: Train Loss: 0.006059, Validation Loss: 0.006713\n",
      " Epoch 50: Train Loss: 0.006067, Validation Loss: 0.006816\n",
      " Epoch 51: Train Loss: 0.006030, Validation Loss: 0.007189\n",
      " Epoch 52: Train Loss: 0.005960, Validation Loss: 0.007116\n",
      " Epoch 53: Train Loss: 0.005973, Validation Loss: 0.006651\n",
      " Epoch 54: Train Loss: 0.005871, Validation Loss: 0.006559\n",
      " Epoch 55: Train Loss: 0.005852, Validation Loss: 0.006530\n",
      " Epoch 56: Train Loss: 0.005762, Validation Loss: 0.006847\n",
      " Epoch 57: Train Loss: 0.005716, Validation Loss: 0.006498\n",
      " Epoch 58: Train Loss: 0.005769, Validation Loss: 0.006668\n",
      " Epoch 59: Train Loss: 0.005658, Validation Loss: 0.006637\n",
      " Epoch 60: Train Loss: 0.005644, Validation Loss: 0.006613\n",
      " Epoch 61: Train Loss: 0.005438, Validation Loss: 0.006409\n",
      " Epoch 62: Train Loss: 0.005388, Validation Loss: 0.006294\n",
      " Epoch 63: Train Loss: 0.005366, Validation Loss: 0.006267\n",
      " Epoch 64: Train Loss: 0.005354, Validation Loss: 0.006331\n",
      " Epoch 65: Train Loss: 0.005336, Validation Loss: 0.006407\n",
      " Epoch 66: Train Loss: 0.005299, Validation Loss: 0.006298\n",
      " Epoch 67: Train Loss: 0.005275, Validation Loss: 0.006257\n",
      " Epoch 68: Train Loss: 0.005266, Validation Loss: 0.006303\n",
      " Epoch 69: Train Loss: 0.005235, Validation Loss: 0.006284\n",
      " Epoch 70: Train Loss: 0.005213, Validation Loss: 0.006328\n",
      " Epoch 71: Train Loss: 0.005193, Validation Loss: 0.006208\n",
      " Epoch 72: Train Loss: 0.005177, Validation Loss: 0.006342\n",
      " Epoch 73: Train Loss: 0.005148, Validation Loss: 0.006180\n",
      " Epoch 74: Train Loss: 0.005122, Validation Loss: 0.006549\n",
      " Epoch 75: Train Loss: 0.005099, Validation Loss: 0.006302\n",
      " Epoch 76: Train Loss: 0.005082, Validation Loss: 0.006204\n",
      " Epoch 77: Train Loss: 0.005074, Validation Loss: 0.006289\n",
      " Epoch 78: Train Loss: 0.005034, Validation Loss: 0.006144\n",
      " Epoch 79: Train Loss: 0.005013, Validation Loss: 0.006243\n",
      " Epoch 80: Train Loss: 0.004982, Validation Loss: 0.006143\n",
      " Epoch 81: Train Loss: 0.004971, Validation Loss: 0.006211\n",
      " Epoch 82: Train Loss: 0.004956, Validation Loss: 0.006154\n",
      " Epoch 83: Train Loss: 0.004925, Validation Loss: 0.006147\n",
      " Epoch 84: Train Loss: 0.004904, Validation Loss: 0.006208\n",
      " Epoch 85: Train Loss: 0.004889, Validation Loss: 0.006154\n",
      " Epoch 86: Train Loss: 0.004850, Validation Loss: 0.006214\n",
      " Epoch 87: Train Loss: 0.004823, Validation Loss: 0.006199\n",
      " Epoch 88: Train Loss: 0.004812, Validation Loss: 0.006161\n",
      " Epoch 89: Train Loss: 0.004788, Validation Loss: 0.006107\n",
      " Epoch 90: Train Loss: 0.004775, Validation Loss: 0.006169\n",
      " Epoch 91: Train Loss: 0.004655, Validation Loss: 0.006090\n",
      " Epoch 92: Train Loss: 0.004626, Validation Loss: 0.006069\n",
      " Epoch 93: Train Loss: 0.004612, Validation Loss: 0.006051\n",
      " Epoch 94: Train Loss: 0.004605, Validation Loss: 0.006051\n",
      " Epoch 95: Train Loss: 0.004586, Validation Loss: 0.006165\n",
      " Epoch 96: Train Loss: 0.004578, Validation Loss: 0.006110\n",
      " Epoch 97: Train Loss: 0.004567, Validation Loss: 0.006093\n",
      " Epoch 98: Train Loss: 0.004557, Validation Loss: 0.006091\n",
      " Epoch 99: Train Loss: 0.004540, Validation Loss: 0.006162\n",
      " Epoch 100: Train Loss: 0.004531, Validation Loss: 0.006070\n",
      " Epoch 101: Train Loss: 0.004513, Validation Loss: 0.006073\n",
      " Epoch 102: Train Loss: 0.004505, Validation Loss: 0.006101\n",
      " Epoch 103: Train Loss: 0.004498, Validation Loss: 0.006098\n",
      " Epoch 104: Train Loss: 0.004485, Validation Loss: 0.006210\n",
      " Epoch 105: Train Loss: 0.004466, Validation Loss: 0.006143\n",
      " Epoch 106: Train Loss: 0.004456, Validation Loss: 0.006088\n",
      " Epoch 107: Train Loss: 0.004441, Validation Loss: 0.006092\n",
      " Epoch 108: Train Loss: 0.004434, Validation Loss: 0.006088\n",
      " Epoch 109: Train Loss: 0.004408, Validation Loss: 0.006093\n",
      " Epoch 110: Train Loss: 0.004399, Validation Loss: 0.006124\n",
      " Epoch 111: Train Loss: 0.004393, Validation Loss: 0.006106\n",
      " Epoch 112: Train Loss: 0.004387, Validation Loss: 0.006088\n",
      " Epoch 113: Train Loss: 0.004356, Validation Loss: 0.006082\n",
      "Early stopping at epoch 113 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.124673, Validation Loss: 0.269782\n",
      " Epoch 2: Train Loss: 0.037175, Validation Loss: 0.054603\n",
      " Epoch 3: Train Loss: 0.026362, Validation Loss: 0.030939\n",
      " Epoch 4: Train Loss: 0.021159, Validation Loss: 0.033145\n",
      " Epoch 5: Train Loss: 0.017927, Validation Loss: 0.021063\n",
      " Epoch 6: Train Loss: 0.016507, Validation Loss: 0.017477\n",
      " Epoch 7: Train Loss: 0.015181, Validation Loss: 0.016845\n",
      " Epoch 8: Train Loss: 0.014354, Validation Loss: 0.016890\n",
      " Epoch 9: Train Loss: 0.013841, Validation Loss: 0.014822\n",
      " Epoch 10: Train Loss: 0.012962, Validation Loss: 0.013001\n",
      " Epoch 11: Train Loss: 0.012467, Validation Loss: 0.013938\n",
      " Epoch 12: Train Loss: 0.011883, Validation Loss: 0.012667\n",
      " Epoch 13: Train Loss: 0.011578, Validation Loss: 0.011550\n",
      " Epoch 14: Train Loss: 0.011018, Validation Loss: 0.013532\n",
      " Epoch 15: Train Loss: 0.010667, Validation Loss: 0.011496\n",
      " Epoch 16: Train Loss: 0.010352, Validation Loss: 0.011157\n",
      " Epoch 17: Train Loss: 0.009861, Validation Loss: 0.011117\n",
      " Epoch 18: Train Loss: 0.009823, Validation Loss: 0.009866\n",
      " Epoch 19: Train Loss: 0.009201, Validation Loss: 0.010009\n",
      " Epoch 20: Train Loss: 0.009725, Validation Loss: 0.030345\n",
      " Epoch 21: Train Loss: 0.009026, Validation Loss: 0.016431\n",
      " Epoch 22: Train Loss: 0.008815, Validation Loss: 0.010470\n",
      " Epoch 23: Train Loss: 0.008420, Validation Loss: 0.008584\n",
      " Epoch 24: Train Loss: 0.008161, Validation Loss: 0.016280\n",
      " Epoch 25: Train Loss: 0.008142, Validation Loss: 0.011759\n",
      " Epoch 26: Train Loss: 0.007924, Validation Loss: 0.008917\n",
      " Epoch 27: Train Loss: 0.007614, Validation Loss: 0.009371\n",
      " Epoch 28: Train Loss: 0.007793, Validation Loss: 0.008949\n",
      " Epoch 29: Train Loss: 0.053888, Validation Loss: 0.411434\n",
      " Epoch 30: Train Loss: 0.021744, Validation Loss: 0.018101\n",
      " Epoch 31: Train Loss: 0.016228, Validation Loss: 0.015964\n",
      " Epoch 32: Train Loss: 0.014843, Validation Loss: 0.014692\n",
      " Epoch 33: Train Loss: 0.013815, Validation Loss: 0.013581\n",
      " Epoch 34: Train Loss: 0.012973, Validation Loss: 0.012972\n",
      " Epoch 35: Train Loss: 0.012225, Validation Loss: 0.012065\n",
      " Epoch 36: Train Loss: 0.011570, Validation Loss: 0.011447\n",
      " Epoch 37: Train Loss: 0.011020, Validation Loss: 0.011061\n",
      " Epoch 38: Train Loss: 0.010569, Validation Loss: 0.010523\n",
      " Epoch 39: Train Loss: 0.010160, Validation Loss: 0.010189\n",
      " Epoch 40: Train Loss: 0.009810, Validation Loss: 0.009846\n",
      " Epoch 41: Train Loss: 0.009520, Validation Loss: 0.009641\n",
      " Epoch 42: Train Loss: 0.009231, Validation Loss: 0.009332\n",
      " Epoch 43: Train Loss: 0.009000, Validation Loss: 0.009106\n",
      "Early stopping at epoch 43 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.006062721833586693\n",
      "Training Time: 867.0390918254852\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.007840166799724102\n",
      "Training Time: 1398.19402718544\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.006050749681890011\n",
      "Training Time: 900.3930752277374\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.00858368631452322\n",
      "Training Time: 360.98468708992004\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#SSIM 0.5\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate,MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(1,0.5)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/SSIM_test01_5x/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea65891f-e92c-48c5-850e-adbc7b2ae7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.054032, Validation Loss: 0.045697\n",
      " Epoch 2: Train Loss: 0.011120, Validation Loss: 0.010547\n",
      " Epoch 3: Train Loss: 0.005477, Validation Loss: 0.004876\n",
      " Epoch 4: Train Loss: 0.004210, Validation Loss: 0.003916\n",
      " Epoch 5: Train Loss: 0.003536, Validation Loss: 0.003373\n",
      " Epoch 6: Train Loss: 0.003106, Validation Loss: 0.003050\n",
      " Epoch 7: Train Loss: 0.002823, Validation Loss: 0.002743\n",
      " Epoch 8: Train Loss: 0.002626, Validation Loss: 0.002572\n",
      " Epoch 9: Train Loss: 0.002471, Validation Loss: 0.002420\n",
      " Epoch 10: Train Loss: 0.002351, Validation Loss: 0.002371\n",
      " Epoch 11: Train Loss: 0.002249, Validation Loss: 0.002232\n",
      " Epoch 12: Train Loss: 0.002162, Validation Loss: 0.002144\n",
      " Epoch 13: Train Loss: 0.002097, Validation Loss: 0.002501\n",
      " Epoch 14: Train Loss: 0.002005, Validation Loss: 0.002060\n",
      " Epoch 15: Train Loss: 0.001940, Validation Loss: 0.001933\n",
      " Epoch 16: Train Loss: 0.001888, Validation Loss: 0.001935\n",
      " Epoch 17: Train Loss: 0.001828, Validation Loss: 0.001838\n",
      " Epoch 18: Train Loss: 0.001789, Validation Loss: 0.001789\n",
      " Epoch 19: Train Loss: 0.001732, Validation Loss: 0.001813\n",
      " Epoch 20: Train Loss: 0.001695, Validation Loss: 0.001707\n",
      " Epoch 21: Train Loss: 0.001677, Validation Loss: 0.002232\n",
      " Epoch 22: Train Loss: 0.001634, Validation Loss: 0.001651\n",
      " Epoch 23: Train Loss: 0.001579, Validation Loss: 0.001624\n",
      " Epoch 24: Train Loss: 0.001543, Validation Loss: 0.001630\n",
      " Epoch 25: Train Loss: 0.001525, Validation Loss: 0.001699\n",
      " Epoch 26: Train Loss: 0.001488, Validation Loss: 0.001544\n",
      " Epoch 27: Train Loss: 0.001475, Validation Loss: 0.001502\n",
      " Epoch 28: Train Loss: 0.001436, Validation Loss: 0.001494\n",
      " Epoch 29: Train Loss: 0.001424, Validation Loss: 0.001558\n",
      " Epoch 30: Train Loss: 0.001382, Validation Loss: 0.001463\n",
      " Epoch 31: Train Loss: 0.001344, Validation Loss: 0.001388\n",
      " Epoch 32: Train Loss: 0.001327, Validation Loss: 0.001375\n",
      " Epoch 33: Train Loss: 0.001314, Validation Loss: 0.001364\n",
      " Epoch 34: Train Loss: 0.001300, Validation Loss: 0.001358\n",
      " Epoch 35: Train Loss: 0.001288, Validation Loss: 0.001341\n",
      " Epoch 36: Train Loss: 0.001276, Validation Loss: 0.001332\n",
      " Epoch 37: Train Loss: 0.001266, Validation Loss: 0.001319\n",
      " Epoch 38: Train Loss: 0.001255, Validation Loss: 0.001314\n",
      " Epoch 39: Train Loss: 0.001245, Validation Loss: 0.001298\n",
      " Epoch 40: Train Loss: 0.001234, Validation Loss: 0.001299\n",
      " Epoch 41: Train Loss: 0.001216, Validation Loss: 0.001270\n",
      " Epoch 42: Train Loss: 0.001210, Validation Loss: 0.001261\n",
      " Epoch 43: Train Loss: 0.001194, Validation Loss: 0.001299\n",
      " Epoch 44: Train Loss: 0.001184, Validation Loss: 0.001256\n",
      " Epoch 45: Train Loss: 0.001173, Validation Loss: 0.001224\n",
      " Epoch 46: Train Loss: 0.001164, Validation Loss: 0.001219\n",
      " Epoch 47: Train Loss: 0.001150, Validation Loss: 0.001222\n",
      " Epoch 48: Train Loss: 0.001141, Validation Loss: 0.001210\n",
      " Epoch 49: Train Loss: 0.001125, Validation Loss: 0.001215\n",
      " Epoch 50: Train Loss: 0.001113, Validation Loss: 0.001211\n",
      " Epoch 51: Train Loss: 0.001106, Validation Loss: 0.001172\n",
      " Epoch 52: Train Loss: 0.001095, Validation Loss: 0.001148\n",
      " Epoch 53: Train Loss: 0.001083, Validation Loss: 0.001144\n",
      " Epoch 54: Train Loss: 0.001078, Validation Loss: 0.001132\n",
      " Epoch 55: Train Loss: 0.001062, Validation Loss: 0.001154\n",
      " Epoch 56: Train Loss: 0.001051, Validation Loss: 0.001115\n",
      " Epoch 57: Train Loss: 0.001046, Validation Loss: 0.001127\n",
      " Epoch 58: Train Loss: 0.001035, Validation Loss: 0.001094\n",
      " Epoch 59: Train Loss: 0.001031, Validation Loss: 0.001082\n",
      " Epoch 60: Train Loss: 0.001025, Validation Loss: 0.001084\n",
      " Epoch 61: Train Loss: 0.000990, Validation Loss: 0.001069\n",
      " Epoch 62: Train Loss: 0.000984, Validation Loss: 0.001061\n",
      " Epoch 63: Train Loss: 0.000978, Validation Loss: 0.001056\n",
      " Epoch 64: Train Loss: 0.000973, Validation Loss: 0.001057\n",
      " Epoch 65: Train Loss: 0.000967, Validation Loss: 0.001041\n",
      " Epoch 66: Train Loss: 0.000963, Validation Loss: 0.001047\n",
      " Epoch 67: Train Loss: 0.000960, Validation Loss: 0.001040\n",
      " Epoch 68: Train Loss: 0.000954, Validation Loss: 0.001031\n",
      " Epoch 69: Train Loss: 0.000950, Validation Loss: 0.001026\n",
      " Epoch 70: Train Loss: 0.000944, Validation Loss: 0.001024\n",
      " Epoch 71: Train Loss: 0.000939, Validation Loss: 0.001026\n",
      " Epoch 72: Train Loss: 0.000936, Validation Loss: 0.001016\n",
      " Epoch 73: Train Loss: 0.000930, Validation Loss: 0.001010\n",
      " Epoch 74: Train Loss: 0.000926, Validation Loss: 0.001010\n",
      " Epoch 75: Train Loss: 0.000922, Validation Loss: 0.001005\n",
      " Epoch 76: Train Loss: 0.000919, Validation Loss: 0.000996\n",
      " Epoch 77: Train Loss: 0.000917, Validation Loss: 0.001005\n",
      " Epoch 78: Train Loss: 0.000910, Validation Loss: 0.000993\n",
      " Epoch 79: Train Loss: 0.000905, Validation Loss: 0.000985\n",
      " Epoch 80: Train Loss: 0.000901, Validation Loss: 0.000995\n",
      " Epoch 81: Train Loss: 0.000895, Validation Loss: 0.000991\n",
      " Epoch 82: Train Loss: 0.000895, Validation Loss: 0.000976\n",
      " Epoch 83: Train Loss: 0.000890, Validation Loss: 0.000979\n",
      " Epoch 84: Train Loss: 0.000884, Validation Loss: 0.000987\n",
      " Epoch 85: Train Loss: 0.000884, Validation Loss: 0.000964\n",
      " Epoch 86: Train Loss: 0.000873, Validation Loss: 0.000963\n",
      " Epoch 87: Train Loss: 0.000875, Validation Loss: 0.000994\n",
      " Epoch 88: Train Loss: 0.000876, Validation Loss: 0.000956\n",
      " Epoch 89: Train Loss: 0.000864, Validation Loss: 0.000953\n",
      " Epoch 90: Train Loss: 0.000859, Validation Loss: 0.000955\n",
      " Epoch 91: Train Loss: 0.000850, Validation Loss: 0.000942\n",
      " Epoch 92: Train Loss: 0.000848, Validation Loss: 0.000939\n",
      " Epoch 93: Train Loss: 0.000844, Validation Loss: 0.000938\n",
      " Epoch 94: Train Loss: 0.000842, Validation Loss: 0.000936\n",
      " Epoch 95: Train Loss: 0.000839, Validation Loss: 0.000934\n",
      " Epoch 96: Train Loss: 0.000837, Validation Loss: 0.000934\n",
      " Epoch 97: Train Loss: 0.000835, Validation Loss: 0.000933\n",
      " Epoch 98: Train Loss: 0.000834, Validation Loss: 0.000931\n",
      " Epoch 99: Train Loss: 0.000831, Validation Loss: 0.000930\n",
      " Epoch 100: Train Loss: 0.000829, Validation Loss: 0.000926\n",
      " Epoch 101: Train Loss: 0.000827, Validation Loss: 0.000927\n",
      " Epoch 102: Train Loss: 0.000825, Validation Loss: 0.000922\n",
      " Epoch 103: Train Loss: 0.000823, Validation Loss: 0.000922\n",
      " Epoch 104: Train Loss: 0.000824, Validation Loss: 0.000925\n",
      " Epoch 105: Train Loss: 0.000818, Validation Loss: 0.000924\n",
      " Epoch 106: Train Loss: 0.000817, Validation Loss: 0.000917\n",
      " Epoch 107: Train Loss: 0.000815, Validation Loss: 0.000919\n",
      " Epoch 108: Train Loss: 0.000813, Validation Loss: 0.000923\n",
      " Epoch 109: Train Loss: 0.000812, Validation Loss: 0.000916\n",
      " Epoch 110: Train Loss: 0.000809, Validation Loss: 0.000920\n",
      " Epoch 111: Train Loss: 0.000808, Validation Loss: 0.000915\n",
      " Epoch 112: Train Loss: 0.000804, Validation Loss: 0.000906\n",
      " Epoch 113: Train Loss: 0.000803, Validation Loss: 0.000914\n",
      " Epoch 114: Train Loss: 0.000801, Validation Loss: 0.000908\n",
      " Epoch 115: Train Loss: 0.000800, Validation Loss: 0.000905\n",
      " Epoch 116: Train Loss: 0.000797, Validation Loss: 0.000902\n",
      " Epoch 117: Train Loss: 0.000792, Validation Loss: 0.000903\n",
      " Epoch 118: Train Loss: 0.000792, Validation Loss: 0.000909\n",
      " Epoch 119: Train Loss: 0.000791, Validation Loss: 0.000902\n",
      " Epoch 120: Train Loss: 0.000789, Validation Loss: 0.000903\n",
      " Epoch 121: Train Loss: 0.000782, Validation Loss: 0.000896\n",
      " Epoch 122: Train Loss: 0.000779, Validation Loss: 0.000895\n",
      " Epoch 123: Train Loss: 0.000778, Validation Loss: 0.000891\n",
      " Epoch 124: Train Loss: 0.000777, Validation Loss: 0.000890\n",
      " Epoch 125: Train Loss: 0.000776, Validation Loss: 0.000892\n",
      " Epoch 126: Train Loss: 0.000774, Validation Loss: 0.000889\n",
      " Epoch 127: Train Loss: 0.000773, Validation Loss: 0.000890\n",
      " Epoch 128: Train Loss: 0.000772, Validation Loss: 0.000889\n",
      " Epoch 129: Train Loss: 0.000772, Validation Loss: 0.000892\n",
      " Epoch 130: Train Loss: 0.000771, Validation Loss: 0.000888\n",
      " Epoch 131: Train Loss: 0.000770, Validation Loss: 0.000887\n",
      " Epoch 132: Train Loss: 0.000769, Validation Loss: 0.000885\n",
      " Epoch 133: Train Loss: 0.000766, Validation Loss: 0.000883\n",
      " Epoch 134: Train Loss: 0.000767, Validation Loss: 0.000887\n",
      " Epoch 135: Train Loss: 0.000765, Validation Loss: 0.000883\n",
      " Epoch 136: Train Loss: 0.000763, Validation Loss: 0.000883\n",
      " Epoch 137: Train Loss: 0.000762, Validation Loss: 0.000882\n",
      " Epoch 138: Train Loss: 0.000761, Validation Loss: 0.000879\n",
      " Epoch 139: Train Loss: 0.000760, Validation Loss: 0.000879\n",
      " Epoch 140: Train Loss: 0.000759, Validation Loss: 0.000878\n",
      " Epoch 141: Train Loss: 0.000757, Validation Loss: 0.000878\n",
      " Epoch 142: Train Loss: 0.000756, Validation Loss: 0.000876\n",
      " Epoch 143: Train Loss: 0.000755, Validation Loss: 0.000877\n",
      " Epoch 144: Train Loss: 0.000753, Validation Loss: 0.000877\n",
      " Epoch 145: Train Loss: 0.000753, Validation Loss: 0.000876\n",
      " Epoch 146: Train Loss: 0.000751, Validation Loss: 0.000882\n",
      " Epoch 147: Train Loss: 0.000749, Validation Loss: 0.000877\n",
      " Epoch 148: Train Loss: 0.000749, Validation Loss: 0.000874\n",
      " Epoch 149: Train Loss: 0.000748, Validation Loss: 0.000875\n",
      " Epoch 150: Train Loss: 0.000745, Validation Loss: 0.000871\n",
      " Epoch 151: Train Loss: 0.000741, Validation Loss: 0.000869\n",
      " Epoch 152: Train Loss: 0.000740, Validation Loss: 0.000870\n",
      " Epoch 153: Train Loss: 0.000740, Validation Loss: 0.000869\n",
      " Epoch 154: Train Loss: 0.000741, Validation Loss: 0.000871\n",
      " Epoch 155: Train Loss: 0.000738, Validation Loss: 0.000868\n",
      " Epoch 156: Train Loss: 0.000738, Validation Loss: 0.000868\n",
      " Epoch 157: Train Loss: 0.000737, Validation Loss: 0.000867\n",
      " Epoch 158: Train Loss: 0.000736, Validation Loss: 0.000867\n",
      " Epoch 159: Train Loss: 0.000736, Validation Loss: 0.000869\n",
      " Epoch 160: Train Loss: 0.000735, Validation Loss: 0.000869\n",
      " Epoch 161: Train Loss: 0.000734, Validation Loss: 0.000868\n",
      " Epoch 162: Train Loss: 0.000734, Validation Loss: 0.000866\n",
      " Epoch 163: Train Loss: 0.000732, Validation Loss: 0.000865\n",
      " Epoch 164: Train Loss: 0.000732, Validation Loss: 0.000866\n",
      " Epoch 165: Train Loss: 0.000732, Validation Loss: 0.000865\n",
      " Epoch 166: Train Loss: 0.000730, Validation Loss: 0.000864\n",
      " Epoch 167: Train Loss: 0.000730, Validation Loss: 0.000867\n",
      " Epoch 168: Train Loss: 0.000729, Validation Loss: 0.000864\n",
      " Epoch 169: Train Loss: 0.000728, Validation Loss: 0.000864\n",
      " Epoch 170: Train Loss: 0.000727, Validation Loss: 0.000866\n",
      " Epoch 171: Train Loss: 0.000727, Validation Loss: 0.000864\n",
      " Epoch 172: Train Loss: 0.000726, Validation Loss: 0.000863\n",
      " Epoch 173: Train Loss: 0.000725, Validation Loss: 0.000862\n",
      " Epoch 174: Train Loss: 0.000724, Validation Loss: 0.000862\n",
      " Epoch 175: Train Loss: 0.000725, Validation Loss: 0.000864\n",
      " Epoch 176: Train Loss: 0.000723, Validation Loss: 0.000863\n",
      " Epoch 177: Train Loss: 0.000722, Validation Loss: 0.000862\n",
      " Epoch 178: Train Loss: 0.000723, Validation Loss: 0.000861\n",
      " Epoch 179: Train Loss: 0.000721, Validation Loss: 0.000860\n",
      " Epoch 180: Train Loss: 0.000720, Validation Loss: 0.000861\n",
      " Epoch 181: Train Loss: 0.000717, Validation Loss: 0.000859\n",
      " Epoch 182: Train Loss: 0.000717, Validation Loss: 0.000859\n",
      " Epoch 183: Train Loss: 0.000716, Validation Loss: 0.000859\n",
      " Epoch 184: Train Loss: 0.000716, Validation Loss: 0.000859\n",
      " Epoch 185: Train Loss: 0.000715, Validation Loss: 0.000858\n",
      " Epoch 186: Train Loss: 0.000715, Validation Loss: 0.000858\n",
      " Epoch 187: Train Loss: 0.000714, Validation Loss: 0.000858\n",
      " Epoch 188: Train Loss: 0.000714, Validation Loss: 0.000858\n",
      " Epoch 189: Train Loss: 0.000713, Validation Loss: 0.000859\n",
      " Epoch 190: Train Loss: 0.000713, Validation Loss: 0.000858\n",
      " Epoch 191: Train Loss: 0.000713, Validation Loss: 0.000857\n",
      " Epoch 192: Train Loss: 0.000712, Validation Loss: 0.000858\n",
      " Epoch 193: Train Loss: 0.000712, Validation Loss: 0.000859\n",
      " Epoch 194: Train Loss: 0.000711, Validation Loss: 0.000857\n",
      " Epoch 195: Train Loss: 0.000711, Validation Loss: 0.000857\n",
      " Epoch 196: Train Loss: 0.000710, Validation Loss: 0.000856\n",
      " Epoch 197: Train Loss: 0.000710, Validation Loss: 0.000857\n",
      " Epoch 198: Train Loss: 0.000710, Validation Loss: 0.000857\n",
      " Epoch 199: Train Loss: 0.000709, Validation Loss: 0.000856\n",
      " Epoch 200: Train Loss: 0.000708, Validation Loss: 0.000856\n",
      " Epoch 201: Train Loss: 0.000708, Validation Loss: 0.000857\n",
      " Epoch 202: Train Loss: 0.000708, Validation Loss: 0.000856\n",
      " Epoch 203: Train Loss: 0.000707, Validation Loss: 0.000855\n",
      " Epoch 204: Train Loss: 0.000707, Validation Loss: 0.000856\n",
      " Epoch 205: Train Loss: 0.000706, Validation Loss: 0.000855\n",
      " Epoch 206: Train Loss: 0.000706, Validation Loss: 0.000856\n",
      " Epoch 207: Train Loss: 0.000706, Validation Loss: 0.000855\n",
      " Epoch 208: Train Loss: 0.000705, Validation Loss: 0.000855\n",
      " Epoch 209: Train Loss: 0.000704, Validation Loss: 0.000855\n",
      " Epoch 210: Train Loss: 0.000704, Validation Loss: 0.000855\n",
      " Epoch 211: Train Loss: 0.000702, Validation Loss: 0.000854\n",
      " Epoch 212: Train Loss: 0.000702, Validation Loss: 0.000854\n",
      " Epoch 213: Train Loss: 0.000701, Validation Loss: 0.000854\n",
      " Epoch 214: Train Loss: 0.000701, Validation Loss: 0.000853\n",
      " Epoch 215: Train Loss: 0.000701, Validation Loss: 0.000855\n",
      " Epoch 216: Train Loss: 0.000701, Validation Loss: 0.000853\n",
      " Epoch 217: Train Loss: 0.000700, Validation Loss: 0.000854\n",
      " Epoch 218: Train Loss: 0.000700, Validation Loss: 0.000853\n",
      " Epoch 219: Train Loss: 0.000700, Validation Loss: 0.000853\n",
      " Epoch 220: Train Loss: 0.000700, Validation Loss: 0.000854\n",
      " Epoch 221: Train Loss: 0.000699, Validation Loss: 0.000853\n",
      " Epoch 222: Train Loss: 0.000699, Validation Loss: 0.000854\n",
      " Epoch 223: Train Loss: 0.000699, Validation Loss: 0.000853\n",
      " Epoch 224: Train Loss: 0.000699, Validation Loss: 0.000853\n",
      " Epoch 225: Train Loss: 0.000698, Validation Loss: 0.000853\n",
      " Epoch 226: Train Loss: 0.000698, Validation Loss: 0.000853\n",
      " Epoch 227: Train Loss: 0.000698, Validation Loss: 0.000853\n",
      " Epoch 228: Train Loss: 0.000698, Validation Loss: 0.000853\n",
      " Epoch 229: Train Loss: 0.000697, Validation Loss: 0.000853\n",
      " Epoch 230: Train Loss: 0.000697, Validation Loss: 0.000853\n",
      " Epoch 231: Train Loss: 0.000697, Validation Loss: 0.000852\n",
      " Epoch 232: Train Loss: 0.000697, Validation Loss: 0.000853\n",
      " Epoch 233: Train Loss: 0.000697, Validation Loss: 0.000854\n",
      " Epoch 234: Train Loss: 0.000696, Validation Loss: 0.000852\n",
      " Epoch 235: Train Loss: 0.000696, Validation Loss: 0.000852\n",
      " Epoch 236: Train Loss: 0.000695, Validation Loss: 0.000852\n",
      " Epoch 237: Train Loss: 0.000695, Validation Loss: 0.000852\n",
      " Epoch 238: Train Loss: 0.000695, Validation Loss: 0.000853\n",
      " Epoch 239: Train Loss: 0.000695, Validation Loss: 0.000853\n",
      " Epoch 240: Train Loss: 0.000694, Validation Loss: 0.000852\n",
      " Epoch 241: Train Loss: 0.000693, Validation Loss: 0.000852\n",
      " Epoch 242: Train Loss: 0.000693, Validation Loss: 0.000852\n",
      " Epoch 243: Train Loss: 0.000693, Validation Loss: 0.000851\n",
      " Epoch 244: Train Loss: 0.000693, Validation Loss: 0.000852\n",
      " Epoch 245: Train Loss: 0.000693, Validation Loss: 0.000851\n",
      " Epoch 246: Train Loss: 0.000692, Validation Loss: 0.000852\n",
      " Epoch 247: Train Loss: 0.000692, Validation Loss: 0.000852\n",
      " Epoch 248: Train Loss: 0.000693, Validation Loss: 0.000852\n",
      " Epoch 249: Train Loss: 0.000692, Validation Loss: 0.000852\n",
      " Epoch 250: Train Loss: 0.000692, Validation Loss: 0.000851\n",
      " Epoch 251: Train Loss: 0.000692, Validation Loss: 0.000851\n",
      " Epoch 252: Train Loss: 0.000692, Validation Loss: 0.000852\n",
      " Epoch 253: Train Loss: 0.000692, Validation Loss: 0.000851\n",
      " Epoch 254: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 255: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 256: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 257: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 258: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 259: Train Loss: 0.000691, Validation Loss: 0.000851\n",
      " Epoch 260: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 261: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 262: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 263: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 264: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 265: Train Loss: 0.000690, Validation Loss: 0.000851\n",
      " Epoch 266: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 267: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 268: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 269: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 270: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 271: Train Loss: 0.000689, Validation Loss: 0.000851\n",
      " Epoch 272: Train Loss: 0.000688, Validation Loss: 0.000851\n",
      " Epoch 273: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 274: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 275: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 276: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 277: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 278: Train Loss: 0.000688, Validation Loss: 0.000851\n",
      " Epoch 279: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 280: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 281: Train Loss: 0.000688, Validation Loss: 0.000850\n",
      " Epoch 282: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 283: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 284: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 285: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 286: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 287: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 288: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 289: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 290: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 291: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 292: Train Loss: 0.000687, Validation Loss: 0.000850\n",
      " Epoch 293: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 294: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 295: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 296: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 297: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 298: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 299: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 300: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 301: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 302: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 303: Train Loss: 0.000686, Validation Loss: 0.000850\n",
      " Epoch 304: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 305: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 306: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 307: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 308: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 309: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 310: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 311: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 312: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 313: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 314: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 315: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 316: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 317: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 318: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 319: Train Loss: 0.000685, Validation Loss: 0.000849\n",
      " Epoch 320: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 321: Train Loss: 0.000685, Validation Loss: 0.000849\n",
      " Epoch 322: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 323: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 324: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 325: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 326: Train Loss: 0.000685, Validation Loss: 0.000850\n",
      " Epoch 327: Train Loss: 0.000685, Validation Loss: 0.000849\n",
      " Epoch 328: Train Loss: 0.000684, Validation Loss: 0.000850\n",
      " Epoch 329: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 330: Train Loss: 0.000684, Validation Loss: 0.000850\n",
      " Epoch 331: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 332: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 333: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 334: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 335: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 336: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 337: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 338: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 339: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 340: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 341: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 342: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 343: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 344: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 345: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 346: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 347: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 348: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 349: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 350: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 351: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 352: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 353: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 354: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 355: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 356: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 357: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 358: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 359: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 360: Train Loss: 0.000684, Validation Loss: 0.000849\n",
      " Epoch 361: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 362: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 363: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 364: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 365: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 366: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 367: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 368: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 369: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 370: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 371: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 372: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 373: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 374: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 375: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 376: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 377: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 378: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 379: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 380: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 381: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 382: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 383: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 384: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 385: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 386: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 387: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 388: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 389: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 390: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 391: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 392: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 393: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 394: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 395: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 396: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 397: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 398: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 399: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 400: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 401: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 402: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 403: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 404: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 405: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 406: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 407: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 408: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 409: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 410: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 411: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 412: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 413: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 414: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 415: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 416: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 417: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 418: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 419: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 420: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 421: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 422: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 423: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 424: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 425: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 426: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 427: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 428: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 429: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 430: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 431: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 432: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 433: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 434: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 435: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 436: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 437: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 438: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 439: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      " Epoch 440: Train Loss: 0.000683, Validation Loss: 0.000849\n",
      "Early stopping at epoch 440 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.055584, Validation Loss: 0.064480\n",
      " Epoch 2: Train Loss: 0.033476, Validation Loss: 0.051727\n",
      " Epoch 3: Train Loss: 0.009117, Validation Loss: 0.006573\n",
      " Epoch 4: Train Loss: 0.004705, Validation Loss: 0.004141\n",
      " Epoch 5: Train Loss: 0.003606, Validation Loss: 0.003326\n",
      " Epoch 6: Train Loss: 0.003095, Validation Loss: 0.002980\n",
      " Epoch 7: Train Loss: 0.002776, Validation Loss: 0.002670\n",
      " Epoch 8: Train Loss: 0.002604, Validation Loss: 0.002542\n",
      " Epoch 9: Train Loss: 0.002381, Validation Loss: 0.002390\n",
      " Epoch 10: Train Loss: 0.002248, Validation Loss: 0.002246\n",
      " Epoch 11: Train Loss: 0.004630, Validation Loss: 0.005182\n",
      " Epoch 12: Train Loss: 0.002692, Validation Loss: 0.002466\n",
      " Epoch 13: Train Loss: 0.002268, Validation Loss: 0.002239\n",
      " Epoch 14: Train Loss: 0.002111, Validation Loss: 0.002117\n",
      " Epoch 15: Train Loss: 0.002010, Validation Loss: 0.002061\n",
      " Epoch 16: Train Loss: 0.001931, Validation Loss: 0.001929\n",
      " Epoch 17: Train Loss: 0.001863, Validation Loss: 0.001879\n",
      " Epoch 18: Train Loss: 0.001807, Validation Loss: 0.001815\n",
      " Epoch 19: Train Loss: 0.001752, Validation Loss: 0.001786\n",
      " Epoch 20: Train Loss: 0.001708, Validation Loss: 0.001731\n",
      " Epoch 21: Train Loss: 0.001664, Validation Loss: 0.001684\n",
      " Epoch 22: Train Loss: 0.001620, Validation Loss: 0.001650\n",
      " Epoch 23: Train Loss: 0.001588, Validation Loss: 0.001620\n",
      " Epoch 24: Train Loss: 0.001555, Validation Loss: 0.001703\n",
      " Epoch 25: Train Loss: 0.001520, Validation Loss: 0.001574\n",
      " Epoch 26: Train Loss: 0.001483, Validation Loss: 0.001518\n",
      " Epoch 27: Train Loss: 0.001454, Validation Loss: 0.001478\n",
      " Epoch 28: Train Loss: 0.001426, Validation Loss: 0.001518\n",
      " Epoch 29: Train Loss: 0.001406, Validation Loss: 0.001426\n",
      " Epoch 30: Train Loss: 0.001374, Validation Loss: 0.001411\n",
      " Epoch 31: Train Loss: 0.001332, Validation Loss: 0.001384\n",
      " Epoch 32: Train Loss: 0.001318, Validation Loss: 0.001369\n",
      " Epoch 33: Train Loss: 0.001303, Validation Loss: 0.001359\n",
      " Epoch 34: Train Loss: 0.001296, Validation Loss: 0.001359\n",
      " Epoch 35: Train Loss: 0.001281, Validation Loss: 0.001341\n",
      " Epoch 36: Train Loss: 0.001268, Validation Loss: 0.001328\n",
      " Epoch 37: Train Loss: 0.001254, Validation Loss: 0.001319\n",
      " Epoch 38: Train Loss: 0.001243, Validation Loss: 0.001307\n",
      " Epoch 39: Train Loss: 0.001233, Validation Loss: 0.001293\n",
      " Epoch 40: Train Loss: 0.001229, Validation Loss: 0.001286\n",
      " Epoch 41: Train Loss: 0.001210, Validation Loss: 0.001277\n",
      " Epoch 42: Train Loss: 0.001198, Validation Loss: 0.001268\n",
      " Epoch 43: Train Loss: 0.001190, Validation Loss: 0.001265\n",
      " Epoch 44: Train Loss: 0.001180, Validation Loss: 0.001249\n",
      " Epoch 45: Train Loss: 0.001167, Validation Loss: 0.001255\n",
      " Epoch 46: Train Loss: 0.001160, Validation Loss: 0.001237\n",
      " Epoch 47: Train Loss: 0.001150, Validation Loss: 0.001226\n",
      " Epoch 48: Train Loss: 0.001137, Validation Loss: 0.001227\n",
      " Epoch 49: Train Loss: 0.001130, Validation Loss: 0.001207\n",
      " Epoch 50: Train Loss: 0.001116, Validation Loss: 0.001237\n",
      " Epoch 51: Train Loss: 0.001107, Validation Loss: 0.001178\n",
      " Epoch 52: Train Loss: 0.001098, Validation Loss: 0.001191\n",
      " Epoch 53: Train Loss: 0.001082, Validation Loss: 0.001171\n",
      " Epoch 54: Train Loss: 0.001078, Validation Loss: 0.001157\n",
      " Epoch 55: Train Loss: 0.001064, Validation Loss: 0.001163\n",
      " Epoch 56: Train Loss: 0.001067, Validation Loss: 0.001163\n",
      " Epoch 57: Train Loss: 0.001047, Validation Loss: 0.001146\n",
      " Epoch 58: Train Loss: 0.001049, Validation Loss: 0.001193\n",
      " Epoch 59: Train Loss: 0.001031, Validation Loss: 0.001135\n",
      " Epoch 60: Train Loss: 0.001033, Validation Loss: 0.001123\n",
      " Epoch 61: Train Loss: 0.001002, Validation Loss: 0.001101\n",
      " Epoch 62: Train Loss: 0.000994, Validation Loss: 0.001099\n",
      " Epoch 63: Train Loss: 0.000989, Validation Loss: 0.001097\n",
      " Epoch 64: Train Loss: 0.000984, Validation Loss: 0.001099\n",
      " Epoch 65: Train Loss: 0.000980, Validation Loss: 0.001089\n",
      " Epoch 66: Train Loss: 0.000980, Validation Loss: 0.001085\n",
      " Epoch 67: Train Loss: 0.000969, Validation Loss: 0.001086\n",
      " Epoch 68: Train Loss: 0.000965, Validation Loss: 0.001078\n",
      " Epoch 69: Train Loss: 0.000963, Validation Loss: 0.001078\n",
      " Epoch 70: Train Loss: 0.000957, Validation Loss: 0.001079\n",
      " Epoch 71: Train Loss: 0.000952, Validation Loss: 0.001066\n",
      " Epoch 72: Train Loss: 0.000947, Validation Loss: 0.001073\n",
      " Epoch 73: Train Loss: 0.000942, Validation Loss: 0.001062\n",
      " Epoch 74: Train Loss: 0.000937, Validation Loss: 0.001066\n",
      " Epoch 75: Train Loss: 0.000932, Validation Loss: 0.001066\n",
      " Epoch 76: Train Loss: 0.000928, Validation Loss: 0.001057\n",
      " Epoch 77: Train Loss: 0.000925, Validation Loss: 0.001072\n",
      " Epoch 78: Train Loss: 0.000921, Validation Loss: 0.001047\n",
      " Epoch 79: Train Loss: 0.000914, Validation Loss: 0.001061\n",
      " Epoch 80: Train Loss: 0.000914, Validation Loss: 0.001051\n",
      " Epoch 81: Train Loss: 0.000905, Validation Loss: 0.001048\n",
      " Epoch 82: Train Loss: 0.000898, Validation Loss: 0.001034\n",
      " Epoch 83: Train Loss: 0.000891, Validation Loss: 0.001035\n",
      " Epoch 84: Train Loss: 0.000891, Validation Loss: 0.001055\n",
      " Epoch 85: Train Loss: 0.000890, Validation Loss: 0.001032\n",
      " Epoch 86: Train Loss: 0.000882, Validation Loss: 0.001026\n",
      " Epoch 87: Train Loss: 0.000874, Validation Loss: 0.001025\n",
      " Epoch 88: Train Loss: 0.000870, Validation Loss: 0.001029\n",
      " Epoch 89: Train Loss: 0.000864, Validation Loss: 0.001024\n",
      " Epoch 90: Train Loss: 0.000863, Validation Loss: 0.001020\n",
      " Epoch 91: Train Loss: 0.000844, Validation Loss: 0.001011\n",
      " Epoch 92: Train Loss: 0.000838, Validation Loss: 0.001014\n",
      " Epoch 93: Train Loss: 0.000837, Validation Loss: 0.001012\n",
      " Epoch 94: Train Loss: 0.000833, Validation Loss: 0.001009\n",
      " Epoch 95: Train Loss: 0.000833, Validation Loss: 0.001017\n",
      " Epoch 96: Train Loss: 0.000829, Validation Loss: 0.001007\n",
      " Epoch 97: Train Loss: 0.000824, Validation Loss: 0.001008\n",
      " Epoch 98: Train Loss: 0.000823, Validation Loss: 0.001006\n",
      " Epoch 99: Train Loss: 0.000820, Validation Loss: 0.001008\n",
      " Epoch 100: Train Loss: 0.000817, Validation Loss: 0.001004\n",
      " Epoch 101: Train Loss: 0.000814, Validation Loss: 0.001002\n",
      " Epoch 102: Train Loss: 0.000811, Validation Loss: 0.001010\n",
      " Epoch 103: Train Loss: 0.000811, Validation Loss: 0.001001\n",
      " Epoch 104: Train Loss: 0.000806, Validation Loss: 0.001001\n",
      " Epoch 105: Train Loss: 0.000803, Validation Loss: 0.001003\n",
      " Epoch 106: Train Loss: 0.000799, Validation Loss: 0.001001\n",
      " Epoch 107: Train Loss: 0.000795, Validation Loss: 0.001002\n",
      " Epoch 108: Train Loss: 0.000794, Validation Loss: 0.001011\n",
      " Epoch 109: Train Loss: 0.000790, Validation Loss: 0.000998\n",
      " Epoch 110: Train Loss: 0.000787, Validation Loss: 0.000999\n",
      " Epoch 111: Train Loss: 0.000784, Validation Loss: 0.001007\n",
      " Epoch 112: Train Loss: 0.000781, Validation Loss: 0.000997\n",
      " Epoch 113: Train Loss: 0.000779, Validation Loss: 0.000993\n",
      " Epoch 114: Train Loss: 0.000773, Validation Loss: 0.000996\n",
      " Epoch 115: Train Loss: 0.000771, Validation Loss: 0.000998\n",
      " Epoch 116: Train Loss: 0.000770, Validation Loss: 0.000995\n",
      " Epoch 117: Train Loss: 0.000765, Validation Loss: 0.000993\n",
      " Epoch 118: Train Loss: 0.000762, Validation Loss: 0.001001\n",
      " Epoch 119: Train Loss: 0.000761, Validation Loss: 0.001000\n",
      " Epoch 120: Train Loss: 0.000757, Validation Loss: 0.001007\n",
      " Epoch 121: Train Loss: 0.000745, Validation Loss: 0.000991\n",
      " Epoch 122: Train Loss: 0.000742, Validation Loss: 0.000991\n",
      " Epoch 123: Train Loss: 0.000740, Validation Loss: 0.000993\n",
      " Epoch 124: Train Loss: 0.000739, Validation Loss: 0.000992\n",
      " Epoch 125: Train Loss: 0.000737, Validation Loss: 0.000996\n",
      " Epoch 126: Train Loss: 0.000735, Validation Loss: 0.000992\n",
      " Epoch 127: Train Loss: 0.000733, Validation Loss: 0.000989\n",
      " Epoch 128: Train Loss: 0.000731, Validation Loss: 0.000991\n",
      " Epoch 129: Train Loss: 0.000729, Validation Loss: 0.000992\n",
      " Epoch 130: Train Loss: 0.000728, Validation Loss: 0.000993\n",
      " Epoch 131: Train Loss: 0.000726, Validation Loss: 0.000991\n",
      " Epoch 132: Train Loss: 0.000724, Validation Loss: 0.000992\n",
      " Epoch 133: Train Loss: 0.000723, Validation Loss: 0.000990\n",
      " Epoch 134: Train Loss: 0.000721, Validation Loss: 0.000993\n",
      " Epoch 135: Train Loss: 0.000719, Validation Loss: 0.000992\n",
      " Epoch 136: Train Loss: 0.000718, Validation Loss: 0.000991\n",
      " Epoch 137: Train Loss: 0.000716, Validation Loss: 0.000995\n",
      " Epoch 138: Train Loss: 0.000714, Validation Loss: 0.000992\n",
      " Epoch 139: Train Loss: 0.000711, Validation Loss: 0.000989\n",
      " Epoch 140: Train Loss: 0.000709, Validation Loss: 0.000988\n",
      " Epoch 141: Train Loss: 0.000708, Validation Loss: 0.000992\n",
      " Epoch 142: Train Loss: 0.000706, Validation Loss: 0.000992\n",
      " Epoch 143: Train Loss: 0.000704, Validation Loss: 0.000992\n",
      " Epoch 144: Train Loss: 0.000702, Validation Loss: 0.000988\n",
      " Epoch 145: Train Loss: 0.000700, Validation Loss: 0.000990\n",
      " Epoch 146: Train Loss: 0.000697, Validation Loss: 0.000990\n",
      " Epoch 147: Train Loss: 0.000697, Validation Loss: 0.000995\n",
      " Epoch 148: Train Loss: 0.000694, Validation Loss: 0.000991\n",
      " Epoch 149: Train Loss: 0.000693, Validation Loss: 0.000998\n",
      " Epoch 150: Train Loss: 0.000691, Validation Loss: 0.000991\n",
      " Epoch 151: Train Loss: 0.000684, Validation Loss: 0.000988\n",
      " Epoch 152: Train Loss: 0.000682, Validation Loss: 0.000990\n",
      " Epoch 153: Train Loss: 0.000682, Validation Loss: 0.000994\n",
      " Epoch 154: Train Loss: 0.000681, Validation Loss: 0.000988\n",
      " Epoch 155: Train Loss: 0.000679, Validation Loss: 0.000994\n",
      " Epoch 156: Train Loss: 0.000678, Validation Loss: 0.000989\n",
      " Epoch 157: Train Loss: 0.000677, Validation Loss: 0.000991\n",
      " Epoch 158: Train Loss: 0.000676, Validation Loss: 0.000989\n",
      " Epoch 159: Train Loss: 0.000675, Validation Loss: 0.000990\n",
      " Epoch 160: Train Loss: 0.000676, Validation Loss: 0.000992\n",
      " Epoch 161: Train Loss: 0.000673, Validation Loss: 0.000993\n",
      " Epoch 162: Train Loss: 0.000672, Validation Loss: 0.000989\n",
      " Epoch 163: Train Loss: 0.000671, Validation Loss: 0.000991\n",
      " Epoch 164: Train Loss: 0.000670, Validation Loss: 0.000991\n",
      " Epoch 165: Train Loss: 0.000669, Validation Loss: 0.000994\n",
      " Epoch 166: Train Loss: 0.000668, Validation Loss: 0.000991\n",
      " Epoch 167: Train Loss: 0.000667, Validation Loss: 0.000992\n",
      " Epoch 168: Train Loss: 0.000666, Validation Loss: 0.000992\n",
      " Epoch 169: Train Loss: 0.000665, Validation Loss: 0.000991\n",
      " Epoch 170: Train Loss: 0.000664, Validation Loss: 0.000990\n",
      " Epoch 171: Train Loss: 0.000663, Validation Loss: 0.000998\n",
      " Epoch 172: Train Loss: 0.000662, Validation Loss: 0.000991\n",
      " Epoch 173: Train Loss: 0.000661, Validation Loss: 0.000995\n",
      " Epoch 174: Train Loss: 0.000659, Validation Loss: 0.000991\n",
      "Early stopping at epoch 174 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.044194, Validation Loss: 0.061506\n",
      " Epoch 2: Train Loss: 0.012101, Validation Loss: 0.025091\n",
      " Epoch 3: Train Loss: 0.005963, Validation Loss: 0.005274\n",
      " Epoch 4: Train Loss: 0.004538, Validation Loss: 0.004177\n",
      " Epoch 5: Train Loss: 0.003894, Validation Loss: 0.003698\n",
      " Epoch 6: Train Loss: 0.003280, Validation Loss: 0.003239\n",
      " Epoch 7: Train Loss: 0.002952, Validation Loss: 0.002890\n",
      " Epoch 8: Train Loss: 0.002725, Validation Loss: 0.002712\n",
      " Epoch 9: Train Loss: 0.002551, Validation Loss: 0.002523\n",
      " Epoch 10: Train Loss: 0.002406, Validation Loss: 0.002386\n",
      " Epoch 11: Train Loss: 0.002290, Validation Loss: 0.002292\n",
      " Epoch 12: Train Loss: 0.002188, Validation Loss: 0.002237\n",
      " Epoch 13: Train Loss: 0.002109, Validation Loss: 0.002196\n",
      " Epoch 14: Train Loss: 0.002025, Validation Loss: 0.002052\n",
      " Epoch 15: Train Loss: 0.001972, Validation Loss: 0.002085\n",
      " Epoch 16: Train Loss: 0.001903, Validation Loss: 0.001908\n",
      " Epoch 17: Train Loss: 0.001839, Validation Loss: 0.001872\n",
      " Epoch 18: Train Loss: 0.001796, Validation Loss: 0.002079\n",
      " Epoch 19: Train Loss: 0.001744, Validation Loss: 0.001778\n",
      " Epoch 20: Train Loss: 0.001702, Validation Loss: 0.001735\n",
      " Epoch 21: Train Loss: 0.001654, Validation Loss: 0.001688\n",
      " Epoch 22: Train Loss: 0.001632, Validation Loss: 0.001765\n",
      " Epoch 23: Train Loss: 0.001581, Validation Loss: 0.001664\n",
      " Epoch 24: Train Loss: 0.001546, Validation Loss: 0.001599\n",
      " Epoch 25: Train Loss: 0.001528, Validation Loss: 0.001650\n",
      " Epoch 26: Train Loss: 0.001488, Validation Loss: 0.001520\n",
      " Epoch 27: Train Loss: 0.001475, Validation Loss: 0.001555\n",
      " Epoch 28: Train Loss: 0.001432, Validation Loss: 0.001482\n",
      " Epoch 29: Train Loss: 0.001408, Validation Loss: 0.001440\n",
      " Epoch 30: Train Loss: 0.001397, Validation Loss: 0.001473\n",
      " Epoch 31: Train Loss: 0.001340, Validation Loss: 0.001394\n",
      " Epoch 32: Train Loss: 0.001323, Validation Loss: 0.001370\n",
      " Epoch 33: Train Loss: 0.001308, Validation Loss: 0.001364\n",
      " Epoch 34: Train Loss: 0.001300, Validation Loss: 0.001351\n",
      " Epoch 35: Train Loss: 0.001286, Validation Loss: 0.001335\n",
      " Epoch 36: Train Loss: 0.001273, Validation Loss: 0.001331\n",
      " Epoch 37: Train Loss: 0.001264, Validation Loss: 0.001323\n",
      " Epoch 38: Train Loss: 0.001251, Validation Loss: 0.001302\n",
      " Epoch 39: Train Loss: 0.001242, Validation Loss: 0.001291\n",
      " Epoch 40: Train Loss: 0.001233, Validation Loss: 0.001319\n",
      " Epoch 41: Train Loss: 0.001228, Validation Loss: 0.001297\n",
      " Epoch 42: Train Loss: 0.001217, Validation Loss: 0.001283\n",
      " Epoch 43: Train Loss: 0.001209, Validation Loss: 0.001259\n",
      " Epoch 44: Train Loss: 0.001192, Validation Loss: 0.001249\n",
      " Epoch 45: Train Loss: 0.001182, Validation Loss: 0.001293\n",
      " Epoch 46: Train Loss: 0.001177, Validation Loss: 0.001245\n",
      " Epoch 47: Train Loss: 0.001174, Validation Loss: 0.001308\n",
      " Epoch 48: Train Loss: 0.001160, Validation Loss: 0.001219\n",
      " Epoch 49: Train Loss: 0.001152, Validation Loss: 0.001247\n",
      " Epoch 50: Train Loss: 0.001140, Validation Loss: 0.001198\n",
      " Epoch 51: Train Loss: 0.001139, Validation Loss: 0.001220\n",
      " Epoch 52: Train Loss: 0.001122, Validation Loss: 0.001180\n",
      " Epoch 53: Train Loss: 0.001136, Validation Loss: 0.001226\n",
      " Epoch 54: Train Loss: 0.001102, Validation Loss: 0.001176\n",
      " Epoch 55: Train Loss: 0.001098, Validation Loss: 0.001164\n",
      " Epoch 56: Train Loss: 0.001090, Validation Loss: 0.001168\n",
      " Epoch 57: Train Loss: 0.001082, Validation Loss: 0.001191\n",
      " Epoch 58: Train Loss: 0.001091, Validation Loss: 0.001144\n",
      " Epoch 59: Train Loss: 0.001064, Validation Loss: 0.001152\n",
      " Epoch 60: Train Loss: 0.001072, Validation Loss: 0.001140\n",
      " Epoch 61: Train Loss: 0.001039, Validation Loss: 0.001121\n",
      " Epoch 62: Train Loss: 0.001032, Validation Loss: 0.001102\n",
      " Epoch 63: Train Loss: 0.001027, Validation Loss: 0.001095\n",
      " Epoch 64: Train Loss: 0.001023, Validation Loss: 0.001093\n",
      " Epoch 65: Train Loss: 0.001019, Validation Loss: 0.001096\n",
      " Epoch 66: Train Loss: 0.001017, Validation Loss: 0.001087\n",
      " Epoch 67: Train Loss: 0.001014, Validation Loss: 0.001081\n",
      " Epoch 68: Train Loss: 0.001010, Validation Loss: 0.001086\n",
      " Epoch 69: Train Loss: 0.001007, Validation Loss: 0.001078\n",
      " Epoch 70: Train Loss: 0.001000, Validation Loss: 0.001080\n",
      " Epoch 71: Train Loss: 0.000997, Validation Loss: 0.001067\n",
      " Epoch 72: Train Loss: 0.000999, Validation Loss: 0.001144\n",
      " Epoch 73: Train Loss: 0.000994, Validation Loss: 0.001067\n",
      " Epoch 74: Train Loss: 0.000986, Validation Loss: 0.001068\n",
      " Epoch 75: Train Loss: 0.000983, Validation Loss: 0.001056\n",
      " Epoch 76: Train Loss: 0.000979, Validation Loss: 0.001061\n",
      " Epoch 77: Train Loss: 0.000979, Validation Loss: 0.001048\n",
      " Epoch 78: Train Loss: 0.000973, Validation Loss: 0.001046\n",
      " Epoch 79: Train Loss: 0.000970, Validation Loss: 0.001060\n",
      " Epoch 80: Train Loss: 0.000963, Validation Loss: 0.001043\n",
      " Epoch 81: Train Loss: 0.000960, Validation Loss: 0.001034\n",
      " Epoch 82: Train Loss: 0.000955, Validation Loss: 0.001049\n",
      " Epoch 83: Train Loss: 0.000953, Validation Loss: 0.001050\n",
      " Epoch 84: Train Loss: 0.000957, Validation Loss: 0.001035\n",
      " Epoch 85: Train Loss: 0.000948, Validation Loss: 0.001045\n",
      " Epoch 86: Train Loss: 0.000945, Validation Loss: 0.001028\n",
      " Epoch 87: Train Loss: 0.000939, Validation Loss: 0.001021\n",
      " Epoch 88: Train Loss: 0.000936, Validation Loss: 0.001015\n",
      " Epoch 89: Train Loss: 0.000931, Validation Loss: 0.001018\n",
      " Epoch 90: Train Loss: 0.000927, Validation Loss: 0.001022\n",
      " Epoch 91: Train Loss: 0.000917, Validation Loss: 0.001002\n",
      " Epoch 92: Train Loss: 0.000914, Validation Loss: 0.001000\n",
      " Epoch 93: Train Loss: 0.000912, Validation Loss: 0.000998\n",
      " Epoch 94: Train Loss: 0.000911, Validation Loss: 0.001002\n",
      " Epoch 95: Train Loss: 0.000908, Validation Loss: 0.001004\n",
      " Epoch 96: Train Loss: 0.000906, Validation Loss: 0.001007\n",
      " Epoch 97: Train Loss: 0.000905, Validation Loss: 0.000997\n",
      " Epoch 98: Train Loss: 0.000903, Validation Loss: 0.000991\n",
      " Epoch 99: Train Loss: 0.000901, Validation Loss: 0.000992\n",
      " Epoch 100: Train Loss: 0.000898, Validation Loss: 0.000988\n",
      " Epoch 101: Train Loss: 0.000896, Validation Loss: 0.000984\n",
      " Epoch 102: Train Loss: 0.000895, Validation Loss: 0.000989\n",
      " Epoch 103: Train Loss: 0.000894, Validation Loss: 0.000984\n",
      " Epoch 104: Train Loss: 0.000892, Validation Loss: 0.000985\n",
      " Epoch 105: Train Loss: 0.000889, Validation Loss: 0.000978\n",
      " Epoch 106: Train Loss: 0.000888, Validation Loss: 0.000982\n",
      " Epoch 107: Train Loss: 0.000885, Validation Loss: 0.000978\n",
      " Epoch 108: Train Loss: 0.000885, Validation Loss: 0.000975\n",
      " Epoch 109: Train Loss: 0.000882, Validation Loss: 0.000978\n",
      " Epoch 110: Train Loss: 0.000880, Validation Loss: 0.000975\n",
      " Epoch 111: Train Loss: 0.000877, Validation Loss: 0.000978\n",
      " Epoch 112: Train Loss: 0.000878, Validation Loss: 0.000970\n",
      " Epoch 113: Train Loss: 0.000873, Validation Loss: 0.000977\n",
      " Epoch 114: Train Loss: 0.000873, Validation Loss: 0.000995\n",
      " Epoch 115: Train Loss: 0.000873, Validation Loss: 0.000969\n",
      " Epoch 116: Train Loss: 0.000867, Validation Loss: 0.000964\n",
      " Epoch 117: Train Loss: 0.000866, Validation Loss: 0.000961\n",
      " Epoch 118: Train Loss: 0.000862, Validation Loss: 0.000963\n",
      " Epoch 119: Train Loss: 0.000863, Validation Loss: 0.000962\n",
      " Epoch 120: Train Loss: 0.000859, Validation Loss: 0.000963\n",
      " Epoch 121: Train Loss: 0.000852, Validation Loss: 0.000951\n",
      " Epoch 122: Train Loss: 0.000850, Validation Loss: 0.000952\n",
      " Epoch 123: Train Loss: 0.000849, Validation Loss: 0.000951\n",
      " Epoch 124: Train Loss: 0.000848, Validation Loss: 0.000948\n",
      " Epoch 125: Train Loss: 0.000846, Validation Loss: 0.000953\n",
      " Epoch 126: Train Loss: 0.000845, Validation Loss: 0.000948\n",
      " Epoch 127: Train Loss: 0.000844, Validation Loss: 0.000953\n",
      " Epoch 128: Train Loss: 0.000844, Validation Loss: 0.000953\n",
      " Epoch 129: Train Loss: 0.000843, Validation Loss: 0.000948\n",
      " Epoch 130: Train Loss: 0.000841, Validation Loss: 0.000945\n",
      " Epoch 131: Train Loss: 0.000840, Validation Loss: 0.000944\n",
      " Epoch 132: Train Loss: 0.000839, Validation Loss: 0.000946\n",
      " Epoch 133: Train Loss: 0.000837, Validation Loss: 0.000942\n",
      " Epoch 134: Train Loss: 0.000836, Validation Loss: 0.000940\n",
      " Epoch 135: Train Loss: 0.000835, Validation Loss: 0.000940\n",
      " Epoch 136: Train Loss: 0.000835, Validation Loss: 0.000939\n",
      " Epoch 137: Train Loss: 0.000833, Validation Loss: 0.000937\n",
      " Epoch 138: Train Loss: 0.000832, Validation Loss: 0.000939\n",
      " Epoch 139: Train Loss: 0.000830, Validation Loss: 0.000937\n",
      " Epoch 140: Train Loss: 0.000829, Validation Loss: 0.000940\n",
      " Epoch 141: Train Loss: 0.000829, Validation Loss: 0.000935\n",
      " Epoch 142: Train Loss: 0.000827, Validation Loss: 0.000933\n",
      " Epoch 143: Train Loss: 0.000825, Validation Loss: 0.000933\n",
      " Epoch 144: Train Loss: 0.000824, Validation Loss: 0.000939\n",
      " Epoch 145: Train Loss: 0.000824, Validation Loss: 0.000932\n",
      " Epoch 146: Train Loss: 0.000822, Validation Loss: 0.000935\n",
      " Epoch 147: Train Loss: 0.000822, Validation Loss: 0.000931\n",
      " Epoch 148: Train Loss: 0.000820, Validation Loss: 0.000929\n",
      " Epoch 149: Train Loss: 0.000817, Validation Loss: 0.000928\n",
      " Epoch 150: Train Loss: 0.000816, Validation Loss: 0.000926\n",
      " Epoch 151: Train Loss: 0.000812, Validation Loss: 0.000924\n",
      " Epoch 152: Train Loss: 0.000811, Validation Loss: 0.000924\n",
      " Epoch 153: Train Loss: 0.000810, Validation Loss: 0.000924\n",
      " Epoch 154: Train Loss: 0.000810, Validation Loss: 0.000923\n",
      " Epoch 155: Train Loss: 0.000809, Validation Loss: 0.000927\n",
      " Epoch 156: Train Loss: 0.000808, Validation Loss: 0.000926\n",
      " Epoch 157: Train Loss: 0.000809, Validation Loss: 0.000922\n",
      " Epoch 158: Train Loss: 0.000807, Validation Loss: 0.000921\n",
      " Epoch 159: Train Loss: 0.000806, Validation Loss: 0.000922\n",
      " Epoch 160: Train Loss: 0.000806, Validation Loss: 0.000921\n",
      " Epoch 161: Train Loss: 0.000805, Validation Loss: 0.000923\n",
      " Epoch 162: Train Loss: 0.000804, Validation Loss: 0.000921\n",
      " Epoch 163: Train Loss: 0.000804, Validation Loss: 0.000920\n",
      " Epoch 164: Train Loss: 0.000803, Validation Loss: 0.000921\n",
      " Epoch 165: Train Loss: 0.000802, Validation Loss: 0.000920\n",
      " Epoch 166: Train Loss: 0.000801, Validation Loss: 0.000918\n",
      " Epoch 167: Train Loss: 0.000802, Validation Loss: 0.000919\n",
      " Epoch 168: Train Loss: 0.000801, Validation Loss: 0.000917\n",
      " Epoch 169: Train Loss: 0.000799, Validation Loss: 0.000917\n",
      " Epoch 170: Train Loss: 0.000798, Validation Loss: 0.000916\n",
      " Epoch 171: Train Loss: 0.000798, Validation Loss: 0.000915\n",
      " Epoch 172: Train Loss: 0.000797, Validation Loss: 0.000915\n",
      " Epoch 173: Train Loss: 0.000796, Validation Loss: 0.000914\n",
      " Epoch 174: Train Loss: 0.000796, Validation Loss: 0.000914\n",
      " Epoch 175: Train Loss: 0.000795, Validation Loss: 0.000918\n",
      " Epoch 176: Train Loss: 0.000794, Validation Loss: 0.000912\n",
      " Epoch 177: Train Loss: 0.000794, Validation Loss: 0.000914\n",
      " Epoch 178: Train Loss: 0.000793, Validation Loss: 0.000913\n",
      " Epoch 179: Train Loss: 0.000792, Validation Loss: 0.000911\n",
      " Epoch 180: Train Loss: 0.000791, Validation Loss: 0.000915\n",
      " Epoch 181: Train Loss: 0.000789, Validation Loss: 0.000910\n",
      " Epoch 182: Train Loss: 0.000788, Validation Loss: 0.000910\n",
      " Epoch 183: Train Loss: 0.000787, Validation Loss: 0.000910\n",
      " Epoch 184: Train Loss: 0.000787, Validation Loss: 0.000910\n",
      " Epoch 185: Train Loss: 0.000786, Validation Loss: 0.000909\n",
      " Epoch 186: Train Loss: 0.000786, Validation Loss: 0.000909\n",
      " Epoch 187: Train Loss: 0.000786, Validation Loss: 0.000908\n",
      " Epoch 188: Train Loss: 0.000785, Validation Loss: 0.000909\n",
      " Epoch 189: Train Loss: 0.000785, Validation Loss: 0.000908\n",
      " Epoch 190: Train Loss: 0.000784, Validation Loss: 0.000908\n",
      " Epoch 191: Train Loss: 0.000784, Validation Loss: 0.000911\n",
      " Epoch 192: Train Loss: 0.000783, Validation Loss: 0.000907\n",
      " Epoch 193: Train Loss: 0.000783, Validation Loss: 0.000909\n",
      " Epoch 194: Train Loss: 0.000783, Validation Loss: 0.000907\n",
      " Epoch 195: Train Loss: 0.000782, Validation Loss: 0.000908\n",
      " Epoch 196: Train Loss: 0.000781, Validation Loss: 0.000906\n",
      " Epoch 197: Train Loss: 0.000781, Validation Loss: 0.000907\n",
      " Epoch 198: Train Loss: 0.000781, Validation Loss: 0.000907\n",
      " Epoch 199: Train Loss: 0.000780, Validation Loss: 0.000906\n",
      " Epoch 200: Train Loss: 0.000780, Validation Loss: 0.000905\n",
      " Epoch 201: Train Loss: 0.000779, Validation Loss: 0.000905\n",
      " Epoch 202: Train Loss: 0.000779, Validation Loss: 0.000907\n",
      " Epoch 203: Train Loss: 0.000779, Validation Loss: 0.000904\n",
      " Epoch 204: Train Loss: 0.000778, Validation Loss: 0.000905\n",
      " Epoch 205: Train Loss: 0.000777, Validation Loss: 0.000904\n",
      " Epoch 206: Train Loss: 0.000777, Validation Loss: 0.000905\n",
      " Epoch 207: Train Loss: 0.000777, Validation Loss: 0.000904\n",
      " Epoch 208: Train Loss: 0.000776, Validation Loss: 0.000903\n",
      " Epoch 209: Train Loss: 0.000776, Validation Loss: 0.000904\n",
      " Epoch 210: Train Loss: 0.000776, Validation Loss: 0.000903\n",
      " Epoch 211: Train Loss: 0.000774, Validation Loss: 0.000902\n",
      " Epoch 212: Train Loss: 0.000774, Validation Loss: 0.000902\n",
      " Epoch 213: Train Loss: 0.000773, Validation Loss: 0.000902\n",
      " Epoch 214: Train Loss: 0.000773, Validation Loss: 0.000902\n",
      " Epoch 215: Train Loss: 0.000773, Validation Loss: 0.000902\n",
      " Epoch 216: Train Loss: 0.000772, Validation Loss: 0.000901\n",
      " Epoch 217: Train Loss: 0.000772, Validation Loss: 0.000902\n",
      " Epoch 218: Train Loss: 0.000772, Validation Loss: 0.000902\n",
      " Epoch 219: Train Loss: 0.000772, Validation Loss: 0.000901\n",
      " Epoch 220: Train Loss: 0.000771, Validation Loss: 0.000902\n",
      " Epoch 221: Train Loss: 0.000771, Validation Loss: 0.000901\n",
      " Epoch 222: Train Loss: 0.000771, Validation Loss: 0.000901\n",
      " Epoch 223: Train Loss: 0.000771, Validation Loss: 0.000901\n",
      " Epoch 224: Train Loss: 0.000770, Validation Loss: 0.000901\n",
      " Epoch 225: Train Loss: 0.000771, Validation Loss: 0.000901\n",
      " Epoch 226: Train Loss: 0.000770, Validation Loss: 0.000901\n",
      " Epoch 227: Train Loss: 0.000770, Validation Loss: 0.000900\n",
      " Epoch 228: Train Loss: 0.000769, Validation Loss: 0.000900\n",
      " Epoch 229: Train Loss: 0.000769, Validation Loss: 0.000900\n",
      " Epoch 230: Train Loss: 0.000769, Validation Loss: 0.000900\n",
      " Epoch 231: Train Loss: 0.000769, Validation Loss: 0.000900\n",
      " Epoch 232: Train Loss: 0.000768, Validation Loss: 0.000900\n",
      " Epoch 233: Train Loss: 0.000768, Validation Loss: 0.000900\n",
      " Epoch 234: Train Loss: 0.000768, Validation Loss: 0.000899\n",
      " Epoch 235: Train Loss: 0.000767, Validation Loss: 0.000899\n",
      " Epoch 236: Train Loss: 0.000767, Validation Loss: 0.000899\n",
      " Epoch 237: Train Loss: 0.000767, Validation Loss: 0.000899\n",
      " Epoch 238: Train Loss: 0.000767, Validation Loss: 0.000899\n",
      " Epoch 239: Train Loss: 0.000767, Validation Loss: 0.000898\n",
      " Epoch 240: Train Loss: 0.000766, Validation Loss: 0.000899\n",
      " Epoch 241: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 242: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 243: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 244: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 245: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 246: Train Loss: 0.000765, Validation Loss: 0.000898\n",
      " Epoch 247: Train Loss: 0.000764, Validation Loss: 0.000898\n",
      " Epoch 248: Train Loss: 0.000765, Validation Loss: 0.000897\n",
      " Epoch 249: Train Loss: 0.000764, Validation Loss: 0.000898\n",
      " Epoch 250: Train Loss: 0.000764, Validation Loss: 0.000898\n",
      " Epoch 251: Train Loss: 0.000764, Validation Loss: 0.000897\n",
      " Epoch 252: Train Loss: 0.000764, Validation Loss: 0.000897\n",
      " Epoch 253: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 254: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 255: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 256: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 257: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 258: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 259: Train Loss: 0.000763, Validation Loss: 0.000897\n",
      " Epoch 260: Train Loss: 0.000762, Validation Loss: 0.000897\n",
      " Epoch 261: Train Loss: 0.000762, Validation Loss: 0.000896\n",
      " Epoch 262: Train Loss: 0.000762, Validation Loss: 0.000897\n",
      " Epoch 263: Train Loss: 0.000762, Validation Loss: 0.000896\n",
      " Epoch 264: Train Loss: 0.000762, Validation Loss: 0.000897\n",
      " Epoch 265: Train Loss: 0.000762, Validation Loss: 0.000896\n",
      " Epoch 266: Train Loss: 0.000761, Validation Loss: 0.000896\n",
      " Epoch 267: Train Loss: 0.000761, Validation Loss: 0.000897\n",
      " Epoch 268: Train Loss: 0.000761, Validation Loss: 0.000896\n",
      " Epoch 269: Train Loss: 0.000761, Validation Loss: 0.000896\n",
      " Epoch 270: Train Loss: 0.000761, Validation Loss: 0.000896\n",
      " Epoch 271: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 272: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 273: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 274: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 275: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 276: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 277: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 278: Train Loss: 0.000760, Validation Loss: 0.000896\n",
      " Epoch 279: Train Loss: 0.000760, Validation Loss: 0.000895\n",
      " Epoch 280: Train Loss: 0.000760, Validation Loss: 0.000895\n",
      " Epoch 281: Train Loss: 0.000759, Validation Loss: 0.000896\n",
      " Epoch 282: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 283: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 284: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 285: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 286: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 287: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 288: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 289: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 290: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 291: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 292: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 293: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 294: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 295: Train Loss: 0.000759, Validation Loss: 0.000895\n",
      " Epoch 296: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 297: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 298: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 299: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 300: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 301: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 302: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 303: Train Loss: 0.000758, Validation Loss: 0.000894\n",
      " Epoch 304: Train Loss: 0.000758, Validation Loss: 0.000895\n",
      " Epoch 305: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 306: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 307: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 308: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 309: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 310: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 311: Train Loss: 0.000757, Validation Loss: 0.000895\n",
      " Epoch 312: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 313: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 314: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 315: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 316: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 317: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 318: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 319: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 320: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 321: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 322: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 323: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 324: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 325: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 326: Train Loss: 0.000757, Validation Loss: 0.000894\n",
      " Epoch 327: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 328: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 329: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 330: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 331: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 332: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 333: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 334: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 335: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 336: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 337: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 338: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 339: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 340: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 341: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 342: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 343: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 344: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 345: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 346: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 347: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 348: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 349: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 350: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 351: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 352: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 353: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 354: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 355: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 356: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 357: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 358: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 359: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 360: Train Loss: 0.000756, Validation Loss: 0.000894\n",
      " Epoch 361: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 362: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 363: Train Loss: 0.000755, Validation Loss: 0.000894\n",
      " Epoch 364: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 365: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 366: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 367: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 368: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 369: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 370: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 371: Train Loss: 0.000755, Validation Loss: 0.000894\n",
      " Epoch 372: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 373: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 374: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 375: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 376: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 377: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 378: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 379: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 380: Train Loss: 0.000755, Validation Loss: 0.000894\n",
      " Epoch 381: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 382: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 383: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 384: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 385: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 386: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 387: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 388: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 389: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 390: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 391: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 392: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 393: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 394: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 395: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 396: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 397: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 398: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 399: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 400: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 401: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 402: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 403: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 404: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 405: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 406: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 407: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 408: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 409: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 410: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 411: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 412: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 413: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 414: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 415: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 416: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 417: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 418: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 419: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 420: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 421: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 422: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 423: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 424: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 425: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 426: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 427: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 428: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 429: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 430: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 431: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 432: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 433: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 434: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 435: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 436: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 437: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 438: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 439: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 440: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 441: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 442: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 443: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 444: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 445: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 446: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 447: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 448: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 449: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 450: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 451: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 452: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 453: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 454: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 455: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 456: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 457: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 458: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 459: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 460: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 461: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 462: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 463: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 464: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 465: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 466: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 467: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 468: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 469: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 470: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 471: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 472: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 473: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 474: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 475: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 476: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 477: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 478: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 479: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 480: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 481: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 482: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 483: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 484: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 485: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 486: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 487: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 488: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 489: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 490: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 491: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 492: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 493: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 494: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 495: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 496: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 497: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 498: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 499: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 500: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 501: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 502: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 503: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      " Epoch 504: Train Loss: 0.000755, Validation Loss: 0.000893\n",
      "Early stopping at epoch 504 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.038617, Validation Loss: 0.037441\n",
      " Epoch 2: Train Loss: 0.010034, Validation Loss: 0.009153\n",
      " Epoch 3: Train Loss: 0.005335, Validation Loss: 0.004777\n",
      " Epoch 4: Train Loss: 0.004195, Validation Loss: 0.003859\n",
      " Epoch 5: Train Loss: 0.003505, Validation Loss: 0.003291\n",
      " Epoch 6: Train Loss: 0.003054, Validation Loss: 0.002923\n",
      " Epoch 7: Train Loss: 0.002745, Validation Loss: 0.002658\n",
      " Epoch 8: Train Loss: 0.002537, Validation Loss: 0.002453\n",
      " Epoch 9: Train Loss: 0.002384, Validation Loss: 0.002348\n",
      " Epoch 10: Train Loss: 0.002283, Validation Loss: 0.003663\n",
      " Epoch 11: Train Loss: 0.002205, Validation Loss: 0.002154\n",
      " Epoch 12: Train Loss: 0.002062, Validation Loss: 0.002090\n",
      " Epoch 13: Train Loss: 0.001971, Validation Loss: 0.002039\n",
      " Epoch 14: Train Loss: 0.001916, Validation Loss: 0.002022\n",
      " Epoch 15: Train Loss: 0.001839, Validation Loss: 0.001919\n",
      " Epoch 16: Train Loss: 0.001782, Validation Loss: 0.001790\n",
      " Epoch 17: Train Loss: 0.001738, Validation Loss: 0.001821\n",
      " Epoch 18: Train Loss: 0.001690, Validation Loss: 0.001707\n",
      " Epoch 19: Train Loss: 0.001648, Validation Loss: 0.001793\n",
      " Epoch 20: Train Loss: 0.001597, Validation Loss: 0.001651\n",
      " Epoch 21: Train Loss: 0.001578, Validation Loss: 0.001665\n",
      " Epoch 22: Train Loss: 0.001522, Validation Loss: 0.001620\n",
      " Epoch 23: Train Loss: 0.001494, Validation Loss: 0.001534\n",
      " Epoch 24: Train Loss: 0.001472, Validation Loss: 0.001509\n",
      " Epoch 25: Train Loss: 0.001435, Validation Loss: 0.001527\n",
      " Epoch 26: Train Loss: 0.001401, Validation Loss: 0.001440\n",
      " Epoch 27: Train Loss: 0.001369, Validation Loss: 0.001450\n",
      " Epoch 28: Train Loss: 0.001363, Validation Loss: 0.001370\n",
      " Epoch 29: Train Loss: 0.001345, Validation Loss: 0.001505\n",
      " Epoch 30: Train Loss: 0.001330, Validation Loss: 0.001354\n",
      " Epoch 31: Train Loss: 0.001264, Validation Loss: 0.001324\n",
      " Epoch 32: Train Loss: 0.001249, Validation Loss: 0.001337\n",
      " Epoch 33: Train Loss: 0.001240, Validation Loss: 0.001289\n",
      " Epoch 34: Train Loss: 0.001232, Validation Loss: 0.001285\n",
      " Epoch 35: Train Loss: 0.001222, Validation Loss: 0.001284\n",
      " Epoch 36: Train Loss: 0.001212, Validation Loss: 0.001262\n",
      " Epoch 37: Train Loss: 0.001204, Validation Loss: 0.001254\n",
      " Epoch 38: Train Loss: 0.001195, Validation Loss: 0.001245\n",
      " Epoch 39: Train Loss: 0.001187, Validation Loss: 0.001229\n",
      " Epoch 40: Train Loss: 0.001174, Validation Loss: 0.001235\n",
      " Epoch 41: Train Loss: 0.001165, Validation Loss: 0.001230\n",
      " Epoch 42: Train Loss: 0.001159, Validation Loss: 0.001214\n",
      " Epoch 43: Train Loss: 0.001149, Validation Loss: 0.001195\n",
      " Epoch 44: Train Loss: 0.001140, Validation Loss: 0.001193\n",
      " Epoch 45: Train Loss: 0.001134, Validation Loss: 0.001262\n",
      " Epoch 46: Train Loss: 0.001125, Validation Loss: 0.001211\n",
      " Epoch 47: Train Loss: 0.001118, Validation Loss: 0.001194\n",
      " Epoch 48: Train Loss: 0.001108, Validation Loss: 0.001156\n",
      " Epoch 49: Train Loss: 0.001107, Validation Loss: 0.001153\n",
      " Epoch 50: Train Loss: 0.001104, Validation Loss: 0.001151\n",
      " Epoch 51: Train Loss: 0.001088, Validation Loss: 0.001147\n",
      " Epoch 52: Train Loss: 0.001074, Validation Loss: 0.001151\n",
      " Epoch 53: Train Loss: 0.001071, Validation Loss: 0.001129\n",
      " Epoch 54: Train Loss: 0.001062, Validation Loss: 0.001128\n",
      " Epoch 55: Train Loss: 0.001069, Validation Loss: 0.001165\n",
      " Epoch 56: Train Loss: 0.001056, Validation Loss: 0.001118\n",
      " Epoch 57: Train Loss: 0.001042, Validation Loss: 0.001120\n",
      " Epoch 58: Train Loss: 0.001041, Validation Loss: 0.001107\n",
      " Epoch 59: Train Loss: 0.001039, Validation Loss: 0.001089\n",
      " Epoch 60: Train Loss: 0.001026, Validation Loss: 0.001129\n",
      " Epoch 61: Train Loss: 0.001006, Validation Loss: 0.001075\n",
      " Epoch 62: Train Loss: 0.000998, Validation Loss: 0.001065\n",
      " Epoch 63: Train Loss: 0.000993, Validation Loss: 0.001059\n",
      " Epoch 64: Train Loss: 0.000990, Validation Loss: 0.001067\n",
      " Epoch 65: Train Loss: 0.000987, Validation Loss: 0.001053\n",
      " Epoch 66: Train Loss: 0.000984, Validation Loss: 0.001050\n",
      " Epoch 67: Train Loss: 0.000981, Validation Loss: 0.001057\n",
      " Epoch 68: Train Loss: 0.000978, Validation Loss: 0.001068\n",
      " Epoch 69: Train Loss: 0.000977, Validation Loss: 0.001051\n",
      " Epoch 70: Train Loss: 0.000973, Validation Loss: 0.001057\n",
      " Epoch 71: Train Loss: 0.000968, Validation Loss: 0.001044\n",
      " Epoch 72: Train Loss: 0.000965, Validation Loss: 0.001033\n",
      " Epoch 73: Train Loss: 0.000960, Validation Loss: 0.001030\n",
      " Epoch 74: Train Loss: 0.000956, Validation Loss: 0.001024\n",
      " Epoch 75: Train Loss: 0.000953, Validation Loss: 0.001036\n",
      " Epoch 76: Train Loss: 0.000952, Validation Loss: 0.001030\n",
      " Epoch 77: Train Loss: 0.000947, Validation Loss: 0.001065\n",
      " Epoch 78: Train Loss: 0.000944, Validation Loss: 0.001014\n",
      " Epoch 79: Train Loss: 0.000939, Validation Loss: 0.001031\n",
      " Epoch 80: Train Loss: 0.000940, Validation Loss: 0.001050\n",
      " Epoch 81: Train Loss: 0.000933, Validation Loss: 0.001006\n",
      " Epoch 82: Train Loss: 0.000932, Validation Loss: 0.001002\n",
      " Epoch 83: Train Loss: 0.000928, Validation Loss: 0.001007\n",
      " Epoch 84: Train Loss: 0.000928, Validation Loss: 0.001002\n",
      " Epoch 85: Train Loss: 0.000922, Validation Loss: 0.001003\n",
      " Epoch 86: Train Loss: 0.000920, Validation Loss: 0.000998\n",
      " Epoch 87: Train Loss: 0.000915, Validation Loss: 0.001000\n",
      " Epoch 88: Train Loss: 0.000909, Validation Loss: 0.000985\n",
      " Epoch 89: Train Loss: 0.000905, Validation Loss: 0.001069\n",
      " Epoch 90: Train Loss: 0.000908, Validation Loss: 0.000993\n",
      " Epoch 91: Train Loss: 0.000895, Validation Loss: 0.000982\n",
      " Epoch 92: Train Loss: 0.000890, Validation Loss: 0.000970\n",
      " Epoch 93: Train Loss: 0.000888, Validation Loss: 0.000968\n",
      " Epoch 94: Train Loss: 0.000886, Validation Loss: 0.000968\n",
      " Epoch 95: Train Loss: 0.000883, Validation Loss: 0.000966\n",
      " Epoch 96: Train Loss: 0.000881, Validation Loss: 0.000969\n",
      " Epoch 97: Train Loss: 0.000880, Validation Loss: 0.000970\n",
      " Epoch 98: Train Loss: 0.000879, Validation Loss: 0.000961\n",
      " Epoch 99: Train Loss: 0.000876, Validation Loss: 0.000959\n",
      " Epoch 100: Train Loss: 0.000875, Validation Loss: 0.000959\n",
      " Epoch 101: Train Loss: 0.000872, Validation Loss: 0.000957\n",
      " Epoch 102: Train Loss: 0.000871, Validation Loss: 0.000955\n",
      " Epoch 103: Train Loss: 0.000870, Validation Loss: 0.000953\n",
      " Epoch 104: Train Loss: 0.000867, Validation Loss: 0.000957\n",
      " Epoch 105: Train Loss: 0.000865, Validation Loss: 0.000960\n",
      " Epoch 106: Train Loss: 0.000864, Validation Loss: 0.000951\n",
      " Epoch 107: Train Loss: 0.000863, Validation Loss: 0.000947\n",
      " Epoch 108: Train Loss: 0.000861, Validation Loss: 0.000948\n",
      " Epoch 109: Train Loss: 0.000858, Validation Loss: 0.000949\n",
      " Epoch 110: Train Loss: 0.000858, Validation Loss: 0.000946\n",
      " Epoch 111: Train Loss: 0.000856, Validation Loss: 0.000946\n",
      " Epoch 112: Train Loss: 0.000854, Validation Loss: 0.000950\n",
      " Epoch 113: Train Loss: 0.000851, Validation Loss: 0.000944\n",
      " Epoch 114: Train Loss: 0.000849, Validation Loss: 0.000942\n",
      " Epoch 115: Train Loss: 0.000849, Validation Loss: 0.000940\n",
      " Epoch 116: Train Loss: 0.000846, Validation Loss: 0.000937\n",
      " Epoch 117: Train Loss: 0.000845, Validation Loss: 0.000942\n",
      " Epoch 118: Train Loss: 0.000843, Validation Loss: 0.000939\n",
      " Epoch 119: Train Loss: 0.000840, Validation Loss: 0.000936\n",
      " Epoch 120: Train Loss: 0.000839, Validation Loss: 0.000936\n",
      " Epoch 121: Train Loss: 0.000831, Validation Loss: 0.000927\n",
      " Epoch 122: Train Loss: 0.000830, Validation Loss: 0.000929\n",
      " Epoch 123: Train Loss: 0.000829, Validation Loss: 0.000925\n",
      " Epoch 124: Train Loss: 0.000828, Validation Loss: 0.000925\n",
      " Epoch 125: Train Loss: 0.000827, Validation Loss: 0.000925\n",
      " Epoch 126: Train Loss: 0.000826, Validation Loss: 0.000927\n",
      " Epoch 127: Train Loss: 0.000825, Validation Loss: 0.000922\n",
      " Epoch 128: Train Loss: 0.000824, Validation Loss: 0.000924\n",
      " Epoch 129: Train Loss: 0.000823, Validation Loss: 0.000921\n",
      " Epoch 130: Train Loss: 0.000822, Validation Loss: 0.000922\n",
      " Epoch 131: Train Loss: 0.000822, Validation Loss: 0.000923\n",
      " Epoch 132: Train Loss: 0.000821, Validation Loss: 0.000922\n",
      " Epoch 133: Train Loss: 0.000820, Validation Loss: 0.000919\n",
      " Epoch 134: Train Loss: 0.000817, Validation Loss: 0.000919\n",
      " Epoch 135: Train Loss: 0.000817, Validation Loss: 0.000919\n",
      " Epoch 136: Train Loss: 0.000817, Validation Loss: 0.000919\n",
      " Epoch 137: Train Loss: 0.000814, Validation Loss: 0.000916\n",
      " Epoch 138: Train Loss: 0.000814, Validation Loss: 0.000923\n",
      " Epoch 139: Train Loss: 0.000814, Validation Loss: 0.000914\n",
      " Epoch 140: Train Loss: 0.000813, Validation Loss: 0.000914\n",
      " Epoch 141: Train Loss: 0.000810, Validation Loss: 0.000914\n",
      " Epoch 142: Train Loss: 0.000809, Validation Loss: 0.000914\n",
      " Epoch 143: Train Loss: 0.000809, Validation Loss: 0.000912\n",
      " Epoch 144: Train Loss: 0.000807, Validation Loss: 0.000916\n",
      " Epoch 145: Train Loss: 0.000807, Validation Loss: 0.000918\n",
      " Epoch 146: Train Loss: 0.000809, Validation Loss: 0.000910\n",
      " Epoch 147: Train Loss: 0.000805, Validation Loss: 0.000918\n",
      " Epoch 148: Train Loss: 0.000803, Validation Loss: 0.000910\n",
      " Epoch 149: Train Loss: 0.000802, Validation Loss: 0.000912\n",
      " Epoch 150: Train Loss: 0.000801, Validation Loss: 0.000909\n",
      " Epoch 151: Train Loss: 0.000797, Validation Loss: 0.000905\n",
      " Epoch 152: Train Loss: 0.000795, Validation Loss: 0.000905\n",
      " Epoch 153: Train Loss: 0.000795, Validation Loss: 0.000906\n",
      " Epoch 154: Train Loss: 0.000795, Validation Loss: 0.000908\n",
      " Epoch 155: Train Loss: 0.000794, Validation Loss: 0.000905\n",
      " Epoch 156: Train Loss: 0.000794, Validation Loss: 0.000904\n",
      " Epoch 157: Train Loss: 0.000792, Validation Loss: 0.000906\n",
      " Epoch 158: Train Loss: 0.000792, Validation Loss: 0.000902\n",
      " Epoch 159: Train Loss: 0.000792, Validation Loss: 0.000902\n",
      " Epoch 160: Train Loss: 0.000792, Validation Loss: 0.000904\n",
      " Epoch 161: Train Loss: 0.000791, Validation Loss: 0.000903\n",
      " Epoch 162: Train Loss: 0.000790, Validation Loss: 0.000902\n",
      " Epoch 163: Train Loss: 0.000789, Validation Loss: 0.000903\n",
      " Epoch 164: Train Loss: 0.000789, Validation Loss: 0.000902\n",
      " Epoch 165: Train Loss: 0.000788, Validation Loss: 0.000900\n",
      " Epoch 166: Train Loss: 0.000787, Validation Loss: 0.000900\n",
      " Epoch 167: Train Loss: 0.000787, Validation Loss: 0.000899\n",
      " Epoch 168: Train Loss: 0.000787, Validation Loss: 0.000900\n",
      " Epoch 169: Train Loss: 0.000786, Validation Loss: 0.000906\n",
      " Epoch 170: Train Loss: 0.000786, Validation Loss: 0.000901\n",
      " Epoch 171: Train Loss: 0.000784, Validation Loss: 0.000898\n",
      " Epoch 172: Train Loss: 0.000783, Validation Loss: 0.000898\n",
      " Epoch 173: Train Loss: 0.000783, Validation Loss: 0.000898\n",
      " Epoch 174: Train Loss: 0.000782, Validation Loss: 0.000897\n",
      " Epoch 175: Train Loss: 0.000781, Validation Loss: 0.000896\n",
      " Epoch 176: Train Loss: 0.000781, Validation Loss: 0.000896\n",
      " Epoch 177: Train Loss: 0.000780, Validation Loss: 0.000898\n",
      " Epoch 178: Train Loss: 0.000780, Validation Loss: 0.000898\n",
      " Epoch 179: Train Loss: 0.000779, Validation Loss: 0.000902\n",
      " Epoch 180: Train Loss: 0.000778, Validation Loss: 0.000899\n",
      " Epoch 181: Train Loss: 0.000776, Validation Loss: 0.000894\n",
      " Epoch 182: Train Loss: 0.000775, Validation Loss: 0.000894\n",
      " Epoch 183: Train Loss: 0.000775, Validation Loss: 0.000894\n",
      " Epoch 184: Train Loss: 0.000775, Validation Loss: 0.000893\n",
      " Epoch 185: Train Loss: 0.000774, Validation Loss: 0.000893\n",
      " Epoch 186: Train Loss: 0.000774, Validation Loss: 0.000893\n",
      " Epoch 187: Train Loss: 0.000774, Validation Loss: 0.000894\n",
      " Epoch 188: Train Loss: 0.000773, Validation Loss: 0.000893\n",
      " Epoch 189: Train Loss: 0.000772, Validation Loss: 0.000894\n",
      " Epoch 190: Train Loss: 0.000772, Validation Loss: 0.000893\n",
      " Epoch 191: Train Loss: 0.000772, Validation Loss: 0.000892\n",
      " Epoch 192: Train Loss: 0.000772, Validation Loss: 0.000894\n",
      " Epoch 193: Train Loss: 0.000771, Validation Loss: 0.000892\n",
      " Epoch 194: Train Loss: 0.000771, Validation Loss: 0.000892\n",
      " Epoch 195: Train Loss: 0.000771, Validation Loss: 0.000892\n",
      " Epoch 196: Train Loss: 0.000770, Validation Loss: 0.000891\n",
      " Epoch 197: Train Loss: 0.000770, Validation Loss: 0.000892\n",
      " Epoch 198: Train Loss: 0.000769, Validation Loss: 0.000891\n",
      " Epoch 199: Train Loss: 0.000769, Validation Loss: 0.000896\n",
      " Epoch 200: Train Loss: 0.000768, Validation Loss: 0.000891\n",
      " Epoch 201: Train Loss: 0.000768, Validation Loss: 0.000892\n",
      " Epoch 202: Train Loss: 0.000768, Validation Loss: 0.000890\n",
      " Epoch 203: Train Loss: 0.000767, Validation Loss: 0.000891\n",
      " Epoch 204: Train Loss: 0.000767, Validation Loss: 0.000890\n",
      " Epoch 205: Train Loss: 0.000766, Validation Loss: 0.000891\n",
      " Epoch 206: Train Loss: 0.000766, Validation Loss: 0.000890\n",
      " Epoch 207: Train Loss: 0.000766, Validation Loss: 0.000890\n",
      " Epoch 208: Train Loss: 0.000765, Validation Loss: 0.000891\n",
      " Epoch 209: Train Loss: 0.000765, Validation Loss: 0.000891\n",
      " Epoch 210: Train Loss: 0.000764, Validation Loss: 0.000891\n",
      " Epoch 211: Train Loss: 0.000763, Validation Loss: 0.000889\n",
      " Epoch 212: Train Loss: 0.000763, Validation Loss: 0.000888\n",
      " Epoch 213: Train Loss: 0.000762, Validation Loss: 0.000889\n",
      " Epoch 214: Train Loss: 0.000762, Validation Loss: 0.000889\n",
      " Epoch 215: Train Loss: 0.000762, Validation Loss: 0.000888\n",
      " Epoch 216: Train Loss: 0.000762, Validation Loss: 0.000888\n",
      " Epoch 217: Train Loss: 0.000762, Validation Loss: 0.000888\n",
      " Epoch 218: Train Loss: 0.000761, Validation Loss: 0.000888\n",
      " Epoch 219: Train Loss: 0.000761, Validation Loss: 0.000888\n",
      " Epoch 220: Train Loss: 0.000761, Validation Loss: 0.000888\n",
      " Epoch 221: Train Loss: 0.000761, Validation Loss: 0.000888\n",
      " Epoch 222: Train Loss: 0.000761, Validation Loss: 0.000888\n",
      " Epoch 223: Train Loss: 0.000760, Validation Loss: 0.000888\n",
      " Epoch 224: Train Loss: 0.000760, Validation Loss: 0.000888\n",
      " Epoch 225: Train Loss: 0.000760, Validation Loss: 0.000887\n",
      " Epoch 226: Train Loss: 0.000760, Validation Loss: 0.000887\n",
      " Epoch 227: Train Loss: 0.000759, Validation Loss: 0.000888\n",
      " Epoch 228: Train Loss: 0.000759, Validation Loss: 0.000887\n",
      " Epoch 229: Train Loss: 0.000759, Validation Loss: 0.000887\n",
      " Epoch 230: Train Loss: 0.000759, Validation Loss: 0.000887\n",
      " Epoch 231: Train Loss: 0.000759, Validation Loss: 0.000887\n",
      " Epoch 232: Train Loss: 0.000758, Validation Loss: 0.000887\n",
      " Epoch 233: Train Loss: 0.000758, Validation Loss: 0.000887\n",
      " Epoch 234: Train Loss: 0.000758, Validation Loss: 0.000886\n",
      " Epoch 235: Train Loss: 0.000758, Validation Loss: 0.000886\n",
      " Epoch 236: Train Loss: 0.000757, Validation Loss: 0.000886\n",
      " Epoch 237: Train Loss: 0.000757, Validation Loss: 0.000886\n",
      " Epoch 238: Train Loss: 0.000757, Validation Loss: 0.000886\n",
      " Epoch 239: Train Loss: 0.000757, Validation Loss: 0.000886\n",
      " Epoch 240: Train Loss: 0.000757, Validation Loss: 0.000887\n",
      " Epoch 241: Train Loss: 0.000756, Validation Loss: 0.000886\n",
      " Epoch 242: Train Loss: 0.000755, Validation Loss: 0.000886\n",
      " Epoch 243: Train Loss: 0.000755, Validation Loss: 0.000886\n",
      " Epoch 244: Train Loss: 0.000755, Validation Loss: 0.000886\n",
      " Epoch 245: Train Loss: 0.000755, Validation Loss: 0.000886\n",
      " Epoch 246: Train Loss: 0.000755, Validation Loss: 0.000886\n",
      " Epoch 247: Train Loss: 0.000755, Validation Loss: 0.000885\n",
      " Epoch 248: Train Loss: 0.000755, Validation Loss: 0.000885\n",
      " Epoch 249: Train Loss: 0.000755, Validation Loss: 0.000885\n",
      " Epoch 250: Train Loss: 0.000754, Validation Loss: 0.000885\n",
      " Epoch 251: Train Loss: 0.000754, Validation Loss: 0.000886\n",
      " Epoch 252: Train Loss: 0.000754, Validation Loss: 0.000885\n",
      " Epoch 253: Train Loss: 0.000754, Validation Loss: 0.000885\n",
      " Epoch 254: Train Loss: 0.000754, Validation Loss: 0.000885\n",
      " Epoch 255: Train Loss: 0.000754, Validation Loss: 0.000886\n",
      " Epoch 256: Train Loss: 0.000754, Validation Loss: 0.000886\n",
      " Epoch 257: Train Loss: 0.000754, Validation Loss: 0.000885\n",
      " Epoch 258: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 259: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 260: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 261: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 262: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 263: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 264: Train Loss: 0.000753, Validation Loss: 0.000885\n",
      " Epoch 265: Train Loss: 0.000752, Validation Loss: 0.000885\n",
      " Epoch 266: Train Loss: 0.000752, Validation Loss: 0.000885\n",
      " Epoch 267: Train Loss: 0.000752, Validation Loss: 0.000885\n",
      " Epoch 268: Train Loss: 0.000752, Validation Loss: 0.000885\n",
      " Epoch 269: Train Loss: 0.000752, Validation Loss: 0.000885\n",
      " Epoch 270: Train Loss: 0.000752, Validation Loss: 0.000884\n",
      " Epoch 271: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 272: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 273: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 274: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 275: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 276: Train Loss: 0.000751, Validation Loss: 0.000885\n",
      " Epoch 277: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 278: Train Loss: 0.000751, Validation Loss: 0.000885\n",
      " Epoch 279: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 280: Train Loss: 0.000751, Validation Loss: 0.000885\n",
      " Epoch 281: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 282: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 283: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 284: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 285: Train Loss: 0.000751, Validation Loss: 0.000884\n",
      " Epoch 286: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 287: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 288: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 289: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 290: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 291: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 292: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 293: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 294: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 295: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 296: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 297: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 298: Train Loss: 0.000750, Validation Loss: 0.000884\n",
      " Epoch 299: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 300: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 301: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 302: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 303: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 304: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 305: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 306: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 307: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 308: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 309: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 310: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 311: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 312: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 313: Train Loss: 0.000749, Validation Loss: 0.000884\n",
      " Epoch 314: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 315: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 316: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 317: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 318: Train Loss: 0.000749, Validation Loss: 0.000883\n",
      " Epoch 319: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 320: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 321: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 322: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 323: Train Loss: 0.000748, Validation Loss: 0.000884\n",
      " Epoch 324: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 325: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 326: Train Loss: 0.000748, Validation Loss: 0.000884\n",
      " Epoch 327: Train Loss: 0.000748, Validation Loss: 0.000884\n",
      " Epoch 328: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 329: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 330: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 331: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 332: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 333: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 334: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 335: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 336: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 337: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 338: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 339: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 340: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 341: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 342: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 343: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 344: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 345: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 346: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 347: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 348: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 349: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 350: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 351: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 352: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 353: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 354: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 355: Train Loss: 0.000748, Validation Loss: 0.000883\n",
      " Epoch 356: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 357: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 358: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 359: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 360: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 361: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 362: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 363: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 364: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 365: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 366: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 367: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 368: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 369: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 370: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 371: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 372: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 373: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 374: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 375: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 376: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 377: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 378: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 379: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 380: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 381: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 382: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 383: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 384: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 385: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 386: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 387: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 388: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 389: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 390: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 391: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 392: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 393: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 394: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 395: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 396: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 397: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 398: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 399: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 400: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 401: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 402: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 403: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 404: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 405: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 406: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 407: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 408: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 409: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 410: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 411: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 412: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 413: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 414: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 415: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 416: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 417: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 418: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 419: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 420: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 421: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 422: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 423: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 424: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 425: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 426: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 427: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 428: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 429: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 430: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 431: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 432: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 433: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 434: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 435: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 436: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 437: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 438: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 439: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 440: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 441: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 442: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 443: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 444: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 445: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 446: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 447: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 448: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 449: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 450: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 451: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 452: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 453: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 454: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 455: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 456: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 457: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 458: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 459: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 460: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 461: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 462: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 463: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 464: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 465: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 466: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 467: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 468: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 469: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 470: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 471: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 472: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 473: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 474: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 475: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 476: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 477: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 478: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 479: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 480: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 481: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 482: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 483: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 484: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 485: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 486: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 487: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 488: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 489: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 490: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 491: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 492: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 493: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 494: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 495: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 496: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 497: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 498: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 499: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 500: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      " Epoch 501: Train Loss: 0.000747, Validation Loss: 0.000883\n",
      "Early stopping at epoch 501 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.0008490215986967087\n",
      "Training Time: 3331.5562551021576\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.000987723469734192\n",
      "Training Time: 5074.415421247482\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.0008931769407354295\n",
      "Training Time: 4068.8410885334015\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0008828734862618148\n",
      "Training Time: 4244.276144504547\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#SSIM 0.05\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate,MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(1,0.05)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/SSIM_test01_0.5x/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a2a0a4-b3f2-46e3-91c8-e785fa05295b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.020664, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.003047, Validation Loss: 0.003182\n",
      " Epoch 3: Train Loss: 0.001342, Validation Loss: 0.001283\n",
      " Epoch 4: Train Loss: 0.000975, Validation Loss: 0.000897\n",
      " Epoch 5: Train Loss: 0.000837, Validation Loss: 0.000789\n",
      " Epoch 6: Train Loss: 0.000753, Validation Loss: 0.000721\n",
      " Epoch 7: Train Loss: 0.000693, Validation Loss: 0.000671\n",
      " Epoch 8: Train Loss: 0.000649, Validation Loss: 0.000629\n",
      " Epoch 9: Train Loss: 0.000612, Validation Loss: 0.000600\n",
      " Epoch 10: Train Loss: 0.000583, Validation Loss: 0.000575\n",
      " Epoch 11: Train Loss: 0.000557, Validation Loss: 0.000554\n",
      " Epoch 12: Train Loss: 0.000537, Validation Loss: 0.000534\n",
      " Epoch 13: Train Loss: 0.000519, Validation Loss: 0.000526\n",
      " Epoch 14: Train Loss: 0.000506, Validation Loss: 0.000506\n",
      " Epoch 15: Train Loss: 0.000490, Validation Loss: 0.000493\n",
      " Epoch 16: Train Loss: 0.000477, Validation Loss: 0.000480\n",
      " Epoch 17: Train Loss: 0.000467, Validation Loss: 0.000474\n",
      " Epoch 18: Train Loss: 0.000454, Validation Loss: 0.000459\n",
      " Epoch 19: Train Loss: 0.000444, Validation Loss: 0.000448\n",
      " Epoch 20: Train Loss: 0.000433, Validation Loss: 0.000441\n",
      " Epoch 21: Train Loss: 0.000429, Validation Loss: 0.000450\n",
      " Epoch 22: Train Loss: 0.000422, Validation Loss: 0.000425\n",
      " Epoch 23: Train Loss: 0.000410, Validation Loss: 0.000427\n",
      " Epoch 24: Train Loss: 0.000405, Validation Loss: 0.000422\n",
      " Epoch 25: Train Loss: 0.000399, Validation Loss: 0.000407\n",
      " Epoch 26: Train Loss: 0.000394, Validation Loss: 0.000401\n",
      " Epoch 27: Train Loss: 0.000388, Validation Loss: 0.000403\n",
      " Epoch 28: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 29: Train Loss: 0.000378, Validation Loss: 0.000395\n",
      " Epoch 30: Train Loss: 0.000376, Validation Loss: 0.000395\n",
      " Epoch 31: Train Loss: 0.000364, Validation Loss: 0.000380\n",
      " Epoch 32: Train Loss: 0.000359, Validation Loss: 0.000376\n",
      " Epoch 33: Train Loss: 0.000358, Validation Loss: 0.000374\n",
      " Epoch 34: Train Loss: 0.000354, Validation Loss: 0.000375\n",
      " Epoch 35: Train Loss: 0.000352, Validation Loss: 0.000370\n",
      " Epoch 36: Train Loss: 0.000349, Validation Loss: 0.000369\n",
      " Epoch 37: Train Loss: 0.000349, Validation Loss: 0.000366\n",
      " Epoch 38: Train Loss: 0.000343, Validation Loss: 0.000365\n",
      " Epoch 39: Train Loss: 0.000346, Validation Loss: 0.000364\n",
      " Epoch 40: Train Loss: 0.000341, Validation Loss: 0.000368\n",
      " Epoch 41: Train Loss: 0.000340, Validation Loss: 0.000359\n",
      " Epoch 42: Train Loss: 0.000336, Validation Loss: 0.000360\n",
      " Epoch 43: Train Loss: 0.000334, Validation Loss: 0.000357\n",
      " Epoch 44: Train Loss: 0.000333, Validation Loss: 0.000354\n",
      " Epoch 45: Train Loss: 0.000330, Validation Loss: 0.000352\n",
      " Epoch 46: Train Loss: 0.000328, Validation Loss: 0.000352\n",
      " Epoch 47: Train Loss: 0.000329, Validation Loss: 0.000349\n",
      " Epoch 48: Train Loss: 0.000325, Validation Loss: 0.000350\n",
      " Epoch 49: Train Loss: 0.000322, Validation Loss: 0.000349\n",
      " Epoch 50: Train Loss: 0.000321, Validation Loss: 0.000346\n",
      " Epoch 51: Train Loss: 0.000321, Validation Loss: 0.000351\n",
      " Epoch 52: Train Loss: 0.000317, Validation Loss: 0.000346\n",
      " Epoch 53: Train Loss: 0.000316, Validation Loss: 0.000342\n",
      " Epoch 54: Train Loss: 0.000313, Validation Loss: 0.000347\n",
      " Epoch 55: Train Loss: 0.000316, Validation Loss: 0.000338\n",
      " Epoch 56: Train Loss: 0.000311, Validation Loss: 0.000337\n",
      " Epoch 57: Train Loss: 0.000312, Validation Loss: 0.000336\n",
      " Epoch 58: Train Loss: 0.000309, Validation Loss: 0.000334\n",
      " Epoch 59: Train Loss: 0.000309, Validation Loss: 0.000337\n",
      " Epoch 60: Train Loss: 0.000313, Validation Loss: 0.000333\n",
      " Epoch 61: Train Loss: 0.000300, Validation Loss: 0.000330\n",
      " Epoch 62: Train Loss: 0.000298, Validation Loss: 0.000329\n",
      " Epoch 63: Train Loss: 0.000297, Validation Loss: 0.000329\n",
      " Epoch 64: Train Loss: 0.000297, Validation Loss: 0.000328\n",
      " Epoch 65: Train Loss: 0.000296, Validation Loss: 0.000327\n",
      " Epoch 66: Train Loss: 0.000294, Validation Loss: 0.000333\n",
      " Epoch 67: Train Loss: 0.000294, Validation Loss: 0.000327\n",
      " Epoch 68: Train Loss: 0.000297, Validation Loss: 0.000331\n",
      " Epoch 69: Train Loss: 0.000294, Validation Loss: 0.000325\n",
      " Epoch 70: Train Loss: 0.000291, Validation Loss: 0.000325\n",
      " Epoch 71: Train Loss: 0.000291, Validation Loss: 0.000323\n",
      " Epoch 72: Train Loss: 0.000289, Validation Loss: 0.000324\n",
      " Epoch 73: Train Loss: 0.000288, Validation Loss: 0.000326\n",
      " Epoch 74: Train Loss: 0.000288, Validation Loss: 0.000322\n",
      " Epoch 75: Train Loss: 0.000290, Validation Loss: 0.000321\n",
      " Epoch 76: Train Loss: 0.000286, Validation Loss: 0.000321\n",
      " Epoch 77: Train Loss: 0.000286, Validation Loss: 0.000322\n",
      " Epoch 78: Train Loss: 0.000284, Validation Loss: 0.000321\n",
      " Epoch 79: Train Loss: 0.000284, Validation Loss: 0.000320\n",
      " Epoch 80: Train Loss: 0.000285, Validation Loss: 0.000320\n",
      " Epoch 81: Train Loss: 0.000283, Validation Loss: 0.000321\n",
      " Epoch 82: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 83: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 84: Train Loss: 0.000280, Validation Loss: 0.000318\n",
      " Epoch 85: Train Loss: 0.000278, Validation Loss: 0.000315\n",
      " Epoch 86: Train Loss: 0.000277, Validation Loss: 0.000318\n",
      " Epoch 87: Train Loss: 0.000276, Validation Loss: 0.000315\n",
      " Epoch 88: Train Loss: 0.000277, Validation Loss: 0.000317\n",
      " Epoch 89: Train Loss: 0.000277, Validation Loss: 0.000314\n",
      " Epoch 90: Train Loss: 0.000275, Validation Loss: 0.000321\n",
      " Epoch 91: Train Loss: 0.000272, Validation Loss: 0.000315\n",
      " Epoch 92: Train Loss: 0.000271, Validation Loss: 0.000313\n",
      " Epoch 93: Train Loss: 0.000270, Validation Loss: 0.000313\n",
      " Epoch 94: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 95: Train Loss: 0.000268, Validation Loss: 0.000312\n",
      " Epoch 96: Train Loss: 0.000269, Validation Loss: 0.000312\n",
      " Epoch 97: Train Loss: 0.000269, Validation Loss: 0.000311\n",
      " Epoch 98: Train Loss: 0.000267, Validation Loss: 0.000311\n",
      " Epoch 99: Train Loss: 0.000268, Validation Loss: 0.000311\n",
      " Epoch 100: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 101: Train Loss: 0.000268, Validation Loss: 0.000310\n",
      " Epoch 102: Train Loss: 0.000265, Validation Loss: 0.000310\n",
      " Epoch 103: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 104: Train Loss: 0.000264, Validation Loss: 0.000310\n",
      " Epoch 105: Train Loss: 0.000264, Validation Loss: 0.000309\n",
      " Epoch 106: Train Loss: 0.000263, Validation Loss: 0.000309\n",
      " Epoch 107: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 108: Train Loss: 0.000263, Validation Loss: 0.000310\n",
      " Epoch 109: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 110: Train Loss: 0.000261, Validation Loss: 0.000309\n",
      " Epoch 111: Train Loss: 0.000262, Validation Loss: 0.000308\n",
      " Epoch 112: Train Loss: 0.000261, Validation Loss: 0.000308\n",
      " Epoch 113: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 114: Train Loss: 0.000259, Validation Loss: 0.000309\n",
      " Epoch 115: Train Loss: 0.000259, Validation Loss: 0.000307\n",
      " Epoch 116: Train Loss: 0.000261, Validation Loss: 0.000311\n",
      " Epoch 117: Train Loss: 0.000258, Validation Loss: 0.000306\n",
      " Epoch 118: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 119: Train Loss: 0.000256, Validation Loss: 0.000305\n",
      " Epoch 120: Train Loss: 0.000257, Validation Loss: 0.000306\n",
      " Epoch 121: Train Loss: 0.000254, Validation Loss: 0.000309\n",
      " Epoch 122: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 123: Train Loss: 0.000253, Validation Loss: 0.000305\n",
      " Epoch 124: Train Loss: 0.000252, Validation Loss: 0.000304\n",
      " Epoch 125: Train Loss: 0.000254, Validation Loss: 0.000306\n",
      " Epoch 126: Train Loss: 0.000252, Validation Loss: 0.000305\n",
      " Epoch 127: Train Loss: 0.000251, Validation Loss: 0.000305\n",
      " Epoch 128: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 129: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 130: Train Loss: 0.000251, Validation Loss: 0.000304\n",
      " Epoch 131: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 132: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 133: Train Loss: 0.000250, Validation Loss: 0.000304\n",
      " Epoch 134: Train Loss: 0.000249, Validation Loss: 0.000303\n",
      " Epoch 135: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 136: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 137: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 138: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 139: Train Loss: 0.000248, Validation Loss: 0.000305\n",
      " Epoch 140: Train Loss: 0.000248, Validation Loss: 0.000303\n",
      " Epoch 141: Train Loss: 0.000246, Validation Loss: 0.000305\n",
      " Epoch 142: Train Loss: 0.000247, Validation Loss: 0.000303\n",
      " Epoch 143: Train Loss: 0.000247, Validation Loss: 0.000304\n",
      " Epoch 144: Train Loss: 0.000246, Validation Loss: 0.000302\n",
      " Epoch 145: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 146: Train Loss: 0.000245, Validation Loss: 0.000305\n",
      " Epoch 147: Train Loss: 0.000245, Validation Loss: 0.000302\n",
      " Epoch 148: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 149: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 150: Train Loss: 0.000244, Validation Loss: 0.000302\n",
      " Epoch 151: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 152: Train Loss: 0.000242, Validation Loss: 0.000302\n",
      " Epoch 153: Train Loss: 0.000242, Validation Loss: 0.000301\n",
      " Epoch 154: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 155: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 156: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 157: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 158: Train Loss: 0.000241, Validation Loss: 0.000303\n",
      " Epoch 159: Train Loss: 0.000241, Validation Loss: 0.000302\n",
      " Epoch 160: Train Loss: 0.000240, Validation Loss: 0.000302\n",
      " Epoch 161: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 162: Train Loss: 0.000240, Validation Loss: 0.000301\n",
      " Epoch 163: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 164: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 165: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 166: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 167: Train Loss: 0.000238, Validation Loss: 0.000302\n",
      " Epoch 168: Train Loss: 0.000239, Validation Loss: 0.000301\n",
      " Epoch 169: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 170: Train Loss: 0.000238, Validation Loss: 0.000301\n",
      " Epoch 171: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 172: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 173: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 174: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 175: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 176: Train Loss: 0.000237, Validation Loss: 0.000300\n",
      " Epoch 177: Train Loss: 0.000237, Validation Loss: 0.000302\n",
      " Epoch 178: Train Loss: 0.000237, Validation Loss: 0.000301\n",
      " Epoch 179: Train Loss: 0.000236, Validation Loss: 0.000300\n",
      " Epoch 180: Train Loss: 0.000236, Validation Loss: 0.000301\n",
      " Epoch 181: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 182: Train Loss: 0.000235, Validation Loss: 0.000302\n",
      " Epoch 183: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 184: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 185: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 186: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 187: Train Loss: 0.000234, Validation Loss: 0.000301\n",
      " Epoch 188: Train Loss: 0.000234, Validation Loss: 0.000300\n",
      " Epoch 189: Train Loss: 0.000233, Validation Loss: 0.000301\n",
      " Epoch 190: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 191: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 192: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 193: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 194: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 195: Train Loss: 0.000233, Validation Loss: 0.000300\n",
      " Epoch 196: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 197: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 198: Train Loss: 0.000232, Validation Loss: 0.000301\n",
      " Epoch 199: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 200: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 201: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      " Epoch 202: Train Loss: 0.000232, Validation Loss: 0.000300\n",
      " Epoch 203: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 204: Train Loss: 0.000231, Validation Loss: 0.000301\n",
      " Epoch 205: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 206: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 207: Train Loss: 0.000231, Validation Loss: 0.000300\n",
      " Epoch 208: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 209: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 210: Train Loss: 0.000230, Validation Loss: 0.000300\n",
      " Epoch 211: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 212: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 213: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 214: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 215: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 216: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 217: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 218: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 219: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 220: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 221: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 222: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 223: Train Loss: 0.000229, Validation Loss: 0.000300\n",
      " Epoch 224: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 225: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 226: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 227: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 228: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 229: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 230: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 231: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 232: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 233: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 234: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 235: Train Loss: 0.000228, Validation Loss: 0.000300\n",
      " Epoch 236: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 237: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 238: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 239: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 240: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 241: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 242: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 243: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 244: Train Loss: 0.000227, Validation Loss: 0.000300\n",
      " Epoch 245: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 246: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 247: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      " Epoch 248: Train Loss: 0.000226, Validation Loss: 0.000300\n",
      "Early stopping at epoch 248 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.016293, Validation Loss: 0.029594\n",
      " Epoch 2: Train Loss: 0.007308, Validation Loss: 0.009537\n",
      " Epoch 3: Train Loss: 0.005686, Validation Loss: 0.005249\n",
      " Epoch 4: Train Loss: 0.002820, Validation Loss: 0.002623\n",
      " Epoch 5: Train Loss: 0.001262, Validation Loss: 0.001208\n",
      " Epoch 6: Train Loss: 0.000950, Validation Loss: 0.000869\n",
      " Epoch 7: Train Loss: 0.000800, Validation Loss: 0.000771\n",
      " Epoch 8: Train Loss: 0.000702, Validation Loss: 0.000685\n",
      " Epoch 9: Train Loss: 0.000637, Validation Loss: 0.000611\n",
      " Epoch 10: Train Loss: 0.000594, Validation Loss: 0.000581\n",
      " Epoch 11: Train Loss: 0.000568, Validation Loss: 0.000650\n",
      " Epoch 12: Train Loss: 0.000530, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000507, Validation Loss: 0.000499\n",
      " Epoch 14: Train Loss: 0.000490, Validation Loss: 0.000500\n",
      " Epoch 15: Train Loss: 0.000479, Validation Loss: 0.000505\n",
      " Epoch 16: Train Loss: 0.000465, Validation Loss: 0.000483\n",
      " Epoch 17: Train Loss: 0.000454, Validation Loss: 0.000568\n",
      " Epoch 18: Train Loss: 0.000453, Validation Loss: 0.000449\n",
      " Epoch 19: Train Loss: 0.000432, Validation Loss: 0.000431\n",
      " Epoch 20: Train Loss: 0.000422, Validation Loss: 0.000424\n",
      " Epoch 21: Train Loss: 0.000413, Validation Loss: 0.000424\n",
      " Epoch 22: Train Loss: 0.000410, Validation Loss: 0.000415\n",
      " Epoch 23: Train Loss: 0.000414, Validation Loss: 0.000457\n",
      " Epoch 24: Train Loss: 0.000397, Validation Loss: 0.000430\n",
      " Epoch 25: Train Loss: 0.000391, Validation Loss: 0.000441\n",
      " Epoch 26: Train Loss: 0.000392, Validation Loss: 0.000434\n",
      " Epoch 27: Train Loss: 0.000383, Validation Loss: 0.000398\n",
      " Epoch 28: Train Loss: 0.000380, Validation Loss: 0.000643\n",
      " Epoch 29: Train Loss: 0.001859, Validation Loss: 0.002344\n",
      " Epoch 30: Train Loss: 0.000713, Validation Loss: 0.000628\n",
      " Epoch 31: Train Loss: 0.000567, Validation Loss: 0.000556\n",
      " Epoch 32: Train Loss: 0.000526, Validation Loss: 0.000513\n",
      " Epoch 33: Train Loss: 0.000500, Validation Loss: 0.000488\n",
      " Epoch 34: Train Loss: 0.000476, Validation Loss: 0.000476\n",
      " Epoch 35: Train Loss: 0.000455, Validation Loss: 0.000449\n",
      " Epoch 36: Train Loss: 0.000441, Validation Loss: 0.000431\n",
      " Epoch 37: Train Loss: 0.000422, Validation Loss: 0.000434\n",
      " Epoch 38: Train Loss: 0.000412, Validation Loss: 0.000409\n",
      " Epoch 39: Train Loss: 0.000403, Validation Loss: 0.000404\n",
      " Epoch 40: Train Loss: 0.000397, Validation Loss: 0.000402\n",
      " Epoch 41: Train Loss: 0.000391, Validation Loss: 0.000390\n",
      " Epoch 42: Train Loss: 0.000384, Validation Loss: 0.000387\n",
      " Epoch 43: Train Loss: 0.000380, Validation Loss: 0.000384\n",
      " Epoch 44: Train Loss: 0.000379, Validation Loss: 0.000378\n",
      " Epoch 45: Train Loss: 0.000372, Validation Loss: 0.000373\n",
      " Epoch 46: Train Loss: 0.000368, Validation Loss: 0.000377\n",
      " Epoch 47: Train Loss: 0.000368, Validation Loss: 0.000374\n",
      " Epoch 48: Train Loss: 0.000364, Validation Loss: 0.000387\n",
      " Epoch 49: Train Loss: 0.000357, Validation Loss: 0.000359\n",
      " Epoch 50: Train Loss: 0.000355, Validation Loss: 0.000360\n",
      " Epoch 51: Train Loss: 0.000355, Validation Loss: 0.000355\n",
      " Epoch 52: Train Loss: 0.000345, Validation Loss: 0.000353\n",
      " Epoch 53: Train Loss: 0.000343, Validation Loss: 0.000351\n",
      " Epoch 54: Train Loss: 0.000344, Validation Loss: 0.000352\n",
      " Epoch 55: Train Loss: 0.000346, Validation Loss: 0.000345\n",
      " Epoch 56: Train Loss: 0.000337, Validation Loss: 0.000346\n",
      " Epoch 57: Train Loss: 0.000335, Validation Loss: 0.000352\n",
      " Epoch 58: Train Loss: 0.000330, Validation Loss: 0.000337\n",
      " Epoch 59: Train Loss: 0.000331, Validation Loss: 0.000343\n",
      " Epoch 60: Train Loss: 0.000330, Validation Loss: 0.000358\n",
      " Epoch 61: Train Loss: 0.000325, Validation Loss: 0.000334\n",
      " Epoch 62: Train Loss: 0.000321, Validation Loss: 0.000330\n",
      " Epoch 63: Train Loss: 0.000319, Validation Loss: 0.000331\n",
      " Epoch 64: Train Loss: 0.000318, Validation Loss: 0.000329\n",
      " Epoch 65: Train Loss: 0.000317, Validation Loss: 0.000334\n",
      " Epoch 66: Train Loss: 0.000315, Validation Loss: 0.000329\n",
      " Epoch 67: Train Loss: 0.000316, Validation Loss: 0.000329\n",
      " Epoch 68: Train Loss: 0.000315, Validation Loss: 0.000325\n",
      " Epoch 69: Train Loss: 0.000312, Validation Loss: 0.000323\n",
      " Epoch 70: Train Loss: 0.000311, Validation Loss: 0.000323\n",
      " Epoch 71: Train Loss: 0.000310, Validation Loss: 0.000325\n",
      " Epoch 72: Train Loss: 0.000309, Validation Loss: 0.000323\n",
      " Epoch 73: Train Loss: 0.000309, Validation Loss: 0.000321\n",
      " Epoch 74: Train Loss: 0.000307, Validation Loss: 0.000331\n",
      " Epoch 75: Train Loss: 0.000307, Validation Loss: 0.000320\n",
      " Epoch 76: Train Loss: 0.000304, Validation Loss: 0.000321\n",
      " Epoch 77: Train Loss: 0.000303, Validation Loss: 0.000317\n",
      " Epoch 78: Train Loss: 0.000303, Validation Loss: 0.000315\n",
      " Epoch 79: Train Loss: 0.000301, Validation Loss: 0.000315\n",
      " Epoch 80: Train Loss: 0.000300, Validation Loss: 0.000318\n",
      " Epoch 81: Train Loss: 0.000299, Validation Loss: 0.000313\n",
      " Epoch 82: Train Loss: 0.000298, Validation Loss: 0.000312\n",
      " Epoch 83: Train Loss: 0.000299, Validation Loss: 0.000312\n",
      " Epoch 84: Train Loss: 0.000296, Validation Loss: 0.000310\n",
      " Epoch 85: Train Loss: 0.000296, Validation Loss: 0.000309\n",
      " Epoch 86: Train Loss: 0.000293, Validation Loss: 0.000317\n",
      " Epoch 87: Train Loss: 0.000292, Validation Loss: 0.000311\n",
      " Epoch 88: Train Loss: 0.000291, Validation Loss: 0.000307\n",
      " Epoch 89: Train Loss: 0.000292, Validation Loss: 0.000309\n",
      " Epoch 90: Train Loss: 0.000289, Validation Loss: 0.000305\n",
      " Epoch 91: Train Loss: 0.000287, Validation Loss: 0.000305\n",
      " Epoch 92: Train Loss: 0.000286, Validation Loss: 0.000303\n",
      " Epoch 93: Train Loss: 0.000285, Validation Loss: 0.000310\n",
      " Epoch 94: Train Loss: 0.000285, Validation Loss: 0.000306\n",
      " Epoch 95: Train Loss: 0.000285, Validation Loss: 0.000303\n",
      " Epoch 96: Train Loss: 0.000284, Validation Loss: 0.000303\n",
      " Epoch 97: Train Loss: 0.000283, Validation Loss: 0.000303\n",
      " Epoch 98: Train Loss: 0.000284, Validation Loss: 0.000302\n",
      " Epoch 99: Train Loss: 0.000284, Validation Loss: 0.000302\n",
      " Epoch 100: Train Loss: 0.000281, Validation Loss: 0.000301\n",
      " Epoch 101: Train Loss: 0.000280, Validation Loss: 0.000301\n",
      " Epoch 102: Train Loss: 0.000280, Validation Loss: 0.000306\n",
      " Epoch 103: Train Loss: 0.000280, Validation Loss: 0.000301\n",
      " Epoch 104: Train Loss: 0.000279, Validation Loss: 0.000303\n",
      " Epoch 105: Train Loss: 0.000278, Validation Loss: 0.000304\n",
      " Epoch 106: Train Loss: 0.000278, Validation Loss: 0.000309\n",
      " Epoch 107: Train Loss: 0.000278, Validation Loss: 0.000298\n",
      " Epoch 108: Train Loss: 0.000277, Validation Loss: 0.000298\n",
      " Epoch 109: Train Loss: 0.000277, Validation Loss: 0.000309\n",
      " Epoch 110: Train Loss: 0.000276, Validation Loss: 0.000298\n",
      " Epoch 111: Train Loss: 0.000277, Validation Loss: 0.000298\n",
      " Epoch 112: Train Loss: 0.000275, Validation Loss: 0.000300\n",
      " Epoch 113: Train Loss: 0.000273, Validation Loss: 0.000295\n",
      " Epoch 114: Train Loss: 0.000274, Validation Loss: 0.000296\n",
      " Epoch 115: Train Loss: 0.000274, Validation Loss: 0.000295\n",
      " Epoch 116: Train Loss: 0.000272, Validation Loss: 0.000294\n",
      " Epoch 117: Train Loss: 0.000270, Validation Loss: 0.000295\n",
      " Epoch 118: Train Loss: 0.000271, Validation Loss: 0.000293\n",
      " Epoch 119: Train Loss: 0.000270, Validation Loss: 0.000302\n",
      " Epoch 120: Train Loss: 0.000269, Validation Loss: 0.000294\n",
      " Epoch 121: Train Loss: 0.000267, Validation Loss: 0.000291\n",
      " Epoch 122: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 123: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 124: Train Loss: 0.000267, Validation Loss: 0.000291\n",
      " Epoch 125: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 126: Train Loss: 0.000266, Validation Loss: 0.000291\n",
      " Epoch 127: Train Loss: 0.000265, Validation Loss: 0.000292\n",
      " Epoch 128: Train Loss: 0.000264, Validation Loss: 0.000290\n",
      " Epoch 129: Train Loss: 0.000264, Validation Loss: 0.000291\n",
      " Epoch 130: Train Loss: 0.000264, Validation Loss: 0.000290\n",
      " Epoch 131: Train Loss: 0.000265, Validation Loss: 0.000290\n",
      " Epoch 132: Train Loss: 0.000263, Validation Loss: 0.000292\n",
      " Epoch 133: Train Loss: 0.000263, Validation Loss: 0.000289\n",
      " Epoch 134: Train Loss: 0.000263, Validation Loss: 0.000289\n",
      " Epoch 135: Train Loss: 0.000262, Validation Loss: 0.000290\n",
      " Epoch 136: Train Loss: 0.000262, Validation Loss: 0.000288\n",
      " Epoch 137: Train Loss: 0.000261, Validation Loss: 0.000291\n",
      " Epoch 138: Train Loss: 0.000261, Validation Loss: 0.000288\n",
      " Epoch 139: Train Loss: 0.000261, Validation Loss: 0.000291\n",
      " Epoch 140: Train Loss: 0.000261, Validation Loss: 0.000287\n",
      " Epoch 141: Train Loss: 0.000260, Validation Loss: 0.000288\n",
      " Epoch 142: Train Loss: 0.000261, Validation Loss: 0.000287\n",
      " Epoch 143: Train Loss: 0.000259, Validation Loss: 0.000289\n",
      " Epoch 144: Train Loss: 0.000259, Validation Loss: 0.000289\n",
      " Epoch 145: Train Loss: 0.000259, Validation Loss: 0.000286\n",
      " Epoch 146: Train Loss: 0.000259, Validation Loss: 0.000286\n",
      " Epoch 147: Train Loss: 0.000257, Validation Loss: 0.000287\n",
      " Epoch 148: Train Loss: 0.000257, Validation Loss: 0.000290\n",
      " Epoch 149: Train Loss: 0.000256, Validation Loss: 0.000286\n",
      " Epoch 150: Train Loss: 0.000258, Validation Loss: 0.000285\n",
      " Epoch 151: Train Loss: 0.000255, Validation Loss: 0.000285\n",
      " Epoch 152: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 153: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 154: Train Loss: 0.000254, Validation Loss: 0.000286\n",
      " Epoch 155: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 156: Train Loss: 0.000254, Validation Loss: 0.000287\n",
      " Epoch 157: Train Loss: 0.000254, Validation Loss: 0.000285\n",
      " Epoch 158: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 159: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 160: Train Loss: 0.000253, Validation Loss: 0.000284\n",
      " Epoch 161: Train Loss: 0.000253, Validation Loss: 0.000286\n",
      " Epoch 162: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 163: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 164: Train Loss: 0.000252, Validation Loss: 0.000284\n",
      " Epoch 165: Train Loss: 0.000251, Validation Loss: 0.000284\n",
      " Epoch 166: Train Loss: 0.000251, Validation Loss: 0.000284\n",
      " Epoch 167: Train Loss: 0.000252, Validation Loss: 0.000283\n",
      " Epoch 168: Train Loss: 0.000251, Validation Loss: 0.000287\n",
      " Epoch 169: Train Loss: 0.000251, Validation Loss: 0.000283\n",
      " Epoch 170: Train Loss: 0.000251, Validation Loss: 0.000287\n",
      " Epoch 171: Train Loss: 0.000251, Validation Loss: 0.000283\n",
      " Epoch 172: Train Loss: 0.000250, Validation Loss: 0.000283\n",
      " Epoch 173: Train Loss: 0.000250, Validation Loss: 0.000283\n",
      " Epoch 174: Train Loss: 0.000250, Validation Loss: 0.000282\n",
      " Epoch 175: Train Loss: 0.000249, Validation Loss: 0.000286\n",
      " Epoch 176: Train Loss: 0.000249, Validation Loss: 0.000282\n",
      " Epoch 177: Train Loss: 0.000249, Validation Loss: 0.000283\n",
      " Epoch 178: Train Loss: 0.000249, Validation Loss: 0.000282\n",
      " Epoch 179: Train Loss: 0.000249, Validation Loss: 0.000283\n",
      " Epoch 180: Train Loss: 0.000248, Validation Loss: 0.000284\n",
      " Epoch 181: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 182: Train Loss: 0.000247, Validation Loss: 0.000283\n",
      " Epoch 183: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 184: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 185: Train Loss: 0.000247, Validation Loss: 0.000282\n",
      " Epoch 186: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 187: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 188: Train Loss: 0.000246, Validation Loss: 0.000282\n",
      " Epoch 189: Train Loss: 0.000246, Validation Loss: 0.000282\n",
      " Epoch 190: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 191: Train Loss: 0.000246, Validation Loss: 0.000281\n",
      " Epoch 192: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 193: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 194: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 195: Train Loss: 0.000245, Validation Loss: 0.000282\n",
      " Epoch 196: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 197: Train Loss: 0.000245, Validation Loss: 0.000281\n",
      " Epoch 198: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 199: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 200: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 201: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 202: Train Loss: 0.000244, Validation Loss: 0.000281\n",
      " Epoch 203: Train Loss: 0.000244, Validation Loss: 0.000280\n",
      " Epoch 204: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 205: Train Loss: 0.000243, Validation Loss: 0.000281\n",
      " Epoch 206: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 207: Train Loss: 0.000244, Validation Loss: 0.000282\n",
      " Epoch 208: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 209: Train Loss: 0.000243, Validation Loss: 0.000283\n",
      " Epoch 210: Train Loss: 0.000243, Validation Loss: 0.000280\n",
      " Epoch 211: Train Loss: 0.000242, Validation Loss: 0.000281\n",
      " Epoch 212: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 213: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 214: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 215: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 216: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 217: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 218: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 219: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 220: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 221: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 222: Train Loss: 0.000242, Validation Loss: 0.000280\n",
      " Epoch 223: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 224: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 225: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 226: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 227: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 228: Train Loss: 0.000241, Validation Loss: 0.000282\n",
      " Epoch 229: Train Loss: 0.000241, Validation Loss: 0.000280\n",
      " Epoch 230: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 231: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 232: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 233: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 234: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 235: Train Loss: 0.000240, Validation Loss: 0.000279\n",
      " Epoch 236: Train Loss: 0.000240, Validation Loss: 0.000280\n",
      " Epoch 237: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 238: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 239: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 240: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 241: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 242: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 243: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 244: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 245: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 246: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 247: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 248: Train Loss: 0.000239, Validation Loss: 0.000279\n",
      " Epoch 249: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 250: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 251: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 252: Train Loss: 0.000239, Validation Loss: 0.000280\n",
      " Epoch 253: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 254: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 255: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 256: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 257: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 258: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 259: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 260: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 261: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 262: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 263: Train Loss: 0.000238, Validation Loss: 0.000280\n",
      " Epoch 264: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 265: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 266: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 267: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 268: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 269: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 270: Train Loss: 0.000238, Validation Loss: 0.000279\n",
      " Epoch 271: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 272: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 273: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 274: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 275: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 276: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 277: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 278: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 279: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 280: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 281: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 282: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 283: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 284: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 285: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 286: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 287: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 288: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 289: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 290: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 291: Train Loss: 0.000237, Validation Loss: 0.000279\n",
      " Epoch 292: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 293: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 294: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 295: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 296: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 297: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 298: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 299: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 300: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 301: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 302: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 303: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 304: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 305: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 306: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 307: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 308: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 309: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 310: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 311: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 312: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 313: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 314: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 315: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 316: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 317: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 318: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 319: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 320: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 321: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 322: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 323: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 324: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 325: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 326: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 327: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 328: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 329: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 330: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 331: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 332: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 333: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 334: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 335: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 336: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 337: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 338: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 339: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 340: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 341: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 342: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 343: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 344: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 345: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 346: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 347: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 348: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 349: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 350: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 351: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 352: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 353: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 354: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 355: Train Loss: 0.000236, Validation Loss: 0.000279\n",
      " Epoch 356: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 357: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 358: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 359: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 360: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 361: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 362: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 363: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 364: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 365: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 366: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 367: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 368: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 369: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 370: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 371: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 372: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 373: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 374: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 375: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 376: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 377: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 378: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 379: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 380: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 381: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 382: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 383: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 384: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 385: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 386: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 387: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 388: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 389: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 390: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 391: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 392: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 393: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 394: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 395: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 396: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 397: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 398: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 399: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 400: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 401: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 402: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 403: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 404: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 405: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 406: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 407: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 408: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 409: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 410: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 411: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 412: Train Loss: 0.000235, Validation Loss: 0.000279\n",
      " Epoch 413: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 414: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 415: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 416: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 417: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 418: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 419: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 420: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 421: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 422: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 423: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 424: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 425: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 426: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 427: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 428: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 429: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 430: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 431: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 432: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 433: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 434: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 435: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 436: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 437: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 438: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 439: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 440: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 441: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 442: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 443: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 444: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 445: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      " Epoch 446: Train Loss: 0.000235, Validation Loss: 0.000278\n",
      "Early stopping at epoch 446 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.014178, Validation Loss: 0.018114\n",
      " Epoch 2: Train Loss: 0.002815, Validation Loss: 0.003503\n",
      " Epoch 3: Train Loss: 0.001962, Validation Loss: 0.002233\n",
      " Epoch 4: Train Loss: 0.001320, Validation Loss: 0.001201\n",
      " Epoch 5: Train Loss: 0.000923, Validation Loss: 0.000874\n",
      " Epoch 6: Train Loss: 0.000807, Validation Loss: 0.000768\n",
      " Epoch 7: Train Loss: 0.000730, Validation Loss: 0.000700\n",
      " Epoch 8: Train Loss: 0.000672, Validation Loss: 0.000648\n",
      " Epoch 9: Train Loss: 0.000624, Validation Loss: 0.000608\n",
      " Epoch 10: Train Loss: 0.000587, Validation Loss: 0.000580\n",
      " Epoch 11: Train Loss: 0.000551, Validation Loss: 0.000540\n",
      " Epoch 12: Train Loss: 0.000523, Validation Loss: 0.000522\n",
      " Epoch 13: Train Loss: 0.000502, Validation Loss: 0.000501\n",
      " Epoch 14: Train Loss: 0.000483, Validation Loss: 0.000491\n",
      " Epoch 15: Train Loss: 0.000467, Validation Loss: 0.000466\n",
      " Epoch 16: Train Loss: 0.000452, Validation Loss: 0.000459\n",
      " Epoch 17: Train Loss: 0.000439, Validation Loss: 0.000444\n",
      " Epoch 18: Train Loss: 0.000429, Validation Loss: 0.000437\n",
      " Epoch 19: Train Loss: 0.000421, Validation Loss: 0.000430\n",
      " Epoch 20: Train Loss: 0.000411, Validation Loss: 0.000417\n",
      " Epoch 21: Train Loss: 0.000404, Validation Loss: 0.000411\n",
      " Epoch 22: Train Loss: 0.000400, Validation Loss: 0.000409\n",
      " Epoch 23: Train Loss: 0.000390, Validation Loss: 0.000398\n",
      " Epoch 24: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 25: Train Loss: 0.000378, Validation Loss: 0.000389\n",
      " Epoch 26: Train Loss: 0.000373, Validation Loss: 0.000382\n",
      " Epoch 27: Train Loss: 0.000367, Validation Loss: 0.000379\n",
      " Epoch 28: Train Loss: 0.000362, Validation Loss: 0.000379\n",
      " Epoch 29: Train Loss: 0.000359, Validation Loss: 0.000375\n",
      " Epoch 30: Train Loss: 0.000357, Validation Loss: 0.000367\n",
      " Epoch 31: Train Loss: 0.000345, Validation Loss: 0.000361\n",
      " Epoch 32: Train Loss: 0.000342, Validation Loss: 0.000360\n",
      " Epoch 33: Train Loss: 0.000339, Validation Loss: 0.000357\n",
      " Epoch 34: Train Loss: 0.000338, Validation Loss: 0.000356\n",
      " Epoch 35: Train Loss: 0.000336, Validation Loss: 0.000355\n",
      " Epoch 36: Train Loss: 0.000333, Validation Loss: 0.000352\n",
      " Epoch 37: Train Loss: 0.000332, Validation Loss: 0.000350\n",
      " Epoch 38: Train Loss: 0.000329, Validation Loss: 0.000349\n",
      " Epoch 39: Train Loss: 0.000327, Validation Loss: 0.000346\n",
      " Epoch 40: Train Loss: 0.000325, Validation Loss: 0.000344\n",
      " Epoch 41: Train Loss: 0.000323, Validation Loss: 0.000343\n",
      " Epoch 42: Train Loss: 0.000321, Validation Loss: 0.000340\n",
      " Epoch 43: Train Loss: 0.000319, Validation Loss: 0.000342\n",
      " Epoch 44: Train Loss: 0.000317, Validation Loss: 0.000339\n",
      " Epoch 45: Train Loss: 0.000317, Validation Loss: 0.000338\n",
      " Epoch 46: Train Loss: 0.000313, Validation Loss: 0.000335\n",
      " Epoch 47: Train Loss: 0.000313, Validation Loss: 0.000337\n",
      " Epoch 48: Train Loss: 0.000312, Validation Loss: 0.000334\n",
      " Epoch 49: Train Loss: 0.000310, Validation Loss: 0.000332\n",
      " Epoch 50: Train Loss: 0.000306, Validation Loss: 0.000331\n",
      " Epoch 51: Train Loss: 0.000306, Validation Loss: 0.000329\n",
      " Epoch 52: Train Loss: 0.000305, Validation Loss: 0.000329\n",
      " Epoch 53: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 54: Train Loss: 0.000299, Validation Loss: 0.000328\n",
      " Epoch 55: Train Loss: 0.000299, Validation Loss: 0.000321\n",
      " Epoch 56: Train Loss: 0.000300, Validation Loss: 0.000323\n",
      " Epoch 57: Train Loss: 0.000297, Validation Loss: 0.000324\n",
      " Epoch 58: Train Loss: 0.000294, Validation Loss: 0.000323\n",
      " Epoch 59: Train Loss: 0.000294, Validation Loss: 0.000316\n",
      " Epoch 60: Train Loss: 0.000290, Validation Loss: 0.000316\n",
      " Epoch 61: Train Loss: 0.000285, Validation Loss: 0.000313\n",
      " Epoch 62: Train Loss: 0.000285, Validation Loss: 0.000312\n",
      " Epoch 63: Train Loss: 0.000283, Validation Loss: 0.000312\n",
      " Epoch 64: Train Loss: 0.000282, Validation Loss: 0.000312\n",
      " Epoch 65: Train Loss: 0.000284, Validation Loss: 0.000310\n",
      " Epoch 66: Train Loss: 0.000282, Validation Loss: 0.000310\n",
      " Epoch 67: Train Loss: 0.000281, Validation Loss: 0.000310\n",
      " Epoch 68: Train Loss: 0.000280, Validation Loss: 0.000309\n",
      " Epoch 69: Train Loss: 0.000279, Validation Loss: 0.000309\n",
      " Epoch 70: Train Loss: 0.000278, Validation Loss: 0.000308\n",
      " Epoch 71: Train Loss: 0.000277, Validation Loss: 0.000307\n",
      " Epoch 72: Train Loss: 0.000276, Validation Loss: 0.000306\n",
      " Epoch 73: Train Loss: 0.000275, Validation Loss: 0.000307\n",
      " Epoch 74: Train Loss: 0.000275, Validation Loss: 0.000306\n",
      " Epoch 75: Train Loss: 0.000274, Validation Loss: 0.000304\n",
      " Epoch 76: Train Loss: 0.000273, Validation Loss: 0.000304\n",
      " Epoch 77: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 78: Train Loss: 0.000274, Validation Loss: 0.000309\n",
      " Epoch 79: Train Loss: 0.000272, Validation Loss: 0.000304\n",
      " Epoch 80: Train Loss: 0.000270, Validation Loss: 0.000302\n",
      " Epoch 81: Train Loss: 0.000269, Validation Loss: 0.000302\n",
      " Epoch 82: Train Loss: 0.000268, Validation Loss: 0.000303\n",
      " Epoch 83: Train Loss: 0.000267, Validation Loss: 0.000300\n",
      " Epoch 84: Train Loss: 0.000266, Validation Loss: 0.000300\n",
      " Epoch 85: Train Loss: 0.000265, Validation Loss: 0.000301\n",
      " Epoch 86: Train Loss: 0.000265, Validation Loss: 0.000298\n",
      " Epoch 87: Train Loss: 0.000264, Validation Loss: 0.000299\n",
      " Epoch 88: Train Loss: 0.000263, Validation Loss: 0.000299\n",
      " Epoch 89: Train Loss: 0.000263, Validation Loss: 0.000297\n",
      " Epoch 90: Train Loss: 0.000263, Validation Loss: 0.000298\n",
      " Epoch 91: Train Loss: 0.000258, Validation Loss: 0.000295\n",
      " Epoch 92: Train Loss: 0.000257, Validation Loss: 0.000295\n",
      " Epoch 93: Train Loss: 0.000257, Validation Loss: 0.000294\n",
      " Epoch 94: Train Loss: 0.000257, Validation Loss: 0.000298\n",
      " Epoch 95: Train Loss: 0.000257, Validation Loss: 0.000295\n",
      " Epoch 96: Train Loss: 0.000255, Validation Loss: 0.000294\n",
      " Epoch 97: Train Loss: 0.000255, Validation Loss: 0.000293\n",
      " Epoch 98: Train Loss: 0.000255, Validation Loss: 0.000293\n",
      " Epoch 99: Train Loss: 0.000254, Validation Loss: 0.000293\n",
      " Epoch 100: Train Loss: 0.000253, Validation Loss: 0.000293\n",
      " Epoch 101: Train Loss: 0.000253, Validation Loss: 0.000292\n",
      " Epoch 102: Train Loss: 0.000252, Validation Loss: 0.000292\n",
      " Epoch 103: Train Loss: 0.000252, Validation Loss: 0.000291\n",
      " Epoch 104: Train Loss: 0.000251, Validation Loss: 0.000291\n",
      " Epoch 105: Train Loss: 0.000251, Validation Loss: 0.000291\n",
      " Epoch 106: Train Loss: 0.000250, Validation Loss: 0.000291\n",
      " Epoch 107: Train Loss: 0.000250, Validation Loss: 0.000290\n",
      " Epoch 108: Train Loss: 0.000249, Validation Loss: 0.000290\n",
      " Epoch 109: Train Loss: 0.000249, Validation Loss: 0.000291\n",
      " Epoch 110: Train Loss: 0.000248, Validation Loss: 0.000290\n",
      " Epoch 111: Train Loss: 0.000249, Validation Loss: 0.000291\n",
      " Epoch 112: Train Loss: 0.000248, Validation Loss: 0.000290\n",
      " Epoch 113: Train Loss: 0.000247, Validation Loss: 0.000289\n",
      " Epoch 114: Train Loss: 0.000246, Validation Loss: 0.000288\n",
      " Epoch 115: Train Loss: 0.000247, Validation Loss: 0.000290\n",
      " Epoch 116: Train Loss: 0.000246, Validation Loss: 0.000288\n",
      " Epoch 117: Train Loss: 0.000245, Validation Loss: 0.000288\n",
      " Epoch 118: Train Loss: 0.000244, Validation Loss: 0.000287\n",
      " Epoch 119: Train Loss: 0.000243, Validation Loss: 0.000287\n",
      " Epoch 120: Train Loss: 0.000243, Validation Loss: 0.000287\n",
      " Epoch 121: Train Loss: 0.000241, Validation Loss: 0.000285\n",
      " Epoch 122: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 123: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 124: Train Loss: 0.000240, Validation Loss: 0.000286\n",
      " Epoch 125: Train Loss: 0.000240, Validation Loss: 0.000285\n",
      " Epoch 126: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 127: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 128: Train Loss: 0.000239, Validation Loss: 0.000285\n",
      " Epoch 129: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 130: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 131: Train Loss: 0.000237, Validation Loss: 0.000285\n",
      " Epoch 132: Train Loss: 0.000237, Validation Loss: 0.000284\n",
      " Epoch 133: Train Loss: 0.000238, Validation Loss: 0.000285\n",
      " Epoch 134: Train Loss: 0.000237, Validation Loss: 0.000284\n",
      " Epoch 135: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 136: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 137: Train Loss: 0.000236, Validation Loss: 0.000284\n",
      " Epoch 138: Train Loss: 0.000235, Validation Loss: 0.000284\n",
      " Epoch 139: Train Loss: 0.000235, Validation Loss: 0.000284\n",
      " Epoch 140: Train Loss: 0.000235, Validation Loss: 0.000283\n",
      " Epoch 141: Train Loss: 0.000234, Validation Loss: 0.000284\n",
      " Epoch 142: Train Loss: 0.000234, Validation Loss: 0.000284\n",
      " Epoch 143: Train Loss: 0.000235, Validation Loss: 0.000283\n",
      " Epoch 144: Train Loss: 0.000234, Validation Loss: 0.000283\n",
      " Epoch 145: Train Loss: 0.000233, Validation Loss: 0.000283\n",
      " Epoch 146: Train Loss: 0.000233, Validation Loss: 0.000283\n",
      " Epoch 147: Train Loss: 0.000232, Validation Loss: 0.000283\n",
      " Epoch 148: Train Loss: 0.000232, Validation Loss: 0.000282\n",
      " Epoch 149: Train Loss: 0.000231, Validation Loss: 0.000282\n",
      " Epoch 150: Train Loss: 0.000231, Validation Loss: 0.000282\n",
      " Epoch 151: Train Loss: 0.000230, Validation Loss: 0.000282\n",
      " Epoch 152: Train Loss: 0.000230, Validation Loss: 0.000281\n",
      " Epoch 153: Train Loss: 0.000230, Validation Loss: 0.000282\n",
      " Epoch 154: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 155: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 156: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 157: Train Loss: 0.000229, Validation Loss: 0.000281\n",
      " Epoch 158: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 159: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 160: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 161: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 162: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 163: Train Loss: 0.000228, Validation Loss: 0.000281\n",
      " Epoch 164: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 165: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 166: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 167: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 168: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 169: Train Loss: 0.000227, Validation Loss: 0.000281\n",
      " Epoch 170: Train Loss: 0.000226, Validation Loss: 0.000281\n",
      " Epoch 171: Train Loss: 0.000226, Validation Loss: 0.000281\n",
      " Epoch 172: Train Loss: 0.000226, Validation Loss: 0.000280\n",
      " Epoch 173: Train Loss: 0.000225, Validation Loss: 0.000281\n",
      " Epoch 174: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 175: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 176: Train Loss: 0.000225, Validation Loss: 0.000280\n",
      " Epoch 177: Train Loss: 0.000224, Validation Loss: 0.000280\n",
      " Epoch 178: Train Loss: 0.000224, Validation Loss: 0.000280\n",
      " Epoch 179: Train Loss: 0.000224, Validation Loss: 0.000281\n",
      " Epoch 180: Train Loss: 0.000224, Validation Loss: 0.000281\n",
      " Epoch 181: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 182: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 183: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 184: Train Loss: 0.000223, Validation Loss: 0.000280\n",
      " Epoch 185: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 186: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 187: Train Loss: 0.000222, Validation Loss: 0.000280\n",
      " Epoch 188: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 189: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 190: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 191: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 192: Train Loss: 0.000221, Validation Loss: 0.000280\n",
      " Epoch 193: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 194: Train Loss: 0.000222, Validation Loss: 0.000279\n",
      " Epoch 195: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 196: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 197: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 198: Train Loss: 0.000221, Validation Loss: 0.000279\n",
      " Epoch 199: Train Loss: 0.000220, Validation Loss: 0.000280\n",
      " Epoch 200: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 201: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 202: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 203: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 204: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 205: Train Loss: 0.000220, Validation Loss: 0.000279\n",
      " Epoch 206: Train Loss: 0.000220, Validation Loss: 0.000280\n",
      " Epoch 207: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 208: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 209: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 210: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 211: Train Loss: 0.000219, Validation Loss: 0.000279\n",
      " Epoch 212: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 213: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 214: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 215: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 216: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 217: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 218: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 219: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 220: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 221: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 222: Train Loss: 0.000218, Validation Loss: 0.000279\n",
      " Epoch 223: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 224: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 225: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 226: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 227: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 228: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 229: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 230: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 231: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 232: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 233: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 234: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 235: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 236: Train Loss: 0.000217, Validation Loss: 0.000279\n",
      " Epoch 237: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 238: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 239: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 240: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 241: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 242: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 243: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 244: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 245: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 246: Train Loss: 0.000216, Validation Loss: 0.000279\n",
      " Epoch 247: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 248: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 249: Train Loss: 0.000216, Validation Loss: 0.000278\n",
      " Epoch 250: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 251: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 252: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 253: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 254: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 255: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 256: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 257: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 258: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 259: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 260: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 261: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 262: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 263: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 264: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 265: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 266: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 267: Train Loss: 0.000215, Validation Loss: 0.000279\n",
      " Epoch 268: Train Loss: 0.000215, Validation Loss: 0.000278\n",
      " Epoch 269: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 270: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 271: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 272: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 273: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 274: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 275: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 276: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 277: Train Loss: 0.000214, Validation Loss: 0.000279\n",
      " Epoch 278: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 279: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 280: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 281: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 282: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 283: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 284: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 285: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 286: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 287: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 288: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 289: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 290: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 291: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 292: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 293: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 294: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 295: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 296: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 297: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 298: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 299: Train Loss: 0.000214, Validation Loss: 0.000278\n",
      " Epoch 300: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 301: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 302: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 303: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 304: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 305: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 306: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 307: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 308: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 309: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 310: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 311: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 312: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 313: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 314: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 315: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 316: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 317: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 318: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 319: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 320: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 321: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 322: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 323: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 324: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 325: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 326: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 327: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 328: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 329: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 330: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 331: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 332: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 333: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 334: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 335: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 336: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 337: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 338: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 339: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 340: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 341: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 342: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 343: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 344: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 345: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 346: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 347: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 348: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 349: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 350: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 351: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 352: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 353: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 354: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 355: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 356: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 357: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 358: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 359: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 360: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 361: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 362: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 363: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 364: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 365: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 366: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 367: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 368: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 369: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 370: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 371: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 372: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 373: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 374: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 375: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 376: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 377: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 378: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 379: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 380: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 381: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 382: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 383: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 384: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 385: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 386: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 387: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 388: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 389: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      " Epoch 390: Train Loss: 0.000213, Validation Loss: 0.000278\n",
      "Early stopping at epoch 390 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.012375, Validation Loss: 0.029329\n",
      " Epoch 2: Train Loss: 0.002698, Validation Loss: 0.005570\n",
      " Epoch 3: Train Loss: 0.001861, Validation Loss: 0.001761\n",
      " Epoch 4: Train Loss: 0.001559, Validation Loss: 0.001402\n",
      " Epoch 5: Train Loss: 0.001243, Validation Loss: 0.001192\n",
      " Epoch 6: Train Loss: 0.000926, Validation Loss: 0.000858\n",
      " Epoch 7: Train Loss: 0.000700, Validation Loss: 0.000683\n",
      " Epoch 8: Train Loss: 0.000632, Validation Loss: 0.000611\n",
      " Epoch 9: Train Loss: 0.000583, Validation Loss: 0.000576\n",
      " Epoch 10: Train Loss: 0.000547, Validation Loss: 0.000542\n",
      " Epoch 11: Train Loss: 0.000515, Validation Loss: 0.000507\n",
      " Epoch 12: Train Loss: 0.000489, Validation Loss: 0.000505\n",
      " Epoch 13: Train Loss: 0.000468, Validation Loss: 0.000467\n",
      " Epoch 14: Train Loss: 0.000451, Validation Loss: 0.000453\n",
      " Epoch 15: Train Loss: 0.000439, Validation Loss: 0.000439\n",
      " Epoch 16: Train Loss: 0.000425, Validation Loss: 0.000429\n",
      " Epoch 17: Train Loss: 0.000414, Validation Loss: 0.000420\n",
      " Epoch 18: Train Loss: 0.000406, Validation Loss: 0.000410\n",
      " Epoch 19: Train Loss: 0.000399, Validation Loss: 0.000407\n",
      " Epoch 20: Train Loss: 0.000391, Validation Loss: 0.000406\n",
      " Epoch 21: Train Loss: 0.000384, Validation Loss: 0.000394\n",
      " Epoch 22: Train Loss: 0.000377, Validation Loss: 0.000397\n",
      " Epoch 23: Train Loss: 0.000374, Validation Loss: 0.000391\n",
      " Epoch 24: Train Loss: 0.000370, Validation Loss: 0.000388\n",
      " Epoch 25: Train Loss: 0.000362, Validation Loss: 0.000374\n",
      " Epoch 26: Train Loss: 0.000354, Validation Loss: 0.000381\n",
      " Epoch 27: Train Loss: 0.000353, Validation Loss: 0.000386\n",
      " Epoch 28: Train Loss: 0.000350, Validation Loss: 0.000363\n",
      " Epoch 29: Train Loss: 0.000341, Validation Loss: 0.000360\n",
      " Epoch 30: Train Loss: 0.000342, Validation Loss: 0.000354\n",
      " Epoch 31: Train Loss: 0.000330, Validation Loss: 0.000349\n",
      " Epoch 32: Train Loss: 0.000327, Validation Loss: 0.000348\n",
      " Epoch 33: Train Loss: 0.000325, Validation Loss: 0.000346\n",
      " Epoch 34: Train Loss: 0.000324, Validation Loss: 0.000345\n",
      " Epoch 35: Train Loss: 0.000322, Validation Loss: 0.000343\n",
      " Epoch 36: Train Loss: 0.000320, Validation Loss: 0.000341\n",
      " Epoch 37: Train Loss: 0.000318, Validation Loss: 0.000340\n",
      " Epoch 38: Train Loss: 0.000316, Validation Loss: 0.000339\n",
      " Epoch 39: Train Loss: 0.000316, Validation Loss: 0.000339\n",
      " Epoch 40: Train Loss: 0.000313, Validation Loss: 0.000335\n",
      " Epoch 41: Train Loss: 0.000312, Validation Loss: 0.000337\n",
      " Epoch 42: Train Loss: 0.000309, Validation Loss: 0.000332\n",
      " Epoch 43: Train Loss: 0.000307, Validation Loss: 0.000331\n",
      " Epoch 44: Train Loss: 0.000309, Validation Loss: 0.000332\n",
      " Epoch 45: Train Loss: 0.000305, Validation Loss: 0.000328\n",
      " Epoch 46: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 47: Train Loss: 0.000302, Validation Loss: 0.000327\n",
      " Epoch 48: Train Loss: 0.000299, Validation Loss: 0.000327\n",
      " Epoch 49: Train Loss: 0.000298, Validation Loss: 0.000324\n",
      " Epoch 50: Train Loss: 0.000296, Validation Loss: 0.000325\n",
      " Epoch 51: Train Loss: 0.000295, Validation Loss: 0.000323\n",
      " Epoch 52: Train Loss: 0.000294, Validation Loss: 0.000320\n",
      " Epoch 53: Train Loss: 0.000292, Validation Loss: 0.000321\n",
      " Epoch 54: Train Loss: 0.000289, Validation Loss: 0.000321\n",
      " Epoch 55: Train Loss: 0.000289, Validation Loss: 0.000316\n",
      " Epoch 56: Train Loss: 0.000288, Validation Loss: 0.000314\n",
      " Epoch 57: Train Loss: 0.000287, Validation Loss: 0.000314\n",
      " Epoch 58: Train Loss: 0.000285, Validation Loss: 0.000313\n",
      " Epoch 59: Train Loss: 0.000283, Validation Loss: 0.000314\n",
      " Epoch 60: Train Loss: 0.000279, Validation Loss: 0.000311\n",
      " Epoch 61: Train Loss: 0.000276, Validation Loss: 0.000308\n",
      " Epoch 62: Train Loss: 0.000274, Validation Loss: 0.000307\n",
      " Epoch 63: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 64: Train Loss: 0.000273, Validation Loss: 0.000307\n",
      " Epoch 65: Train Loss: 0.000272, Validation Loss: 0.000306\n",
      " Epoch 66: Train Loss: 0.000271, Validation Loss: 0.000306\n",
      " Epoch 67: Train Loss: 0.000270, Validation Loss: 0.000305\n",
      " Epoch 68: Train Loss: 0.000270, Validation Loss: 0.000305\n",
      " Epoch 69: Train Loss: 0.000269, Validation Loss: 0.000304\n",
      " Epoch 70: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 71: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 72: Train Loss: 0.000266, Validation Loss: 0.000304\n",
      " Epoch 73: Train Loss: 0.000267, Validation Loss: 0.000303\n",
      " Epoch 74: Train Loss: 0.000265, Validation Loss: 0.000301\n",
      " Epoch 75: Train Loss: 0.000264, Validation Loss: 0.000301\n",
      " Epoch 76: Train Loss: 0.000264, Validation Loss: 0.000300\n",
      " Epoch 77: Train Loss: 0.000262, Validation Loss: 0.000300\n",
      " Epoch 78: Train Loss: 0.000261, Validation Loss: 0.000301\n",
      " Epoch 79: Train Loss: 0.000262, Validation Loss: 0.000301\n",
      " Epoch 80: Train Loss: 0.000261, Validation Loss: 0.000300\n",
      " Epoch 81: Train Loss: 0.000262, Validation Loss: 0.000298\n",
      " Epoch 82: Train Loss: 0.000259, Validation Loss: 0.000297\n",
      " Epoch 83: Train Loss: 0.000257, Validation Loss: 0.000300\n",
      " Epoch 84: Train Loss: 0.000256, Validation Loss: 0.000297\n",
      " Epoch 85: Train Loss: 0.000257, Validation Loss: 0.000298\n",
      " Epoch 86: Train Loss: 0.000258, Validation Loss: 0.000300\n",
      " Epoch 87: Train Loss: 0.000254, Validation Loss: 0.000298\n",
      " Epoch 88: Train Loss: 0.000252, Validation Loss: 0.000296\n",
      " Epoch 89: Train Loss: 0.000253, Validation Loss: 0.000294\n",
      " Epoch 90: Train Loss: 0.000252, Validation Loss: 0.000294\n",
      " Epoch 91: Train Loss: 0.000248, Validation Loss: 0.000293\n",
      " Epoch 92: Train Loss: 0.000247, Validation Loss: 0.000293\n",
      " Epoch 93: Train Loss: 0.000246, Validation Loss: 0.000292\n",
      " Epoch 94: Train Loss: 0.000247, Validation Loss: 0.000292\n",
      " Epoch 95: Train Loss: 0.000247, Validation Loss: 0.000292\n",
      " Epoch 96: Train Loss: 0.000245, Validation Loss: 0.000292\n",
      " Epoch 97: Train Loss: 0.000244, Validation Loss: 0.000292\n",
      " Epoch 98: Train Loss: 0.000244, Validation Loss: 0.000293\n",
      " Epoch 99: Train Loss: 0.000244, Validation Loss: 0.000292\n",
      " Epoch 100: Train Loss: 0.000243, Validation Loss: 0.000291\n",
      " Epoch 101: Train Loss: 0.000244, Validation Loss: 0.000291\n",
      " Epoch 102: Train Loss: 0.000243, Validation Loss: 0.000291\n",
      " Epoch 103: Train Loss: 0.000242, Validation Loss: 0.000291\n",
      " Epoch 104: Train Loss: 0.000242, Validation Loss: 0.000290\n",
      " Epoch 105: Train Loss: 0.000241, Validation Loss: 0.000292\n",
      " Epoch 106: Train Loss: 0.000242, Validation Loss: 0.000290\n",
      " Epoch 107: Train Loss: 0.000240, Validation Loss: 0.000290\n",
      " Epoch 108: Train Loss: 0.000240, Validation Loss: 0.000291\n",
      " Epoch 109: Train Loss: 0.000239, Validation Loss: 0.000290\n",
      " Epoch 110: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 111: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 112: Train Loss: 0.000238, Validation Loss: 0.000289\n",
      " Epoch 113: Train Loss: 0.000237, Validation Loss: 0.000288\n",
      " Epoch 114: Train Loss: 0.000237, Validation Loss: 0.000290\n",
      " Epoch 115: Train Loss: 0.000236, Validation Loss: 0.000289\n",
      " Epoch 116: Train Loss: 0.000235, Validation Loss: 0.000288\n",
      " Epoch 117: Train Loss: 0.000236, Validation Loss: 0.000288\n",
      " Epoch 118: Train Loss: 0.000234, Validation Loss: 0.000288\n",
      " Epoch 119: Train Loss: 0.000234, Validation Loss: 0.000288\n",
      " Epoch 120: Train Loss: 0.000233, Validation Loss: 0.000288\n",
      " Epoch 121: Train Loss: 0.000231, Validation Loss: 0.000287\n",
      " Epoch 122: Train Loss: 0.000231, Validation Loss: 0.000288\n",
      " Epoch 123: Train Loss: 0.000231, Validation Loss: 0.000287\n",
      " Epoch 124: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 125: Train Loss: 0.000230, Validation Loss: 0.000288\n",
      " Epoch 126: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 127: Train Loss: 0.000230, Validation Loss: 0.000287\n",
      " Epoch 128: Train Loss: 0.000229, Validation Loss: 0.000286\n",
      " Epoch 129: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 130: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 131: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 132: Train Loss: 0.000228, Validation Loss: 0.000286\n",
      " Epoch 133: Train Loss: 0.000227, Validation Loss: 0.000286\n",
      " Epoch 134: Train Loss: 0.000227, Validation Loss: 0.000286\n",
      " Epoch 135: Train Loss: 0.000226, Validation Loss: 0.000287\n",
      " Epoch 136: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 137: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 138: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 139: Train Loss: 0.000226, Validation Loss: 0.000286\n",
      " Epoch 140: Train Loss: 0.000225, Validation Loss: 0.000286\n",
      " Epoch 141: Train Loss: 0.000225, Validation Loss: 0.000286\n",
      " Epoch 142: Train Loss: 0.000224, Validation Loss: 0.000286\n",
      " Epoch 143: Train Loss: 0.000224, Validation Loss: 0.000286\n",
      " Epoch 144: Train Loss: 0.000224, Validation Loss: 0.000285\n",
      " Epoch 145: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 146: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 147: Train Loss: 0.000223, Validation Loss: 0.000285\n",
      " Epoch 148: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 149: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 150: Train Loss: 0.000222, Validation Loss: 0.000285\n",
      " Epoch 151: Train Loss: 0.000220, Validation Loss: 0.000285\n",
      " Epoch 152: Train Loss: 0.000220, Validation Loss: 0.000284\n",
      " Epoch 153: Train Loss: 0.000220, Validation Loss: 0.000284\n",
      " Epoch 154: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 155: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 156: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 157: Train Loss: 0.000219, Validation Loss: 0.000284\n",
      " Epoch 158: Train Loss: 0.000219, Validation Loss: 0.000285\n",
      " Epoch 159: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 160: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 161: Train Loss: 0.000218, Validation Loss: 0.000284\n",
      " Epoch 162: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 163: Train Loss: 0.000218, Validation Loss: 0.000285\n",
      " Epoch 164: Train Loss: 0.000217, Validation Loss: 0.000284\n",
      " Epoch 165: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 166: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 167: Train Loss: 0.000217, Validation Loss: 0.000285\n",
      " Epoch 168: Train Loss: 0.000216, Validation Loss: 0.000284\n",
      " Epoch 169: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 170: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 171: Train Loss: 0.000216, Validation Loss: 0.000284\n",
      " Epoch 172: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 173: Train Loss: 0.000216, Validation Loss: 0.000285\n",
      " Epoch 174: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 175: Train Loss: 0.000215, Validation Loss: 0.000284\n",
      " Epoch 176: Train Loss: 0.000215, Validation Loss: 0.000284\n",
      " Epoch 177: Train Loss: 0.000215, Validation Loss: 0.000285\n",
      " Epoch 178: Train Loss: 0.000214, Validation Loss: 0.000284\n",
      " Epoch 179: Train Loss: 0.000214, Validation Loss: 0.000285\n",
      " Epoch 180: Train Loss: 0.000214, Validation Loss: 0.000284\n",
      " Epoch 181: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 182: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 183: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 184: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 185: Train Loss: 0.000213, Validation Loss: 0.000284\n",
      " Epoch 186: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 187: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 188: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 189: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 190: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 191: Train Loss: 0.000212, Validation Loss: 0.000284\n",
      " Epoch 192: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 193: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 194: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 195: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 196: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 197: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 198: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 199: Train Loss: 0.000211, Validation Loss: 0.000284\n",
      " Epoch 200: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 201: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 202: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 203: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 204: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 205: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      " Epoch 206: Train Loss: 0.000210, Validation Loss: 0.000284\n",
      "Early stopping at epoch 206 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.0002997401461470872\n",
      "Training Time: 1884.7417941093445\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.000278433202765882\n",
      "Training Time: 13021.315030813217\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.00027825470897369087\n",
      "Training Time: 3152.0255892276764\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0002839059161487967\n",
      "Training Time: 1747.2583448886871\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#SSIM 0\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate,MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(1,0)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/SSIM_comparison/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59543aaa-c958-4bd1-9d25-9347677fe10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.025253, Validation Loss: 0.064641\n",
      " Epoch 2: Train Loss: 0.006185, Validation Loss: 0.005309\n",
      " Epoch 3: Train Loss: 0.004491, Validation Loss: 0.005149\n",
      " Epoch 4: Train Loss: 0.003757, Validation Loss: 0.003665\n",
      " Epoch 5: Train Loss: 0.003356, Validation Loss: 0.003276\n",
      " Epoch 6: Train Loss: 0.003086, Validation Loss: 0.003024\n",
      " Epoch 7: Train Loss: 0.002853, Validation Loss: 0.002780\n",
      " Epoch 8: Train Loss: 0.002703, Validation Loss: 0.003007\n",
      " Epoch 9: Train Loss: 0.002588, Validation Loss: 0.002508\n",
      " Epoch 10: Train Loss: 0.002439, Validation Loss: 0.002667\n",
      " Epoch 11: Train Loss: 0.002349, Validation Loss: 0.002625\n",
      " Epoch 12: Train Loss: 0.002228, Validation Loss: 0.002218\n",
      " Epoch 13: Train Loss: 0.002148, Validation Loss: 0.002196\n",
      " Epoch 14: Train Loss: 0.002065, Validation Loss: 0.002116\n",
      " Epoch 15: Train Loss: 0.002004, Validation Loss: 0.002167\n",
      " Epoch 16: Train Loss: 0.001943, Validation Loss: 0.001993\n",
      " Epoch 17: Train Loss: 0.001884, Validation Loss: 0.001879\n",
      " Epoch 18: Train Loss: 0.001782, Validation Loss: 0.001791\n",
      " Epoch 19: Train Loss: 0.001763, Validation Loss: 0.001856\n",
      " Epoch 20: Train Loss: 0.001688, Validation Loss: 0.001785\n",
      " Epoch 21: Train Loss: 0.001630, Validation Loss: 0.001680\n",
      " Epoch 22: Train Loss: 0.001596, Validation Loss: 0.001642\n",
      " Epoch 23: Train Loss: 0.001556, Validation Loss: 0.001589\n",
      " Epoch 24: Train Loss: 0.001492, Validation Loss: 0.001723\n",
      " Epoch 25: Train Loss: 0.001498, Validation Loss: 0.001529\n",
      " Epoch 26: Train Loss: 0.001466, Validation Loss: 0.001667\n",
      " Epoch 27: Train Loss: 0.001453, Validation Loss: 0.001525\n",
      " Epoch 28: Train Loss: 0.001395, Validation Loss: 0.001479\n",
      " Epoch 29: Train Loss: 0.001375, Validation Loss: 0.001619\n",
      " Epoch 30: Train Loss: 0.001354, Validation Loss: 0.001420\n",
      " Epoch 31: Train Loss: 0.001277, Validation Loss: 0.001382\n",
      " Epoch 32: Train Loss: 0.001259, Validation Loss: 0.001372\n",
      " Epoch 33: Train Loss: 0.001248, Validation Loss: 0.001362\n",
      " Epoch 34: Train Loss: 0.001234, Validation Loss: 0.001352\n",
      " Epoch 35: Train Loss: 0.001224, Validation Loss: 0.001339\n",
      " Epoch 36: Train Loss: 0.001215, Validation Loss: 0.001353\n",
      " Epoch 37: Train Loss: 0.001206, Validation Loss: 0.001358\n",
      " Epoch 38: Train Loss: 0.001197, Validation Loss: 0.001332\n",
      " Epoch 39: Train Loss: 0.001186, Validation Loss: 0.001326\n",
      " Epoch 40: Train Loss: 0.001175, Validation Loss: 0.001312\n",
      " Epoch 41: Train Loss: 0.001163, Validation Loss: 0.001311\n",
      " Epoch 42: Train Loss: 0.001156, Validation Loss: 0.001289\n",
      " Epoch 43: Train Loss: 0.001144, Validation Loss: 0.001310\n",
      " Epoch 44: Train Loss: 0.001140, Validation Loss: 0.001283\n",
      " Epoch 45: Train Loss: 0.001132, Validation Loss: 0.001326\n",
      " Epoch 46: Train Loss: 0.001125, Validation Loss: 0.001271\n",
      " Epoch 47: Train Loss: 0.001111, Validation Loss: 0.001278\n",
      " Epoch 48: Train Loss: 0.001103, Validation Loss: 0.001272\n",
      " Epoch 49: Train Loss: 0.001093, Validation Loss: 0.001263\n",
      " Epoch 50: Train Loss: 0.001078, Validation Loss: 0.001267\n",
      " Epoch 51: Train Loss: 0.001076, Validation Loss: 0.001241\n",
      " Epoch 52: Train Loss: 0.001069, Validation Loss: 0.001245\n",
      " Epoch 53: Train Loss: 0.001062, Validation Loss: 0.001242\n",
      " Epoch 54: Train Loss: 0.001054, Validation Loss: 0.001229\n",
      " Epoch 55: Train Loss: 0.001041, Validation Loss: 0.001231\n",
      " Epoch 56: Train Loss: 0.001035, Validation Loss: 0.001218\n",
      " Epoch 57: Train Loss: 0.001030, Validation Loss: 0.001291\n",
      " Epoch 58: Train Loss: 0.001025, Validation Loss: 0.001250\n",
      " Epoch 59: Train Loss: 0.001018, Validation Loss: 0.001212\n",
      " Epoch 60: Train Loss: 0.001013, Validation Loss: 0.001219\n",
      " Epoch 61: Train Loss: 0.000966, Validation Loss: 0.001194\n",
      " Epoch 62: Train Loss: 0.000959, Validation Loss: 0.001201\n",
      " Epoch 63: Train Loss: 0.000952, Validation Loss: 0.001205\n",
      " Epoch 64: Train Loss: 0.000947, Validation Loss: 0.001195\n",
      " Epoch 65: Train Loss: 0.000942, Validation Loss: 0.001195\n",
      " Epoch 66: Train Loss: 0.000939, Validation Loss: 0.001195\n",
      " Epoch 67: Train Loss: 0.000935, Validation Loss: 0.001187\n",
      " Epoch 68: Train Loss: 0.000930, Validation Loss: 0.001190\n",
      " Epoch 69: Train Loss: 0.000925, Validation Loss: 0.001182\n",
      " Epoch 70: Train Loss: 0.000920, Validation Loss: 0.001196\n",
      " Epoch 71: Train Loss: 0.000917, Validation Loss: 0.001190\n",
      " Epoch 72: Train Loss: 0.000912, Validation Loss: 0.001179\n",
      " Epoch 73: Train Loss: 0.000905, Validation Loss: 0.001180\n",
      " Epoch 74: Train Loss: 0.000901, Validation Loss: 0.001179\n",
      " Epoch 75: Train Loss: 0.000898, Validation Loss: 0.001180\n",
      " Epoch 76: Train Loss: 0.000894, Validation Loss: 0.001182\n",
      " Epoch 77: Train Loss: 0.000890, Validation Loss: 0.001183\n",
      " Epoch 78: Train Loss: 0.000886, Validation Loss: 0.001221\n",
      " Epoch 79: Train Loss: 0.000881, Validation Loss: 0.001174\n",
      " Epoch 80: Train Loss: 0.000877, Validation Loss: 0.001180\n",
      " Epoch 81: Train Loss: 0.000872, Validation Loss: 0.001211\n",
      " Epoch 82: Train Loss: 0.000873, Validation Loss: 0.001181\n",
      " Epoch 83: Train Loss: 0.000862, Validation Loss: 0.001178\n",
      " Epoch 84: Train Loss: 0.000858, Validation Loss: 0.001187\n",
      " Epoch 85: Train Loss: 0.000859, Validation Loss: 0.001184\n",
      " Epoch 86: Train Loss: 0.000849, Validation Loss: 0.001186\n",
      " Epoch 87: Train Loss: 0.000846, Validation Loss: 0.001164\n",
      " Epoch 88: Train Loss: 0.000843, Validation Loss: 0.001198\n",
      " Epoch 89: Train Loss: 0.000834, Validation Loss: 0.001191\n",
      " Epoch 90: Train Loss: 0.000834, Validation Loss: 0.001175\n",
      " Epoch 91: Train Loss: 0.000811, Validation Loss: 0.001171\n",
      " Epoch 92: Train Loss: 0.000805, Validation Loss: 0.001162\n",
      " Epoch 93: Train Loss: 0.000801, Validation Loss: 0.001165\n",
      " Epoch 94: Train Loss: 0.000799, Validation Loss: 0.001168\n",
      " Epoch 95: Train Loss: 0.000797, Validation Loss: 0.001163\n",
      " Epoch 96: Train Loss: 0.000794, Validation Loss: 0.001166\n",
      " Epoch 97: Train Loss: 0.000791, Validation Loss: 0.001172\n",
      " Epoch 98: Train Loss: 0.000791, Validation Loss: 0.001166\n",
      " Epoch 99: Train Loss: 0.000788, Validation Loss: 0.001172\n",
      " Epoch 100: Train Loss: 0.000785, Validation Loss: 0.001172\n",
      " Epoch 101: Train Loss: 0.000783, Validation Loss: 0.001168\n",
      " Epoch 102: Train Loss: 0.000780, Validation Loss: 0.001167\n",
      " Epoch 103: Train Loss: 0.000780, Validation Loss: 0.001172\n",
      " Epoch 104: Train Loss: 0.000776, Validation Loss: 0.001169\n",
      " Epoch 105: Train Loss: 0.000773, Validation Loss: 0.001176\n",
      " Epoch 106: Train Loss: 0.000771, Validation Loss: 0.001174\n",
      " Epoch 107: Train Loss: 0.000768, Validation Loss: 0.001173\n",
      " Epoch 108: Train Loss: 0.000768, Validation Loss: 0.001185\n",
      " Epoch 109: Train Loss: 0.000766, Validation Loss: 0.001171\n",
      " Epoch 110: Train Loss: 0.000760, Validation Loss: 0.001169\n",
      " Epoch 111: Train Loss: 0.000761, Validation Loss: 0.001177\n",
      " Epoch 112: Train Loss: 0.000756, Validation Loss: 0.001173\n",
      "Early stopping at epoch 112 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.030292, Validation Loss: 0.029722\n",
      " Epoch 2: Train Loss: 0.006628, Validation Loss: 0.006977\n",
      " Epoch 3: Train Loss: 0.004738, Validation Loss: 0.004988\n",
      " Epoch 4: Train Loss: 0.003900, Validation Loss: 0.003776\n",
      " Epoch 5: Train Loss: 0.003430, Validation Loss: 0.003515\n",
      " Epoch 6: Train Loss: 0.003121, Validation Loss: 0.003107\n",
      " Epoch 7: Train Loss: 0.002874, Validation Loss: 0.002848\n",
      " Epoch 8: Train Loss: 0.002693, Validation Loss: 0.002674\n",
      " Epoch 9: Train Loss: 0.002556, Validation Loss: 0.002576\n",
      " Epoch 10: Train Loss: 0.002392, Validation Loss: 0.002412\n",
      " Epoch 11: Train Loss: 0.002278, Validation Loss: 0.003243\n",
      " Epoch 12: Train Loss: 0.002163, Validation Loss: 0.002216\n",
      " Epoch 13: Train Loss: 0.002068, Validation Loss: 0.002147\n",
      " Epoch 14: Train Loss: 0.001961, Validation Loss: 0.002062\n",
      " Epoch 15: Train Loss: 0.001903, Validation Loss: 0.001996\n",
      " Epoch 16: Train Loss: 0.001833, Validation Loss: 0.001950\n",
      " Epoch 17: Train Loss: 0.001750, Validation Loss: 0.001857\n",
      " Epoch 18: Train Loss: 0.001702, Validation Loss: 0.001791\n",
      " Epoch 19: Train Loss: 0.001643, Validation Loss: 0.001828\n",
      " Epoch 20: Train Loss: 0.001594, Validation Loss: 0.001768\n",
      " Epoch 21: Train Loss: 0.001564, Validation Loss: 0.001703\n",
      " Epoch 22: Train Loss: 0.001515, Validation Loss: 0.001987\n",
      " Epoch 23: Train Loss: 0.001497, Validation Loss: 0.001640\n",
      " Epoch 24: Train Loss: 0.014338, Validation Loss: 0.070381\n",
      " Epoch 25: Train Loss: 0.005609, Validation Loss: 0.004298\n",
      " Epoch 26: Train Loss: 0.003338, Validation Loss: 0.003106\n",
      " Epoch 27: Train Loss: 0.002861, Validation Loss: 0.002951\n",
      " Epoch 28: Train Loss: 0.002579, Validation Loss: 0.002560\n",
      " Epoch 29: Train Loss: 0.002341, Validation Loss: 0.002279\n",
      " Epoch 30: Train Loss: 0.002158, Validation Loss: 0.002117\n",
      " Epoch 31: Train Loss: 0.002021, Validation Loss: 0.002022\n",
      " Epoch 32: Train Loss: 0.001953, Validation Loss: 0.001959\n",
      " Epoch 33: Train Loss: 0.001894, Validation Loss: 0.001906\n",
      " Epoch 34: Train Loss: 0.001842, Validation Loss: 0.001858\n",
      " Epoch 35: Train Loss: 0.001795, Validation Loss: 0.001842\n",
      " Epoch 36: Train Loss: 0.001752, Validation Loss: 0.001785\n",
      " Epoch 37: Train Loss: 0.001717, Validation Loss: 0.001761\n",
      " Epoch 38: Train Loss: 0.001681, Validation Loss: 0.001743\n",
      " Epoch 39: Train Loss: 0.001647, Validation Loss: 0.001698\n",
      " Epoch 40: Train Loss: 0.001621, Validation Loss: 0.001693\n",
      " Epoch 41: Train Loss: 0.001593, Validation Loss: 0.001643\n",
      " Epoch 42: Train Loss: 0.001563, Validation Loss: 0.001618\n",
      " Epoch 43: Train Loss: 0.001543, Validation Loss: 0.001599\n",
      " Epoch 44: Train Loss: 0.001520, Validation Loss: 0.001582\n",
      " Epoch 45: Train Loss: 0.001500, Validation Loss: 0.001566\n",
      " Epoch 46: Train Loss: 0.001481, Validation Loss: 0.001545\n",
      " Epoch 47: Train Loss: 0.001462, Validation Loss: 0.001538\n",
      " Epoch 48: Train Loss: 0.001441, Validation Loss: 0.001519\n",
      " Epoch 49: Train Loss: 0.001427, Validation Loss: 0.001526\n",
      " Epoch 50: Train Loss: 0.001415, Validation Loss: 0.001553\n",
      " Epoch 51: Train Loss: 0.001400, Validation Loss: 0.001509\n",
      " Epoch 52: Train Loss: 0.001385, Validation Loss: 0.001470\n",
      " Epoch 53: Train Loss: 0.001376, Validation Loss: 0.001475\n",
      " Epoch 54: Train Loss: 0.001361, Validation Loss: 0.001445\n",
      " Epoch 55: Train Loss: 0.001345, Validation Loss: 0.001432\n",
      " Epoch 56: Train Loss: 0.001332, Validation Loss: 0.001468\n",
      " Epoch 57: Train Loss: 0.001322, Validation Loss: 0.001428\n",
      " Epoch 58: Train Loss: 0.001309, Validation Loss: 0.001412\n",
      " Epoch 59: Train Loss: 0.001299, Validation Loss: 0.001437\n",
      " Epoch 60: Train Loss: 0.001285, Validation Loss: 0.001389\n",
      " Epoch 61: Train Loss: 0.001264, Validation Loss: 0.001382\n",
      " Epoch 62: Train Loss: 0.001254, Validation Loss: 0.001376\n",
      " Epoch 63: Train Loss: 0.001249, Validation Loss: 0.001368\n",
      " Epoch 64: Train Loss: 0.001244, Validation Loss: 0.001368\n",
      " Epoch 65: Train Loss: 0.001239, Validation Loss: 0.001358\n",
      " Epoch 66: Train Loss: 0.001233, Validation Loss: 0.001353\n",
      " Epoch 67: Train Loss: 0.001227, Validation Loss: 0.001357\n",
      " Epoch 68: Train Loss: 0.001222, Validation Loss: 0.001351\n",
      " Epoch 69: Train Loss: 0.001216, Validation Loss: 0.001343\n",
      " Epoch 70: Train Loss: 0.001210, Validation Loss: 0.001345\n",
      " Epoch 71: Train Loss: 0.001206, Validation Loss: 0.001347\n",
      " Epoch 72: Train Loss: 0.001200, Validation Loss: 0.001343\n",
      " Epoch 73: Train Loss: 0.001195, Validation Loss: 0.001345\n",
      " Epoch 74: Train Loss: 0.001191, Validation Loss: 0.001332\n",
      " Epoch 75: Train Loss: 0.001184, Validation Loss: 0.001322\n",
      " Epoch 76: Train Loss: 0.001177, Validation Loss: 0.001323\n",
      " Epoch 77: Train Loss: 0.001174, Validation Loss: 0.001319\n",
      " Epoch 78: Train Loss: 0.001168, Validation Loss: 0.001318\n",
      " Epoch 79: Train Loss: 0.001163, Validation Loss: 0.001313\n",
      " Epoch 80: Train Loss: 0.001158, Validation Loss: 0.001330\n",
      " Epoch 81: Train Loss: 0.001153, Validation Loss: 0.001315\n",
      " Epoch 82: Train Loss: 0.001147, Validation Loss: 0.001309\n",
      " Epoch 83: Train Loss: 0.001145, Validation Loss: 0.001304\n",
      " Epoch 84: Train Loss: 0.001135, Validation Loss: 0.001292\n",
      " Epoch 85: Train Loss: 0.001132, Validation Loss: 0.001296\n",
      " Epoch 86: Train Loss: 0.001127, Validation Loss: 0.001297\n",
      " Epoch 87: Train Loss: 0.001122, Validation Loss: 0.001304\n",
      " Epoch 88: Train Loss: 0.001117, Validation Loss: 0.001298\n",
      " Epoch 89: Train Loss: 0.001112, Validation Loss: 0.001289\n",
      " Epoch 90: Train Loss: 0.001107, Validation Loss: 0.001287\n",
      " Epoch 91: Train Loss: 0.001089, Validation Loss: 0.001270\n",
      " Epoch 92: Train Loss: 0.001084, Validation Loss: 0.001271\n",
      " Epoch 93: Train Loss: 0.001081, Validation Loss: 0.001268\n",
      " Epoch 94: Train Loss: 0.001080, Validation Loss: 0.001274\n",
      " Epoch 95: Train Loss: 0.001077, Validation Loss: 0.001267\n",
      " Epoch 96: Train Loss: 0.001075, Validation Loss: 0.001269\n",
      " Epoch 97: Train Loss: 0.001070, Validation Loss: 0.001266\n",
      " Epoch 98: Train Loss: 0.001070, Validation Loss: 0.001263\n",
      " Epoch 99: Train Loss: 0.001065, Validation Loss: 0.001262\n",
      " Epoch 100: Train Loss: 0.001062, Validation Loss: 0.001260\n",
      " Epoch 101: Train Loss: 0.001058, Validation Loss: 0.001267\n",
      " Epoch 102: Train Loss: 0.001059, Validation Loss: 0.001261\n",
      " Epoch 103: Train Loss: 0.001055, Validation Loss: 0.001260\n",
      " Epoch 104: Train Loss: 0.001050, Validation Loss: 0.001259\n",
      " Epoch 105: Train Loss: 0.001047, Validation Loss: 0.001260\n",
      " Epoch 106: Train Loss: 0.001044, Validation Loss: 0.001262\n",
      " Epoch 107: Train Loss: 0.001041, Validation Loss: 0.001257\n",
      " Epoch 108: Train Loss: 0.001039, Validation Loss: 0.001257\n",
      " Epoch 109: Train Loss: 0.001035, Validation Loss: 0.001252\n",
      " Epoch 110: Train Loss: 0.001033, Validation Loss: 0.001249\n",
      " Epoch 111: Train Loss: 0.001029, Validation Loss: 0.001250\n",
      " Epoch 112: Train Loss: 0.001026, Validation Loss: 0.001252\n",
      " Epoch 113: Train Loss: 0.001023, Validation Loss: 0.001252\n",
      " Epoch 114: Train Loss: 0.001020, Validation Loss: 0.001252\n",
      " Epoch 115: Train Loss: 0.001017, Validation Loss: 0.001246\n",
      " Epoch 116: Train Loss: 0.001012, Validation Loss: 0.001246\n",
      " Epoch 117: Train Loss: 0.001011, Validation Loss: 0.001253\n",
      " Epoch 118: Train Loss: 0.001006, Validation Loss: 0.001245\n",
      " Epoch 119: Train Loss: 0.001004, Validation Loss: 0.001248\n",
      " Epoch 120: Train Loss: 0.001000, Validation Loss: 0.001246\n",
      " Epoch 121: Train Loss: 0.000990, Validation Loss: 0.001238\n",
      " Epoch 122: Train Loss: 0.000987, Validation Loss: 0.001246\n",
      " Epoch 123: Train Loss: 0.000985, Validation Loss: 0.001239\n",
      " Epoch 124: Train Loss: 0.000983, Validation Loss: 0.001237\n",
      " Epoch 125: Train Loss: 0.000981, Validation Loss: 0.001236\n",
      " Epoch 126: Train Loss: 0.000979, Validation Loss: 0.001240\n",
      " Epoch 127: Train Loss: 0.000978, Validation Loss: 0.001238\n",
      " Epoch 128: Train Loss: 0.000976, Validation Loss: 0.001239\n",
      " Epoch 129: Train Loss: 0.000974, Validation Loss: 0.001236\n",
      " Epoch 130: Train Loss: 0.000972, Validation Loss: 0.001234\n",
      " Epoch 131: Train Loss: 0.000971, Validation Loss: 0.001237\n",
      " Epoch 132: Train Loss: 0.000968, Validation Loss: 0.001235\n",
      " Epoch 133: Train Loss: 0.000967, Validation Loss: 0.001239\n",
      " Epoch 134: Train Loss: 0.000965, Validation Loss: 0.001233\n",
      " Epoch 135: Train Loss: 0.000963, Validation Loss: 0.001247\n",
      " Epoch 136: Train Loss: 0.000961, Validation Loss: 0.001238\n",
      " Epoch 137: Train Loss: 0.000959, Validation Loss: 0.001237\n",
      " Epoch 138: Train Loss: 0.000958, Validation Loss: 0.001236\n",
      " Epoch 139: Train Loss: 0.000956, Validation Loss: 0.001241\n",
      " Epoch 140: Train Loss: 0.000954, Validation Loss: 0.001240\n",
      " Epoch 141: Train Loss: 0.000952, Validation Loss: 0.001233\n",
      " Epoch 142: Train Loss: 0.000950, Validation Loss: 0.001236\n",
      " Epoch 143: Train Loss: 0.000947, Validation Loss: 0.001233\n",
      " Epoch 144: Train Loss: 0.000945, Validation Loss: 0.001231\n",
      " Epoch 145: Train Loss: 0.000943, Validation Loss: 0.001232\n",
      " Epoch 146: Train Loss: 0.000942, Validation Loss: 0.001246\n",
      " Epoch 147: Train Loss: 0.000940, Validation Loss: 0.001233\n",
      " Epoch 148: Train Loss: 0.000938, Validation Loss: 0.001244\n",
      " Epoch 149: Train Loss: 0.000936, Validation Loss: 0.001232\n",
      " Epoch 150: Train Loss: 0.000933, Validation Loss: 0.001233\n",
      " Epoch 151: Train Loss: 0.000928, Validation Loss: 0.001230\n",
      " Epoch 152: Train Loss: 0.000926, Validation Loss: 0.001234\n",
      " Epoch 153: Train Loss: 0.000924, Validation Loss: 0.001230\n",
      " Epoch 154: Train Loss: 0.000924, Validation Loss: 0.001230\n",
      " Epoch 155: Train Loss: 0.000922, Validation Loss: 0.001229\n",
      " Epoch 156: Train Loss: 0.000921, Validation Loss: 0.001230\n",
      " Epoch 157: Train Loss: 0.000920, Validation Loss: 0.001231\n",
      " Epoch 158: Train Loss: 0.000919, Validation Loss: 0.001232\n",
      " Epoch 159: Train Loss: 0.000919, Validation Loss: 0.001232\n",
      " Epoch 160: Train Loss: 0.000917, Validation Loss: 0.001233\n",
      " Epoch 161: Train Loss: 0.000916, Validation Loss: 0.001232\n",
      " Epoch 162: Train Loss: 0.000915, Validation Loss: 0.001232\n",
      " Epoch 163: Train Loss: 0.000914, Validation Loss: 0.001231\n",
      " Epoch 164: Train Loss: 0.000913, Validation Loss: 0.001230\n",
      " Epoch 165: Train Loss: 0.000911, Validation Loss: 0.001230\n",
      " Epoch 166: Train Loss: 0.000910, Validation Loss: 0.001230\n",
      " Epoch 167: Train Loss: 0.000909, Validation Loss: 0.001232\n",
      " Epoch 168: Train Loss: 0.000908, Validation Loss: 0.001231\n",
      " Epoch 169: Train Loss: 0.000907, Validation Loss: 0.001231\n",
      " Epoch 170: Train Loss: 0.000906, Validation Loss: 0.001231\n",
      " Epoch 171: Train Loss: 0.000904, Validation Loss: 0.001230\n",
      " Epoch 172: Train Loss: 0.000903, Validation Loss: 0.001235\n",
      " Epoch 173: Train Loss: 0.000902, Validation Loss: 0.001231\n",
      " Epoch 174: Train Loss: 0.000901, Validation Loss: 0.001232\n",
      " Epoch 175: Train Loss: 0.000900, Validation Loss: 0.001230\n",
      "Early stopping at epoch 175 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.027729, Validation Loss: 0.043923\n",
      " Epoch 2: Train Loss: 0.006723, Validation Loss: 0.005861\n",
      " Epoch 3: Train Loss: 0.004853, Validation Loss: 0.009357\n",
      " Epoch 4: Train Loss: 0.003869, Validation Loss: 0.003693\n",
      " Epoch 5: Train Loss: 0.003341, Validation Loss: 0.003331\n",
      " Epoch 6: Train Loss: 0.003038, Validation Loss: 0.003000\n",
      " Epoch 7: Train Loss: 0.002838, Validation Loss: 0.002757\n",
      " Epoch 8: Train Loss: 0.002615, Validation Loss: 0.002683\n",
      " Epoch 9: Train Loss: 0.002462, Validation Loss: 0.002449\n",
      " Epoch 10: Train Loss: 0.002382, Validation Loss: 0.002335\n",
      " Epoch 11: Train Loss: 0.002211, Validation Loss: 0.002247\n",
      " Epoch 12: Train Loss: 0.002272, Validation Loss: 0.003001\n",
      " Epoch 13: Train Loss: 0.002039, Validation Loss: 0.002054\n",
      " Epoch 14: Train Loss: 0.001963, Validation Loss: 0.002129\n",
      " Epoch 15: Train Loss: 0.001897, Validation Loss: 0.001893\n",
      " Epoch 16: Train Loss: 0.001840, Validation Loss: 0.001920\n",
      " Epoch 17: Train Loss: 0.001769, Validation Loss: 0.001811\n",
      " Epoch 18: Train Loss: 0.001723, Validation Loss: 0.001797\n",
      " Epoch 19: Train Loss: 0.001694, Validation Loss: 0.002240\n",
      " Epoch 20: Train Loss: 0.001640, Validation Loss: 0.001688\n",
      " Epoch 21: Train Loss: 0.001592, Validation Loss: 0.001630\n",
      " Epoch 22: Train Loss: 0.001574, Validation Loss: 0.001615\n",
      " Epoch 23: Train Loss: 0.001499, Validation Loss: 0.001556\n",
      " Epoch 24: Train Loss: 0.001476, Validation Loss: 0.002027\n",
      " Epoch 25: Train Loss: 0.001469, Validation Loss: 0.001530\n",
      " Epoch 26: Train Loss: 0.001448, Validation Loss: 0.001596\n",
      " Epoch 27: Train Loss: 0.001406, Validation Loss: 0.001483\n",
      " Epoch 28: Train Loss: 0.001366, Validation Loss: 0.001453\n",
      " Epoch 29: Train Loss: 0.001360, Validation Loss: 0.001459\n",
      " Epoch 30: Train Loss: 0.001323, Validation Loss: 0.001602\n",
      " Epoch 31: Train Loss: 0.001269, Validation Loss: 0.001389\n",
      " Epoch 32: Train Loss: 0.001244, Validation Loss: 0.001363\n",
      " Epoch 33: Train Loss: 0.001232, Validation Loss: 0.001349\n",
      " Epoch 34: Train Loss: 0.001227, Validation Loss: 0.001340\n",
      " Epoch 35: Train Loss: 0.001213, Validation Loss: 0.001358\n",
      " Epoch 36: Train Loss: 0.001206, Validation Loss: 0.001324\n",
      " Epoch 37: Train Loss: 0.001195, Validation Loss: 0.001321\n",
      " Epoch 38: Train Loss: 0.001183, Validation Loss: 0.001324\n",
      " Epoch 39: Train Loss: 0.001177, Validation Loss: 0.001347\n",
      " Epoch 40: Train Loss: 0.001167, Validation Loss: 0.001332\n",
      " Epoch 41: Train Loss: 0.001158, Validation Loss: 0.001297\n",
      " Epoch 42: Train Loss: 0.001146, Validation Loss: 0.001290\n",
      " Epoch 43: Train Loss: 0.001149, Validation Loss: 0.001290\n",
      " Epoch 44: Train Loss: 0.001136, Validation Loss: 0.001280\n",
      " Epoch 45: Train Loss: 0.001118, Validation Loss: 0.001279\n",
      " Epoch 46: Train Loss: 0.001111, Validation Loss: 0.001275\n",
      " Epoch 47: Train Loss: 0.001108, Validation Loss: 0.001271\n",
      " Epoch 48: Train Loss: 0.001095, Validation Loss: 0.001279\n",
      " Epoch 49: Train Loss: 0.001093, Validation Loss: 0.001266\n",
      " Epoch 50: Train Loss: 0.001083, Validation Loss: 0.001265\n",
      " Epoch 51: Train Loss: 0.001095, Validation Loss: 0.001281\n",
      " Epoch 52: Train Loss: 0.001078, Validation Loss: 0.001267\n",
      " Epoch 53: Train Loss: 0.001069, Validation Loss: 0.001274\n",
      " Epoch 54: Train Loss: 0.001066, Validation Loss: 0.001268\n",
      " Epoch 55: Train Loss: 0.001048, Validation Loss: 0.001389\n",
      " Epoch 56: Train Loss: 0.001042, Validation Loss: 0.001350\n",
      " Epoch 57: Train Loss: 0.001029, Validation Loss: 0.001239\n",
      " Epoch 58: Train Loss: 0.001035, Validation Loss: 0.001234\n",
      " Epoch 59: Train Loss: 0.001005, Validation Loss: 0.001252\n",
      " Epoch 60: Train Loss: 0.001004, Validation Loss: 0.001398\n",
      " Epoch 61: Train Loss: 0.000972, Validation Loss: 0.001210\n",
      " Epoch 62: Train Loss: 0.000957, Validation Loss: 0.001207\n",
      " Epoch 63: Train Loss: 0.000953, Validation Loss: 0.001212\n",
      " Epoch 64: Train Loss: 0.000948, Validation Loss: 0.001211\n",
      " Epoch 65: Train Loss: 0.000943, Validation Loss: 0.001208\n",
      " Epoch 66: Train Loss: 0.000940, Validation Loss: 0.001215\n",
      " Epoch 67: Train Loss: 0.000936, Validation Loss: 0.001224\n",
      " Epoch 68: Train Loss: 0.000932, Validation Loss: 0.001207\n",
      " Epoch 69: Train Loss: 0.000927, Validation Loss: 0.001209\n",
      " Epoch 70: Train Loss: 0.000923, Validation Loss: 0.001213\n",
      " Epoch 71: Train Loss: 0.000918, Validation Loss: 0.001210\n",
      " Epoch 72: Train Loss: 0.000917, Validation Loss: 0.001211\n",
      " Epoch 73: Train Loss: 0.000913, Validation Loss: 0.001205\n",
      " Epoch 74: Train Loss: 0.000906, Validation Loss: 0.001226\n",
      " Epoch 75: Train Loss: 0.000901, Validation Loss: 0.001222\n",
      " Epoch 76: Train Loss: 0.000899, Validation Loss: 0.001214\n",
      " Epoch 77: Train Loss: 0.000895, Validation Loss: 0.001211\n",
      " Epoch 78: Train Loss: 0.000889, Validation Loss: 0.001206\n",
      " Epoch 79: Train Loss: 0.000885, Validation Loss: 0.001218\n",
      " Epoch 80: Train Loss: 0.000879, Validation Loss: 0.001203\n",
      " Epoch 81: Train Loss: 0.000877, Validation Loss: 0.001214\n",
      " Epoch 82: Train Loss: 0.000873, Validation Loss: 0.001204\n",
      " Epoch 83: Train Loss: 0.000870, Validation Loss: 0.001207\n",
      " Epoch 84: Train Loss: 0.000864, Validation Loss: 0.001222\n",
      " Epoch 85: Train Loss: 0.000860, Validation Loss: 0.001207\n",
      " Epoch 86: Train Loss: 0.000859, Validation Loss: 0.001228\n",
      " Epoch 87: Train Loss: 0.000854, Validation Loss: 0.001221\n",
      " Epoch 88: Train Loss: 0.000848, Validation Loss: 0.001204\n",
      " Epoch 89: Train Loss: 0.000845, Validation Loss: 0.001215\n",
      " Epoch 90: Train Loss: 0.000841, Validation Loss: 0.001208\n",
      " Epoch 91: Train Loss: 0.000819, Validation Loss: 0.001198\n",
      " Epoch 92: Train Loss: 0.000810, Validation Loss: 0.001200\n",
      " Epoch 93: Train Loss: 0.000807, Validation Loss: 0.001201\n",
      " Epoch 94: Train Loss: 0.000805, Validation Loss: 0.001199\n",
      " Epoch 95: Train Loss: 0.000804, Validation Loss: 0.001208\n",
      " Epoch 96: Train Loss: 0.000801, Validation Loss: 0.001203\n",
      " Epoch 97: Train Loss: 0.000799, Validation Loss: 0.001201\n",
      " Epoch 98: Train Loss: 0.000796, Validation Loss: 0.001201\n",
      " Epoch 99: Train Loss: 0.000795, Validation Loss: 0.001212\n",
      " Epoch 100: Train Loss: 0.000795, Validation Loss: 0.001210\n",
      " Epoch 101: Train Loss: 0.000792, Validation Loss: 0.001207\n",
      " Epoch 102: Train Loss: 0.000788, Validation Loss: 0.001217\n",
      " Epoch 103: Train Loss: 0.000785, Validation Loss: 0.001204\n",
      " Epoch 104: Train Loss: 0.000784, Validation Loss: 0.001204\n",
      " Epoch 105: Train Loss: 0.000782, Validation Loss: 0.001217\n",
      " Epoch 106: Train Loss: 0.000778, Validation Loss: 0.001212\n",
      " Epoch 107: Train Loss: 0.000776, Validation Loss: 0.001210\n",
      " Epoch 108: Train Loss: 0.000776, Validation Loss: 0.001214\n",
      " Epoch 109: Train Loss: 0.000772, Validation Loss: 0.001211\n",
      " Epoch 110: Train Loss: 0.000771, Validation Loss: 0.001208\n",
      " Epoch 111: Train Loss: 0.000769, Validation Loss: 0.001218\n",
      "Early stopping at epoch 111 (no improvement in validation loss for 20 epochs).\n",
      " Epoch 1: Train Loss: 0.025984, Validation Loss: 0.065800\n",
      " Epoch 2: Train Loss: 0.006772, Validation Loss: 0.006767\n",
      " Epoch 3: Train Loss: 0.004826, Validation Loss: 0.006540\n",
      " Epoch 4: Train Loss: 0.003861, Validation Loss: 0.003671\n",
      " Epoch 5: Train Loss: 0.003366, Validation Loss: 0.003276\n",
      " Epoch 6: Train Loss: 0.003050, Validation Loss: 0.003052\n",
      " Epoch 7: Train Loss: 0.002901, Validation Loss: 0.003018\n",
      " Epoch 8: Train Loss: 0.002651, Validation Loss: 0.002798\n",
      " Epoch 9: Train Loss: 0.002485, Validation Loss: 0.002508\n",
      " Epoch 10: Train Loss: 0.002466, Validation Loss: 0.002466\n",
      " Epoch 11: Train Loss: 0.002227, Validation Loss: 0.002299\n",
      " Epoch 12: Train Loss: 0.002142, Validation Loss: 0.002192\n",
      " Epoch 13: Train Loss: 0.002073, Validation Loss: 0.002060\n",
      " Epoch 14: Train Loss: 0.001977, Validation Loss: 0.002549\n",
      " Epoch 15: Train Loss: 0.001884, Validation Loss: 0.001900\n",
      " Epoch 16: Train Loss: 0.001835, Validation Loss: 0.001880\n",
      " Epoch 17: Train Loss: 0.001794, Validation Loss: 0.002427\n",
      " Epoch 18: Train Loss: 0.001710, Validation Loss: 0.001764\n",
      " Epoch 19: Train Loss: 0.001645, Validation Loss: 0.001823\n",
      " Epoch 20: Train Loss: 0.001644, Validation Loss: 0.003882\n",
      " Epoch 21: Train Loss: 0.001640, Validation Loss: 0.001963\n",
      " Epoch 22: Train Loss: 0.001545, Validation Loss: 0.001663\n",
      " Epoch 23: Train Loss: 0.001487, Validation Loss: 0.001587\n",
      " Epoch 24: Train Loss: 0.001463, Validation Loss: 0.001539\n",
      " Epoch 25: Train Loss: 0.001454, Validation Loss: 0.001510\n",
      " Epoch 26: Train Loss: 0.001414, Validation Loss: 0.001555\n",
      " Epoch 27: Train Loss: 0.001449, Validation Loss: 0.001473\n",
      " Epoch 28: Train Loss: 0.001388, Validation Loss: 0.001478\n",
      " Epoch 29: Train Loss: 0.001342, Validation Loss: 0.001484\n",
      " Epoch 30: Train Loss: 0.001334, Validation Loss: 0.001510\n",
      " Epoch 31: Train Loss: 0.001252, Validation Loss: 0.001389\n",
      " Epoch 32: Train Loss: 0.001235, Validation Loss: 0.001349\n",
      " Epoch 33: Train Loss: 0.001224, Validation Loss: 0.001336\n",
      " Epoch 34: Train Loss: 0.001216, Validation Loss: 0.001328\n",
      " Epoch 35: Train Loss: 0.001207, Validation Loss: 0.001350\n",
      " Epoch 36: Train Loss: 0.001197, Validation Loss: 0.001334\n",
      " Epoch 37: Train Loss: 0.001187, Validation Loss: 0.001362\n",
      " Epoch 38: Train Loss: 0.001177, Validation Loss: 0.001291\n",
      " Epoch 39: Train Loss: 0.001166, Validation Loss: 0.001313\n",
      " Epoch 40: Train Loss: 0.001157, Validation Loss: 0.001316\n",
      " Epoch 41: Train Loss: 0.001150, Validation Loss: 0.001317\n",
      " Epoch 42: Train Loss: 0.001143, Validation Loss: 0.001311\n",
      " Epoch 43: Train Loss: 0.001139, Validation Loss: 0.001282\n",
      " Epoch 44: Train Loss: 0.001126, Validation Loss: 0.001308\n",
      " Epoch 45: Train Loss: 0.001126, Validation Loss: 0.001260\n",
      " Epoch 46: Train Loss: 0.001106, Validation Loss: 0.001298\n",
      " Epoch 47: Train Loss: 0.001100, Validation Loss: 0.001329\n",
      " Epoch 48: Train Loss: 0.001099, Validation Loss: 0.001271\n",
      " Epoch 49: Train Loss: 0.001083, Validation Loss: 0.001265\n",
      " Epoch 50: Train Loss: 0.001084, Validation Loss: 0.001253\n",
      " Epoch 51: Train Loss: 0.001073, Validation Loss: 0.001246\n",
      " Epoch 52: Train Loss: 0.001063, Validation Loss: 0.001288\n",
      " Epoch 53: Train Loss: 0.001059, Validation Loss: 0.001279\n",
      " Epoch 54: Train Loss: 0.001052, Validation Loss: 0.001236\n",
      " Epoch 55: Train Loss: 0.001048, Validation Loss: 0.001231\n",
      " Epoch 56: Train Loss: 0.001044, Validation Loss: 0.001216\n",
      " Epoch 57: Train Loss: 0.001030, Validation Loss: 0.001215\n",
      " Epoch 58: Train Loss: 0.001041, Validation Loss: 0.001206\n",
      " Epoch 59: Train Loss: 0.001024, Validation Loss: 0.001324\n",
      " Epoch 60: Train Loss: 0.001016, Validation Loss: 0.001197\n",
      " Epoch 61: Train Loss: 0.000973, Validation Loss: 0.001170\n",
      " Epoch 62: Train Loss: 0.000965, Validation Loss: 0.001228\n",
      " Epoch 63: Train Loss: 0.000963, Validation Loss: 0.001171\n",
      " Epoch 64: Train Loss: 0.000956, Validation Loss: 0.001184\n",
      " Epoch 65: Train Loss: 0.000954, Validation Loss: 0.001173\n",
      " Epoch 66: Train Loss: 0.000949, Validation Loss: 0.001171\n",
      " Epoch 67: Train Loss: 0.000944, Validation Loss: 0.001176\n",
      " Epoch 68: Train Loss: 0.000940, Validation Loss: 0.001168\n",
      " Epoch 69: Train Loss: 0.000937, Validation Loss: 0.001205\n",
      " Epoch 70: Train Loss: 0.000935, Validation Loss: 0.001175\n",
      " Epoch 71: Train Loss: 0.000928, Validation Loss: 0.001167\n",
      " Epoch 72: Train Loss: 0.000926, Validation Loss: 0.001184\n",
      " Epoch 73: Train Loss: 0.000920, Validation Loss: 0.001177\n",
      " Epoch 74: Train Loss: 0.000917, Validation Loss: 0.001172\n",
      " Epoch 75: Train Loss: 0.000912, Validation Loss: 0.001241\n",
      " Epoch 76: Train Loss: 0.000912, Validation Loss: 0.001176\n",
      " Epoch 77: Train Loss: 0.000907, Validation Loss: 0.001175\n",
      " Epoch 78: Train Loss: 0.000904, Validation Loss: 0.001181\n",
      " Epoch 79: Train Loss: 0.000899, Validation Loss: 0.001173\n",
      " Epoch 80: Train Loss: 0.000897, Validation Loss: 0.001166\n",
      " Epoch 81: Train Loss: 0.000891, Validation Loss: 0.001184\n",
      " Epoch 82: Train Loss: 0.000894, Validation Loss: 0.001183\n",
      " Epoch 83: Train Loss: 0.000882, Validation Loss: 0.001174\n",
      " Epoch 84: Train Loss: 0.000880, Validation Loss: 0.001203\n",
      " Epoch 85: Train Loss: 0.000874, Validation Loss: 0.001204\n",
      " Epoch 86: Train Loss: 0.000868, Validation Loss: 0.001174\n",
      " Epoch 87: Train Loss: 0.000867, Validation Loss: 0.001169\n",
      " Epoch 88: Train Loss: 0.000860, Validation Loss: 0.001177\n",
      " Epoch 89: Train Loss: 0.000858, Validation Loss: 0.001234\n",
      " Epoch 90: Train Loss: 0.000865, Validation Loss: 0.001289\n",
      " Epoch 91: Train Loss: 0.000835, Validation Loss: 0.001155\n",
      " Epoch 92: Train Loss: 0.000826, Validation Loss: 0.001163\n",
      " Epoch 93: Train Loss: 0.000822, Validation Loss: 0.001161\n",
      " Epoch 94: Train Loss: 0.000820, Validation Loss: 0.001165\n",
      " Epoch 95: Train Loss: 0.000818, Validation Loss: 0.001189\n",
      " Epoch 96: Train Loss: 0.000817, Validation Loss: 0.001185\n",
      " Epoch 97: Train Loss: 0.000811, Validation Loss: 0.001159\n",
      " Epoch 98: Train Loss: 0.000809, Validation Loss: 0.001174\n",
      " Epoch 99: Train Loss: 0.000808, Validation Loss: 0.001163\n",
      " Epoch 100: Train Loss: 0.000805, Validation Loss: 0.001163\n",
      " Epoch 101: Train Loss: 0.000806, Validation Loss: 0.001181\n",
      " Epoch 102: Train Loss: 0.000801, Validation Loss: 0.001166\n",
      " Epoch 103: Train Loss: 0.000799, Validation Loss: 0.001200\n",
      " Epoch 104: Train Loss: 0.000797, Validation Loss: 0.001160\n",
      " Epoch 105: Train Loss: 0.000793, Validation Loss: 0.001171\n",
      " Epoch 106: Train Loss: 0.000790, Validation Loss: 0.001176\n",
      " Epoch 107: Train Loss: 0.000790, Validation Loss: 0.001185\n",
      " Epoch 108: Train Loss: 0.000786, Validation Loss: 0.001164\n",
      " Epoch 109: Train Loss: 0.000784, Validation Loss: 0.001168\n",
      " Epoch 110: Train Loss: 0.000782, Validation Loss: 0.001169\n",
      " Epoch 111: Train Loss: 0.000781, Validation Loss: 0.001175\n",
      "Early stopping at epoch 111 (no improvement in validation loss for 20 epochs).\n",
      "Model: CNN\n",
      "Validation Loss: 0.0011623442405834794\n",
      "Training Time: 842.6801857948303\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock\n",
      "Validation Loss: 0.0012293100589886308\n",
      "Training Time: 5098.211152076721\n",
      "--------------------------------------------------\n",
      "Model: CNN3D\n",
      "Validation Loss: 0.001197935314849019\n",
      "Training Time: 888.1934027671814\n",
      "--------------------------------------------------\n",
      "Model: CNNwithSEBlock3D\n",
      "Validation Loss: 0.0011552870273590088\n",
      "Training Time: 934.2463738918304\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#SSIM all\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train2 import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate,MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    'CNN3D': CNN3D,\n",
    "    'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(0,0.1)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/SSIM_comparison2/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9ecdf-01d4-4bf0-9816-e287757ac62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation is not None\n",
      "Min: 0.0\n",
      "Max: 17.789060592651367\n",
      "Global Min: tensor([[[[0.]]]])\n",
      "Global Max: tensor([[[[17.7891]]]])\n",
      "8000\n",
      "1000\n",
      " Epoch 1: Train Loss: 0.048071, Validation Loss: 0.044820\n",
      " Epoch 2: Train Loss: 0.010151, Validation Loss: 0.008157\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from model_train import CNN, CNNwithSEBlock, CNN3D, CNNwithSEBlock3D, UNet, UNetwithSEBlock, UNetwithSelfattention, UNet3D, UNetwithSEBlock3D, UNetwithSelfattention3D\n",
    "\n",
    "from DataSet_2 import MaxMinNormalizeGlobalPerChannel,MyDataSet, dataset_2\n",
    "from train_and_eval import train_one_epoch, evaluate, MixedMSE\n",
    "\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "torch.cuda.manual_seed(26)\n",
    "torch.cuda.manual_seed_all(26) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 或者 \":4096:8\"\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    'CNN': CNN,\n",
    "    # 'CNNwithSEBlock': CNNwithSEBlock,\n",
    "    # 'CNN3D': CNN3D,\n",
    "    # 'CNNwithSEBlock3D': CNNwithSEBlock3D,\n",
    "    # 'UNet': UNet,\n",
    "    # 'UNetwithSEBlock': UNetwithSEBlock,\n",
    "    # 'UNetwithSelfattention': UNetwithSelfattention,\n",
    "    # 'UNet3D': UNet3D,\n",
    "    # 'UNetwithSEBlock3D': UNetwithSEBlock3D,\n",
    "    # 'UNetwithSelfattention3D': UNetwithSelfattention3D,\n",
    "}\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: 如果在多少个epoch内验证集损失没有改善，则提前停止训练\n",
    "        :param delta: 在认为损失有改善时，损失变化的最小值\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.best_epoch = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0  # 重置计数器\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} (no improvement in validation loss for {self.patience} epochs).\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 在每次训练之前根据模型名实例化模型\n",
    "def get_model(model_name):\n",
    "    return model_dict[model_name]()\n",
    "\n",
    "def train(model_name, testloader, valloader, epochs, device, earlystoplimit, lr):\n",
    "    model = get_model(model_name).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    loss_function = MixedMSE(1,0.05)\n",
    "    early_stopping = EarlyStopping(patience=20, delta=earlystoplimit)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_val_loss = 10000\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model, optimizer, testloader, device, epoch, loss_function)\n",
    "        scheduler.step()\n",
    "        val_loss = evaluate(model, valloader, device, loss_function)\n",
    "        \n",
    "        # 输出每个epoch的损失\n",
    "        print(f\" Epoch {epoch + 1}: Train Loss: {train_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if epoch > 50 :#设置模型保存间隔\n",
    "                best_model = model\n",
    "        early_stopping(val_loss, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    torch.save(best_model.state_dict(), f\"/home/linux/3.3lab/outcomes/new_minmax/{model_name}.pth\")\n",
    "    training_time = time.time() - start_time\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_loss': best_val_loss,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    data_transform = {\n",
    "        \"without_jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()]),\n",
    "        \"jet\": transforms.Compose([MaxMinNormalizeGlobalPerChannel()])}\n",
    "    # 实例化训练数据集\n",
    "    data_set = MyDataSet(img_dir=args.img_dir,\n",
    "                        group_size=10000,\n",
    "                        size_in = 10000,\n",
    "                        splition = True,\n",
    "                        split_shuffle = False,\n",
    "                        transform=data_transform['without_jet'])\n",
    "    train_dataset = dataset_2(data_set.train_X, data_set.train_Y)\n",
    "    val_dataset = dataset_2(data_set.val_X, data_set.val_Y)\n",
    "    test_dataset = dataset_2(data_set.test_X, data_set.test_Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=200, shuffle=False)\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    \n",
    "    all_results = []\n",
    "    # 训练每个模型并记录结果\n",
    "    for model_name in model_dict.keys():\n",
    "        result = train(model_name, train_dataloader, val_dataloader, epochs=args.epochs,\n",
    "                                        device=args.device, earlystoplimit=args.earlystoplimit, lr=args.lr)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # 输出所有模型的结果\n",
    "    for result in all_results:\n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Validation Loss: {result['model_loss']}\")\n",
    "        print(f\"Training Time: {result['training_time']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1000\n",
    "        self.batch_size = 200\n",
    "        self.lr = 0.001\n",
    "        self.img_dir = 'Gauss_S1.00_NL0.30_B0.50/Gauss_S1.00_NL0.30_B0.50' \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.earlystoplimit = 0\n",
    "\n",
    "\n",
    "opt = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff27ec7-f1a5-42f9-8e43-291b49e27409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zyg",
   "language": "python",
   "name": "zyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
